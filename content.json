{"meta":{"title":"LiZeC的博客","subtitle":"厚德博学，追求卓越","description":"分享技术,传播知识","author":"LiZeC","url":"https://lizec.top","root":"/"},"pages":[{"title":"","date":"2021-04-18T10:37:20.326Z","updated":"2020-12-24T08:36:16.064Z","comments":true,"path":"about/index.html","permalink":"https://lizec.top/about/index.html","excerpt":"","text":"关于博客 本博客采用Hexo技术构建, 主题基础为MiHo, 部分样式进行了轻微的调整 评论区采用Gitalk实现, 评论相当于在Github上发布issue. 博客的内容围绕计算机技术和论文展开, 以后也可能涉及其他领域的内容 转载文章不需要经过我同意, 只需要注明作者和原文地址即可 如果有问题, 欢迎到评论区交流 关于博主 计算机研究生在读, 但物理学才是真爱 熟悉Java开发, 平常用Python写一点小工具 对程序架构和分布式系统很感兴趣 偶尔会看看量子计算机, 虽然根本看不懂 不喝肥宅快乐水, 也没有肥宅快乐兽 友情链接欢迎评论区留言, 交换友链 wenhaohao的博客 mathor’s blog 学习是场不停歇的旅途, 我们要一直向前进啊~"},{"title":"","date":"2021-04-18T10:37:20.342Z","updated":"2020-06-26T03:56:30.168Z","comments":true,"path":"notebook/SmartTodo.html","permalink":"https://lizec.top/notebook/SmartTodo.html","excerpt":"","text":"Smart-Todo 待办管理器Smart-Todo 是一个待办事项管理程序. Smart-Todo除了提供基本的创建和删除待办事项功能以外,还提供自动优先级排序, 离线下载文件, 创建便签等重要的辅助功能. 具体特性如下. 基础特性介绍截止日期在创建任意类型的任务时, 可以使用-dl参数来设置截止日期. 例如 12写日记 -dl 11.12周末会议 -dl 3.12:12 可以用11.12的方式指定日期, 也可以使用3.12:12的方式将截止日期精确到当天的中午12时.如果不指定小时, 则默认为当天的零点, 只需要指定日期, 程序会自动推断年份. 特定日期任务在创建任意类型的任务时, 可以使用-sp参数来设置每周的触发时间. 例如 1周日任务 -sp 7 则每周日此任务会自动转换为待办状态. -sp后的数字表示一周的第几天, 从周一开始, 且用数字1表示周一. 可重复标记在创建任意类型的任务时, 可以使用-re参数来标记为可重复任务. 例如 1每日看论文 -re 标记为可重复任务的项目在标记为完成状态后不会被垃圾收集, 并且在第二天自动变为未完成状态 工作段任务标记在创建任意类型的任务时, 可以使用-wk参数来标记为工作段任务. 例如 1工作时间的任务 -wk 工作段任务在工作时间段会提高展示的优先级, 在非工作时间段会降低展示的优先级. 网页书签在创建待办时, 如果输入一个URL, 则自动将此URL对应的页面的标题作为此待办的标题.创建完成后, 直接点击这个待办可打开相应的网页. 新生代与老年代系统中的项目可以划分为新生代和老年代. 新生代中的待办事项快速的创建和消亡, 老年代中的任务会保持一段较长的时间. 自动优先级如果给定了必要的属性, 程序将自动对任务进行优先级排序. 基础概念所有的优先级算法都是根据Item的属性, 计算出一个浮点数值. 并且以天为单位进行调整.两个不具有任何特殊属性的Item之间, 创建时间越晚, 则优先级越高.一个Item的优先级提高 1 天, 相当于比同时间提交的普通任务晚一天提交. 工作时间段工作时间段指每周一至周五的上午九点至下午六点.具有工作时间段属性的任务将会根据当前是否为工作时间段调整优先级, 规则如下 如果现在处于工作时间段, 任务优先级提高 30 天 如果现在不处于工作时间段, 任务优先级降级 30 天 工作时间段的定义为 周一到周五 上午9点到下午6点 截止日期创建任务时, 可以设置截止日志. 系统将根据截止日期的远近进行排序. 规则如下如果现在距离截止日期还有X天, 则任务优先级提高 (56 - 8X) 天 根据截止日期与当前时间, 可以计算出urgent等级, 并依据等级在页面上使用不同的颜色预警 此算法应该满足如下的约束条件 X&gt;7时, 优先级降低 X=7时, 优先级不提高也不降低 X&gt;3时, 优先级一定程度提高 X=3时, 优先级至少提高 30 天, 从而比工作任务优先展示 函数应该尽可能平滑, 不存在间断点 特定任务特定任务在每周的特定的一天触发, 属于最高优先级的任务.特定任务触发时, 会在当前时间的基础上将优先级提高 100 天 文件控制文件是一种特殊类型的Item, 点击文件类型的Item后, 会自动从服务器下载此文件. 离线下载文件选择文件下载类型, 输入需要下载的文件URL, 服务器将下载指定的文件, 并创建一个文件标记的Item. 本地上传文件点击上传文件, 选择需要上传的文件, 文件将会上传到服务器, 并且生成一个文件标记的Item. 通过上传和下载可以实现文件中转功能 文件生命周期 无论是上传的文件还是下载的文件, 都与Item的生命周期绑定 当Item被删除时, 相应的文件同时被删除 Note系统Note是一种特殊的Item, 创建完成后, 点击相应的Item会跳转到一个Note页面其中包含一个可以编辑的窗口, 可以通过此窗口输入任意的文本内容. 同时, Note页面也可以创建Item, 此处创建的Item只在此页面可见, 是私有的Item借助于此功能, 可以将一个计划放入一个Note, 并逐步分解为Item. 当Note对应的Item被删除时, Note所包含的全部数据同时被删除(通过类似Java的引用分析来回收资源). 保存在Note页面, 输入的内容会静默的执行自动保存, 每5秒执行一次在页面按下Ctrl+S也可以手动保存 参考 10行 JavaScript 实现文本编辑器 类型与属性虽然都表现为一个待办项目, 但系统实际上可以按照类型和属性进行划分. 整个系统有三个类型, 即 类型 含义 single 普通的待办项目 file 离线下载或者上传的文件 note 创建的便签 与此同时, 还有一个平行的属性系统, 系统中具有如下的一些属性 属性 含义 deadline 截止时间 sp/re/work 是否为 特殊/可重复/工作 任务 old 是否为老年代项目 url 项目对应的连接 任意一个项目只能具有一个类型, 但可以拥有任意数量的属性. 指令系统系统提供了一个简单的指令系统来实现高级功能, 例如动态的修改Item的属性. 事务模式由于指令系统可以执行任意有意义的指令, 因此有可能出现输入错误导致系统无法正常运行的问题.因此可以在执行指令之前开启事务模式, 确认指令执行效果后再提交或者回滚. 如果重复启用事务, 则前一个事务的操作自动回滚.如果启用事务后一小时仍然没有提交或者回滚事务, 则自动回滚 指令格式对于大部分操作而言, 本质上是重新设置某个属性, 因此指令的格式为 1set &lt;name1&gt;, &lt;name2&gt;, &lt;name3&gt; -&gt; &lt;attr1&gt;, &lt;attr2&gt; = &lt;value1&gt;, &lt;value2&gt; &lt;name&gt;是Item的任意一部分文字片段, 要求选择的文字片段具有唯一性. &lt;attr&gt;是属性名称, 支持简写. &lt;value&gt;是设置的属性, 支持None/True/False等字面量以及日期 &lt;value&gt;部分支持以文字片段的方式代替id, 此时需要将文本放在&lt; &gt;之中 属性简写对应关系位于tool4interpreter.py/attr_name_map, 具体内容如下所示 123456789101112attr_name_map = &#123; &quot;id&quot;: &quot;id&quot;, &quot;name&quot;: &quot;name&quot;, &quot;u&quot;: &quot;urgent&quot;, &quot;dl&quot;: &quot;deadline&quot;, &quot;old&quot;: &quot;old&quot;, &quot;re&quot;: &quot;repeatable&quot;, &quot;sp&quot;: &quot;specific&quot;, &quot;wk&quot;: &quot;work&quot;, &quot;url&quot;: &quot;url&quot;, &quot;p&quot;: &quot;parent&quot;&#125; 例如 1读书笔记-&gt;p = &lt;读书计划&gt; 将会把包含文字读书笔记的Item的parent属性的值设置为包含文字读书计划的id通过这样的指令, 可以将一个全局创建的Item移动到一个Note中 高级操作由于系统会自动回收没有引用的Item, 因此可以将一个Item的parent字段设置为一个不存在的id,则此Item由于没有引用, 将会在下次垃圾回收时被删除."},{"title":"","date":"2021-04-18T10:37:20.342Z","updated":"2020-07-07T11:27:01.766Z","comments":true,"path":"notebook/index.html","permalink":"https://lizec.top/notebook/index.html","excerpt":"","text":"Contents博客内容扩展以下的NoteBook都是某些博客文章的扩展内容, 主要是一些不便于在博客中展示的内容, 例如包含大量的数学公式或图片. Sympy使用示例补充 Numpy使用示例补充 Pandas使用示例补充 Matplotlib使用示例补充 Cheat Sheet CheatSheet4LinuxCommand.pdf CheatSheet4Matplotlib.pdf CheatSheet4Redis.pdf CheatSheet4VSCode.pdf 使用指南 Smart-Todo操作说明"}],"posts":[{"title":"Go语言笔记之基础知识","slug":"Go语言笔记之基础知识","date":"2021-07-01T12:06:01.000Z","updated":"2021-07-04T08:25:17.434Z","comments":true,"path":"2021/07/01/Go语言笔记之基础知识/","link":"","permalink":"https://lizec.top/2021/07/01/Go%E8%AF%AD%E8%A8%80%E7%AC%94%E8%AE%B0%E4%B9%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/","excerpt":"","text":"Go基础配置Go语言的下载和安装过程比较简单, 不需要进行特殊处理. 在Go安装完毕后, 需要注意两个特殊的环境变量GOROOT和GOPATH. 其中GOROOT表示Go语言安装的位置, 安装后自动设置不需要管. GOPATH表示项目的位置, 一般位于用户目录下的go目录, 例如在我的电脑上就是C:\\Users\\lizec\\go 因为GOPATH指定了项目的存放位置, 所以一般情况下就不要在其他地方放置源代码, 否则虽然Go也能编译项目, 但其他工具不一定完全支持. GOPATH下一般具有如下的目录结构 12345678910111213- bin - gocode.exe - godef.exe - ...- pkg - mod - sumdb- src - example.com - gohttp - hello - github.com - cmp 其中bin目录存放编译好的可执行文件, pkg目录存放相关的包, src目录存放源代码. 由于Go项目的名称需要标志如何下载这个项目, 所以源码的文件夹一般以发布代码的平台开头, 例如在Github上发布代码, 则以github.com开头. Go项目开发流程初始化项目需要初始化一个Go项目时， 首先创建保存项目的文件夹，然后执行 1go mod init example.com/hello Go语言中以模块作为基本单位，所以创建一个项目就是创建一个模块。最后的example.com/hello是模块的名称。执行完此命令以后，Go会在当前目录下创建go.mod文件，其中存储了此模块的基本信息，例如模块的名称，使用的Go语言版本，依赖的模块等。 如果在src目录初始化, 那么也可以不指定模块名称, Go可以自动根据路径产生模块名称 引入第三方模块需要使用第三方模块时，可以使用https://pkg.go.dev/网站查询需要的模块。 进入相应模块的详细页面中可以看到模块的主要功能， API文档等信息。找到需要的模块后，使用get指令获取这一模块， 例如 1go get rsc.io/quote 以上指令会更新当前模块的go.mod文件，并下载对应的依赖， 之后在代码中可以通过import的方式引入模块， 例如 123456789package mainimport &quot;fmt&quot;import &quot;rsc.io/quote&quot;func main() &#123; fmt.Println(quote.Go())&#125; 可以使用go mod tidy使编译器检查依赖变化，添加新的依赖，删除未使用的依赖 添加测试在当前模块下创建以_test.go结尾的文件来表面一个文件是测试文件。在测试文件中可以进行任意形式的测试， 例如 123456789101112131415161718192021222324import ( &quot;testing&quot; &quot;regexp&quot;)// TestHelloName calls greetings.Hello with a name, checking// for a valid return value.func TestHelloName(t *testing.T) &#123; name := &quot;Gladys&quot; want := regexp.MustCompile(`\\b`+name+`\\b`) msg, err := Hello(&quot;Gladys&quot;) if !want.MatchString(msg) || err != nil &#123; t.Fatalf(`Hello(&quot;Gladys&quot;) = %q, %v, want match for %#q, nil`, msg, err, want) &#125;&#125;// TestHelloEmpty calls greetings.Hello with an empty string,// checking for an error.func TestHelloEmpty(t *testing.T) &#123; msg, err := Hello(&quot;&quot;) if msg != &quot;&quot; || err == nil &#123; t.Fatalf(`Hello(&quot;&quot;) = %q, %v, want &quot;&quot;, error`, msg, err) &#125;&#125; 最后使用 1go test -v 运行测试并查看测试结果 编译应用程序每个应用程序需要包含一个main包并包含一个位于此包下的main函数。 然后使用 1go build 编译应用程序并生成可执行文件。 如果进一步执行 1go install 还可以将此可执行文件复制到指定的目录之中。 发布模块模块在发布以后才能够被其他模块引用。因为模块的名称会作为获得模块的依据，因此在创建模块的时候就需要设置一个合适的模块名称。例如创建模块时打算在GitHub上进行发布， 那么可以在GitHub上创建一个仓库，然后以仓库的URL路径作为名称（例如github.com/LiZeC123/go-test） 此后在开发代码的过程中，对GitHub上的代码标记适当的版本tag就完成来模块的发布。 对于自己使用的模块，如果不想走发布流程，也可以通过编辑go.mod文件来修改Go语言查找模块的方式，从而即使不发布模块也能够被其他模块引用。指令为 1go mod edit -replace=example.com/greetings=../greetings 这条指令的含义非常简单，即如果需要查找example.com/greetings模块，就访问../greetings路径。 执行上面的指令后，会在go.mod文件中加入如下的一行内容 1replace example.com/greetings =&gt; ../greetings 错误处理错误处理分为两个部分，即如何抛出错误和如何处理错误。 因为Go语言的函数支持返回多个值，因此如果一个函数需要抛出错误，一般具有如下的格式 1234567891011121314151617181920// 倒入errors模块import ( &quot;errors&quot; &quot;fmt&quot;)// 返回值包含正常的输出和错误信息func Hello(name string) (string, error) &#123; if name == &quot;&quot; &#123; // 如果出现错误，返回错误信息 return &quot;&quot;, errors.New(&quot;Empty Name&quot;) &#125; message := fmt.Sprintf(&quot;Hi, %v. Welcome!&quot;, name) // 如果没有错误，错误信息位置返回nil return message, nil&#125; 当调用这种函数时， 一般具有如下的格式 1234567891011func main() &#123; // 调用时接受返回值和错误信息 message, err := greating.Hello(&quot;&quot;) // 检查是否有错误 if err != nil &#123; // 有错误执行错误分支 log.Fatal(err) &#125; // 没有错误执行正常分支 fmt.Println(message)&#125; 以上为Go语言中标准的错误抛出和处理方案 使用模块Go程序的基本单位是模块，一个Go应用程序对应一个模块，一个Go的库也对应一个模块。模块的名称与项目顶层文件夹的名称不必保持相同，而且为了方便Go的工具获取模块，模块名称一般也指定来如何获得这个模块，例如如果需要模块golang.org/x/tools表明Go的工具可以直接访问https://golang.org/x/tools来获取这一模块。 Go语言中一个模块由一系列的包组成。一个包由一组位于同一目录下的若干源文件组成。Go的包名称不必和目录名称一致，但同一目录下只能有一个包名。例如在ROOT/hello目录下的文件包名可以是hello也可以是abc或者任何其他的名称，但位于该目录下的文件必须具有同样的包名称。 为了减少导入时的问题，一般还是会保持包名与路径名称一致 同一个包内的一个文件中的函数变量等各种元素对包内的其他文件都是可见的。 根据规则，首字母大写的函数和变量才可以被导出，从而被其他包访问 语法结构控制流Go的if结构与C语言类似，但是不需要圆括号且始终需要大括号， 例如 123if x &lt; 0 &#123; return sqrt(-x) + &quot;i&quot;&#125; 可以在if的条件前加入一个语句，这个语句在执行后再进行if条件判断， 例如 123if v := math.Pow(x, n); v &lt; lim &#123; return v&#125; Go语言只有一种循环语句， 即for循环。通过设置不同的条件来实现不同的循环语句，例如 123456789101112131415func main() &#123; sum := 0 for i := 0; i &lt; 10; i++ &#123; sum += i &#125; fmt.Println(sum)&#125;func main() &#123; sum := 1 for sum &lt; 1000 &#123; sum += sum &#125; fmt.Println(sum)&#125; defer被defer修饰的语句会在当前模块的其他语句执行结束后执行。如果是函数调用， 那么函数的参数会立即计算，但函数调用会延后执行。 12345func main() &#123; defer fmt.Println(&quot;world&quot;) fmt.Println(&quot;hello&quot;)&#125; 多个defer语句会按照逆序执行 结构体123456789101112type Vertex struct &#123; X int Y int&#125;func main() &#123; fmt.Println(Vertex&#123;1, 2&#125;) v.X = 4 // 指针操作与C类似，但不需要 -&gt; p := &amp;v p.X = 1e9&#125; 数组12345678910func main() &#123; var a [2]string a[0] = &quot;Hello&quot; a[1] = &quot;World&quot; fmt.Println(a[0], a[1]) fmt.Println(a) primes := [6]int&#123;2, 3, 5, 7, 11, 13&#125; fmt.Println(primes)&#125; 切片123456func main() &#123; primes := [6]int&#123;2, 3, 5, 7, 11, 13&#125; var s []int = primes[1:4] fmt.Println(s)&#125; 类Go语言中并没有类， 但可以把方法绑定到一个类型上。例如 123456789101112type Vertex struct &#123; X, Y float64&#125;func (v Vertex) Abs() float64 &#123; return math.Sqrt(v.X*v.X + v.Y*v.Y)&#125;func main() &#123; v := Vertex&#123;3, 4&#125; fmt.Println(v.Abs())&#125; 其实这一操作有点类似与lambda表达式的变量捕获。 当Vertex直接以变量的形式声明时， 采取复制的方式传递值，因此方法内部不能对变量进行修改。如果希望方法能够修改变量，则需要声明为指针，例如 1234func (v *Vertex) Scale(f float64) &#123; v.X = v.X * f v.Y = v.Y * f&#125; 除了绑定在一个自定义的类似上， 也可以绑定到已有的类型上，例如 12345678910111213type MyFloat float64func (f MyFloat) Abs() float64 &#123; if f &lt; 0 &#123; return float64(-f) &#125; return float64(f)&#125;func main() &#123; f := MyFloat(-math.Sqrt2) fmt.Println(f.Abs())&#125; 方法只能绑定在同一个包中的类型上 接口与其他语言中的概念一致， 接口是一组方法签名的集合。 例如 123type Abser interface &#123; Abs() float64&#125; 可以将实现了接口中方法的变量赋值给接口， 例如 1234567891011func main() &#123; var a Abser f := MyFloat(-math.Sqrt2) v := Vertex&#123;3, 4&#125; a = f // a MyFloat implements Abser a = &amp;v // a *Vertex implements Abser fmt.Println(a.Abs())&#125; 注意：在对接口赋值时，绑定在Vertex上的方法和绑定在*Vertex上的方法是不通用的。 基于上面的赋值操作， 我们可以注意到对于接口的实现是没有显式的声明的。 这有点类似Python的鸭子类型，只要实现了对应的方法就可以视为对应的接口。 接口类型转换可以使用如下的语法得到接口下对应的具体实现 1234567891011121314151617181920212223242526func main() &#123; var i interface&#123;&#125; = &quot;hello&quot; s := i.(string) fmt.Println(s) s, ok := i.(string) fmt.Println(s, ok) f, ok := i.(float64) fmt.Println(f, ok) f = i.(float64) // panic fmt.Println(f)&#125;func do(i interface&#123;&#125;) &#123; switch v := i.(type) &#123; case int: fmt.Printf(&quot;Twice %v is %v\\n&quot;, v, v*2) case string: fmt.Printf(&quot;%q is %v bytes long\\n&quot;, v, len(v)) default: fmt.Printf(&quot;I don&#x27;t know about type %T!\\n&quot;, v) &#125;&#125; 并发编程协程协程是Go的运行时管理的一种轻量级的线程。协程之间通过自己主动切换来实现调度。使用go关键字即可使一个函数在协程上运行，例如 1234567891011func say(s string) &#123; for i := 0; i &lt; 5; i++ &#123; time.Sleep(100 * time.Millisecond) fmt.Println(s) &#125;&#125;func main() &#123; go say(&quot;world&quot;) say(&quot;hello&quot;)&#125; 通道123456789101112131415161718func sum(s []int, c chan int) &#123; sum := 0 for _, v := range s &#123; sum += v &#125; c &lt;- sum // send sum to c&#125;func main() &#123; s := []int&#123;7, 2, 8, -9, 4, 0&#125; c := make(chan int) go sum(s[:len(s)/2], c) go sum(s[len(s)/2:], c) x, y := &lt;-c, &lt;-c // receive from c fmt.Println(x, y, x+y)&#125; make创建通道时，可以额外用一个参数指定通道缓冲区的大小，此时只有缓冲区空或者满时才会阻塞 可以调用close函数关闭通道，但一般情况下不需要手动关闭 selectselect语句可以时协程在多个条件上等待，直到其中一个条件能够执行时，执行相应的语句。 如果同时有多个条件可以执行， 则Go随机选择一个条件分支执行。 12345678910111213141516171819202122232425func fibonacci(c, quit chan int) &#123; x, y := 0, 1 for &#123; select &#123; case c &lt;- x: // 等待c通道可以写入 x, y = y, x+y case &lt;-quit: // 等待quit通道可以读取 fmt.Println(&quot;quit&quot;) return &#125; &#125;&#125;func main() &#123; c := make(chan int) quit := make(chan int) go func() &#123; for i := 0; i &lt; 10; i++ &#123; fmt.Println(&lt;-c) // 循环读取c通道， 使得fibonacci函数能够持续计算 &#125; quit &lt;- 0 // 向quit写入数据，使得fibonacci函数中quit通道变为可读状态 &#125;() fibonacci(c, quit)&#125;","categories":[{"name":"Go语言笔记","slug":"Go语言笔记","permalink":"https://lizec.top/categories/Go%E8%AF%AD%E8%A8%80%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Go","slug":"Go","permalink":"https://lizec.top/tags/Go/"}]},{"title":"Python笔记之高阶技巧","slug":"Python笔记之高阶技巧","date":"2021-06-02T02:50:07.000Z","updated":"2021-06-27T00:36:08.710Z","comments":true,"path":"2021/06/02/Python笔记之高阶技巧/","link":"","permalink":"https://lizec.top/2021/06/02/Python%E7%AC%94%E8%AE%B0%E4%B9%8B%E9%AB%98%E9%98%B6%E6%8A%80%E5%B7%A7/","excerpt":"","text":"本文主要介绍一些Python中的高级技巧, 从而使我们的代码更加pythonic. 本文的主要内容来自《Python Cookbook》3rd Edition, 可以访问python3-cookbook查看中文翻译版本. 基础与数据结构星号表达式Python可以将一个集合拆开赋值给多个变量, 如果涉及的变量比较多, 也可以使用*表示匹配任意多个字段, 例如 123first, *middle, last = grades # 将成绩的第一个数据和最后一个数据取出, 其他数据存放在middle之中record = (&#x27;Dave&#x27;, &#x27;dave@example.com&#x27;, &#x27;773-555-1212&#x27;, &#x27;847-555-1212&#x27;)name, email, *phone_numbers = record # 将剩余的字段复制给phone_numbers 使用*表达式产生的字段必然是列表类型, 而且这个字段允许匹配0个数据. 因此可以始终按照集合类型处理这些字段, 而不必考虑空值问题. 字典的键映射多个值解决方案: 将list或者set作为字典的值. 为了方便使用, 可以使用collections模块中的defaultdict 1234567891011from collections import defaultdictd = defaultdict(list)d[&#x27;a&#x27;].append(1)d[&#x27;a&#x27;].append(2)d[&#x27;b&#x27;].append(4)d = defaultdict(set)d[&#x27;a&#x27;].add(1)d[&#x27;a&#x27;].add(2)d[&#x27;b&#x27;].add(4) 命名切片切片是可以作为一个变量的, 因此可以将一个切片赋值给一个变量, 从而使切片具有含义. 这避免了硬编码大量magic number. 123###### 0123456789012345678901234567890123456789012345678901234567890&#x27;record = &#x27;....................100 .......513.25 ..........&#x27;cost = int(record[20:23]) * float(record[31:37]) 上面的代码可以修改为: 123SHARES = slice(20, 23)PRICE = slice(31, 37)cost = int(record[SHARES]) * float(record[PRICE]) 命名元组使用namedtuple方法可以将一个元组绑定到一个给定的字段列表上. 其本质是创建了一个类并实现了元组的所有操作, 从而既可以按照字段访问变量, 又支持元组的所有操作. 123from collections import namedtupleSubscriber = namedtuple(&#x27;Subscriber&#x27;, [&#x27;addr&#x27;, &#x27;joined&#x27;])sub = Subscriber(&#x27;jonesy@example.com&#x27;, &#x27;2012-10-19&#x27;) 之后可以按照类的方式访问需要的字段 1234&gt;&gt;&gt; sub.addr&#x27;jonesy@example.com&#x27;&gt;&gt;&gt; sub.joined&#x27;2012-10-19&#x27; 命名元组可以作为字典的替代选项. 且具有不可变且内存消耗更小的优势 字符串和文本通配符匹配如果在某些时候需要使用一些简单的通配符匹配, 同时又不需要引入正则表达式, 那么可以使用fnmatch库实现这一功能. 例如 12345678910&gt;&gt;&gt; from fnmatch import fnmatch, fnmatchcase&gt;&gt;&gt; fnmatch(&#x27;foo.txt&#x27;, &#x27;*.txt&#x27;)True&gt;&gt;&gt; fnmatch(&#x27;foo.txt&#x27;, &#x27;?oo.txt&#x27;)True&gt;&gt;&gt; fnmatch(&#x27;Dat45.csv&#x27;, &#x27;Dat[0-9]*&#x27;)True&gt;&gt;&gt; names = [&#x27;Dat1.csv&#x27;, &#x27;Dat2.csv&#x27;, &#x27;config.ini&#x27;, &#x27;foo.py&#x27;]&gt;&gt;&gt; [name for name in names if fnmatch(name, &#x27;Dat*.csv&#x27;)][&#x27;Dat1.csv&#x27;, &#x27;Dat2.csv&#x27;] 字符串对齐Python提供了ljust(), rjust()和center()方法来提供字符串的对齐操作, 例如 1234567&gt;&gt;&gt; text = &quot;Hello&quot;&gt;&gt;&gt; text.ljust(20)&#x27;Hello &#x27;&gt;&gt;&gt; text.rjust(20)&#x27; Hello&#x27;&gt;&gt;&gt; text.center(20, &#x27;*&#x27;)&#x27;*******Hello********&#x27; 更加一般地, 可以使用format函数进行格式化, 例如 1234&gt;&gt;&gt; format(text, &#x27;=&gt;20s&#x27;)&#x27;===============Hello&#x27;&gt;&gt;&gt; format(text, &#x27;*^20s&#x27;)&#x27;*******Hello********&#x27; 其中format函数的第二个参数用于控制格式化的样式(format_spec). 其基本结构为 12345678format_spec ::= [[fill]align][sign][#][0][width][grouping_option][.precision][type]fill ::= &lt;any character&gt; align ::= &quot;&lt;&quot; | &quot;&gt;&quot; | &quot;=&quot; | &quot;^&quot;sign ::= &quot;+&quot; | &quot;-&quot; | &quot; &quot;width ::= digit+grouping_option ::= &quot;_&quot; | &quot;,&quot;precision ::= digit+type ::= &quot;b&quot; | &quot;c&quot; | &quot;d&quot; | &quot;e&quot; | &quot;E&quot; | &quot;f&quot; | &quot;F&quot; | &quot;g&quot; | &quot;G&quot; | &quot;n&quot; | &quot;o&quot; | &quot;s&quot; | &quot;x&quot; | &quot;X&quot; | &quot;%&quot; 总体来说, 这部分的语法与其他位置使用的格式化语法差别不大, 其中align部分的四个符号分别表示左对齐, 右对齐, 强制在付好后填充和居中. type部分表示数据的显示类型, 根据其缩写, 分别表示二进制,字符, 货币类型, 八进制, 十六进制以及字符串等. 使用 help(‘FORMATTING’) 查看内置文档 format函数可以格式化任何类型的数据(如果此类型支持), 也能够在字符串上格式化, 例如 12345&gt;&gt;&gt; format(3.1415926, &#x27;&gt;+4.2f&#x27;)&#x27;+3.14&#x27;&gt;&gt;&gt; &#x27;&#123;:&gt;10s&#125; &#123;:&gt;10s&#125;&#x27;.format(&#x27;Hello&#x27;, &#x27;World&#x27;)&#x27; Hello World&#x27; 数字运算分数运算Python中提供了Fraction类用于分数运算， 例如 1234567891011121314151617181920212223242526272829&gt;&gt;&gt; from fractions import Fraction&gt;&gt;&gt; a = Fraction(5, 4)&gt;&gt;&gt; b = Fraction(7, 16)&gt;&gt;&gt; print(a + b)27/16&gt;&gt;&gt; print(a * b)35/64&gt;&gt;&gt; # Getting numerator/denominator&gt;&gt;&gt; c = a * b&gt;&gt;&gt; c.numerator35&gt;&gt;&gt; c.denominator64&gt;&gt;&gt; # Converting to a float&gt;&gt;&gt; float(c)0.546875&gt;&gt;&gt; # Limiting the denominator of a value&gt;&gt;&gt; print(c.limit_denominator(8))4/7&gt;&gt;&gt; # Converting a float to a fraction&gt;&gt;&gt; x = 3.75&gt;&gt;&gt; y = Fraction(*x.as_integer_ratio())&gt;&gt;&gt; yFraction(15, 4)&gt;&gt;&gt; 迭代同时迭代多个序列12345678&gt;&gt;&gt; a = [1, 2, 3]&gt;&gt;&gt; b = [&#x27;w&#x27;, &#x27;x&#x27;, &#x27;y&#x27;, &#x27;z&#x27;]&gt;&gt;&gt; for i in zip(a,b):... print(i)...(1, &#x27;w&#x27;)(2, &#x27;x&#x27;)(3, &#x27;y&#x27;) 12345678910111213141516&gt;&gt;&gt; from itertools import zip_longest&gt;&gt;&gt; for i in zip_longest(a,b):... print(i)...(1, &#x27;w&#x27;)(2, &#x27;x&#x27;)(3, &#x27;y&#x27;)(None, &#x27;z&#x27;)&gt;&gt;&gt; for i in zip_longest(a, b, fillvalue=0):... print(i)...(1, &#x27;w&#x27;)(2, &#x27;x&#x27;)(3, &#x27;y&#x27;)(0, &#x27;z&#x27;) 基于zip的这一特性，也可以用于将两个list对应的转化为dict（dictd的构造函数接受zip的输出） 不同集合上迭代如果需要在多个集合上执行同样的操作， 可以使用chain函数将多个集合链接起来，一次性的迭代处理 1234567891011121314&gt;&gt;&gt; from itertools import chain&gt;&gt;&gt; a = [1, 2, 3, 4]&gt;&gt;&gt; b = [&#x27;x&#x27;, &#x27;y&#x27;, &#x27;z&#x27;]&gt;&gt;&gt; for x in chain(a, b):... print(x)...1234xyz&gt;&gt;&gt; 从而避免在两个集合上分别执行两次迭代操作 展开嵌套集合from collections import Iterable def flatten(items, ignore_types=(str, bytes)): for x in items: if isinstance(x, Iterable) and not isinstance(x, ignore_types): yield from flatten(x) else: yield x yield from 是python协程中的用法， 表示将一个可迭代对象逐元素的yield输出","categories":[{"name":"Python笔记","slug":"Python笔记","permalink":"https://lizec.top/categories/Python%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://lizec.top/tags/Python/"}]},{"title":"MySQL笔记之事务原理","slug":"MySQL笔记之事务原理","date":"2021-05-10T08:27:49.000Z","updated":"2021-05-19T02:18:20.337Z","comments":true,"path":"2021/05/10/MySQL笔记之事务原理/","link":"","permalink":"https://lizec.top/2021/05/10/MySQL%E7%AC%94%E8%AE%B0%E4%B9%8B%E4%BA%8B%E5%8A%A1%E5%8E%9F%E7%90%86/","excerpt":"","text":"事务事务特性MySQL采取默认提交(AUTOCOMMIT)模式, 即除非显式的开始一个事务, 则每个语句都是为一个事务在执行后立即提交. 事务的基本特征是ACID, 即原子性, 一致性, 隔离性和持久性. 原子性表明一个事务必须视为一个不可分割的最小执行单位, 其中的操作要么同时成功, 要么同时失败. 一致性表明数据库总是一致的从一个状态转移到另一个状态, 而不会导致数据出现不一致. 隔离性表明一个事务的操作在提交之前应该对其他事务不可见. 虽然事务要求有隔离性, 但MySQL对隔离性提供了不同的等级, 因此对隔离性也有不同的表现. MySQL默认采取的隔离级别为可重复读. 持久性表明一个事务的操作一旦提交到数据库, 则即使数据库崩溃, 数据也不会丢失. 但实际上, 显然并不存在可以保证绝对不丢失数据的数据库, 而持久性也存在不同的等级. SQL标准规定了四种隔离级别, 每种级别都规定了一个事务的修改, 在其他事务内的可见性. 低级别的隔离通常具有更高的并发性并且系统开销也更低. 关于事务的基本特性和隔离级别, 可以参考之前的博客数据库原理之事务并发控制. 实现了ACID特性的数据库比没有实现ACID特性的数据库需要消耗更多CPU性能, 内存空间和磁盘空间. MySQL由于可以选择不同的存储引擎, 因此可以自由的选择是否需要事务相关的特性, 从而更灵活的适应需求. 隐式提交默认情况下，MySQL是自动提交的，即如果没有明确表示开始一个事务，则每个语句都视为一个单独的事务。但即使手动k开启了事务，当执行某些特定操作时，此操作之前的操作还是会被提交，这一特性称为隐式提交。这类操作包括定义或修改数据库结构，在事务中开启新的事务，手动锁定表，加载数据，复制数据等。 保存点在事务中执行多步操作时，可以指定一些保存点，从而在回滚的时候，不回滚全部操作，而是回滚到指定的保存点。例如 123456BEGIN;SELECT ...;UPDATE ...;SAVEPOINT A;UPDATE ...;ROLLBACK TO A; #回滚到保存点A redo日志由于硬盘的IO速度比较慢，因此MySQL并不会每次修改操作都将修改写入硬盘，而是会将结果先缓存到内存之中，在某个时机再整页的写入数据。由于数据写入操作的滞后性，存在数据修改后还未写入之前，数据库发生崩溃的可能性。MySQL使用redo日志来解决这一问题。 当事务提交时，MySQL并不会将数据的修改立刻写入硬盘，但会将相应的redo日志立即写入硬盘。由于写日志操作是顺序IO，因此相比于更随机的写入页面，写入日志的性能更高。当数据库发生崩溃时，数据库可以根据redo日志恢复已经提交的事务，从而保证事务的一致性和持久性。 redo日志格式redo日志是一种物理机制，其中并不是记录相关的SQL语句，而是记录了页面修改情况的详细信息。 redo日志的行格式中包含很多类型，有的类型指示简单的记录那个页面的那个偏移位置有修改，有的类型就会记录一些更复杂的信息。 一条插入语句可能只需要在某个位置加入一个记录，因此只需要一条redo日志即可。但在另外一些情况下，插入数据可能导致页面分裂，进而引发一系列的修改，就可能产生数十条redo日志。因此实际写入redo日志的过程也需要保证原子性，例如上述的数十条redo日志，要保证要么不写入，要么全部写入，否则就可能导致数据恢复到不正确的中间位置。 MySQL中将底层的一次原子操作称为一个Mini-Transaction（MTR），例如前面提到了插入数据后导致页面分裂的一系列操作就是一个MTR。redo日志的写入过程以MTR为基本单位。 redo日志写入过程redo日志也存在缓冲区，其中按照512字节分割为不同的block。在事务的执行过程中，会不断的产生redo日志，这些redo日志先按照组存在在某个地方，等一组任务完成以后再写入到redo日志的缓冲区中。 缓冲区内的redo日志在如下的一些时机会被刷入硬盘 缓冲区空间不足 事务提交 后台专门刷新的线程 关闭服务器 checkpoint redo日志文件组redo日志在磁盘上对应了几个文件，一般的命名格式类似ib_logfile0，ib_logfile1。这些日志文件会被循环写入，后写入的日志会覆盖以前写入的日志。 redo日志中使用log sequence number(lsn)来记录日志的写入位置，从而判断哪些位置日志已经失效，哪些位置的日志还需要保存。 undo日志事务ID每个开启的事务都会被分配一个事务ID， 如果这个事务不进行任何修改，则ID默认为0。 锁机制InnoDB采用两段锁协议, 在事务过程中随时可能加锁, 并且在事务结束时统一释放所有的锁. InnoDB会根据隔离级别, 在需要的时候自动加锁. 由于引入了锁机制, 因此事务之间可能存在死锁. InnoDB等存储引擎实现了死锁检测和死锁超时机制. 当出现死锁时, InnoDB会回滚持有最少行级排它锁的事务. 锁的行为与顺序和存储引擎有关, 同样的执行语句, 在不同的存储引擎上可能有不同的执行情况. 语句本身和存储引擎的实现都可能导致死锁. MVCC机制MySQL的大多数支持事务的存储引擎都采用多版本并发控制机制来实现行级锁. 其他的数据库系统也都实现了MVCC机制, 但具体的实现可能不尽相同, 因为MVCC并没有规定实现标准. MySQL中InnoDB的MVCC机制的实现方法的核心在于每行数据后有两个隐藏字段, 一个表示创建时间, 一个表示删除时间, 两个字段都使用系统版本号进行标识. 开启一个事务时, 系统版本号会自动递增, 并且事务以此时的系统版本号作为此事务的版本号. 并且在执行不同操作时, 有如下的约束 SELECT操作只读取创建时间的版本号小于等于当前版本号的数据和删除时间为未定义或大于当前事务版本号的数据. 这样可以保证读取的数据要么在事务开始前已经创建, 要么在事务开始后才被删除. INSERT操作将当前事务的版本号作为新插入数据的创建时间版本号. DELETE操作将当前事务的版本号作为删除数据的删除时间版本号 UPDATE操作先插入一条数据, 然后将原来的数据删除. 按照如上的约定, 即可实现可重复读. 如果放宽SELECT操作对创建时间的限制, 那么就可以将隔离级别降低为读已提交. 通过MVCC机制, 可以使大部分读操作不加锁的实现. (写操作还是会加锁, 否则可能导致事务特性被破坏)","categories":[{"name":"MySQL笔记","slug":"MySQL笔记","permalink":"https://lizec.top/categories/MySQL%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://lizec.top/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"MySQL","slug":"MySQL","permalink":"https://lizec.top/tags/MySQL/"}]},{"title":"Netty笔记之基础知识","slug":"Netty笔记之基础知识","date":"2021-04-09T02:14:15.000Z","updated":"2021-04-12T06:19:01.346Z","comments":true,"path":"2021/04/09/Netty笔记之基础知识/","link":"","permalink":"https://lizec.top/2021/04/09/Netty%E7%AC%94%E8%AE%B0%E4%B9%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/","excerpt":"","text":"Netty是一个基于Java的高性能的, 异步事件驱动的网络通信框架, 其对Java的NIO进行了封装并提供简单易用的API. Netty本身是一个Jar包, 可以通过Maven进行管理. 基本概念同步与阻塞同步: 请求方发送请求后, 被请求方在完成请求前不返回结果异步: 请求方发送请求后, 被请求方立刻返回一个结构表示已经接受到请求阻塞: 同步/异步主要是从请求响应的角度来描述, 而阻塞/非阻塞 主要从返回相应的角度来描述. Java的IO模型 BIO(Blocking IO): 即同步阻塞IO, 在这种场景下, 通常使用一个线程对应一个IO连接的方式. 当请求较多时, 虚拟机的压力较大 伪异步IO: 依然是BIO, 但引入线程池进行优化, 从而限制最大线程数量 NIO(Java Non-blocking IO): 同步非阻塞IO, 通过Channel, Selector和Buffer实现 AIO(Java Asynchronous IO): 异步非阻塞IO, 通过回调通知线程, 回调时已经完成IO操作 Reactor模型将需要处理的IO事件注册到一个中心IO多路复用器上, 同时主线程阻塞在复用器上, 当相应的IO事件发生时, 主线程被唤醒, 将相应的事件派发给相应的的处理器进行处理. Handler Synchronous Event Demultiplexer(同步事件分离器): 一般就是指IO多路复用机制 Event Handler(事件处理器): 由开发人员编写的回调代码 Concrete Event Handler(具体事件处理器): 事件处理器的具体的实现 Initiation Dispatcher(初始分发器): 控制事件的调度, 事件处理器的注册和删除. 单线程模式: 所有的IO操作在一个线程上完成 多线程模式:","categories":[],"tags":[]},{"title":"MySQL笔记之性能优化","slug":"MySQL笔记之性能优化","date":"2021-01-21T08:28:36.000Z","updated":"2021-05-19T02:18:24.594Z","comments":true,"path":"2021/01/21/MySQL笔记之性能优化/","link":"","permalink":"https://lizec.top/2021/01/21/MySQL%E7%AC%94%E8%AE%B0%E4%B9%8B%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/","excerpt":"","text":"MySQL索引结构在开始MySQL索引相关的内容之前, 有必要先介绍一下MySQL的索引结构和索引的实现原理. 在理解这些内容之后, 很多MySQL索引的特性都是显然的. B+树总所周知, 数据库中一般采取B+树的结构来存储数据. 一颗B+树一般具有如下的结构: B+树是一种多分支的树, 除去B+树常规的定义以外(即什么是B+树, 可以具有多少个分支等等), B+树最显著的特点是仅叶子节点具有数据, 而中间节点只存储索引值. 相比于平衡二叉树和红黑树之类可以自动调整的树, 由于B+树每一个节点的分支更多, 因此同样数量的节点时, B+树的深度更低. 由于磁盘的IO操作速度远远低于内存的读写次数, 因此更低的树深度能够减少IO次数, 从而提高数据的读取速度. B+树在每个叶子节点上添加了一个指向下一个数据的指针, 可以根据这个指针顺序的遍历数据, 这有助于数据库进行范围遍历操作. B树和B+树的插入、删除图文详解 主键索引(聚族索引) InnoDB采取聚族索引的方式组织数据, 即数据行和索引的键紧凑的存储在B+树的叶子节点中, 这也就是聚族的含义. 由于InnoDB的这种数据存储方式, 每个数据表都必须要有一个主键, 如果没有规定, MySQL也会自动生成一个主键来组织数据. 二级索引(非聚族索引)因为不可能把全部数据同时放到两个B+树中, 因此一个表只能有一个聚族索引, 其他的索引称为二级索引. 二级索引也是一颗B+树, 只不过其叶子节点仅包含索引值和此数据的主键值. 根据二级索引查询数据时, MySQL首先查询二级索引获得主键值, 然后根据主键值在聚族索引上再次查询. InnoDB采取这一架构的主要原因是, 当数据位置发生变化时, 只需要修改聚类索引, 而不需要修改二级索引, 从而降低索引维护成本. 覆盖索引由于二级索引中包含了索引的列的数据, 因此如果只需要这一列数据, 则MySQL可以跳过根据聚族索引再次查询的操作, 从而提高查询效率. 这种情况称为覆盖索引. 当MySQL能够使用覆盖索引时, 使用EXPLAIN指令可以看到Extra: Using Index的提示. 与此相反, 如果MySQL需要根据索引获取一段范围内的数据, 且需要的数据没有被索引覆盖, 则MySQL需要不断重复的从索引获取主键值, 再根据主键值获取数据的过程. 这一操作造成了大量的随机I/O, 因此有可能性能还不如直接全表遍历. 由于索引存储了一部分的数据, 因此如果建立太多的索引, 会导致维护成本和存储成本快速上升 索引下推索引下推技术主要是为了减少数据库的回表操作次数. 例如给定如下的语句 1SELECT * FROM s1 WHERE key1 &gt; &#x27;z&#x27; AND key1 LIKE &#x27;%a&#x27; 在不使用索引下推时, 只有key1 &gt; &#39;z&#39;这个条件可以使用索引快速定位, 之后存储引擎需要根据索引取出从z开始的所有记录, 然后每一条记录都需要在主表中进行回表操作取出所有字段. 如果使用索引下推, 则存储引擎可以拿到另外一个条件key1 LIKE &#39;%a&#39;, 由于索引中本来就包含key1的全部信息, 因此可以在索引上直接判断是否满足条件, 从而对于不满足条件的数据, 可以直接避免一次回表操作. 联合索引对多个列建立的索引称为联合索引. 此时索引中的数据会按照字段的先后顺序依次的排序. 例如存在三个字段A, B, C, 则先按照A进行排序, A字段值相同的多条记录按照B字段排序; A, B 字段值都相同的记录再按照C字段排序. 基于上面的这一特性, 就会产生左前匹配原则, 例如以下操作可以通过索引完成 可以使用全值匹配, 即给定A,B,C三个字段的值 范围匹配A的值 给定A的值的同时, 范围匹配B的值 而下面的这些操作无法通过索引完成 单独匹配C的值 单独匹配A和C的值 本质上, 就是操作能否选择一段连续的区域, 连续存储的区域才可以加速 唯一索引当数据表中的一个字段要求唯一时, MySQL就会对该字段建立一个唯一索引. 唯一索引也是一颗B+树, MySQL在插入数据时, 会通过这个B+树来检查插入数据是否具有唯一性. 因为唯一索引也是一个索引, 因此在此字段上的查询操作也能够被索引加速或者获得覆盖索引的效果. 参考资料 MySQL 索引结构 MySQL索引背后的数据结构及算法原理 你分得清MySQL普通索引和唯一索引了吗？ 索引使用技巧使用独立的列在Where语句中使用列的表达式将会导致无法使用索引, 例如 1SELECT * FROM user WHERE age + 1 &gt; 10 如果在age上存在索引, 则上述语句将会导致索引无法被使用. 显然, 对上述表达式进行简单的代数变换就可以消除表达式. 前缀索引如果索引中包含长度很大的字符串, 则维持这样的索引会带来很大的开销, 此时可以选择将字段的部分内容作为索引, 从而建立前缀索引. 多列索引一个常见的错误是创建多个单列索引. 如果一个查询涉及多个条件, 但每个条件上都是单列索引, 那么实际上就等于只有一列使用了索引. 即使MySQL的优化器可以使用合并索引技术使用多个索引, 也还是会带来额外的性能开销, 甚至导致优化器错误估计代价, 使得性能还不如直接全表遍历. 涉及多个查询条件的情况下, 创建一个有合适顺序的多列索引才是正确的做法. 这里的顺序主要考虑B+树的结构, 使得精确匹配和范围匹配能够最大限度的利用索引. 冗余索引能否索引覆盖将会极大的影响查询性能. 但过大的索引也会降低索引性能. 例如一个包含VARCHAR字段的索引就可能严重降低索引查询性能. 针对这一问题, 可以引入冗余索引, 即分别创建几个不同的索引替代一个单一的索引. 冗余索引虽然导致空间消耗和维护索引的成本提高, 但查询时可以分别使用不同的索引, 从而保证了查询效率不会降低. 查询性能优化为什么查询会慢不要获取不需要的列和行. 先获取数据在抛弃不需要数据的方式会浪费很多性能, 并且可能导致相关的语句无法被优化. (例如原本可以被索引覆盖, 但因为获取了不需要的列而导致了更多的无效操作) 不要重复查询同样的数据. 这样的场景可以使用缓存来降低数据库的压力. 如果一个查询需要扫描大量数据, 但只返回少量数据, 那么就应该考虑对这种查询进行优化.(MySQL并不能提供扫描了多少数据的精确指标, 因此关键是理解查询背后的行为). 可以考虑三种方式对这种查询进行优化 使用覆盖索引. 如果查询的列被覆盖, 则可以直接从索引获得数据, 减少扫描量 改变表结构, 增加单独的汇总表 重写查询 拆分查询以往的开发实践认为, 在数据库层应该尽可能完成多的工作, 因为网络通信和优化的代价比较高. 但实际上, MySQL的网络开销并没有高到不可接受, 在合适的情况下, 将一个复杂的查询拆分为若干个子查询可能性能更好. 以删除数据为例, 如果一条指令需要删除大量数据, 那么很有可能需要锁定大量数据行, 导致其他查询受到影响. 此时将任务拆分为若干相同的小任务, 就可以降低这一操作对其他查询的影响. 将关联查询分割为几个单独的子查询, 并且在应用程序中执行连接操作, 有如下的一些好处 程序可以缓存数据, 从而减少了查询数据量 单独的子查询减少了锁竞争 应用层做连接可以使数据库更容易拆分处理 数据库连接操作可能对某些数据重复访问, 拆分为子查询能减少冗余查询 EXPLAIN语句详解MySQL查询语句的性能可以通过EXPLAIN语句分析. 以下是一个查询语句的实例, 经过EXPLAIN语句后, 产生了如下图所示的结果 以下分别解释其中出现的各个字段的含义 列名 含义 列名 含义 id 选择标识符 select_type 表示查询的类型 table 输出结果集的表 partitions 匹配的分区 possible_keys 表示查询时, 可能使用的索引 key 表示实际使用的索引 key_len 索引字段的长度 ref 列与索引的比较 type 表示表的连接类型 rows 扫描出的行数(估算的行数) filtered 按表条件过滤的行百分比 Extra 执行情况的描述和说明 id字段ID表示查询顺序, 具有如下特点 如果是子查询, ID递增, 因此ID越大, 越先执行 ID相同时, 从上到下顺序执行 select_type字段select_type表示查询类型, 具有如下的一些取值 名称 含义 名称 含义 SIMPLE 简单SELECT, 不使用UNION或子查询等 PRIMARY 子查询中最外层查询 UNION UNION中的第二个或后面的SELECT语句 DEPENDENT UNION UNION且操作取决于外面的查询 UNION RESULT UNION的结果 DERIVED 派生表的SELECT, FROM子句的子查询 SUBQUERY 子查询中的第一个SELECT, 结果不依赖于外部查询 DEPENDENT SUBQUERY 子查询中的第一个SELECT, 依赖于外部查询 UNCACHEABLE SUBQUERY 一个子查询的结果不能被缓存, 必须重新评估外链接的第一行 type字段对表的访问类型, 具有如下的一些取值 名称 含义 all 遍历全表以找到匹配的行 index 只遍历索引树(索引覆盖) range 根据索引值范围查询并回表查询 ref 根据索引获得主键值并回表查询 eq_ref 类似ref, 区别就在使用的索引是唯一索引 const 一次读取就可以获得数据 system const且只查询结果一行 NULL MySQL在优化过程中分解语句, 执行时不用访问表或索引 Extra字段查询过程中使用的额外信息. 包括如下的一些取值 名称 含义 Using where 不用读取表中所有信息, 仅通过索引就可以获取所需数据 Using temporary 表示MySQL需要使用临时表来存储结果集, 常见于排序和分组查询 Using filesort 查询中包含排序操作, 且无法利用索引完成 Using join buffer 在获取连接条件时没有可用索引, 需要连接缓冲区来存储中间结果 Impossible where where语句会导致没有符合条件的行（通过收集统计信息不可能存在结果） Select tables optimized away 仅通过使用索引, 优化器可能仅从聚合函数结果中返回一行 No tables used 查询语句中使用from dual 或不含任何from子句 注意: 如果出现了Using join buffer, 那么可以考虑是否需要添加索引. Extended Explain有时候使用了EXPLAIN语句后, 会显示有warning, 此时如果执行 1SHOW WARNINGS 会给出具体的细节, 其中可能包含MySQL优化器重写的SQL语句, 这些SQL语句有助于我们理解优化器如何对我们的查询语句进行优化. 参考资料与扩展阅读以下的几篇文章中, 第一篇文章比较精炼的概括的EXPLAIN返回的各字段的取值与含义. 第二篇文章更为详细的介绍了各字段的取值和含义, 可以作为第一篇文章的补充. MySQL Explain详解 MySQL - EXPLAIN详解","categories":[{"name":"MySQL笔记","slug":"MySQL笔记","permalink":"https://lizec.top/categories/MySQL%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://lizec.top/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"MySQL","slug":"MySQL","permalink":"https://lizec.top/tags/MySQL/"}]},{"title":"MySQL笔记之基本配置","slug":"MySQL笔记之基本配置","date":"2021-01-20T09:12:54.000Z","updated":"2021-05-19T02:43:08.487Z","comments":true,"path":"2021/01/20/MySQL笔记之基本配置/","link":"","permalink":"https://lizec.top/2021/01/20/MySQL%E7%AC%94%E8%AE%B0%E4%B9%8B%E5%9F%BA%E6%9C%AC%E9%85%8D%E7%BD%AE/","excerpt":"","text":"最近打算给服务器端的MySQL配置一个只读远程的远程账号, 找了一圈居然没有一篇博客能完整解决这个问题, 所以这篇博客会记录MySQL的一些常见需求的操作方法. 创建账号创建账号的语句非常简单, 执行如下的SQL语句, 即可创建名为lizec的用户. 1CREATE USER lizec; 授予权限授权基本格式授权语句的格式如下 1GRANT &lt;methods&gt; ON &lt;databaseName&gt;.&lt;tableName&gt; TO &quot;&lt;username&gt;&quot;@&quot;%&quot; IDENTIFIED BY &#x27;&lt;password&gt;&#x27; WITH GRANT OPTION; 其中&lt;username&gt;和&lt;password&gt;分别表示需要授权的账号和密码, 使用相应的值替换即可. &lt;databaseName&gt;和&lt;tableName&gt;表示需要授权的数据库和表的名字, 例如test.*表示授予test数据库下所有表的权限, 而*.*表示授予所有数据库的所有表的权限. &lt;methods&gt;表示授予用于允许的操作, 可选值为all privileges, select, delete, update, create, drop. 这些取值对应了相关的SQL操作. 授权举例下面用几个例子解释授权语句 授予所有权限 1GRANT all privileges ON *.* TO &quot;user&quot;@&quot;%&quot; IDENTIFIED BY &#x27;123456&#x27; WITH GRANT OPTION; 上述语句对用户名为user, 密码为123456的用户在所有的数据库上授予了所有的权限. 授予只读权限 1GRANT select ON test1.* TO &quot;user&quot;@&quot;%&quot; IDENTIFIED BY &#x27;123456&#x27; WITH GRANT OPTION; 上述语句对用户名为user, 密码为123456的用户在test1数据库上授予了SELECT权限, 因此该用户只能在此数据库上执行SELECT操作 参考文献 MySQL中授权(grant)和撤销授权(revoke) MySQL允许远程登录1. 修改监听地址首先打开MySQL的配置文件/etc/mysql/mysql.conf.d/mysqld.cnf, 找到如下的段落 123# Instead of skip-networking the default is now to listen only on# localhost which is more compatible and is not less secure.bind-address = 127.0.0.1 其中的bind-address决定了MySQL服务的监听IP地址, 按照上面的配置, 仅允许本地的IP地址连接MYSQL. 可以将这一行注释掉, 或者改为0.0.0.0使所有的IP地址都能访问MySQL. 2. 设置防火墙这一步非常关键, 如果设置了防火墙, 需要将MySQL的3306端口放行, 否则无法访问MySQL. 参考资料 How To Allow Remote Connections To MySQL MySQL笔记之事务原理","categories":[{"name":"MySQL笔记","slug":"MySQL笔记","permalink":"https://lizec.top/categories/MySQL%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://lizec.top/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"MySQL","slug":"MySQL","permalink":"https://lizec.top/tags/MySQL/"}]},{"title":"深入理解JVM之类加载机制","slug":"深入理解JVM之类加载机制","date":"2021-01-12T06:22:55.000Z","updated":"2021-01-12T10:14:34.000Z","comments":true,"path":"2021/01/12/深入理解JVM之类加载机制/","link":"","permalink":"https://lizec.top/2021/01/12/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JVM%E4%B9%8B%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/","excerpt":"","text":"类加载过程 一个类从加载到卸载的生命周期如上图所示. 其中验证, 准备, 解析三个阶段也统称为链接阶段. 加载在加载阶段, Java虚拟机需要完成三件事情 根据类的全限定名获取其二进制流 将二进制流转化为方法区的运行时数据结构 在内存中生成一个代表这个类的class对象, 作为方法区这个类各种数据的访问入口 因为并没有规定如何获取二进制流, 因此在实现的时候有多种选择, 例如从压缩包(jar)或者网络(web applet)读取, 这些读取方法各自产生了一些Java的技术. 加载阶段和链接阶段可以有一部分重叠, 在加载还没有完全结束之前, 就可以先开始一部分链接阶段的工作(例如开始部分验证工作). 验证验证阶段主要的工作是验证字节码是否满足Java虚拟机中的约束要求, 是否存在危害虚拟机安全的代码. Java语言规定了很对不安全的行为, 包括数组越界, 跳转到不存在的代码位置等. 如果在Java语言中出现了这些行为, 代码将无法编译. 但字节码文件可以通过其他方式产生, 因此JVM并不能直接信任字节码文件中的代码. 验证阶段的内容比较多且比较细节, 具体可以查看Java Virtual Machine Specification 5.4.1. Verification 准备准备阶段的工作是为类变量(类中的静态变量)分配内存空间并赋予初始值. 这一阶段的内存分配工作与实例变量没有关系, 从逻辑上将, 这是在方法区分配内存空间. 不过在最终的实现上, HotSpot虚拟机的方法区也位于Java堆上. 如果静态变量并没有被final修饰, 那么赋予的初始值是相应类型的零值, 而实际的赋值在类构造器&lt;clinit&gt;()方法之中. 反之, 如果被final修饰, 那么此时就会赋予给定的初始值. 解析解析阶段的主要工作是将常量池中的符号引用替换为直接引用. 初始化初始化阶段执行用户在Java代码中写的初始化语句, 包括对static变量赋值和位于static&#123;&#125;代码块中的其他代码. 编译器会自动收集这些操作, 并在&lt;clinit&gt;()方法中进行调用. 对于类, 虚拟机保证父类的&lt;clinit&gt;()方法会比子类的&lt;clinit&gt;()方法先执行. 而对于接口, 只有使用到父类的字段时才会对父类进行初始化, 否则仅初始化子类的接口. 虚拟机保证在多线程环境下, 初始化过程能够被正确的同步. 类加载器类加载器用于实现类的加载动作, 但对于每一个类, 加载它的类加载器和这个类本身一起共同确立其在Java虚拟机中的唯一性. 也就是说同一个类加载器加载的同一个类才是相同的, 不同的类加载器即使加载了同一个类, 在JVM中也认为是不同的. 双亲委派模型JVM的类加载器使用双亲委派模型, 即系统中存在多种不同的类加载器, 各种类加载器之间存在一定的层次结构. 其示意图如下图所示 其中Bootstrap Class Loader由JVM提供实现, 用于加载核心的类. Extension Class Loader和之后的类加载器都使用功Java实现, 其中Extension Class Loader加载扩展类, 而Application Class Loader加载用户自定义的类. 每当一个类加载器需要加载一个类时, 其首先将这一加载请求委托给父加载器处理, 如果父加载器无法处理, 再由自己进行处理. 其代码如下所示 12345678910111213141516171819202122232425262728protected synchronized Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException&#123; // 首先，检查请求的类是否已经被加载过了 Class c = findLoadedClass(name); if (c == null) &#123; try &#123; if (parent != null) &#123; c = parent.loadClass(name, false); &#125; else &#123; c = findBootstrapClassOrNull(name); &#125; &#125; catch (ClassNotFoundException e) &#123; // 如果父类加载器抛出ClassNotFoundException // 说明父类加载器无法完成加载请求 &#125; if (c == null) &#123; // 在父类加载器无法加载时 // 再调用本身的findClass方法来进行类加载 c = findClass(name); &#125; &#125; if (resolve) &#123; resolveClass(c); &#125; return c;&#125; 使用双亲委托模型可以保证核心的库始终被Bootstrap Class Loader加载. 基础的类库不会因为不同的加载器加载导致出现混乱. 自定义的类加载器应该重写findClass方法, 从而复用loadClass的双亲委派逻辑 模块化的类加载器JDK9中引入模块化系统, 模块化下的类加载器发生了一些变化. 首先, Extension Class Loader被Platform Class Loader取代, 因为模块化以后, 模块天然具有扩展性, 因此不再需要Extension Class Loader. 并且由于模块化之后, 新版本的JDK中也不再单独提供jre目录, 用户可以根据自己的需要在jmod中选择需要的模块构成自定义的jre. 其次, 平台类加载器和应用程序类加载器都不再派生自java.net.URLClassLoader, 如果之前的程序依赖了相关的方法, 那么在新的JDK上可能会启动失败.","categories":[{"name":"深入理解JVM","slug":"深入理解JVM","permalink":"https://lizec.top/categories/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JVM/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://lizec.top/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"https://lizec.top/tags/JVM/"}]},{"title":"深入理解JVM之字节码","slug":"深入理解JVM之字节码","date":"2021-01-11T06:21:12.000Z","updated":"2021-01-11T11:50:18.000Z","comments":true,"path":"2021/01/11/深入理解JVM之字节码/","link":"","permalink":"https://lizec.top/2021/01/11/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JVM%E4%B9%8B%E5%AD%97%E8%8A%82%E7%A0%81/","excerpt":"","text":"本文主要介绍Java虚拟机的字节码相关的内容. 由于Java字节码的独特设计, 使得大部分指令仅需要一个字节即可表示, 这也是其被称为字节码的原因. 由于Java字节码严格区分数据类型, 因此很多指令都会针对不同的数据类型单独设计一条指令. 例如load指令根据数据类型的不同, 就存在iload和fload等特殊指令. 但如果每一条指令都针对各种数据类型设计一种字节码, 那么字节码的范围可能也无法容纳. 因此JVM引入了一些不平衡的设计, 对于部分指令, 并没有专用的字节码, 而是与其他类型共用一种字节码. 下面将字节码分为不同的大类, 分别介绍其含义. 加载与存储指令 字节码 含义 &lt;T&gt;load , &lt;T&gt;load_&lt;n&gt; 将局部变量加载到操作栈 &lt;T&gt;store, &lt;T&gt;store_&lt;n&gt; 将操作栈上的数据存储到局部变量 &lt;T&gt;const_&lt;I&gt; 将指定类型的常量I加载到操作栈 bipush, sipush 将byte类型/short类型的指定常量推送到操作栈顶 补充说明 iload表示将一个指定的int类型数据加载到操作栈, 而fload_2表示将第二个本地的float变量加载到操作栈. iconst_1表示把int类型的常量1加载到操作栈, 而dconst_2表示把double类型常量2.0加载到操作栈. bipush指令后面需要加上需要推送的数字 ldc, ldc_w, ldc2_w, aconst_null, iconst_m1, wide 运算指令运算指令与汇编的命名基本相同, 具体如下 操作 字节码格式 算术操作 &lt;T&gt;add, &lt;T&gt;sub, &lt;T&gt;mul, &lt;T&gt;div, &lt;T&gt;rem, &lt;T&gt;neg, &lt;T&gt;inc 移位操作 &lt;T&gt;[u]shl&lt;l/r&gt; 逻辑操作 &lt;T&gt;or, &lt;T&gt;and, &lt;T&gt;xor 比较操作 &lt;f/d&gt;cmp&lt;g/l&gt; lcmp 所有的运算操作的结果都会自动压入操作栈(虽然这好像是废话) 移位操作可选有符号移位和无符号移位, 左移和右移, 例如iushl表示int型无符号左移 比较操作先比较栈顶两个数字的大小, 并将比较结果(-1, 0, 1)入栈 浮点类型的比较操作可以对NaN进行特殊处理, 例如fcmpg表示存在NaN时将1入栈, 而dcmpl表示存在NaN时将-1入栈 Java虚拟机规划规定, 除了div和rem指令遇到除数为零的情况抛出异常以外, 其他任何整数运算都不会抛出算术异常 类型转换指令 操作 字节码格式 类型转换 &lt;T&gt;2&lt;U&gt; 将long类型转化为int类型的指令为l2i. 将double类型转化为int类型的指令为d2i 整数转换直接丢弃高位数据, 这一操作可能导致符号变化 浮点类型转整数类型T遵循如下的规则 如果浮点数为NaN, 则相应的整数为0, 否则先按照规则舍入成整数V 如果V处于T的表示范围, 则转换值为V 否则根据V的符号转化为T能表达的最大值或最小值 double类型数据转为float类型数据, 按照规划处理 将double类型数据舍入为最接近的float类型数据 如果double类型数据绝对值太小, 返回float类型的正负零 如果doubel类型数据绝对值太大, 返回float类型的NaN 如果double类型数据为NaN, 返回float类型的NaN 对象创建与访问指令 操作 字节码格式 创建对象 new 创建数组 newarray, anewarray, multianewarray 访问对象 getfield, putfield, getstatic, putstatic 访问数组 &lt;T&gt;aload, &lt;T&gt;astore, arraylength 检查实例 instanceof, checkcast 操作数栈管理指令 操作 字节码格式 出栈 pop, pop2 复制 dup, dup2, dup_x&lt;I&gt;, dup2_x&lt;I&gt; 交换 swap pop和pop2分别表示将1个/2个元素出栈 swap表示交换栈顶的两个元素 dup系列的指令比较复杂, 其复制操作涉及到栈顶数据的长度. dup2既可以复制栈顶的一个2倍长度的数据, 也可以复制两个1倍长度的数据. 控制转移指令控制转移指令与汇编类似, 不过转移条件都是根据栈顶元素确定, 包括如下的指令 操作 字节码格式 条件跳转 ifeq, iflt, ifle, ifne, ifgt, ifge, ifnull, ifnonnull 比较跳转 if_icmpeq, if_icmpne, if_icmplt, if_icmpgt, if_icmple, if_icmpge 引用比较 if_acmpeq, if_acmpne 复合条件 tableswitch, lookupswitch 无条件分支 goto, goto_w, jsr, jsr_w, ret 条件跳转指令比较栈顶int值与0的大小, 并决定是否跳转 比较跳转指令比较栈顶两个int值的大小, 并确定是否跳转 对于小于int范围的数据, 使用int类型的比较跳转指令 对于浮点类型, 先执行比较指令, 然后使用条件跳转指令进行跳转 方法调用和返回指令 操作 字节码格式 方法调用 invoke&lt;virtual / interface / special / static/ dynamic&gt; 返回 &lt;T&gt;return 前四种方法调用指令分别调用对象的实例方法, 接口方法, 特殊方法(例如初始化方法)和静态方法 第五中方法调用指令调用运行时动态解析的方法 调用函数不区分类型, 返回时指定返回值类型 异常指令使用athrow指令抛出栈顶的异常对象. 此外JVM内部的一些操作也会抛出异常, 例如除法的除数为零. 同步指令Java的同步分为方法级同步和代码段同步. 方法级同步是隐式实现的, 蕴含在方法调用和返回的字节码中. 而代码段级别的同步是显式的, 使用monitorenter和monitorexit实现. 扩展资料 JVM 虚拟机字节码指令表 Java虚拟机规范 第六章Java虚拟机指令集","categories":[{"name":"深入理解JVM","slug":"深入理解JVM","permalink":"https://lizec.top/categories/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JVM/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://lizec.top/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"https://lizec.top/tags/JVM/"}]},{"title":"数据结构知识库","slug":"数据结构知识库","date":"2020-11-29T14:36:46.000Z","updated":"2021-03-03T09:06:23.000Z","comments":true,"path":"2020/11/29/数据结构知识库/","link":"","permalink":"https://lizec.top/2020/11/29/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%9F%A5%E8%AF%86%E5%BA%93/","excerpt":"","text":"栈的性质栈满的时候要考虑上溢的情况，栈空的时候要考虑下溢的情况。 队列的性质设队尾指针是rear, 队头是front, 循环队列的最大长度为QueueSize, 循环队列的相关条件和公式为: 条件 代码 条件 代码 队空条件 rear==front 队满条件 (rear+1) % QueueSIze==front 入队位置 (rear+1)%QueueSize 出队条件 (front+1) % QueueSize 计算队列长度 : (rear-front+QueueSize) % QueueSize 二叉树的性质节点与度的关系设k为节点数, 则整个树的度为k-1, 分别考虑节点数量和度数量有 k = n0 + n1 + n2k-1 = 2*n2 + n1 求解上式可得 n0 = n2 + 1 即度为0的节点数为度为2的节点数加1 二叉树的种类完全二叉树: 对于深度为K的，有n个结点的二叉树，当且仅当其每一个结点都与深度为K的满二叉树中编号从1至n的结点一一对应时称之为完全二叉树。注意: 完全二叉树在给定深度的情况下, 存在最多节点和最少节点两种情况 二叉排序树: 左右子节点和根节点满足排序关系的树, 也就是最基本的树 树转森林与森林转树 将树通过儿子兄弟表示法变成二叉树 由于根节点右子树为空, 因此依次连接所有的树 二叉树转森林过程相反, 断开所有右子树的连接即可 B树对于m阶B树 每个节点至多有m个节点 除了根节点与叶节点外, 每个节点至少有 m/2向上取整 个节点 根节点至少有两个节点 所有叶子节点在同一层 有k个子节点的非根节点包含k-1个关键码 平衡二叉树 什么是平衡二叉树（AVL） 查找表静态查找表（Static Search Table）：只作查找操作的查找表。A：查询某个“特定”数据元素是否在查找表中；B：检索某个“特定”数据元素和各种属性。 动态查找表（Dynamic Search Table）：在查找过程同时插入查找表中不存在的数据元素，或者从查找表中删除已经存在的某个数据元素。A：查找是插入数据元素；B：查找时删除数据元素。 最优二叉树最优二叉树就是从已给出的目标带权结点(单独的结点) 经过一种方式的组合形成一棵树，使树的权值最小.最优二叉树是带权路径长度最短的二叉树, 典型代表是*哈夫曼树 胜者树与败者树假设数据直接进行比赛, 中间节点记录比赛的胜者信息, 由此构成的树称为胜者树. 借助于这一结构, 可以快速的找到一组数据中的最大值, 并且可以不断的插入和删除数据 堆的性质堆一般构造成完全二叉树的结构, 但这只是为了计算简便, 也可以构造满足堆要求但不是完全二叉树的结构 哈希表冲突解决算法 开放地址法: 根据某种规则使用其他的位置, 例如线性探查法, 平方探查法 再哈希法: 使用另外的哈希函数在此计算, 包括 拉链法: 也称为链地址法, 即使用链表 建立公共溢出区 开放地址法可以将所有数据都存放在哈希表的数组中, 而不必引入额外的链表结果, 因此结构上更简单. 但是非常不适合需要删除数据的情况. 当删除数据时, 除了删除当前元素, 还需要妥善的处理之前由于碰撞而放到其他地方的元素. 无论是移动元素还是加入DELETE标记, 都会引入额外的开销. 解决Hash碰撞冲突方法总结 图的性质基本概念图的表示方法: 对于图 G=(V, E) 有两种表示方法, 分别是邻接链表和邻接矩阵, 当边的数量\\(E\\)远远小于\\(V^2\\)时(即稀疏图), 使用邻接链表表示法更加紧凑, 反之可能使用邻接矩阵更加简单. 此外如果希望快速判断两个节点之间是否联通, 使用邻接矩阵也更快. 由于两种存储方式的差异, 可以认为邻接链表的空间复杂度为\\(O(V+E)\\), 而邻接矩阵的空间复杂度为\\(O(V^2)\\). 由于很多图的操作本质上是对图的数据结构的遍历, 因此存储结构的差异也决定了这些操作的时间复杂度. 邻接表: 邻接表是表示了图中与每一个顶点相邻的边集的集合邻接多重表: 与邻接表的差别，仅仅在于同一条边在邻接表中用两个节点表示，在邻接多重表中只用一个节点 注意: 边的数量与度的区别, 无向图中一条边会计算两次度 入度与出度: od表示初度，id表示入度 邻接表的边结点是指示弧尾到弧头，而逆邻接表的边结点指示弧头到弧尾，所以有多少条边就有多少个结点，一一对应，逆邻接表中边节点个数等于邻接表边结点个数 拓扑排序拓扑排序有两种计算方式, 通常的拓扑排序可以表述为, 依次从图中选择入度为0的边, 将其从图中移除并输出该节点. 以下图为例, 可以依次 1234567digraph graphname &#123; rankdir=LR; 1 -&gt; 4 -&gt; 5; 1 -&gt; 2 -&gt; 4; 2 -&gt; 3 -&gt; 5; 4 -&gt; 3;&#125; 输出节点1, 移除节点1指向2和4节点的边 输出节点2, 移除节点2指向3和4节点的边 省略后续操作… 拓扑排序也可以用深度优先遍历算法完成. 此时深度优先算法在递归开始前和递归结束后都需要给每个节点一个遍历的时间戳, 然后按照结束时间戳的大小进行排序输出. 对上面的图遍历结果如下图所示: 12345678910111213digraph graphname &#123; rankdir=LR; 1 [label=&quot;1(1/10)&quot;]; 2 [label=&quot;2(2/9)&quot;]; 3 [label=&quot;3(3/6)&quot;]; 4 [label=&quot;4(7/8)&quot;]; 5 [label=&quot;5(4/5)&quot;]; 1 -&gt; 4 -&gt; 5; 1 -&gt; 2 -&gt; 4; 2 -&gt; 3 -&gt; 5; 4 -&gt; 3;&#125; 其中括号内数字表示开始遍历和结束遍历时的时间戳大小. 拓扑排序算法和深度优先遍历都可以实现有向无环图的拓扑排序, 但针对有环的情况, 拓扑排序能够探测到环的存在, 而深度优先遍历无法探测到环的存在. 最小生成树最小生成树有两个算法, 分别是Kruskal算法和Prim算法. Kruskal算法通过不断合并两个集合完成最小生成树的构建, 而Prim通过不断加入新的点来实现最小生成树的构建. 流量计算技巧： 按层计算，瞻前顾后 首先计算每一层向终点方向的最大输出能力，不包括回流的量然后计算总体的最大流量，为各个层中流量最小的一层的流量 本题中分为三层：第一层为s。 朝终点最大输出量为11+22+10 = 43第二层为节点1、2、3。 朝终点最大输出量为10+17+14 = 41（10是因为节点4最多接受10，出度为10，14是因为节点3的入度为14，所以是14而不是16）第三层为节点4、5、6。 朝终点最大输出量为10+16+16 = 42所以综合考虑总体最大的流量只能41. 拓扑排序拓扑排序算法将一个有向, 无环图 排列成一个有序序列. 图的深度优先遍历有一个特点: 当一个顶点的子结点都被访问完了, 该顶点才会结束访问, 并开始向上回溯访问它的父结点的其它子结点==&gt; 一个顶点的结束访问时间与其子结点的结束访问时间存在先后关系 ==&gt; 逆拓扑排序注意: 此方案无法检测环路 关键路径关键路径是指设计中从输入到输出经过的延时最长的逻辑路径 最小生成树Prim算法: 从一个顶点开始, 依次选择可到的边中, 权值最小的Kruskal算法: 对边权值进行排序, 依次选择权值最小的边, 如果这条边连接了新的点, 则加入 相比于Kruskal算法，Prim算法更适合于求边稠密的无向网的最小代价生成树 图的基本算法（最小生成树） 其他内容总时差TF(Total Float):一项工作在不影响总工期的前提下所具有的机动时间, 最迟完成时间与最早完成时间之差自由时差FF(Free Float): 一项工作在不影响其紧后工作最早开始时间的条件下, 本工作可以利用的机动时间 总时差就是拖拖拖，可以拖多少天才做工作M，自由时差就是早早完成，然后在下次工作委派之前可以休息多少天 排序 排序算法 平均时间 空间 排序方式 稳定性 冒泡排序 O(n^2) O(1) In-place 稳定 选择排序 O(n^2) O(1) In-place 不稳定 插入排序 O(n^2) O(1) In-place 稳定 希尔排序 O(nlogn) O(1) In-place 不稳定 归并排序 O(nlogn) O(n) Out-place 稳定 快速排序 O(nlogn) O(logn) In-place 不稳定 堆排序 O(nlogn) O(1) In-place 不稳定 计数排序 O(n+k) O(k) Out-place 稳定 桶排序 O(n+k) O(n+k) Out-place 稳定 基数排序 O(nk) O(n+k) Out-place 稳定 完整信息可参考排序表 空间复杂度说明: 归并排序需要一个额外的空间做合并操作 快速排序由于递归而产生对数级别的空间占用 计数排序k表示数据分布范围, 基数排序k表示数字的位数 稳定性分析: 选择排序由于直接交换位置, 因此可能导致顺序变化, 而冒泡和插入排序只移动相邻的元素, 因此顺序不变 希尔排序和快速排序显然不稳定 归并排序按照顺序划分区间, 按照顺序合并区间, 因此稳定 堆排序建立堆的过程按照堆结构交换元素位置, 因此顺序可能变化 排序方法说明: 堆排序: 首先构建一个最大堆, 依次将堆顶元素与最后一个未排序元素交换 计数排序: 已知数字位于0..99, 开一个100元素的数组, 每遇到一个数字, 数组相应位置++, 最后输出 遍历数据一次, 遍历记录的数组一次, 因此时间复杂度为O(n+k), 空间复杂度为记录数组的消耗, 为O(k) 桶排序: 先将数据映射到不同的桶中, 然后对桶内数据进行排序, 最后合并所有数据 桶排序是计数排序的升级版, 计数排序相当于每个数字一个桶 计数排序 基数排序的正确性 如果给定如下的一组数据, 并进行基数排序, 则排序结果如下表所示 123 234 345 532 244 332 451 321 第一轮 第二轮 第三轮 451 321 123 321 123 234 532 532 244 332 332 321 123 234 332 234 244 451 244 451 532 注意在进行第k轮排序后, 如果只看末尾的k位数字, 则这部分数据均是正确排序的. 例如经过第二轮排序后, 如果只看每个数字的末尾两位, 那么这些两位数都是正确排序的. 那么在进行第k+1轮排序时, 针对每一个桶内的数字, 第k+1位是相同的, 而末尾的k位根据顺序, 数字越小越先进入桶中, 因此经过第k+1轮排序后, 末尾的k+1位数字都是正确排序的. 根据这个性质, 可以显然的证明基数排序的正确性. 主定理对于一个递推公式 $$T(n) = aT(n/b) + O(n^d)$$ 并且令 $$f=\\log_{b}{a}$$ 则可以通过比较f与d的大小关系获得递推式的时间复杂度 相对关系 时间复杂度 f &gt; d \\(O(n^f)\\) f = d \\(O(n^f \\log{n})\\) f &lt; d \\(O(n^d)\\) 主定理 Master Theorem","categories":[],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"https://lizec.top/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]},{"title":"VIM笔记","slug":"VIM笔记","date":"2020-11-01T13:26:02.000Z","updated":"2021-01-12T10:38:33.660Z","comments":true,"path":"2020/11/01/VIM笔记/","link":"","permalink":"https://lizec.top/2020/11/01/VIM%E7%AC%94%E8%AE%B0/","excerpt":"","text":"由于最近经常需要在服务器端简单修改一些配置文件, 因此有必要了解一下VIM的基本操作. 此外, 目前的主流IDE基本都提供了VIM的键位映射, 虽然这些键位映射的模式并不能等同于VIM, 但大部分基本操作都是支持的. 因此掌握了VIM的基本操作还是能够在其他IDE上提高代码的编辑速度. 目前的个人体验是, VIM适合编辑不太依赖代码补全的项目, 例如Python. 对于需要切换输入法的场景, 例如写博客, 由于多了切换的步骤, 因此不适合VIM. 对于写LeetCode这种可能要手写代码的场景, 可以考虑使用VIM作为IDE. 由于VIM的操作实在是太多, 根本不可能完全的记住, 所以本文采取需求驱动的方法, 每次遇到一个需求时, 使用查询VIM的相关用法, 并记录再这里. 按照这样的规律进行学习可能更容易记住相关的操作. 搜索和替换在正常模式输入/进入搜索模式, 此时直接搜索需要的字符串, 即可在文本中进行搜索. 输入要查找的字符串并按下回车进入搜索模式, 此时按n查找下一个, 按N查找上一个. 查找过程支持正则表达式. VIM使用:substitute指令进行搜索和替换, 这一指令通常简写为:s, :s将当前行的指定字符串替换为另外一个字符串, 格式如下 1:s/&lt;find-this&gt;/&lt;replace-with-this&gt;/&lt;flags&gt; 在 Vim 中优雅地查找和替换 行号跳转 gg: 跳转到第一行 G: 跳转到最后一行 &lt;N&gt;G/:&lt;N&gt;: 跳转到第N行 快速跳转 fa: 移动到下一个字母a上 ta: 移动到下一个字母a之前 如果使用大写字母, 则可以反向搜索 这些指令可以组合使用, 例如dt&quot;表示从当前光标位置删除内容直到&quot;之前. 键位图 需要的时候看一看就可以了, 反正也记不住 VIM基础配置VIM基本上是不能认为开箱即用的, 需要进行一些基本配置. VIM的配置位于用户目录的.vimrc文件, 建议在其中加入如下的内容 1234567891011121314syntax on &quot; 开启语法高亮filetype plugin indent on &quot; 根据文件类型自动缩进set autoindent &quot; 开始新的一行时自动缩进set expandtab &quot; 将Tab展开为空格set tabstop=4 &quot; tab的空格数set shiftwidth=4 &quot; 自动缩进的空格数set hlsearch &quot; 高亮搜索结果set incsearch &quot; 在没有完成搜索输入时, 就根据搜索输入开始匹配set backspace=2 &quot; 修正backspace的行为set number &quot; 显示行号colorscheme slate &quot; 颜色主题 如果只是使用VIM的键位映射, 那么就没必要进行配置了 参考资料 简明 VIM 练级攻略 Linux vi/vim | 菜鸟教程 Vim简明教程【CoolShell】 Vim配置及说明——IDE编程环境","categories":[],"tags":[]},{"title":"深入理解JVM之内存与线程","slug":"深入理解JVM之内存与线程","date":"2020-10-29T07:12:25.000Z","updated":"2021-03-02T08:12:49.000Z","comments":true,"path":"2020/10/29/深入理解JVM之内存与线程/","link":"","permalink":"https://lizec.top/2020/10/29/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JVM%E4%B9%8B%E5%86%85%E5%AD%98%E4%B8%8E%E7%BA%BF%E7%A8%8B/","excerpt":"","text":"Java内存模型由于不同的物理硬件和操作系统使用了不同的内存模型, 因此Java虚拟机需要提供一套内存的标准, 使得Java在不同平台下有同样的内存模型. Java内存模型主要目标是定义程序中各个变量的访问规则. Java内存模型规定所有的变量都存储在主内存中, 同时每个线程还有自己的工作内存, 工作内存保存了线程需要使用的变量的主内存的副本. 线程对变量的所有操作都在工作内存上进行, 而不能直接对主内存读写. 各个线程的工作内存相互独立, 只能通过主内存交换信息. 内存间操作Java内存模型定义了以下的8种操作来完成工作内存与主内存的同步, 每一种操作都是原子的. 操作 作用位置 作用 lock 主内存 将变量标记为线程独占状态 unlock 主内存 对变量解除线程独占状态 read 主内存 将变量的值从主内存取出 load 工作内存 接受主内存取出的值并放入工作内存 use 工作内存 将工作内存的值传递给执行引擎 assign 工作内存 将从执行引擎受到的值写入工作内存 store 工作内存 将变量的值从工作内存取出 write 主内存 接受工作内存取出的值并写入主内存 read和load, store和write不能单独使用, 但可以在两者之间插入其他无关的指令, 例如对主内存的a,b进行访问可以执行 1234read aread bload bload a 这些指令还需要以下的规则 不允许丢弃assign操作, 即执行引擎的计算结果必须同步到主内存 不允许无原因的(无assign操作)把数据从工作内存同步到主内存 变量只能在主内存创建, 一个变量只能被一个线程lock, 但一个线程可以多次lock同一变量, 最后需要unlock同样的次数 一个变量被lock以后,会清除工作内存的值, 之后需要重新load或assign 不可以unlock没有被lock的变量, 也不可以unlock其他线程lock的变量 变量执行unlock之前, 必须同步回主内存 volatile变量的特殊规则volatile是Java提供的最轻量级的同步机制. volatile有两个特性, 第一是保证此变量对所有线程的可见性, 即一个线程修改了这个变量的值, 其他线程可以立即得知. 对于普通的变量, 一个线程修改了变量以后, 需要先写回主内存, 其他线程从主内存读取后才会获得变量新的值. volatile可以保证每次读取的值都是最新的, 但是不能保证并发安全. 只有以下两种情况适合使用volatile保证原子性 运算结果不依赖变量的当前值, 或者只有一个线程修改变量的值 变量不需要与其他的状态变量共同参加不变约束 第二个特性是禁止指令重排序优化. 普通的变量只保证在依赖赋值结果的地方获得正确的结果, 而不保证计算顺序与代码顺序一致. 123456789101112131415Map configOptions;char[] configText;volatile boolean initialized = false;// 假设在A线程中执行配置文件初始化的操作configOptions = new HashMap();configText = readConfigFile(fileName);processConfigOptions(configText,configOptions);initialized = true;// 假设B线程通过initialized变量判断配置文件是否处理完毕while(!initialized)&#123; sleep();&#125;doSomethingWithConfig(); 由于指令重排序, 当initialized为普通变量时, initialized = true;语句可能会提前执行, 这样就会导致B线程出现错误. Java线程的实现线程一般有三种实现方法, 分别是使用内核线程实现, 使用用户线程实现, 使用用户线程加轻量级进程混合实现. 内核线程实现是将Java的线程映射到操作系统内核直接支持的进程上(Kernel-Level Thread, KLT), 这种线程由内核完成线程的调度功能. 但程序一般不直接使用KLT, 而使用KLT的一种高级接口轻量级进程(Light Weight Process，LWP) 由于使用了内核支持的线程, 因此一次线程阻塞不会影响其他线程. 但线程调度由操作系统完成, 需要进行用户态和内核态的切换. 切换代价比较高. 内核线程需要消耗系统的资源, 因此操作系统能支持的内核线程数量也有限. 用户线程实现是在用户态实现线程的调度功能, 从而操作系统对用户线程不可感知. 由于不借助于操作系统内核, 因此不需要切换用户态, 线程调度的消耗更低. 但诸如处理器分配和线程映射到特定处理器之类的功能也因为不借助于操作系统内核而难以实现或根本无法实现. 混合实现混合了上面两种线程的实现方法. Java虚拟机早期有基于用户线程的实现方案, 目前主流的Java虚拟机都基于内核线程实现 Java API与线程安全Java API标记为线程安全的类并不能保证绝对的线程安全. 例如Vector类在所有的操作上都加上了synchronized关键字, 但是存在多个线程同时修改和删除时, 依然会产生线程问题. 123456789101112131415161718192021222324252627private static Vector&lt;Integer&gt; vector = new Vector&lt;&gt;(); public static void main(String[] args) &#123; while (true)&#123; for(int i=0;i&lt;10;i++)&#123; vector.add(i); &#125; Thread removeThread = new Thread(() -&gt; &#123; for(int i=0;i&lt;vector.size();i++)&#123; vector.remove(i); &#125; &#125;); Thread printThread = new Thread(() -&gt; &#123; for(int i=0;i&lt;vector.size();i++)&#123; System.out.println(Thread.currentThread().getName()+ &quot; &quot;+(vector.get(i))); &#125; &#125;); removeThread.start(); printThread.start(); // 这里使用空循环控制线程的数量 while (Thread.activeCount() &gt; 20); &#125; &#125; 执行上述代码, 可以在控制台发现抛出了如下的异常(注意: 由于是子线程的异常, 此异常只会在控制台显示而不会终止当前程序) 1234java.lang.ArrayIndexOutOfBoundsException: Array index out of range: 10 at java.util.Vector.remove(Vector.java:834) at top.lizec.TestVector$1.run(TestVector.java:18) at java.lang.Thread.run(Thread.java:748) Vector虽然所有的方法都使用了synchronized关键字进行锁定, 但是两个方法连续执行时, 无法保证不发生线程切换, 因此执行删除任务时, 获得的size数据可能已经失效, 进而导致越界. 对于这种场景, 还是需要使用同步的方式来手动锁定一段代码. 实现线程安全互斥同步互斥同步的基本操作就是synchronized关键字, 此外Java也提供了ReentrantLock. 两者的实现并没有太大区别, 但ReentrantLock具有如下的一些特点 等待可中断 公平锁 绑定多个条件 使用ReentrantLock时, 等待线程可以决定是都中断等待. 创建ReentrantLock时, 可以确定是否使用公平锁, 是否绑定多个Condition. 在JDK1.6以前, ReentrantLock相比synchronized关键字具有更好的性能, 但在JDK1.6以后, 两者在性能上并没有显著的区别. 考虑到synchronized由编译器自动控制锁释放, 因此应该默认优先使用synchronized关键字. 非阻塞同步在这种模式下, 程序假设并不存在频繁的竞争, 在大部分情况下, 不进行同步操作, 而是直接操作数据. 如果发现数据产生冲突, 再进行补救的方法. 比较和交换(Compare-and-Swap, CAS) 一条CPU指令, 大部分指令集中都有相同或类似的指令. CAS操作需要三个操作数, 即变量内存地址V, 旧的预期值A, 新的值B. CAS执行首先判断变量V的值是否为旧的预期值A, 如果满足则使用新的值B替换, 否则不执行任何操作. 如果是否成功执行, 都会返回V的旧值. 无同步方案如果两个线程之间没有数据共享, 那么就不需要进入任何的同步处理, 从而天然的实现线程安全. 这样的代码有两类常见的方案 可重入代码(Reentrant Code), 也称为纯代码(Pure Code), 这样的代码在任意位置中断执行, 转去执行其他代码, 再恢复执行也不会导致错误. 可重入代码都是线程安全的. 可重入代码一般都具有如下的一些特点 不依赖堆上变量, 不依赖公共变量 状态量由参数传入 不调用非可重入方法 如果一个方法的结果可以预测, 只要输入了相同的数据, 则必定返回相同的输出, 则这个方法是可重入的. **线程本地存储(Thread Local Storage)**的核心思想是将使用相同数据的操作尽可能集合到一个方法之中, 从而将需要共享的变量变为本地变量. 经典的Web交互模型中, “一个请求对应一个线程”的处理方法就是这种思想的典型表现. 如果一个变量仅仅需要保存在线程本地, 可以使用ThreadLocal对象. 锁优化自旋锁由于将线程挂起涉及到系统调用, 整体开销比加大, 所以引入了自旋锁机制. 当一个线程等待一个锁的时候, 并不是立即被挂起, 而是执行一个忙循环, 这个忙循环被称为自旋. 当自旋时间比较短时(例如自旋10次), 自旋锁的效果比较好. 从JDK1.6开始, 引入了自适应自旋锁, 虚拟机会根据之前的情况决定自旋的最大次数. 锁消除和锁粗化JVM的即时编译器在运行时, 可以分析代码是否需要进行锁定, 如果判断锁定没有必要, 则可以消除相应的锁定. 判断的依据是逃逸分析. 通常情况下, 锁定的范围应该是越小越好, 但如果在循环中使用锁定块, 则会导致频繁的加锁和解锁, 反而导致性能下降. JVM可以探测这种操作, 并且自动将锁的范围扩大到外部, 从而一次加锁即可完成全部操作. 偏向锁与轻量级锁JVM对于加锁这一操作, 实现了三个不同等级的加锁, 分别是偏向锁, 轻量级锁和重量级锁. 这三个锁分别解决只有一个线程进入临界区, 多个线程交替的进入临界区, 以及多个线程希望同时进入临界区的情况. 在对象的头部, 依据不同的状态, 使用不同的结构存储了不同的信息, 具体如下图所示 这一部分数据称为Mark Word, 是实现偏向锁和轻量级锁的关键. 偏向锁 的目的是消除无竞争状态下的整个同步操作. 偏向锁会偏向于第一个获得此锁的线程, 如果后续此锁没有被其他线程获得, 则获得此线程的锁永远不需要进行同步. 当锁对象初次被线程获得时, JVM使用CAS操作替换Mark Word并使用偏向模式, Mark Word中记录了获得此对象锁的线程ID. 一个线程A获得偏向锁后不会主动释放锁, 因此后续A进入此锁的同步块时, 不需要进行任何同步操作(只需要对比线程ID是否相同). 当另外一个线程B尝试获取此锁时, 由于对象上的标记为偏向状态, 因此首先检查A是否还持有这个锁. 如果A已经结束或者不持有这个锁, 那么对象头恢复到未锁定状态, 然后B按照偏向锁的规则重新尝试获得偏向锁. 如果A没有结束, 那么偏向状态结束, 当程序到达安全点时, 暂停A线程, 将其锁定方式替换为轻量级锁, 从而线程A以轻量级锁的方式持有对象. 之后A和B按照轻量级锁的方式竞争. 偏向锁在无竞争状态下获得高性能, 在频繁竞争环境下, 第一次的偏向操作就纯粹是多余操作了. 可以使用-XX:-UseBiasedLocking来控制是否启用偏向锁. 轻量级锁针对多个线程都需要锁, 但基本不存在同时请求锁的情况. 轻量级锁使用CAS实现同步, 因此相比于引入操作系统的信号量, 轻量级锁消耗的性能更少. 在执行轻量锁时, JVM首先在栈上分配一段称为Lock Record空间, 其中存放了当前对象的Mark Word的拷贝, 接下来JVM尝试使用CAS操作将对象头部替换为指向Lock Record的指针. 如果操作成功, 那么获得锁. 后续通过反向使用CAS将记录替换回来即可释放锁. 当线程A和线程B同时尝试获取轻量级锁时, 必然有一个线程的CAS操作失败, 此时可以通过自旋的方式等待锁. 如果一个线程A已经获得锁, 使对象进入锁定状态, 那么另外一个线程B也可以通过自旋等待锁的释放, 如果达到自旋次数后仍未获得锁或者第三个线程尝试获得锁, 则轻量级锁碰撞为重量级锁, 此时Mark Word存储指向重量级锁(互斥量)的指针, 后面等待的线程进入阻塞状态. 与偏向锁一样, 如果线程竞争压力很大, 那么轻量级锁也是多余操作了. 参考资料 看完这篇恍然大悟，理解Java中的偏向锁，轻量级锁，重量级锁","categories":[{"name":"深入理解JVM","slug":"深入理解JVM","permalink":"https://lizec.top/categories/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JVM/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://lizec.top/tags/Java/"},{"name":"多线程","slug":"多线程","permalink":"https://lizec.top/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"JVM","slug":"JVM","permalink":"https://lizec.top/tags/JVM/"}]},{"title":"Wireshark数据分析笔记","slug":"Wireshark数据分析笔记","date":"2020-10-21T03:49:30.000Z","updated":"2020-10-22T09:06:24.000Z","comments":true,"path":"2020/10/21/Wireshark数据分析笔记/","link":"","permalink":"https://lizec.top/2020/10/21/Wireshark%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E7%AC%94%E8%AE%B0/","excerpt":"","text":"路由器抓包如果路由器是OpenWrt系统, 那么可以使用管道的方式将数据传输给WireShark进行分析. 首先在OpenWrt路由器上安装工具 12opkg updateopkg install tcpdump 然后执行下面的指令将网络数据通过管道传递给Wireshark执行 1ssh root@openwrt &#x27;tcpdump -s 0 -U -n -w - -i br-lan&#x27; | &quot;C:\\Program Files\\Wireshark\\Wireshark.exe&quot; -k -i - 注意: 虽然在Windows平台执行上述代码, 但由于Powershell的解析规则不一样, 因此上面的指令可能需要用Git Bash这样的Linux Bash来执行. 使用Wireshark完成OpenWrt抓包 捕获过滤器注意: 捕获过滤器在开始捕获之前进行设置, 与得到数据以后的过滤表达式语法并不一致. 捕获过滤器的语法格式为 1&lt;Protocol&gt; &lt;Direction&gt; &lt;Host(s)&gt; &lt;Value&gt; &lt;LogicalOperation&gt; &lt;OtherExpression&gt; Protocol是网络协议的名称, 例如tcp, ether等 Direction是数据包方向, 取值为src和dst 一些常见的捕获过滤器如下所示 12345host 192.168.1.100 net 192.168.1 net 192.168.1.0/24 port 80 portrange 8000-8080 上述指定可以指定方向, 例如src host 192.168.1.100 表示源地址为192.168.1.100的数据包, dst net 192.168.1表示目标网段为192.168.1的数据包. WireShark提供了内置的捕获过滤器, 可以从 菜单-&gt;捕获-&gt;捕获过滤器 选择使用 显示过滤器显示过滤器是在获取到数据包之后对数据进行筛选的方式. WireShark的GUI软件提供了直接生成显示过滤器的方法. 在报文的结构窗口的任意字段上右键, 选择作为过滤器应用即可以改字段为条件进行过滤. 由于大部分时候的过滤需求都很简单, 因此上面的方法基本可以满足大部分需求, 但显示过滤器也支持更复杂的范围过滤语法, 需要的时候再查询即可.","categories":[],"tags":[]},{"title":"深入理解JVM之内存与垃圾回收","slug":"深入理解JVM之内存与垃圾回收","date":"2020-10-17T07:40:01.000Z","updated":"2020-11-18T14:24:49.000Z","comments":true,"path":"2020/10/17/深入理解JVM之内存与垃圾回收/","link":"","permalink":"https://lizec.top/2020/10/17/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JVM%E4%B9%8B%E5%86%85%E5%AD%98%E4%B8%8E%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/","excerpt":"","text":"运行时数据区 程序计数区这一部分和计算机结构中的程序计数器原理相同, 用于指示当前程序执行的指令位置. 程序计数器是线程私有的, 每个线程都具有一个独立的程序计数区. 虚拟机栈与本地方法栈与C语言一样, Java内存也可以大致分为栈和堆, 但Java的内存划分实际上更为细致. 对于栈空间, 处理有传统意义上的虚拟机栈以外, 还包括一个本地方法栈. 虚拟机栈保存了虚拟机在执行某个方法时需要的局部变量表, 操作数栈, 动态链接和方法出口等信息. 具体的栈帧接口在后面会有详细介绍. 虚拟机栈中的局部变量表保存了编译期可知的各种基本信息, 包括各个变量的类型, 引用的对象的地址(可能是指针, 也可能是句柄)和方法的返回地址. 这些数据类型在局部变量表中的存储空间以局部变量槽（Slot）来表示, long和double类型的数据占用两个Slot, 其他类型的数据占用一个Slot(每个Slot对应多少内存空间是JVM实现自己决定的) 对于虚拟机栈, 定义了两种内存异常. 如果线程请求的栈深度大于虚拟机运行的最大深度, 就会抛出StackOverflowError异常. 如果Java虚拟机栈容量可以动态扩展, 但内存耗尽, 则抛出OutOfMemoryError异常. HotSpot虚拟机的栈容量是不可以动态扩展, 因此只要栈空间申请成功就不会抛出OutOfMemoryError异常. 本地方法栈与虚拟机栈类似, 也定义了就会抛出StackOverflowError异常和OutOfMemoryError异常. Java堆Java堆主要存放创建的对象和数据, 几乎所有对象都在堆上分配. 但由于逃逸分析技术的日渐强大, 也存在栈上分配和标量替换等技术, 使得对象没有在堆上分配. 多年以前, Java的垃圾收集器都采用了分代回收算法, 因此Java堆可以细分为新生代和老年代. 但现在垃圾收集器已经有了很大的变化, 已经存在不使用分代算法的垃圾收集器. 因此堆内存不再可以简单的划分为新生代和老年代了. Java虚拟机的堆可以是固定大小的, 也可以是可扩展的. 不过目前主流的Java虚拟机都是按照可扩展实现的. 如果需要分配新的对象且堆无法扩展, 则虚拟机抛出OutOfMemoryError异常. 在内存分配方面, Java堆是所有线程共享的区域, 但为了提高分配效率, Java堆中也存在线程私有的分配缓冲区. 方法区方法区是所有线程共享的区域, 存储了已经被虚拟机加载的类型信息, 常量, 静态变量, JIT编译的代码等数据. 根据Java虚拟机规范, 方法区在逻辑上应该是堆的一部分, 但它却有一个别名叫作”非堆”(Non-Heap), 其实质上与堆是不同的内存空间. 在以前, Java程序员习惯将方法区称为永久代, 因为HotSpot虚拟机将垃圾回收扩展到方法区, 并使用永久代来管理方法区的内存. 但这种设计存在一些问题, 使得Java应用更容易遇到内存溢出的问题. 因此在JDK8之后, 就放弃了永久代的概念, 改用使用本地内存中实现的元空间(Metaspace)来代替. 如果方法区无法满足新的内存分配要求, 则会抛出utOfMemoryError异常. 运行时常量池是方法区的一部分, 对应了Class文件中的常量池. 但Java语言中并非在编译时确定值的变量才是常量, 在运行时也可以产生常量, 因此运行时常量池可以在运行时动态的添加常量的特性使得Java语言的这一特性得以实现. 常见的产生运行时常量的方法是String.intern方法. 直接内存直接内存不是虚拟机运行时数据区的一部分, 也不是Java虚拟机规范规定的内存区域. 在JDK1.4中引入了NIO类, 引入了基于通道与缓冲区的I/O方式, 可以使用Native方法直接分配的堆外内存, 然后通过存储在Java堆中的对象对这块内存进行操作. 这样能在一些场景中避免在Java堆和Native堆中来回复制数据. 这一部分内存不会受到虚拟机内存总量的限制, 但会受到物理机器的总内存限制. 设置内存参数时, 如果忽略了直接内存, 则可能导致总内存操作物理内存的限制, 从而导致OutOfMemoryError. HotSpot对象对象的创建Java虚拟机在遇到一个new指令时, 首先需要检查需要创建的类是否能在常量池找到定义, 对应的类是否被加载. 如果没有没加载就先执行类加载过程. 完成类加载过程后, 虚拟机为对象分配内存空间. 根据不同的内存分配算法, 分配内存空间的过程可能是简单的移动一个指针, 也可能是根据空闲列表选择一个合适的区域. 由于创建对象是一个高频操作, 因此虚拟机需要考虑创建对象的线程安全问题. 这也有两种方案. 第一种方案是使用CAS操作保证更新是一个原子操作, 第二种方案是给每个线程在Java堆中预先分配一部分内存, 只有预先分配的内存用完之后才进行同步锁定. 内存分配完成后, Java虚拟机需要将分配的内存空间全部置零, 从而使得实例的字段即使没有初始化也有正确的零值. 接下来Java虚拟机填充对象头, 包括这个对象是哪个类的实例, 如何找到类的元数据, 对象的哈希吗以及GC年龄信息等内容. 完成上面的工作后, 从虚拟机的角度看, 一个对象已经创建了. 但从Java语言的角度看, 这才是刚刚开始. 接下来虚拟机需要调用对象的构造函数即Class文件中的&lt;init&gt;()方法. 执行完此方法后, 才算是从Java语言的角度完成了对象的创建工作. 对象的内存布局在HotSpot虚拟机中, Java对象的内存布局可以划分为三个部分, 即对象头, 实例数据和对齐填充. 对象头中包含两类信息, 第一类是存储对象自身的运行时数据, 包括哈希吗, GC分代年龄, 锁状态标志, 线程持有的锁等, 这部分数据的长度在32位虚拟机和64位虚拟机上的长度分别为32bit和64bit. 但因为需要存储的数据很多, 已经超过了能够记录的最大数据量, 因此实际上这部分内存会根据不同的状态存储不同的值. 对象头中的另一部分是类型指针, 此指针指向了此对象的类型元数据, 从而Java虚拟机能够得知这块内存对应的实例是那种类型. 但并非所有的虚拟机都以这种方案获取对象的元数据. 此外, 如果是数组类型, 对象头中还包括了数组的长度信息. 实例数据部分存储的就是在Java语言层面上定义的各种成员变量. 通常按照先父类变量再子类变量的方式排布成员变量, 但如果开启压缩字段功能, 那么也运行将子类中较窄的变量插入到父类变量的空隙之间. 最后是对齐填充, HotSpot虚拟机对象的内存必须是8字节的整数倍, 因此如果不满足要求时, 将会填充一些额外的字节. 对象的访问定位Java虚拟机规范只规定了通过引用获得对象, 但如何实现引用并没有规定. 因此有句柄和直接指针两种实现方式. 如果使用句柄, 那么内存中可能会划分出一部分空间作为句柄池, 句柄中存储对象的具体地址和类型信息, Java栈通过引用句柄来间接引用对象. 如果使用直接指针, 那么所有的引用就都直接是对象的具体地址, 此时就要考虑如何存储对象的类型信息. 使用句柄的好处是所有的引用都通过句柄间接引用, 因此可以直接修改对象的地址. 移动对象在垃圾回收过程中很常见. 但使用句柄导致访问对象要经过多次寻址, 这对于程序的性能可能有较多的影响. 垃圾收集概述引用类型Java中定义了四种不同的应用类型, 各种类型和相应的含义如下表所示 引用类型 含义 强引用 传统的引用, 只要存在强引用就不会被回收 软引用 当内存不足时, 虚拟机回收只有软引用对象 弱引用 无论是否内存不足, 虚拟机都会回收只有弱引用的对象 虚引用 虚引用的存在不影响对象的生命周期, 仅用于对象被回收是收到系统通知 分代收集理论当代的商业虚拟机垃圾收集器大都遵守分代收集理论, 即 弱分代假说: 绝大多数对象都是朝生夕灭的 强分代假说: 熬过越多次垃圾收集过程的对象就越难以消亡 根据上面的分代假设, Java虚拟机可以将内存划分为新生代和老年代. 其中新生代的对象大部分都是新创建的, 而经过足够多次垃圾回收后仍存活的对象进入老年代. Java虚拟机可以以不同的评率扫描新生代和老年代, 从而获得更好的收集效果. 虽然分代可以使虚拟机针对某一个区域进行垃圾收集, 但这里存在一个跨代引用的问题, 即老年代可能对新生代有引用, 而如果进扫描新生代来判断是否有引用则会导致错误. 针对这一问题, 可以引入第三个假设, 即 跨代引用假说: 跨代引用相对于同代引用来说仅占极少数 一般情况下, 相互引用的对象应该具有相似的GC年龄, 从而一同进入老年代, 只有少量的对象存在跨代引用. 因此针对少量的跨代引用, 可以通过引入额外的数据结构(记忆集, Remembered Set)来避免对整个老年代的扫描. 记忆集将老年代划分为若干小区域, 每个区域有一个标志位指示此区域内的对象有没有跨代引用. 从而在后续的扫描时, 只需要扫描少量有标记的区域中的对象. 标记清除算法标记清除算法首先标记对象的可达性, 然后直接原地清除不可达对象. 整个过程不需要移动任何对象, 但会产生空间碎片. 空间碎片过多可能导致大对象无法分配, 进而触发又一次的垃圾回收动作. 标记复制算法标记复制算法首先将内存分割为两个相等大小的区域, 每次只使用其中的一个区域. 在进行垃圾回收时, 标记复制算法首先标记对象的可达性, 然后将存活的对象直接复制到另一个区域之中, 最后直接情况原区域的内存. 由于存在一个复制过程, 因此可以保证垃圾收集以后的内存是规整的, 但复制过程需要改变对象的地址, 因此可能需要调整对象引用的值. 根据弱分代假说, 如果收集时大部分对象都是死亡的, 那么复制导致的影响可以接受. 在具体的实现时, 不一定需要划分为两个等大的区域, 而是可以划分一个较大的Eden区域和两个较小的Survivor区域. 每次只使用Eden区域和其中的一个Survivor区域. 在清理的时候直接把存活对象都复制到另外一个Survivor区域. HotSpot虚拟机默认Eden和Survivor的大小比例是8:1, 即Eden区域占80%的空间, 两个Survivor区域各占10%的空间. 如果按照Eden和Survivor的模式进行划分, 存在一定概率出现存活的对象较多, 一个Survivor区域无法存放的情况. 这种情况下就会出现分配担保, 即让一部分存活对象直接进入老年代. 标记整理方法标记复制算法虽然可以避免空间碎片, 但当大部分对象都是存活状态时, 复制操作的代价较大, 而且如果不使用等大的两块内存空间, 就可能出现需要分配担保的情况. 因此老年代一般不使用标记复制算法. 标记整理方法的初始步骤与标记清除方法一致, 但后续步骤不是直接对可回收对象进行清理, 而是让所有存活的对象都向内存空间一端移动, 然后直接清理掉边界以外的内存. 这个过程有点类似磁盘的碎片整理过程. 虽然移动存活对象可以避免空间碎片, 但也导致虚拟机需要更新引用值. 老年代中的对象大部分都是存货的, 因此更新地址值的代价也很大, 垃圾回收器需要仔细的衡量空间碎片和更新地址的代价. HotSpot算法实现细节根节点枚举垃圾回收的第一步是获得GC Root, 从而后续可以通过GC Root遍历引用关系来寻找所有的可达对象. 安全点与安全区域垃圾收集器并不能随意的暂停用户的进程. 用户进程可以被垃圾收集器暂停的地方称为安全点. 设置安全点有性能开销, 因此虚拟机只会在方法调用, 循环跳转, 异常跳转等位置设置安全点. 当垃圾收集器希望用户进程暂停时, 一般会设置一个标志位, 然后等待用户线程自己检查是否需要暂停, 并自己主动挂起. 安全区域是一段代码区域, 其中引用关系不会发生变化, 从而在这个区域的任何位置开始垃圾收集都是安全的. 当线程进入安全区域时, 设置一个标志位, 从而当垃圾收集器进行根节点枚举时, 直接忽略这些线程. 当这些线程离开安全区时, 会检查是否完成了根节点枚举, 如果没有完成就等待根节点枚举完成后再继续执行. 否则就可以当做什么事情都没有发生, 继续正常执行. 记忆集与卡表记忆集从逻辑上只需要能够记录是否有跨代引用即可, 在实现上可以以不同的粒度进行实现. 其中以内存块为粒度的实现称为卡表. 这一实现类似操作系统的分页机制, 将内存分成不同的内存块, 每一块称为一个卡页. 记忆集中保存每个卡页是否有跨代引用. 写屏障虽然记忆集可以缩小搜索范围, 但是维护记忆集又需要引入额外的计算. 针对维护问题, HotSpot虚拟机引入了写屏障技术. 写屏障可以理解为对引用类型字段赋值的AOP切面. 虚拟机能够在赋值操作的前后执行需要的代码. 对卡表的维护就可以通过写屏障在每次赋值的时候进行维护. 虽然使用写屏障导致每次赋值都存在一些额外的开销, 但相比于Mirror GC需要扫描整个老年代的开销还是小很多了. 虽然写屏障能够更新卡表, 但由于CPU的缓存机制, 卡表存在伪共享问题. 一般情况下, CPU会一次读取一行数据(64字节)并放入缓存之中, 而卡表的一个元素只有一个字节, 因此有可能64个卡表元素在一个缓存行. 在多核情况下, 一个CPU对某一行数据进行修改会导致其他CPU中的该行缓存数据失效, 从而强制其他CPU重新获取该行数据, 这将导致多线程下对卡表的更新性能下降. 为了避免这一问题, 可以在写卡表之前先检查对应的元素是否被标记了, 只有需要更新的时候才对卡表进行写入. 不过这又会引入一次额外的判断, 因此虽然避免了伪共享的问题, 但也有性能损耗. 可以通过JVM参数控制是否需要开启写入前判断的功能. -杂谈 什么是伪共享（false sharing）？ 并发的可达性分析 JVM学习 并发可达性分析详解 垃圾收集器 经典的七种引用于不同的分代的垃圾收集器如上图所示. Serial系列收集器Serial / Serial Old收集器如同其名称这样, 是线性的垃圾收集器, 两者分别应用于新生代和老年代. 新生代采取标记-复制算法, 老年代采取标记-整理算法. 在执行垃圾收集的过程时, 都需要暂停所有的用户进程. 虽然现在已经有很多其他更为复杂的垃圾收集器, 但Serial系列的收集器具有实现简单, 内存占用少, 单核性能高的优势, 因此在资源受限的环境下还是有很好的效果. ParNew收集器ParNew收集器是Serial收集器的多线程版本. 收集过程中还是需要暂停用户线程, 但收集过程新生代时会使用多条GC线程同时收集. ParNew收集器并没有太多创新, 但在JDK9以后, 就只能和CMS收集器搭配使用了, 可以将ParNew收集器视为CMS收集器的新生代部分了. Parallel Scavenger收集器Parallel Scavenger收集器也是基于标记复制的多线程并行收集器, 与ParNew收集的特性非常相似. 但Parallel Scavenger收集器更关注于吞吐量. $$吞吐量=\\frac{运行用户代码时间}{运行用户代码时间+运行垃圾收集时间}$$ 停顿时间段可以保证服务的相应时间, 提高用户体验. 而吞吐量高能够最高效率的利用服务器资源, 因此适合在后台计算不需要太多交互的任务. Parallel Scavenger收集器能够明确的指定最大停顿时间和吞吐量比例, 并且支持给定一个参数后由虚拟机根据运行情况决定另外一个参数的值. Parallel Old收集器Parallel Old收集器是Parallel Scavenger收集器的老年代版本. 采用多线程收集和标记-整理算法. 在Parallel Old收集器出现之前, Parallel Scavenger收集器只能和Serial Old收集器搭配, 在服务器端的多核环境中, Serial Old拖累了整个垃圾收集的效率, 因此吞吐量可能还不如ParNew和CMS的组合. CMS收集器CMS(Concurrent Mark Sweep)收集器是以最短回收停顿时间为目标的收集器. 正如名字的含义, CMS收集器使用标记-清除算法且具有并发收集的特性. CMS收集器的运行过程可以分为四个步骤 步骤名称 是否暂停用户线程 相对耗时 初始标记 是 较短 并发标记 否 较长 重新标记 是 较短 并发清除 否 其中初始标记和重新标记阶段需要暂停用户线程, 其他阶段可以与用户线程并发执行. 初始标记节点仅标记CG Root可以直接关联的对象, 速度很快. 并发标记节点与用户线程一同并发的标记其他可达对象, 这一操作的用时较长. 重新标记阶段修正并发标记阶段用户改变的一些引用关系(采用增量更新), 这一阶段需要重新标记的对象较少, 因此耗时也与并发标记阶段耗时更短. 最后的并发清除阶段因为不需要移动对象, 因此也可以和用户进程一同运行. CMS收集器具有低停顿, 并发收集的特点, 但也存在三个明显的缺点 对CPU资源敏感, 与用户进程并行执行时会导致用户进程执行时间变长 无法处理浮动垃圾, 即垃圾收集过程中新产生的垃圾 标记-清除算法会导致内存碎片 Garbage First收集器Garbage First(G1)收集器与以往的分代收集器不同, G1收集器采取Region布局, 对象局部收集的思路. G1收集器可以对每个Region分析收集价值, 每次都先收集价值最高的Region, 并且对收集时间进行建模预测, 从而能够保证每次的收集时间都少于一个给定的值. G1虽然保留新生代和老年代的概念, 但此时的新生代和老年代不再需要是连续的内存空间, 任何一个Region都可以是新生代或者老年代. 由于每个Region都可以是老年代, 因此G1收集器需要维护一个更复杂的记忆集, 记录所有Region之间的引用关系. 这导致G1收集器需要额外消耗大约10%到20%的内存空间来维护这些信息. G1收集器的并发标记节点采用原始快照实现与用户进程并发执行.因此在此过程中创建的新对象都会直接分配到一个指定的区域, 并且均视为存活对象. 如果回收速度赶不上垃圾产生的速度, 那么G1收集器就要被迫暂停用户进行执行Full GC. G1收集器的过程与CMS收集器差不多, 但最后的清理阶段G1将Region中存活的对象复制到新的Region之中. G1收集器与CMS收集器相比具有优势, 但也存在内存消耗更大, CPU性能消耗更多的问题. 一般认为在更大的Java堆上(大约6~8GB)G1收集器能获得更好的效果. Shenandoah收集器Shenandoah是以低延迟为目标的收集器, 几乎可以在任意的堆大小上做到固定的停顿时间. Shenandoah的布局与G1非常相似, 可以视为对G1收集器的改进. Shenandoah的改进包括 使用连接矩阵代替记忆集, 连接矩阵以Region为单位记录引用关系 引入读屏障和Brooks Pointers解决并发移动对象的问题 ZCGZGC也是以低延迟为目标的收集器, 也采取和G1类似的Region布局, 由于当前还处于开发阶段, 因此不支持分代. ZGC采用染色指针和转发表实现在不暂停用户进程的同时移动对象. ZGC的主要特点是将对象的状态信息记录到引用这个对象的指针之中. ZGC可以大致分为四个阶段: 并发标记: 此阶段与G1类似, 包括初始标记, 并发标记和重新标记三个阶段, 具体操作和停顿原因都和G1一致. 并发预备重分配: 通过规则判断哪些Region要回收. ZGC目前不进行分代, 因此不需要记忆集, 但因此也需要扫描更多内存空间. 并发重分配: 移动Region中存活的对象, 并维护一个转发表. 由于染色指针的标记, ZCG可以根据指针判断一个对象是否被重分配. 如果对象被重分配, 则通过内存屏障截获请求并通过转发表返回新的对象地址并更新此指针的值. 此后再通过此指针即可直接访问最新的对象, 这一特性也称为指针的自愈 并发重映射: 此阶段修正指向就对象的指针. 由于指针可以自愈, 因此这一操作并不紧急, 被ZGC合并到了并发标记阶段, 从而节省一次遍历对象图的操作. ZGC的主要问题是没有采取分代的设计, 导致新生对象不能单独以一个较高的速率进行处理. 由于整个垃圾回收过程是并行执行的, 一次垃圾回收可能需要一段较长的时间, 这段时间产生的浮动垃圾都无法有效的收集.","categories":[{"name":"深入理解JVM","slug":"深入理解JVM","permalink":"https://lizec.top/categories/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JVM/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://lizec.top/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"https://lizec.top/tags/JVM/"}]},{"title":"CSAPP笔记之汇编语言","slug":"CSAPP笔记之汇编语言","date":"2020-08-10T04:06:34.000Z","updated":"2020-09-04T09:43:21.541Z","comments":true,"path":"2020/08/10/CSAPP笔记之汇编语言/","link":"","permalink":"https://lizec.top/2020/08/10/CSAPP%E7%AC%94%E8%AE%B0%E4%B9%8B%E6%B1%87%E7%BC%96%E8%AF%AD%E8%A8%80/","excerpt":"","text":"指令后缀与X86汇编相比, X64汇编的一个显著区别是增加了对64bit数据的操作, 对于所有的数据传输指令, 都可以添加指令后缀来明确具体数据的具体长度, 后缀的关系如下表所示 C语言声明 Intel数据类型 汇编后缀 字节长度 char 字节(byte) b 1 short 字(word) w 2 int 双字(double word) l 4 long 四字(quad word) q 8 char* 四字(quad word) q 8 float 单精度(single) s 4 double 双精度(double) l 8 双字使用l作为后缀, 因此双字也被认为是一种长字节(long word). 浮点数指令和整数指令后缀有一些冲突, 但实际上由于浮点数指令是一套单独的指令, 因此并不会构成冲突. 寄存器结构X64寄存器数量和寄存器长度都在X86的基础上再次翻倍, 每个寄存器都是64位长度, 并且新加入的8个寄存器, 新加入的寄存器分别命名为%r8~%r15. 所有寄存器和使用规则如下表所示 寄存器 使用规则 寄存器 使用规则 %rax 返回值 %r8 第5个参数 %rbx 被调用者保存 %r9 第6个参数 %rcx 第4个参数 %r10 调用者保存 %rdx 第3个参数 %r11 调用者保存 %rsi 第2个参数 %r12 被调用者保存 %rdi 第1个参数 %r13 被调用者保存 %rbp 被调用者保存 %r14 被调用者保存 %rps 栈指针 %r15 被调用者保存 与X86汇编一样, 可以通过类似%eax, %ax, %ah, %al的方式访问原有的8个寄存器的低位部分. 对于新增的寄存器, 也可以使用类似%r8d, %r8w, %r8b的方式访问r8寄存器的低32位, 低16位和低8位. 由于寄存器数量有明显的增加, 因此与X86相比, 一个显著的变化就是大部分时候的函数调用不需要再进行参数入栈的操作, 大部分时候函数调用的参数都可以直接用寄存器传递. 将数据移动到寄存器时, 如果移动的数据是1字节或2字节, 则寄存器的高位不变. 如果移动的数据是4字节, 则将高位数据置零 操作数指示符格式 $0x1234 | 立即数0x1234 | 立即数寻址%rax | 取%rax的值 | 寄存器寻址 数据传送指令mov指令结合四种长度后缀可以表示四种不同长度的数据传输指令, 即movb, movw, movl和movq. mov指令既可以在寄存器之间传送数据, 也可以将立即数传入寄存器. 但movq指令只能接受32位的有符号立即数, 将其进行符号扩展到64位, 并传入寄存器. 如果需要传送64位立即数, 则需要使用movabsq指令进行绝对传送. mov指令有两种变形, 分别是movz和movs. 两个指令分别表示零扩展和符号扩展. 例如movzbl表示将一个字节的数据先进行零扩展变为一个双字长度, 然后传送到目标位置, movzwq表示将一个字长度的数据进行零扩展变成四字长度后传送到目标位置. 数据传送指令虽然指定了数据的长度, 但不能与操作的寄存器发生冲突. 例如movl %rax, (%rbx) 似乎希望传送%rax的两个字节到内存, 但并没有这种用法, 如果需要传送低位, 只能使用%eax替换. cltq指令是movslq %eax %rax指令的简化指令, 表示将%eax的数据符号扩展到%rax 栈操作栈操作与X86汇编没有太大区别, 只是入栈和出栈的基本单元的大小都设置为8字节.","categories":[{"name":"CSAPP笔记","slug":"CSAPP笔记","permalink":"https://lizec.top/categories/CSAPP%E7%AC%94%E8%AE%B0/"}],"tags":[]},{"title":"Java开发手册笔记","slug":"Java开发手册笔记","date":"2020-06-29T09:17:17.000Z","updated":"2020-09-11T08:14:56.716Z","comments":true,"path":"2020/06/29/Java开发手册笔记/","link":"","permalink":"https://lizec.top/2020/06/29/Java%E5%BC%80%E5%8F%91%E6%89%8B%E5%86%8C%E7%AC%94%E8%AE%B0/","excerpt":"","text":"本文是对阿里巴巴的Java开发手册的笔记, 对其中的一些平时没有注意的细节进行记录, 并对一些内容补充细节和自己的理解. 命名风格【强制】 类名使用UpperCamelCase风格，但以下情形例外：DO / BO / DTO / VO / AO / PO / UID等 这些例外情况都是缩写词, 缩写词始终保持全大写. 【强制】 抽象类以Abstract或Base开头 【强制】 POJO类中的任何布尔类型的变量, 都不要加is前缀 由于各种框架对于布尔型变量可能生成is开头的get方法, 因此不建议加入is, 以免解析过程中产生冲突. 【强制】 包名统一使用小写, 点分隔符之间有且仅有一个自然语义的英语单词. 包名统一使用单数形式, 类名根据需要可以使用复数形式 【参考】 各层命名规约 方法含义 前缀 方法含义 前缀 获取单个对象 get 获取多个对象 list 获取统计值 count 插入数据 save / insert 删除数据 remove / delete 修改数据 update 领域模型 命名 备注 数据对象 xxxDO xxx为对应的表名 数据传输对象 xxxDTO xxx为业务领域相关名称 展示对象 xxxVO xxx为网页名称 【推荐】 单个方法的总行数不超过80行 一个方法写太长则可读性不好, 方法太过零散也不适合阅读. 因此需要把方法的长度控制在适当的范围内. 要分清楚主干代码和辅助代码. 辅助代码写成函数, 使主干逻辑保持清晰简洁. OOP规范【强制】 禁止使用构造方法BigDecimal(double)的方式把double值转化为BigDecimal对象. double不能精确表示数字, 使用String类型构造函数可以保证数字与字面值完全一致 【强制】 定义数据对象DO类时, 属性类型要与数据库字段类型相匹配 不当的数据类型可能导致溢出, 从而导致错误 【强制】 所有的POJO类属性必须使用包装数据类型【强制】 RPC方法的返回值和参数必须使用包装数据类型【推荐】 所有的局部变量使用基本数据类型 包装类型可以设置为null, 从而提供额外的信息. 【强制】 定义DO/DTO/VO等POJO类时，不要设定任何属性默认值 构造函数不包含参数, 但实际却设置了属性, 容易产生误解","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://lizec.top/tags/Java/"}]},{"title":"MySQL笔记之基础知识","slug":"MySQL笔记之基础知识","date":"2020-06-26T13:25:03.000Z","updated":"2021-05-13T06:36:03.663Z","comments":true,"path":"2020/06/26/MySQL笔记之基础知识/","link":"","permalink":"https://lizec.top/2020/06/26/MySQL%E7%AC%94%E8%AE%B0%E4%B9%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/","excerpt":"","text":"MySQL架构MySQL可以分为三层结构, 最外层是网络层, 负责处理客户端连接, 授权认证等操作. 中间层是核心服务, 包括解析器, 优化器, 查询缓存和内置函数. 最底层是存储引擎, 负责数据的存储和提取. MySQL提供了不同的存储引擎, 并且通过中间层屏蔽了底层的差异. MySQL在解析查询语句时, 会对查询语句进行优化. 优化器不关心底层使用什么存储引擎, 但不同的存储引擎可能影响优化结果, 因此优化器会向存储引擎请求容量, 某个操作的开销信息, 表数据的统计信息来辅助优化过程. 用户可以通过特殊关键字提示优化器, 从而影响优化器的选择. 用户也可以要求优化器解释优化操作的因素. 从MySQL 8.0开始, 查询缓存已经被删除. MySQL为什么取消了Query Cache? MySQL中常见的存储引擎有InnoDB, MyISAM和MEMORY. 从MySQL 5.5.5开始, InnoDB作为MySQL默认的存储引擎, 在此之前MyISAM作为默认的存储引擎. MySQL支持的存储引擎如下所示 1234567891011121314mysql&gt; show engines;+--------------------+---------+----------------------------------------------------------------+--------------+------+------------+| Engine | Support | Comment | Transactions | XA | Savepoints |+--------------------+---------+----------------------------------------------------------------+--------------+------+------------+| MEMORY | YES | Hash based, stored in memory, useful for temporary tables | NO | NO | NO || MRG_MYISAM | YES | Collection of identical MyISAM tables | NO | NO | NO || CSV | YES | CSV storage engine | NO | NO | NO || FEDERATED | NO | Federated MySQL storage engine | NULL | NULL | NULL || PERFORMANCE_SCHEMA | YES | Performance Schema | NO | NO | NO || MyISAM | YES | MyISAM storage engine | NO | NO | NO || InnoDB | DEFAULT | Supports transactions, row-level locking, and foreign keys | YES | YES | YES || BLACKHOLE | YES | /dev/null storage engine (anything you write to it disappears) | NO | NO | NO || ARCHIVE | YES | Archive storage engine | NO | NO | NO |+--------------------+---------+----------------------------------------------------------------+--------------+------+------------+ XA表示是否支持分布式事务, Savepoints表示是否支持部分回滚 InnoDB是MySQL默认的事务存储引擎, 它被设计用来处理大量短期事务, 此类事务的特点是大部分时候事务都正常提交, 很少被回滚. InnoDB的性能和自动崩溃恢复使得非事务任务也可以考虑使用InnoDB. 字符集MySQL支持的字符集如下所示, 其中比较少见的字符集已经从表格中删除 1234567891011121314mysql&gt; show charset;+----------+---------------------------------+---------------------+--------+| Charset | Description | Default collation | Maxlen |+----------+---------------------------------+---------------------+--------+| ascii | US ASCII | ascii_general_ci | 1 || gb2312 | GB2312 Simplified Chinese | gb2312_chinese_ci | 2 || gbk | GBK Simplified Chinese | gbk_chinese_ci | 2 || latin1 | cp1252 West European | latin1_swedish_ci | 1 || latin2 | ISO 8859-2 Central European | latin2_general_ci | 1 || utf16 | UTF-16 Unicode | utf16_general_ci | 4 || utf32 | UTF-32 Unicode | utf32_general_ci | 4 || utf8 | UTF-8 Unicode | utf8_general_ci | 3 || utf8mb4 | UTF-8 Unicode | utf8mb4_0900_ai_ci | 4 |+----------+---------------------------------+---------------------+--------+ 以上编码中需要注意: latin1编码又被称为ISO 8859-1编码, 这一编码在ASCII编码的基础上, 扩展了高位的128个编码, 收录了西欧的常用字符 utf8编码是MySQL自带的只使用3字节的编码方式, 可能导致一些UTF-8收录的字符无法显示 utf8mb4对应真正的UTF-8编码 各级别字符集MySQL服务器端默认的字符集和比较规则如下所示, 可以看到在当前的MySQL中已经将真正的UTF-8编码作为默认的字符集编码了. 12345678910111213mysql&gt; show variables like &#x27;character_set_server&#x27;;+----------------------+---------+| Variable_name | Value |+----------------------+---------+| character_set_server | utf8mb4 |+----------------------+---------+mysql&gt; show variables like &#x27;collation_server&#x27;;+------------------+--------------------+| Variable_name | Value |+------------------+--------------------+| collation_server | utf8mb4_0900_ai_ci |+------------------+--------------------+ 数据库级别的编码可以在创建数据库时指定, 例如 1CREATE DATABASE dbtest CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci; 如果不指定编码, 则会使用服务器级的值作为默认值 表级别的编码也是在创建表的时候指定, 例如 123CREATE TABLE t( col VARCHAR(10)) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci; 同样地, 如果不指定编码, 则使用功能数据库级别的编码作为默认值 在MySQL表中的不同列也可以指定不同的编码, 例如 123CREATE TABLE t( col VARCHAR(10) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci); 或者 1ALERT TABLE t MODIFY col VARCHAR(10) CHARACTER SET gbk COLLATE gbk_chinese_ci; InnoDB行格式相比于内存读写的速度, 硬盘读写的速度要慢几个数量级, 因此如何高效的从硬盘上读写数据是数据库需要解决的一个重要问题. InnoDB支持四种不同的行格式, 即COMPACT, REDUNDANT, DYNAMIC和COMPRESSED. COMPACT格式COMPACT格式的结构如下所示: 1变长字段列表 | NULL值列表 | 记录头信息 | 列1的值 | 列2的值 | ... | 列n的值 变长字段列表: 存储记录中各个变长字段的长度信息. NULL值列表: 记录每一行记录中值为NULL的字段, 由于SQL语法可以规定某个指定不可为NULL, 因此这一列表可以不存在. 如果这一列表存在, 则每个可以为NULL的字段对应一个二进制位. 由于字节对齐的需要, 不足一字节的部分还是会占用一字节. 记录头信息: 这一部分占5字节, 主要是一些标记信息. 除了上述的信息以外, 每一行还会包含一些隐藏信息, 这些信息被称为隐藏列, 具体包括 名称 是否必须 占用空间 含义 DB_ROW_ID 否 6字节 行ID DB_TRX_ID 是 6字节 事务ID DB_ROLL_PTR 是 7字节 回滚指针 没有主键时, MYSQL才会自动生成DB_ROW_ID 补充: 字段的长度假设在某个数据集中, 一个字符最多需要W个字节表示, 对于变长类型VARCHAR(M)而言, 这表示最多可以存储M个字符, 因此该字段最多可能占用MxW个字节, 假设其实际占用的字节数为L, 则 如果MxW &lt; 255, 则使用1字节表示该字段的实际长度 否则判断是否L &lt;= 127, 是则使用1字节表示该字段的实际程度, 否则使用2字节表示该字段的实际长度 MySQL可通过表结构得知一个字段是否可以存储超过255字节, 之后可以通过分析这一字节的最高位是否为1得知是否使用了2字节表示长度 如果是小端序, 使用2字节表示长度时, 则正好低位字节在前, 高位字节在后 对于固定长度类型, 例如CHAR(M), 如果使用的字符集是固定长度, 则字段占用的空间也是固定大小. 但如果字符集是变长的, 则此时CHAR(M)类型为了实现性能与空间的平衡, 实际也是变长的,并且至少分配M字节的空间. 例如CAHR(10)在utf8字符集上分配的空间就是10~30字节, 且至少为10字节. 这一设置一方面减少了空间的浪费, 同时又预留了一定的空间, 减少了页面分裂的概率. REDUNDANT格式REDUNDANT格式的细节如下所示: 1字段长度偏移列表 | 记录头信息 | 列1的值 | 列2的值 | ... | 列n的值 字段长度偏移列表: 记录了之后每个字段在记录内的偏移地址 记录头信息: 这一部分占6字节, 主要是一些标记信息. 如果整个记录的长度小于127字节, 则使用1字节表示偏移量, 否则全部采取2字节存储偏移量. 对于定长类型, 直接分配最大的空间, 并且使用零填充. 对于变长类型, 由于记录了偏移值, 因此如果为NULL则不占据任何空间. 因此REDUNDANT格式相比于COMPACT格式确实更加冗余 补充: 溢出页由于InnoDB按照页的格式存储数据, 而InnoDB的一页的大小一般为16KB, 因此当存储的一行数据就超过了一个页面长度时, 在这一行记录中只会存在前768个字节以及一个20字节的溢出页指针. 多余的数据会存储到溢出页中. 此外, MYSQL还规定每个页至少需要存储两条数据(溢出页不受此规则的约束), 因此是否产生溢出页主要取决于字段类型和编码集. 其他行格式DYNAMIC格式和COMPRESSED格式与COMPACT格式比较类似, 不同之处在于DYNAMIC格式处理溢出数据时不会存储前768个字节, 而是直接存储指针. 而COMPRESSED格式在DYNAMIC格式的基础上还会使用压缩算法对页面进行压缩. 目前DYNAMIC格式是MYSQL的默认格式 InnoDB数据页格式前面的InnoDB行格式是MYSQL中一条记录的存储格式, 而InnoDB数据页格式是存储这些记录的页的格式, 具体如下 名称 长度 详细信息 File Header 38 Byte 文件头, 数据页的通用信息 Page Header 56 Byte 页面头：数据页的专有信息 Infimum + Supremum 26 Byte 两个虚拟记录 User Records N/A 用户的实际记录 Free Space N/A 剩余的可用空间 Page Directory N/A 页面中某些记录的相对位置 File Trailer 8 Byte 校验 页目录MySQL中使用链表将记录按照主键的大小进行串联, 因此实际的存储顺序不一定是按照主键的顺序. 由于这一设置, 当需要在表内查询记录的时候就需要按照链表进行遍历, 为了加速查询过程, 页目录中存储了一个类似索引的结构, 从而在按照主键查询的时候可以使用二分法定位记录的位置. 用户的数据首先分割为不同的槽, 每个槽中可以包含4~8条数据, 页目录中存储了每个槽中最大的记录再页面中的偏移地址. File Trailer这一部分存储的是校验值, 校验值在文件头部也有存储, 这一部分的目的是为了防止将数据写入磁盘的过程中断电导致记录只有一半被刷新的情况. 在这种情况下通过对比头部的校验值与尾部的校验值是否一致即可判断页面是否完全刷新. MySQL数据目录通过查询如下的变量可以知道MySQL当前的数据目录位置: 123456mysql&gt; show variables like &#x27;datadir&#x27;;+---------------+---------------------------------------------+| Variable_name | Value |+---------------+---------------------------------------------+| datadir | C:\\ProgramData\\MySQL\\MySQL Server 8.0\\Data\\ |+---------------+---------------------------------------------+ 访问这一目录可以发现, 其中每个数据库在这里都对应了一个文件夹, 而每个表都在对应的文件夹内对应了一个IDB文件 Buffer Pool由于磁盘速度远低于CPU速度， 因此MySQL的InnoDB会将硬盘上的页缓存到内存之中，从而减少IO操作的耗时。 可以通过如下的指令查看Buffer Pool的大小 123456mysql&gt; show global variables like &#x27;innodb_buffer_pool_size&#x27;;+-------------------------+---------+| Variable_name | Value |+-------------------------+---------+| innodb_buffer_pool_size | 8388608 |+-------------------------+---------+ Buffer Pool以页作为基本单位， 一个页面的大小也是16KB，与硬盘上的页一一对应。除了页以外，Buffer Pool中还包含一些控制信息， 包括记录页面基本信息的控制块以及free链表和flush链表。 free链表记录那些页是空闲的，flush链表记录那些页等待刷新 当需要判断一个页是否已经被缓存时，MySQL使用表空间号和页号作为key，使用哈希表直接定位。 LRU链表Buffer Pool作为一个缓冲区，其核心问题就是如何提高缓存命中率。使用LRU算法进行页替换是一种常规操作。但在此基础上，MySQL还需要做一些优化。 MySQL中有预读取机制，即当某些页面满足一定的条件后，会异步的读取后续的页面到Buffer Pool之中，如果预读取的页面后续被用到了，则可以极大的提高效率。但如果后续的页面没有被用到，则会导致大量页面进入Buffer Pool，将其他频繁访问的页面挤出。 此外如果执行了全表扫描，也会导致大量页面进入Buffer Pool，挤出其他频繁访问的页面。 针对上面的问题，MySQL引入了分区设置，将Buffer Pool分为两个区域，从而使上述的操作不会挤占热点数据的页面。 查看信息使用show engine innodb status可以查看相关的信息 1234567891011121314151617181920----------------------BUFFER POOL AND MEMORY----------------------Total large memory allocated 136970240Dictionary memory allocated 443780Buffer pool size 8192Free buffers 7134Database pages 1048Old database pages 387Modified db pages 0Pending reads 0Pending writes: LRU 0, flush list 0, single page 0Pages made young 0, not young 00.00 youngs/s, 0.00 non-youngs/sPages read 851, created 197, written 8620.00 reads/s, 0.00 creates/s, 0.00 writes/sNo buffer pool page gets since the last printoutPages read ahead 0.00/s, evicted without access 0.00/s, Random read ahead 0.00/sLRU len: 1048, unzip_LRU len: 0I/O sum[0]:cur[0], unzip sum[0]:cur[0] 并发控制MySQL通过锁实现并发控制. 表锁是MySQL中最基本, 且性能开销最小的锁. 表锁是读写锁, 且写锁具有更高的优先级, 可能在队列中插入到读锁的前面. 行级锁是并发程度最高, 同时开销也是最大的锁. 在InnoDB和XtraDB中实现了行级锁. 在MySQL架构中, 行级锁由存储引擎实现, 而中间服务层不关系存储引擎中锁的具体实现. 存储引擎MySQL为每个数据库在数据目录下创建一个子目录, 然后在子目录下创建与表名同名的.frm表定义文件. 由于MySQL使用了操作系统的文件系统, 因此是否大小写敏感取决于具体的操作系统.","categories":[{"name":"MySQL笔记","slug":"MySQL笔记","permalink":"https://lizec.top/categories/MySQL%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://lizec.top/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"MySQL","slug":"MySQL","permalink":"https://lizec.top/tags/MySQL/"}]},{"title":"机器学习之强化学习","slug":"机器学习之强化学习","date":"2020-06-26T04:45:16.000Z","updated":"2020-06-27T03:35:01.526Z","comments":true,"path":"2020/06/26/机器学习之强化学习/","link":"","permalink":"https://lizec.top/2020/06/26/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/","excerpt":"","text":"强化学习(Reinforcement Learning, RL), 也叫增强学习, 是指一类从(与环境)交互中不断学习的问题以及解决这类问题的方法. 强化学习的关键是贡献度分配问题, 每一个动作不能直接得到监督信息, 需要通过最终结果获得监督信息, 并且存在延时. 基础概念强化学习涉及如下的一些基础概念 智能体(agent)可以感知外界环境的状态(state)和反馈的奖励(reward), 并进行学习和决策 智能体的决策功能是指根据外界环境的状态来做出不同的动作(action), 而学习功能是指根据外界环境的奖励来调整策略 环境(environment)是智能体外部的所有事物, 并受智能体动作的影响而改变其状态, 并反馈给智能体相应的奖励 在此基础上, 可以抽象出如下的一些概念 名称 符号 备注 状态 s 对环境的描述/ 可以是离散的或连续 / 状态空间为S 动作 a 对智能体行为的描述 / 可以是离散的或连续 / 动作空间为A 策略 π(a&#124;s) 智能体根据环境状态s 来决定下一步的动作a 的函数 状态转移概率 p(s′&#124;s, a) 智能体做出一个动作, 环境在下一个时刻转变为状态s′ 的概率 即时奖励 r(s, a, s′) 智能体做出动作之后，环境反馈给智能体的奖励(标量) 策略可以分为确定性策略和随机性策略, 其中随机性策略表示在某个状态下, 智能体选择的动作服从某一个概率分布而不是确定动作. 强化学习一般采用随机性策略. 回报与折扣率给定一个策略后, 智能体收到的所有即时回报之和为总回报(Return). 可以引入一个折扣率来综合考虑近期回报与远期回报, 其定义为 $$G(\\tau)=\\sum_{t=0}^{T-1} \\gamma^{t} r_{t+1}$$ 其中 \\( \\gamma^{t} \\) 表示折扣率. \\( \\tau \\) 表示马尔可夫决策过程的一个轨迹, 即由s,a和r构成的一组序列, 表示了智能体在环境中的一系列操作下, 相应的环境变换和奖励. 目标函数与值函数强化学习的目标是获得一个策略, 来最大化期望回报, 即 $$\\mathcal{J}(\\theta)=E_{\\tau \\sim p_{\\theta}(\\tau)}[G(\\tau)]=E_{\\tau \\sim p_{\\theta}(\\tau)}\\left[\\sum_{t=0}^{T-1} \\gamma^{t} r_{t+1}\\right]$$ 其中\\( p_{\\theta}(\\tau) \\)表示一个通过参数\\(\\theta\\)调节分布, 而\\(\\tau \\sim p_{\\theta}(\\tau)\\) 表示轨迹服从这一分布, 最终这个公式的含义就是此分布下求解期望值. 上述公式可以分解为 $$\\begin{aligned}E_{\\tau \\sim p(\\tau)}[G(\\tau)] &amp;=E_{s \\sim p\\left(s_{0}\\right)}\\left[E_{\\tau \\sim p(\\tau)}\\left[\\sum_{t=0}^{T-1} \\gamma^{t} r_{t+1} \\mid \\tau_{s_{0}}=s\\right]\\right] \\\\&amp;=E_{s \\sim p\\left(s_{0}\\right)}\\left[V^{\\pi}(s)\\right]\\end{aligned}$$ 其中\\( V^{\\pi}(s) \\)称为状态值函数(State Value Function), 表示从状态s开始, 执行策略π 得到的期望总回报. 经过一番推导, 可以得到如下的贝尔曼方程, 按照这种方程计算的方法也称为动态规划法. $$V^{\\pi}(s)=E_{a \\sim \\pi(a \\mid s)} E_{s^{\\prime} \\sim p\\left(s^{\\prime} \\mid s, a\\right)}\\left[r\\left(s, a, s^{\\prime}\\right)+\\gamma V^{\\pi}\\left(s^{\\prime}\\right)\\right]$$ 通过此公式可以使用迭代法计算状态值函数. 如果定义状态-动作值函数为 $$Q^{\\pi}(s, a)=E_{s^{\\prime} \\sim p\\left(s^{\\prime} \\mid s, a\\right)}\\left[r\\left(s, a, s^{\\prime}\\right)+\\gamma V^{\\pi}\\left(s^{\\prime}\\right)\\right]$$ 则可以进一步将上述公式表示为状态值函数中\\( V^{\\pi}(s) \\)是Q函数\\(Q^{\\pi}(s, a)\\)关于动作a的期望, 即 $$V^{\\pi}(s)=E_{a \\sim \\pi(a \\mid s)}\\left[Q^{\\pi}(s, a)\\right]$$ 总结两种值函数, 即 \\(V^{\\pi}(s)\\): 在状态s下, 以策略π可以获得的总期望回报 \\(Q^{\\pi}(s, a)\\): 在状态s下, 选择动作a后, 以策略π可以获得的总期望回报 值函数可以看作是对策略π的评估. 如果在状态s，有一个动作a使得\\( Q^{\\pi}(s, a) &gt; V^{\\pi}(s)\\), 则说明执行动作a 比当前的策略要好，我们就可以调整参数使得动作a的概率增加. 深度强化学习深度强化学习是指将强化学习与深度学习结合的方法. 用强化学习来定义问题和优化目标, 用深度学习来解决策略和值函数. 蒙特卡洛方法模型无关的强化学习使用采样的方法计算值函数, 在这种情况下, 往往无法得知状态转移概率和及时奖励, 因此首先以状态s和动作a开始, 随机执行若干次采样过程, 获取一组轨迹, 则Q函数近似为这组轨迹的总回报的平均值 $$Q^{\\pi}(s, a) \\approx \\hat{Q}^{\\pi}(s, a)=\\frac{1}{N} \\sum_{n=1}^{N} G\\left(\\tau_{s_{0}=s, a_{0}=a}^{(n)}\\right)$$ 获得近似的Q函数以后, 就可以执行策略迭代过程, 即令 $$\\forall s, \\pi(s)=\\arg \\max _{a} Q(s, a)$$ 在上述蒙特卡洛方法中, 如果是确定性策略, 那么实际上采样过程获取的样本都是一样的, 并不能获取不同样本. 因此可以引入环境探索率ϵ, 使得再采样过程中, 以ϵ的概率不选择当前策略, 而是随机从所有动作中随机选择一个执行. 同策略与异策略同策略(On Policy): 采样策略与待优化策略是同一个策略异策略(Off Policy): 采样策略与待优化策略是不同策略 策略梯度强化学习的目标是获得一个策略, 来最大化期望回报, 即求 $$\\bar{R}_{\\theta}=\\sum_{\\tau} R(\\tau) p_{\\theta}(\\tau)$$ 对上式计算梯度, 可得 $$\\nabla \\bar{R}_{\\theta}=\\sum_{\\tau} R(\\tau) \\nabla p_{\\theta}(\\tau)=\\sum_{\\tau} R(\\tau) p_{\\theta}(\\tau) \\frac{\\nabla p_{\\theta}(\\tau)}{p_{\\theta}(\\tau)}$$ 由于 \\( p_{\\theta}(\\tau)\\)中, 可以控制的部分只有策略, 因此最终可得 $$\\nabla \\bar{R}_{\\theta}=\\frac{1}{N} \\sum_{n=1}^{N} \\sum_{t=1}^{T_{n}} R\\left(\\tau^{n}\\right) \\nabla \\log p_{\\theta}\\left(a_{t}^{n} \\mid s_{t}^{n}\\right)$$ 由于要期望最大化, 因此获得梯度后, 使用梯度上升的方法, 即可逐渐增加目标函数值.","categories":[{"name":"机器学习","slug":"机器学习","permalink":"https://lizec.top/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://lizec.top/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}]},{"title":"Docker笔记之使用镜像","slug":"Docker笔记之使用镜像","date":"2020-06-19T06:17:47.000Z","updated":"2020-11-27T11:00:25.000Z","comments":true,"path":"2020/06/19/Docker笔记之使用镜像/","link":"","permalink":"https://lizec.top/2020/06/19/Docker%E7%AC%94%E8%AE%B0%E4%B9%8B%E4%BD%BF%E7%94%A8%E9%95%9C%E5%83%8F/","excerpt":"","text":"Docker可以视为一种轻量级的虚拟机, 可以将应用程序和其依赖环境进行打包, 从而在新平台上直接部署. 因此如果依赖环境基本不变, 服务器状态基本不变, 只有其中的应用程序不断更新, 那么在这种场景下, Docker的意义不大. 以Python项目为例, Conda完全可以实现配置依赖环境的功能, 且与Docker相比, 减少了打包等操作. Docker的另外一个意义是实现微服务, 每一个组件都可以单独放置在一个Docker容器内, 并且容器之间相互隔离. 因此如果不使用微服务, 那么这种情况下也不适合使用Docker. 在适合Docker的场景下, 使用Docker可以减少工作量, 在其他场景下, 使用脚本可能是一个更适合的方案. 本文介绍Docker的基本概念, 配置方法, 和基本使用. Docker安装与配置对于Linux系统, 可以直接执行apt进行安装, 指令如下 123sudo apt install docker.iosudo systemctl start dockersudo systemctl enable docker 注意: 如果已经安装了docker, 需要先卸载相关组件在进行安装 其他的安装方式, 可以参考如下内容 How To Install Docker On Ubuntu 18.04 Bionic Beaver 配置镜像在 /etc/docker/daemon.json 中写入如下内容（如果文件不存在请新建该文件） 123456&#123; &quot;registry-mirrors&quot;: [ &quot;https://hub-mirror.c.163.com&quot;, &quot;https://mirror.baidubce.com&quot; ]&#125; 然后重启服务 12sudo systemctl daemon-reloadsudo systemctl restart docker 镜像加速器 Docker操作镜像Docker的镜像操作都是以docker image开始的指令, 常见指令如下表所示 操作 指令 操作 指令 显示本地镜像 ls 删除本地镜像 rm &lt;imageName&gt; 拉取远程镜像 pull &lt;imageName&gt; 例如, 想要拉取官方的测试镜像, 可以执行 1docker image pull library/hello-world 由于官方的镜像都位于library/下, 因此library/是默认路径, 也可以省略不写. 此外, 每个镜像还可以具有不同的标签, 例如UBUNTU:18.04表示具有18.04标签的的UBUNTU镜像. 如果不指定标签, 则默认下载LATEST标签 官方镜像Docker Hub是官方的镜像查询网站. 在此网站上可以查询最近的进行镜像, 以及镜像的使用说明. Docker操作容器镜像文件在运行之后, 就会生成容器文件. 关闭容器后, 其中的程序停止运行, 但容器文件本身并不会被删除. 容器操作的指令都是以docker container开头的指令, 常见的指令如下表所示 操作 指令 操作 指令 查看运行中容器 ls 查看所有容器 ls --all 启动镜像 run &lt;imageName&gt; 启动容器 start &lt;containerId&gt; 删除容器 rm &lt;containerID&gt; 停止容器 kill &lt;containerId&gt; 执行ls指令后, 会输入类似如下格式的内容 123CONTAINER ID IMAGE COMMAND CREATED STATUSf1cdbb6d6fce onlyoffice/documentserver &quot;/bin/sh -c /app/ds/…&quot; 5 weeks ago Up 5 weeks673ef1834e3d nextcloud &quot;/entrypoint.sh apac…&quot; 2 months ago Up 2 months 运行镜像启动镜像时, 可以指定如下的一些参数来控制容器的行为, 具体如下表所示: 参数 效果 参数 效果 -i 交互使用 -t 连接镜像的终端 --rm 容器关闭后删除容器文件 例如, 以下指令表示启动ubuntu 18.04的镜像文件, 以交互模式连接该系统的终端, 并且在容器关闭后删除容器文件. 1docker container run -it --rm ubuntu:18.04 bash 通常情况下, 是不会删除容器文件的, 但出于测试的目的, 可以在使用完毕后删除容器文件, 从而节省硬盘空间. 进入容器在镜像运行以后, 还可以通过命令行进入容器内, 从而查看或者执行需要的指令. 可以使用如下的指令进入容器并启动一个shell 1sudo docker exec -it &lt;containerID&gt; /bin/bash 例如可以进入一个mysql容器中, 并查看IP地址信息, 从而从外部连接到数据库. 进入docker容器的四种方法 Docker维护映射通常情况下, 可以直接运行相关的镜像, 如果容器需要存储空间, 会自动映射数据卷. 但也可以通过手动指定的方式, 明确数据卷的存储位置. 1$ docker run -d -v nextcloud:/var/www/html -p 8080:80 nextcloud 以上述指令为例, 通过-v参数将宿主机的相对路径目录nextcloud映射到了容器中的/var/www/html. 当宿主机使用功能相对路径时, 其相对于数据卷的根目录/var/lib/docker/volumes/. 通过-p参数, 将宿主机的8080端口与容器的80端口关联, 从而访问宿主机8080端口就等价于访问容器的80端口. 关于Docker目录挂载的总结 查看空间占用情况Docker的容器在运行过程中可能需要存储数据, 进而在磁盘上创建数据卷, 可以使用docker system df -v查看docker所有相关组件的空间占用情况 12345678910111213141516171819root@iZ:~# docker system df -vImages space usage:REPOSITORY TAG IMAGE ID CREATED SIZE SHARED SIZE UNIQUE SIZE CONTAINERSnextcloud latest 137bb882dbc1 12 months ago 676.3MB 0B 676.3MB 0Containers space usage:CONTAINER ID IMAGE COMMAND LOCAL VOLUMES SIZE CREATED STATUS NAMESLocal Volumes space usage:VOLUME NAME LINKS SIZE1faa7f03e67410a04aa6fb5038d89f8349210e0c3a27cf30d65043843426ea5e 0 202.6MB3124a81cd8cfae41156f80fb6d4ff49df17d4af1d10705b9aae609e0851cd5c5 0 1.201GBBuild cache usage: 0BCACHE ID CACHE TYPE SIZE CREATED LAST USED USAGE SHARED 其中VOLUME为容器的数据卷, 其生命周期独立于容器, 如果需要清理无用的数据卷, 可以执行docker volume prune 参考文献第一篇文章对Docker进行了简要的介绍, 第二篇文章是一个系列教程, 对Docker进行了比较深入的介绍. Docker 入门教程 Docker —— 从入门到实践","categories":[],"tags":[{"name":"docker","slug":"docker","permalink":"https://lizec.top/tags/docker/"}]},{"title":"数学工具之LINGO使用笔记","slug":"数学工具之LINGO使用笔记","date":"2020-05-10T02:15:08.000Z","updated":"2020-05-15T14:32:51.381Z","comments":true,"path":"2020/05/10/数学工具之LINGO使用笔记/","link":"","permalink":"https://lizec.top/2020/05/10/%E6%95%B0%E5%AD%A6%E5%B7%A5%E5%85%B7%E4%B9%8BLINGO%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/","excerpt":"","text":"基本模型如果需要求解的问题比较简单, 可以直接使用数学表示, 例如 12345min=2*x1+3*x2;x1+x2&gt;=350;x1&gt;=100;2*x1+x2&lt;=600; 注意: 第一行是目标函数, 其余为约束条件 约束条件默认取等号 变量默认大于零 程序结构小型模型一个标准的程序示例如下所示: 123456789model:title: 标准程序示例;! 这是注释;[opt] min=2*x1+3*x2;[st1] x1+x2&gt;=350;[st2] x1&gt;=100;[st3] 2*x1+x2&lt;=600;@gin(x1);@gin(x2);end 注意: 所有语句都用分号结尾, 包括注释 使用title来指定标题 使用中括号对行命名, 在分析报告中使用此名称替代行号对应的数字 大型模型大型模型采用分段的结构, 将变量, 数据和模型分离, 整体结构类似于如下的结构 123456789101112131415161718192021222324252627model:title: 6发点8收点运输问题;sets: warehouses/wh1..wh6/: capacity; vendors/v1..v8/: demand; links(warehouses,vendors): cost, volume;endsets!目标函数; min=@sum(links: cost*volume);!需求约束; @for(vendors(J): @sum(warehouses(I): volume(I,J))=demand(J));!产量约束; @for(warehouses(I): @sum(vendors(J): volume(I,J))&lt;=capacity(I));!这里是数据;data: capacity=60 55 51 43 41 52; demand=35 37 22 32 41 32 43 38; cost=6 2 6 7 4 2 9 5 4 9 5 3 8 5 8 2 5 2 1 9 7 4 3 3 7 6 7 3 9 2 7 1 2 3 9 5 7 2 6 5 5 5 2 2 8 1 4 3;enddataend 定义变量集对于有大量变量的优化问题, 逐一定义变量是一件非常麻烦的事情. 此时可以使用集的概念来批量的定义变量. 集是一组成员的集合, 而每个成员又可以具有若干的属性, 因此集的定义表示为 123set:&lt;setname&gt;[/&lt;member_list&gt;/][:&lt;attribute_list&gt;];endsets 成员名称可以使用逗号分割的方式逐一制定, 也可以按照上面的例子, 使用缩写表示来自动定义多个变量. 隐式成员格式有 格式 示例 成员 1..n 1..5 1,2,3,4,5 StringM..StringN Car2..Car5 Car2, Car3, Car4, Car5 DayM..DayN Mon..Fri Mon, Tue, Wed, Thu, Fri MonthM..MonthN Oct..Jan Oct, Nov, Dec, Jan MonthYearM..MonthYearN Oct2001..Jan2002 Oct2001, Nov2001, Dec2001, Jan2002 派生集派生集是在其他集合的基础上构建的新集合, 默认情况下, 其成员为所有继承的集合的组合, 派生集语法为 1&lt;setname&gt;(&lt;parent_set_list&gt;)[/&lt;member_list&gt;/][:&lt;attribute_list&gt;]; 例如分别定义三个集合, 则基于这三个集合的派生集合可以定义为如下的形式 123456sets: product/A B/; machine/M N/; week/1..2/; allowed(product,machine,week):x;endsets allowed拥有2x2x2=8个成员, 且每个成员都具有x属性. 这种默认包含所有成员的组合的集合称为稠密集, 如果希望去掉部分不需要的元素, 可以使用LINGO的逻辑表达式, 例如 属性列在data部分指定数据, 可以依据某一个属性来指定, 也可以依据对象来指定. 1234567sets: set1/A,B,C/: X,Y;endsetsdata: X=1,2,3; Y=4,5,6;enddata 12345678sets: set1/A,B,C/: X,Y;endsetsdata: X,Y=1 4 2 5 3 6;enddata 将所有成员的属性指定为一个值 123456sets: days /MO,TU,WE,TH,FR,SA,SU/:needs;endsetsdata: needs = 20;enddata 部分指定 123456sets: years/1..5/: capacity;endsetsdata: capacity = ,34,20,,;enddata 函数数学函数LINGO提供了大量的函数, 一般以@开头, 例如@sin,@abs,@log(自然对数)等等. 除去这些常见的数学函数以外, LINGO还定义了如下的一些重要的数学函数 函数 作用 函数 作用 @sign 符号函数 @floor 取整 @smax 返回一组数据的最大值 @smin 返回一组数的最小值 使用示例: 12345678910111213model:sets: object/1..3/: f;endsetsdata: a, b = 3, 4; !两个直角边长，修改很方便;enddata f(1) = a * @sin(x); f(2) = b * @cos(x); f(3) = a * @cos(x) + b * @sin(x); min = @smax(f(1),f(2),f(3)); @bnd(0,x,1.57);end 变量定界函数 函数 作用 函数 作用 @bin(x) 限制为0-1变量 @gin(x) 限制为整数 @bnd(L,x,U) 限制取值范围在L和U之间 @free(x) 取消变量默认大于零的限制 变量定界函数在约束条件部分单独对变量执行即可. 例如 1234567sets:a/1..100/:x;b/1..100/:y;endsets@for(b(j):@gin(y(j))); @for(a(i):@bin(x(i))); 集循环函数1@&lt;function&gt;(&lt;setname&gt;[(&lt;set_index_list&gt;)[|&lt;conditional_qualifier&gt;]]:&lt;expression_list&gt;); 从上面的格式可以注意到: 集合名称必须指定 索引可以省略 过滤条件可以省略 表达式部分必须指定 因此如果是针对整个集合的操作, 显然可以省略索引和过滤条件, 例如某个集合之和小于90可以表示为 12345model:sets: s/1..100/:x;endsets@sum(s:x)&lt;90; 逻辑表达式可以表达分段函数","categories":[],"tags":[]},{"title":"PyTorch笔记之TorchText","slug":"PyTorch笔记之TorchText","date":"2020-04-11T04:13:30.000Z","updated":"2020-06-26T14:53:17.403Z","comments":true,"path":"2020/04/11/PyTorch笔记之TorchText/","link":"","permalink":"https://lizec.top/2020/04/11/PyTorch%E7%AC%94%E8%AE%B0%E4%B9%8BTorchText/","excerpt":"","text":"本文介绍PyTorch的文本处理库TorchText. 在自然语言相关的任务中, 训练模型的第一步就是对文本数据进行预处理. 通常文本数据的预处理包括: (1) 从磁盘加载文本数据并分词; (2) 将单词映射为数字, 将句子映射成数字的列表; (3) 将数据转化为分批次的数据. 本文的主要内容是TorchText的基本概念以及上述预处理过程的TorchText实现方法. TorchText概述TorchText的作用是从文本文件, csv文件, json文件或者文件夹中读取数据并转换为一种标准格式的Dataset. 之后, TorchText使用迭代器对数据集中的数据进行数字化, 批次化等操作并决定是否将数据输送到GPU的显存之中. TorchText涉及如下的几个概念 概念 含义 概念 含义 Dataset 存储数据的对象, 由Example构成 Example 一个训练数据, 例如一行记录 Fields 定义数据集属性的处理方法 Iterator 定义数据的批次化, 数字化和遍历顺序等输入细节 关于上述几个类有几种实现, 每种实现提供什么功能可以参考官方文档. 以下分别介绍这些概念的基础信息. FieldsFields的含义是字段, 但在TorchText中指的是数据的处理方式, Fields指定数据集的字段的处理方法. 例如一个数据集可能按照如下的方式定义 12345from torchtext.data import Fieldtokenize = lambda x: x.split()TEXT = Field(sequential=True, tokenize=tokenize, lower=True)LABEL = Field(sequential=False, use_vocab=False) 上面是一个分类任务, 其中文本是连续的句子, 而标签是一个词, 因此两者的处理方式显然不同. Fieid提供了很多字段来表达如何对某个字段的数据进行处理, 一些常见的字段含义如下表所示. 参数 含义 sequential 是否需要对输入分词 use_vocab 是否使用单词表, 否则表明输入已经数字化了 lower 是否将字母转化为小写字母 fix_length 是否有固定长度 Fieid的Doc String提供了详细的说明, 编程时可以直接参考 TorchText提供了多种不同功能的Field, 具体效果可以参考文档的Field章节. Dataset如果给定的数据是CSV这类格式化数据, 可以使用TorchText提供的TabularDataset类, 此类可以自动完成数据的读取和分割操作. 具体代码如下所示 12345678910111213141516171819202122232425from torchtext.data import TabularDatasettv_datafields = [(&quot;id&quot;, None), (&quot;comment_text&quot;, TEXT), (&quot;toxic&quot;, LABEL), (&quot;severe_toxic&quot;, LABEL), (&quot;threat&quot;, LABEL), (&quot;obscene&quot;, LABEL), (&quot;insult&quot;, LABEL), (&quot;identity_hate&quot;, LABEL)]# splits函数可以分别制定训练集, 验证集和测试集的文件位置. 给定几个位置, 就返回几个数据集trn, vld = TabularDataset.splits( path=&quot;data&quot;, train=&#x27;train.csv&#x27;, validation=&quot;valid.csv&quot;, format=&#x27;csv&#x27;, skip_header=True, fields=tv_datafields)tst_datafields = [(&quot;id&quot;, None), (&quot;comment_text&quot;, TEXT)]tst = TabularDataset( path=&quot;data/test.csv&quot;, # the file path format=&#x27;csv&#x27;, skip_header=True, fields=tst_datafields) 在构建数据组的过程中, 我们首先创建(name, field)的元组列表, 其中name指定的数据列的名称, field指定了数据的处理方式. 使用同一field的字段共用单词表. 这个列表需要和数据集的属性一一对应. 对于我们不使用的属性列, 可以将field列置为None. 由于python是动态语言, 因此可以通过访问相应的字段获得相应的数据, 具体如下所示: 123456&gt;&gt;&gt; trn[0]torchtext.data.example.Example at 0x10d3ed3c8&gt;&gt;&gt; trn[0].__dict__.keys()dict_keys([&#x27;comment_text&#x27;, &#x27;toxic&#x27;, &#x27;severe_toxic&#x27;, &#x27;threat&#x27;, &#x27;obscene&#x27;, &#x27;insult&#x27;, &#x27;identity_hate&#x27;])&gt;&gt;&gt; trn[0].comment_text[:3][&#x27;explanation&#x27;, &#x27;why&#x27;, &#x27;the&#x27;] 从上面的输出可以注意到如下的几点: Dataset确实是Example组成的列表. 数据集中的句子已经被分词, 但还没有转化为数字 划分数据集注意到上面的代码分别读取了测试集的文件和验证集的文件. 如果给定的数据集并没有专门的划分测试集和验证集, 则可以通过split方法进行划分. 示例如下: 1234567891011dataset = TabularDataset( path=&quot;data/all.csv&quot;, format=&#x27;csv&#x27;, skip_header=True, fields=tst_datafields)# 指定测试集与验证集的比例trn, vld = dataset.split(split_ratio=0.9)# 完整的指定所有的比例为8:1:1trn, test, vld = dataset.split(split_ratio=[8,1,1]) split方法的参数传递方式比较复杂, 但我认为主要是以上的两种使用方法, 更多细节可以参考此方法的文档 Vocab构建单词表从Dataset的comment_text字段的输出可以看到, 句子已经被分词, 但还没有转化为数字, 因此接下来需要执行数字化操作, 将每个单词对应一个数字, 这一操作只需要一行代码, 即 1TEXT.build_vocab(trn) 测试集(trn)中所有与TEXT绑定的属性都会被遍历一次, 将所有的单词构成一个词表. 经过此操作后, TEXT会包含两个字典TEXT.vocab.stoi和TEXT.vocab.itos. 这两个字典实现了单词到数字和数字到单词的转换, 一个例子如下所示 12345678In[9] :TEXT.vocab.stoiOut[9]: defaultdict(&lt;bound method Vocab._default_unk_index of &lt;torchtext.vocab.Vocab object at 0x7efe7974f310&gt;&gt;, &#123;&#x27;&lt;unk&gt;&#x27;: 0, &#x27;&lt;pad&gt;&#x27;: 1, &#x27;the&#x27;: 2, ...&#125;) 如果查询的单词不在单词本中, 则使用&lt;unk&gt;符号代替(表示Unknow) 预训练词向量TorchText提供了加载预训练词向量的功能, 内置的词向量列表如下所示: 123456789101112131415pretrained_aliases = &#123; &quot;charngram.100d&quot;: partial(CharNGram), &quot;fasttext.en.300d&quot;: partial(FastText, language=&quot;en&quot;), &quot;fasttext.simple.300d&quot;: partial(FastText, language=&quot;simple&quot;), &quot;glove.42B.300d&quot;: partial(GloVe, name=&quot;42B&quot;, dim=&quot;300&quot;), &quot;glove.840B.300d&quot;: partial(GloVe, name=&quot;840B&quot;, dim=&quot;300&quot;), &quot;glove.twitter.27B.25d&quot;: partial(GloVe, name=&quot;twitter.27B&quot;, dim=&quot;25&quot;), &quot;glove.twitter.27B.50d&quot;: partial(GloVe, name=&quot;twitter.27B&quot;, dim=&quot;50&quot;), &quot;glove.twitter.27B.100d&quot;: partial(GloVe, name=&quot;twitter.27B&quot;, dim=&quot;100&quot;), &quot;glove.twitter.27B.200d&quot;: partial(GloVe, name=&quot;twitter.27B&quot;, dim=&quot;200&quot;), &quot;glove.6B.50d&quot;: partial(GloVe, name=&quot;6B&quot;, dim=&quot;50&quot;), &quot;glove.6B.100d&quot;: partial(GloVe, name=&quot;6B&quot;, dim=&quot;100&quot;), &quot;glove.6B.200d&quot;: partial(GloVe, name=&quot;6B&quot;, dim=&quot;200&quot;), &quot;glove.6B.300d&quot;: partial(GloVe, name=&quot;6B&quot;, dim=&quot;300&quot;)&#125; 如果需要使用这些词向量, 可以通过的两种方式使用 12345# 直接通过名称获取预训练词向量TEXT.build_vocab(train, vectors=&quot;glove.6B.200d&quot;)# 或者通过一个具体的类型来获取相应的词向量TEXT.build_vocab(train, vectors=GloVe(name=&#x27;6B&#x27;, dim=300)) TorchText将会通过网络下载对应的预训练词向量 通过上述的方法加载词向量后, 可以将词向量的值传递给Embedding层, 代码如下 12345# 通过pytorch创建的Embedding层embedding = nn.Embedding(2000, 256)# 指定嵌入矩阵的初始权重weight_matrix = TEXT.vocab.vectorsembedding.weight.data.copy_(weight_matrix ) 加载预训练词向量后, Field对象的vocab字段会加载词向量(即vectors). 将词向量复制给Embedding层的权重矩阵, 即可实现词向量的加载. Example针对表格类型的数据集, TabularDataset能够很好的处理, 但如果涉及更一般的数据集, 则必须使用更一般的方式构建. 因为Dataset实际是就是Example的列表, 因此构建自定义数据集的关键就是构建Example. 1234567891011121314151617from torchtext.data import Examplefrom torchtext.data import Field, Dataset# 假设数据集由两句话构成text = [&quot;How are you?&quot;, &quot;I am fine. Thank you.&quot;]# 同样的构建FieldTEXT = Field(sequential=True, tokenize=lambda x: x.split(), lower=True)LABEL = Field(sequential=False, use_vocab=False)fields = [(&quot;text&quot;, TEXT), (&quot;label&quot;, LABEL)]examples = []for t in text: # 每一个Example中, text部分来自t, label部分始终等于&quot;LABEL&quot; examples.append(Example.fromlist([t, &quot;LABEL&quot;], fields))# 通过Example和Field构建Datasetdataset = Dataset(examples, fields) Example还提供了从CVS和JSON读取数据的方法 Iterator迭代器的作用是完成最后的数据处理, 包括基本的数据转换, 将数据组成批次, 数据移动到GPU等. 1234567891011device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)train_iter, val_iter = BucketIterator.splits( (trn, vld), # we pass in the datasets we want the iterator to draw data from batch_sizes=(64, 64), device=device, sort_key=lambda x: len(x.comment_text), sort_within_batch=False, repeat=False )test_iter = Iterator(tst, batch_size=64, device=device, sort=False, sort_within_batch=False, repeat=False) BucketIterator支持批量操作, 因此可以同时输入多个数据集, BucketIterator就相应的返回多个迭代器. BucketIterator的特点是支持对数据进行排序, 从而将相似的数据移动到同一批次. 当数据需要进行填充对齐时, 可以利用这一特点将长度相近的数据移动到一起, 从而提高效率. 测试集通常不需要改变顺序, 因此可以使用普通的迭代器. 迭代器创建之后, 可以调用__iter__()方法获得迭代器对象, 并使用Python的next()函数获取数据. 不过由于接口和数据集的字段有一些耦合, 因此可以使用下面的类对迭代器进行包装 123456789101112131415161718class BatchWrapper: def __init__(self, dl, x_var, y_vars): self.dl, self.x_var, self.y_vars = dl, x_var, y_vars # we pass in the list of attributes for x def __iter__(self): for batch in self.dl: x = getattr(batch, self.x_var) # we assume only one input in this wrapper if self.y_vars is not None: # we will concatenate y into a single tensor y = torch.cat([getattr(batch, feat).unsqueeze(1) for feat in self.y_vars], dim=1).float() else: y = torch.zeros((1)) yield (x, y) def __len__(self): return len(self.dl) 这个类的作用是将迭代器的属性分成x和y两个集合, 从而方便后续的处理. 使用方法如下所示 12345train_dl = BatchWrapper(train_iter, &quot;comment_text&quot;, [&quot;toxic&quot;, &quot;severe_toxic&quot;, &quot;obscene&quot;, &quot;threat&quot;, &quot;insult&quot;, &quot;identity_hate&quot;])valid_dl = BatchWrapper(val_iter, &quot;comment_text&quot;, [&quot;toxic&quot;, &quot;severe_toxic&quot;, &quot;obscene&quot;, &quot;threat&quot;, &quot;insult&quot;, &quot;identity_hate&quot;])test_dl = BatchWrapper(test_iter, &quot;comment_text&quot;, None) 一点细节如何加载词向量以下是torchtext.vocab.Vocab.load_vectors方法的代码片段. vectors是加载的预训练词向量, self.vectors是根据任务构建的词汇向量表. 123456789tot_dim = sum(v.dim for v in vectors)self.vectors = torch.Tensor(len(self), tot_dim)for i, token in enumerate(self.itos): start_dim = 0 for v in vectors: end_dim = start_dim + v.dim self.vectors[i][start_dim:end_dim] = v[token.strip()] start_dim = end_dim assert(start_dim == tot_dim) 从上面的代码可以发现, 加载词向量的过程就是根据任务构建的词汇表向预训练词汇表查询的过程. 如果预训练的vectors是一个列表, 那么还可以自动实现将多个预训练向量首位拼接为一个向量的功能. 为了保证通用性, 预训练的词向量文件加载后提供 “根据单词查询向量” 的功能, 是非常符合逻辑的. 预训练词表中没有的单词的取值情况显然取决于各个词表的默认行为了.","categories":[{"name":"PyTorch笔记","slug":"PyTorch笔记","permalink":"https://lizec.top/categories/PyTorch%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://lizec.top/tags/Python/"},{"name":"PyTorch","slug":"PyTorch","permalink":"https://lizec.top/tags/PyTorch/"}]},{"title":"Python笔记之数据转换","slug":"Python笔记之数据转换","date":"2020-03-12T07:35:11.000Z","updated":"2020-06-20T13:36:06.309Z","comments":true,"path":"2020/03/12/Python笔记之数据转换/","link":"","permalink":"https://lizec.top/2020/03/12/Python%E7%AC%94%E8%AE%B0%E4%B9%8B%E6%95%B0%E6%8D%AE%E8%BD%AC%E6%8D%A2/","excerpt":"","text":"本文介绍Python数据转换相关的库, 主要包括如何使用Python读写Excel文件和数据库. 本文中, 读取Excel的库为openpyxl 打开和保存Excel文件123from openpyxl import Workbookwb1 = Workbook() # 直接在内存中创建一个Excel文件wb2 = load_workbook(&#x27;test.xlsx&#x27;) # 读取一个已经存在的Excel文件 无论是哪种方法创建的Excel, 其中至少包含一个Sheet. 可以使用如下的方法获得默认Sheet 12ws = wb.activews = wb[&#x27;Sheet1&#x27;] 最终, 可以调用wb.save(&lt;name&gt;)保存文件. 访问Excel的数据openpyxl充分利用了Python的切片功能, 因此可以非常简单的获得Excel中某个区域的数据, 例如 要求 示例 要求 示例 获得某一行 ws[10] 获得某一列 ws[&#39;C&#39;] 获得某些行 ws[5:10] 获得某些列 ws[&#39;A:C&#39;] 获得任意数据 ws[A1:C5] 无论是获得一个矩形区域的数据, 还是单行数据, 或者一个单元的数据, 使用这种风格获得的数据的返回值都是一个二维的Tuple. 例如 123((&lt;Cell &#x27;Sheet1&#x27;.A1&gt;,), (&lt;Cell &#x27;Sheet1&#x27;.A2&gt;,), (&lt;Cell &#x27;Sheet1&#x27;.A3&gt;,)) 因此可以考虑使用如下的方式将二维数组变为一维数组. 12345import operatorfrom functools import reducea = [[1,2,3], [4,6], [7,8,9,8]]print(reduce(operator.add, a))[1, 2, 3, 4, 6, 7, 8, 9, 8] 如果是取出一行或者一列, 那么直接取出返回值的第0个元素即可. 按行按列遍历openpyxl提供了两个迭代器ws.iter_rows, ws.iter_cols和两个属性ws.rows, ws,columns, 可以分别按行和按列遍历整个表格, 例如 123456789&gt;&gt;&gt; for row in ws.iter_rows(min_row=1, max_col=3, max_row=2):... for cell in row:... print(cell)&lt;Cell Sheet1.A1&gt;&lt;Cell Sheet1.B1&gt;&lt;Cell Sheet1.C1&gt;&lt;Cell Sheet1.A2&gt;&lt;Cell Sheet1.B2&gt;&lt;Cell Sheet1.C2&gt; 如果只需要值(默认返回Cell, 需要手动取值), 可以对迭代器指定一个参数values_only=True, 或者直接遍历属性ws.values 添加数据如果是规则的按行添加数据, 可以直接使用ws.append在表格的末尾加入一行数据. 例如 1ws.append([1,2,3]) 也可以直接对Cell进行赋值来添加数据. 其他事项 如果只是写入Excel, 那么可以考虑用pandas进行处理, 然后直接用其API保存为Excel文件","categories":[{"name":"Python笔记","slug":"Python笔记","permalink":"https://lizec.top/categories/Python%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://lizec.top/tags/Python/"},{"name":"Excel","slug":"Excel","permalink":"https://lizec.top/tags/Excel/"}]},{"title":"PyTorch笔记之基础知识","slug":"PyTorch笔记之基础知识","date":"2020-02-07T06:04:56.000Z","updated":"2020-06-26T14:53:12.313Z","comments":true,"path":"2020/02/07/PyTorch笔记之基础知识/","link":"","permalink":"https://lizec.top/2020/02/07/PyTorch%E7%AC%94%E8%AE%B0%E4%B9%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/","excerpt":"","text":"TensorTensor与Numpy的数组类似, 但Tensor可以在GPU上运算. 有两种方式构造Tensor, 第一种方式是直接构造Tensor, 第二种方式将一个Python的数组转化为Tensor. 两种方式的代码如下所示 123x = torch.ones([2, 2, 2]) # torch.Size([2, 2, 2]) 即 2x2x2的Tensor, 且值全部为1y = torch.tensor([2,2,2]) # torch.Size([3]) 即包含三个元素的Tensorr0 = torch.rand((2,3), dtype=torch.float32) 直接构造方法的API与Numpy类似, 也提供了各种like函数(例如ones_like)创建和输入尺寸相同的数组 切片操作 表达式 结果 说明 a[0],a[3],a[-2] (0, 3, 8) 直接访问 a[2:8:2] array([2, 4, 6]) 切片 a[3:7] array([3, 4, 5, 6]) 省略步长 a[:4] array([0, 1, 2, 3]) 省略起始和步长 a[6:] array([6, 7, 8, 9]) 省略末尾和步长 对于二维数据有如下的访问方法和访问结果: 表达式 结果 说明 b[0,0],b[2,-1] (0, 25) 直接访问 b[0,2:5] array([2, 3, 4]) 切片 b[2,:] array([20, 21, 22, 23, 24, 25]) 选取整行 b[:,3] array([ 3, 13, 23, 33, 43, 53]) 选取整列 切片操作与Numpy的API相同, 可以参考相关的笔记 调整维度pyTorch使用view函数调整维数, 示例如下 1234x = torch.randn(4, 4) # torch.Size([4, 4]) y = x.view(16) # torch.Size([16]) z = x.view(-1, 8) # torch.Size([2, 8]) w = x.view(1,-1) # torch.Size([1, 16]) 注意: -1表示从其他维度推断此维度的大小 torch.Size([16]) 和 torch.Size([1, 16]) 是不同的, 后者是二维的数组 pyTorch使用squeeze()函数和unsqueeze()函数调整Tensor的维度. squeeze()函数取消数量为1的维度, unsqueeze()函数增加一个数量为1的维度. 例如 12345678910111213141516171819202122# 创建一个2x3的Tensor, 输出如下所示&gt;&gt;&gt; x = torch.tensor([[1,2,3],[4,5,6]])xtensor([[1, 2, 3], [4, 5, 6]])# 在第0个维度添加一个额外的维度&gt;&gt;&gt; x.unsqueeze(dim=0)tensor([[[1, 2, 3], [4, 5, 6]]])# 在第1个维度添加一个额外的维度x.unsqueeze(dim=1)tensor([[[1, 2, 3]], [[4, 5, 6]]])# 查看两者情况的维度&gt;&gt;&gt; x.unsqueeze(dim=0).size()torch.Size([1, 2, 3])&gt;&gt;&gt; x.unsqueeze(dim=1).size()torch.Size([2, 1, 3]) 数据转换 如果Tensor中仅包含一个元素, 则无论此Tensor的维度是多少, 都可以使用item()方法取值. 使用from_numpy()将numpy数组转化为Tensor, 使用numpy()函数将Tensor转化为numpy数组 PyCharm与DebugPycharm的Debug模式只会显示Tensor的第一个维度的信息, 例如 12x2 = torch.tensor([[1, 2, 3], [4, 3, 5]])x3 = torch.tensor([[[1, 2, 3], [4, 3, 5]], [[1, 2, 3], [4, 3, 5]]]) Debug时看到的信息如下所示: 12x2 = &#123;Tensor:2&#125; tensor([[1, 2, 3], \\n [4, 3, 5]])x2 = &#123;Tensor:2&#125; tensor([[[1, 2, 3], \\n [4, 3, 5]], \\n\\n [[1, 2, 3], \\n [4, 3, 5]]]) 因此获取维度信息最准确的办法是在Debug时使用变量计算机直接调用Tensor的size()方法 显示的信息包含了一些换行符号(\\n), 因此直接输出的效果与IPython中的Numpy矩阵类似 自动微分概述PyTorch提供自动微分功能 定义Tensor时指定参数requires_grad=True可以开启自动微分的记录功能 在Tensor上调用backward()函数将梯度信息写入Tensor的grad字段 如果Tensor是标量, 则backward()函数不需要参数, 否则需要提供一个Tensor作为参数 Module通常使用python的类机制构建Module, 每个Module就是一个可以独立计算的模块. 一个标准的Module一般具有如下的结构 12345678910111213class NGramLanguageModeler(nn.Module): def __init__(self, vocab_size, embedding_dim, context_size): super(NGramLanguageModeler, self).__init__() self.embeddings = nn.Embedding(vocab_size, embedding_dim) self.linear1 = nn.Linear(context_size * embedding_dim, 128) self.linear2 = nn.Linear(128, vocab_size) def forward(self, inputs): embeds = self.embeddings(inputs).view((1, -1)) out = F.relu(self.linear1(embeds)) out = self.linear2(out) log_probs = F.log_softmax(out, dim=1) return log_probs 可以明显的看到代码具有如下的特点: 自定义模块继承标准的nn.Module类 在init函数中构造网络的子模块 在forward函数中定义网络的正向计算过程 通常init函数定义包含可训练参数的模块, forward模块定义不包含可训练参数的模块 内置的模块都定义在nn包中 此外还要注意以下几点: nn.Module类自动计算反向传播过程 nn.Module类重载了call运算符, 因此直接圆括号调用模型, 不需要手动调用forward方法 圆括号调用使得我们的自定义模块和内置的模块的调用方法一致, 便于将我们的模块嵌入到其他模块之中 小知识 任何会就地(in place)改变Tensor的操作都会后置一个_符号, 例如 y.add_(x) PyTorch 的 backward 为什么有一个 grad_variables 参数？因为张量对张量的求导不易表示, 因此框架强制限定只能做标量对张量的求导(结果始终是确定维数的张量). 如果需要微分的变量是张量, 则传递另外一个张量, 将带求变量求和成标量后再求导数 训练过程完成网络的forward计算以后, 训练过程就相对比较固定了, 可以分为如下的步骤 构造网络的输入数据 清空网络的梯度 使用网络计算输出 计算损失函数值loss loss计算整个图的梯度并使用优化器优化网络 整个过程可以参考以下的代码 123456789101112131415161718192021222324252627for epoch in range(10): total_loss = 0 for context, target in trigrams: # Step 1. Prepare the inputs to be passed to the model (i.e, turn the words # into integer indices and wrap them in tensors) context_idxs = torch.tensor([word_to_ix[w] for w in context], dtype=torch.long) # Step 2. Recall that torch *accumulates* gradients. Before passing in a # new instance, you need to zero out the gradients from the old # instance model.zero_grad() # Step 3. Run the forward pass, getting log probabilities over next # words log_probs = model(context_idxs) # Step 4. Compute your loss function. (Again, Torch wants the target # word wrapped in a tensor) loss = loss_function(log_probs, torch.tensor([word_to_ix[target]], dtype=torch.long)) # Step 5. Do the backward pass and update the gradient loss.backward() optimizer.step() # Get the Python number from a 1-element Tensor by calling tensor.item() total_loss += loss.item() losses.append(total_loss) 损失函数和优化器都有多种选择, 可以参考官方文档. 保存和加载1234567# 保存和加载整个模型torch.save(model_object, &#x27;model.pt&#x27;)model = torch.load(&#x27;model.pt&#x27;)# 仅保存和加载模型参数(推荐使用)torch.save(model.state_dict(), &#x27;params.pt&#x27;)model.load_state_dict(torch.load(&#x27;params.pt&#x27;)) 每一轮训练后都应该及时存档, 以免意外中断导致计算结果丢失 GPU操作如果服务器上存在多块GPU, PyTorch默认使用第0块GPU, 如果此时第0块GPU正在运行程序, 则可以手动指定其他GPU. 例如希望在第1块GPU上运行, 则可以输入 1CUDA_VISIBLE_DEVICES=1 python my_script.py","categories":[{"name":"PyTorch笔记","slug":"PyTorch笔记","permalink":"https://lizec.top/categories/PyTorch%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://lizec.top/tags/Python/"},{"name":"PyTorch","slug":"PyTorch","permalink":"https://lizec.top/tags/PyTorch/"}]},{"title":"深度自然语言处理笔记","slug":"深度自然语言处理笔记","date":"2020-02-05T06:13:09.000Z","updated":"2020-06-26T14:47:35.780Z","comments":true,"path":"2020/02/05/深度自然语言处理笔记/","link":"","permalink":"https://lizec.top/2020/02/05/%E6%B7%B1%E5%BA%A6%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E7%AC%94%E8%AE%B0/","excerpt":"","text":"本文是斯坦福大学的深度自然语言处理课程的笔记, 可以在B站查看此课程的全部视频. 这里先随便写一点自己的理解. word2vec核心思想: “A word’s meaning is given by the words that frequently appear close-by.” 即对于每个词, 周围的几个词应该和这个词具有相近的含义, 因此他们的词向量应该接近. 实现这个目的, 有如下的步骤 通过两个词向量的点乘来表示两者的相识度 通过softmax函数将相似度转化为概率分布 将似然函数最大作为优化目标, 使用梯度下降优化词向量 其中使用softmax转为为概率分布的公式为 $$P(o|c)= \\frac{exp(v_0^T)}{\\sum_{w=1}^{u} exp(u_w^Tv_c)}$$ 从而有目标函数为 $$J(\\theta)=-\\frac{1}{T}\\sum_{1}^{T}\\sum_{-m \\leq j\\leq m} log P(w_{t+j}|w_t)$$ 注意第二个求和中有\\( j \\neq 0 \\) 之后如何求梯度就是各个计算框架的问题了. 减少计算量的优化由于每次计算时需要求解整个语料库的点乘, 而实际只更新窗口中的几个词, 因此可以考虑不计算整个语料库, 而是每次计算时, 随机从语料库中抽取若干词汇, 优化目标函数使这些词汇与中心词的点乘尽量小. 即 $$J(\\theta)=log\\sigma(u_o^Tv_c)+\\sum_{j\\sim P(w)}(log\\sigma(-u_j^Tv_c))$$ 通过优化此目标函数, 可以保证中心词周围的词汇的词向量与中心词接近, 随机抽取的其他词与中心词的词向量不接近. 通过P实现按频率随机选择词汇, 可以使用3/4次方来抑制抽到停止词的概率 GloVeGloVe的主要思想先读取语料库获得计数矩阵. 然后通过构造目标函数来优化计数矩阵. 计数矩阵统计了每个词周围的词出现的次数, 可以直接粗略的将每一列作为相应词的词向量. GloVe的目标函数定义为 $$J(\\theta)= \\frac{1}{2} \\sum_{i,j=1}^{w}f(P_{ij})(w_i^Tv_j-logP_{ij})^2$$ GloVe模型是一种常见的预训练词向量模型, 更多细节可以参考下面的文章 GloVe模型总结 Softmax分类器定义数据集为 \\( \\{ x_i,y_i \\}^N \\) 其中\\( x_i \\)是输入, 可以是一个词向量. \\( y_i \\)是输出, 可以是一个标签. Softmax分类器的定义为 $$p(y|x)=\\frac{exp(W_y x)}{\\sum_{c=1}^{C}exp(W_c x)}=softmax(f)_y$$ 其中W是一个权重矩阵, 是需要训练的参数. C是标签(分类)的数量. 其中有 $$W_y x = \\sum_{i=1}^d w_{yi}x_{i}=f_y$$ \\(f_y\\)就是将矩阵乘法看做函数的一种表现 相应的目标函数定义为 $$-logP(y|x) = -log\\left(\\frac{exp(f_y)}{\\sum_{c=1}^C exp(f_c)}\\right)$$ 目标函数的定义可以从交叉熵的表达式推导 设p为目标概率分布. 即一个正确分类为1, 其他分类为0的概率分布. 设q为通过softmax计算出的概率分布. 则交叉熵定义为 $$H(p,q)=-\\sum_{c=1}^C p(c)logq(c)$$ p只有正确的分为值为1, 因此就是正确分类的softmax值的负对数 最终\\( J(\\theta)\\)定义为所有样本数据的平均值 $$J(\\theta)=\\frac{1}{N} \\sum_{i=1}^N -log\\left(\\frac{exp(f_y)}{\\sum_{c=1}^C exp(f_c)}\\right)$$ 此时 \\( \\theta = W \\in R^{Cd} \\), 如果同时调整词向量的取值, 则\\( \\theta \\in R^{Cd + Vd} \\). 由于Vd是一个较大的值, 因此模型的参数数量显著增加, 如果数据集数量较少, 容易导致模型欠拟合. Window ClassificationWindow Classification是一个分类任务, 其核心思想是提取中心词周围的若干词汇, 构成一个拼接的词向量, 然后使用这个词向量训练一个softmax分类模型. 设\\( \\hat{y} \\) 为通过softmax计算的概率分布, \\( t \\)为目标分布, 则导数可以拆分为对每个分类的导数. $$\\frac{\\partial }{\\partial x} = -log softmax(f_y(x))=\\sum_{c=1}^C - \\frac{\\partial log softmax(f_y(x))}{\\partial f_c} \\frac{\\partial f_c(x)}{\\partial x}$$ 此时可以分为c为目标分类(等于y)和c不是目标分类进行讨论. 一波操作后可以得到 $$\\frac{\\partial }{\\partial x} = \\begin{bmatrix}\\hat{y_1}\\\\\\vdots\\\\\\hat{y_y}-1\\\\\\vdots\\\\\\hat{y_c}\\end{bmatrix}= [\\hat{y} - t] = \\delta$$ The Max-Margin Loss定义\\(s\\)表示正确的分类的得分, \\(s_c\\)表示错误的分类的得分, 则损失函数定义为 $$J=max(0, 1-s+s_c)$$ 这里的数字1是一个超参数, 表示当正确的分类和错误的分类的得分差值大于1就可以停止优化. 通过这样的定义,可以使得每次优化时集中优化差距较大的数据, 而足够好的数据就直接忽略. \\(s_c\\)表示负样本, 可以通过随机采样的方式获取. 循环神经网络模型RNN模型的特点是具有一个隐含层, 从而每一次输出除了和当前的输入相关, 还与隐含层的值相关, 具体定义如下 $$h_t &amp;= \\phi(h_{t-1},x_t) = f(w^{(hh)}h_{t-1}+W^{(hx)}x_t) \\\\ $$ GRUs模型GRUs模型相比于RNN模型引入了update和reset机制, 首先定义两个控制向量 $$\\begin{align}z_t &amp;= \\sigma(W^{(z)}x_t + U^{(z)}h_{t-1}) \\\\r_t &amp;= \\sigma(W^{(r)}x_t + U^{(r)}h_{t-1})\\end{align}$$ 其中 \\( z_t \\) 称为Update Gate, \\( r_t \\) 称为Reset Gate. 在此基础上定义 $$\\begin{align}\\tilde{h}t &amp;= tanh(Wx_t + r_t \\circ Uh{t-1}) \\\\h_t &amp;= z_t \\circ h_{t-1} + (1-z_t) \\circ \\tilde{h}_t\\end{align}$$ 其中r用于控制是否忽略以往的取值(即隐含层), 当r为0时, 则与考虑本次输入的影响. z用于控制隐含层的更新情况. 当z取值为1时, 则隐含层取值等于上一次隐含层的取值, 从而可以保存关键信息不被新的输入影响. LSTMs模型LSTMs模型首先定义了Input Gate, Forget Gate和输出, LSTMs模型与GRUs模型很类似, Input Gate 用于控制输入, Forget Gate用于控制隐含层, 三个部分的结构是相同的. $$\\begin{align}i_t &amp;= \\sigma(W^{(i)}x_t + U^{(i)}h_{t-1}) \\\\f_t &amp;= \\sigma(W^{(f)}x_t + U^{(f)}h_{t-1}) \\\\o_t &amp;= \\sigma(W^{(o)}x_t + U^{(o)}h_{t-1})\\end{align}$$ 然后可以分别定义New Memory Cell, Final Memory Cell和Final Hidden State, 具体如下所示. $$\\begin{align}\\tilde{c}t &amp;= tanh(W^{(c)}x_t + U^{(c)}h{t-1}) \\\\c_t &amp;= f_t \\circ c_{t-1} + i_t \\circ \\tilde{c}_t \\\\h_t &amp;= o_t \\circ tanh(c_t)\\end{align}$$ 注意力机制由于在执行机器翻译任务是, 会自动时候所有的输入作为参数, 因此注意力机制引入了一个额外的模块, 这个模块对输入的此进行评分, 从而使得网络在翻译的时候可以侧重于某个部分. BLUE评分方法BLUE评分方法是一种评价机器翻译质量的方法. 其核心思想是对于一篇文章, 给定一个人类翻译的版本作为参考, 比较机器翻译的版本与人翻译的版本有多少个词是按照同样的顺序出现. 此外, 为了避免机器翻译只输出一个词, 如果机器翻译的文本长度比人类翻译的文本的长度小, 则会受到的一定程度的惩罚. 通过此方法可以一定程度的体现机器翻译对语法结构的掌握. 递归神经网络模型递归神经网络的核心思想是提供一种将局部模块组合为一个整体的方法 短语的词向量在前面的课程中, 以及学习了如何获得单词的向量, 现在希望对一些短语也能获得相应的向量, 从而能够比较不同短语的含义. 但由于短语的数量远大于单词的数量, 因此无法将所有的短语都存储下来. 一个合理的方法是提供一种合成方法, 从而根据单词的向量合成短语的向量. 通过训练一个神经网络来实现向量的合并同时给出分数来指示这个合并是否正确","categories":[],"tags":[{"name":"自然语言处理","slug":"自然语言处理","permalink":"https://lizec.top/tags/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/"}]},{"title":"服务器端配置机器学习环境","slug":"服务器端配置机器学习环境","date":"2020-01-26T06:13:44.000Z","updated":"2020-06-26T14:44:35.809Z","comments":true,"path":"2020/01/26/服务器端配置机器学习环境/","link":"","permalink":"https://lizec.top/2020/01/26/%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%AB%AF%E9%85%8D%E7%BD%AE%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83/","excerpt":"","text":"Conda基本使用Conda是Python的包管理软件. 以下是一些常用的Conda指令 操作 指令 操作 指令 创建环境 conda create -n &lt;envname&gt; 删除环境 conda remove -n envname --all 激活环境 conda activate &lt;envname&gt; 退出环境 conda deactivate 列出环境 conda env list 列出安装包 conda list 导出环境 conda env export &gt; py36.yaml 导入环境 conda env create -f &lt;file&gt; 克隆环境 conda create -n &lt;scr&gt; --clone &lt;dst&gt; 安装包 conda install -n &lt;envname&gt; &lt;package&gt; 指定特定版本conda将Python也视为一个包, 因此可以安装特定版本的Python, 只需要在创建环境的时候指定版本, 例如 1conda create --name &lt;envname&gt; python=2.7 如果需要安装特定版本的包, 也可以使用同样的语法指定版本, 例如 1conda install pytorch=0.3 显卡信息使用nvidia-smi查看显卡的基本信息. 界面上同时会显示驱动版本和CUDA版本,这对于安装计算框架非常重要. CUDA TOOLKIT DOCUMENTATION Conda安装计算框架安装12345conda create -n tf # 安装默认版本的Python, 不需要新下载, 速度快source activate tfconda install cudatoolkit=9.1 # 注意驱动版本是否匹配, 否则无法运行conda install cudnnconda install tensorflow-gpu 测试执行如下的代码测试TensorFlow框架是否能使用GPU 12from tensorflow.python.client import device_libprint(device_lib.list_local_devices()) 执行如下代码测试PyTorch框架能否使用GPU 123import torchtorch.cuda.is_available()torch.cuda.get_device_name(0) 使用GPU如果服务器上存在多块GPU, PyTorch默认使用第0块GPU, 如果此时第0块GPU正在运行程序, 则可以手动指定其他GPU. 例如希望在第1块GPU上运行, 则可以输入 1CUDA_VISIBLE_DEVICES=1 python my_script.py Tmux基本使用Tmux是一个虚拟的终端, 当我们远程连接服务器时, 如果SSH进程断开, 通过此SSH启动的进程也会结束. 使用Tmux可以使相应的进程在后台运行, 并在需要的时候切换到前台. 操作 指令 创建进程 tmux new -s &lt;session-name&gt; 连接进程 tmux attach -t &lt;num&gt;/&lt;session-name&gt; 断开进程 tmux detach / Ctrl+b d 杀死进程 tmux kill-session -t 0 tmux attach可以缩写为tmux a 如果不指定&lt;session-name&gt;, 则默认创建一个数字ID Tmux绝对比nohup不知道高到哪里去了 高级操作Tmux具有三级的层次关系, 即session:windows:panel. Tmux实际上可以在一个session上创建多个window, 或者在一个window下创建多个panel(即分屏). 窗口基本的操作都是以前缀键Ctrl+b开始的. 分屏操作指令如下 操作 指令 操作 指令 水平分屏 Ctrl+b “ 垂直分屏 Ctrl+b % 切换窗格 Ctrl+b ↑↓←→ 调整大小 Ctrl+b Ctrl+↑↓←→ 关闭窗格 Ctrl+b x 独立窗格 Ctrl+b ! 显示编号 Ctrl+b q 全屏窗格 Ctrl+b z 如果能通过分屏解决问题, 则应该先考虑分屏 窗口操作指令如下 操作 指令 Ctrl+b c - (c)reate 生成一个新的窗口 Ctrl+b n - (n)ext 移动到下一个窗口 Ctrl+b p - (p)revious 移动到前一个窗口 参考文献 Tmux 使用教程 - 阮一峰的网络日志 终端分屏软件 tmux简单教程 前后台切换除了使用Tmux以外, 也可以使用Linux自带的控制指令手动切换前台和后台进程. 首先将当前进程挂起, 然后就可以输入下面的一些指令来切换 操作 指令 将当前进程在后台挂起 Ctrl + z 让进程在后台运行 &lt;command&gt; &amp; 查看后台运行的进程 jobs 让后台运行的进程n到前台来 fg %n 让进程n到后台运行 bg %n 杀死job kill %n为jobs命令查看到的job编号, 如果不指定则默认为当前的进程或最近的进程 参考文献 Linux - 请允许我静静地后台运行 - 知乎","categories":[{"name":"机器学习","slug":"机器学习","permalink":"https://lizec.top/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"环境配置","slug":"环境配置","permalink":"https://lizec.top/tags/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"},{"name":"Python","slug":"Python","permalink":"https://lizec.top/tags/Python/"},{"name":"机器学习","slug":"机器学习","permalink":"https://lizec.top/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}]},{"title":"Scala笔记之基础知识","slug":"Scala笔记之基础知识","date":"2019-12-17T07:12:25.000Z","updated":"2020-09-06T02:41:07.212Z","comments":true,"path":"2019/12/17/Scala笔记之基础知识/","link":"","permalink":"https://lizec.top/2019/12/17/Scala%E7%AC%94%E8%AE%B0%E4%B9%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/","excerpt":"","text":"Scala语言运行在JVM上, 因此Scala可以认为在一定程度上与Java是兼容的, Scala可以自由的使用Java所有的类. 变量Scala的变量分为可变变量与不可变变量. 变量在创建时可以指定变量类型, 也可以省略, 让编译器更具赋予的初始值自动推断类型. 所有变量都必须在定义时初始化，但如果初始值不确定, 可以使用占位符进行初始化. 12345var numberA = 123val numberB: Int = 456var strA:String = &quot;Hello&quot;val strB = &quot;World&quot;var t:Int = _ 在Scala中统一了基本类型和封装类型, 因此无论是Java中的int类型还是Integer类型, 在Scala中都是为Int类型. 惰性初始化初始化变量时， 可以采用lazy关键字， 使得变量在使用时才会赋值. lazy关键字只能修饰val变量 12345&gt; lazy val v1 = &quot;test&quot;v1: String = [lazy]&gt; v1res9: String = &quot;test 基础特性Scala有一些基础特性, 在其他语言中可能有类似的语言, 具体如下 3个双引号”””包裹的字符串保持原样输出 以s开头的字符串使用$x的形式在字符串中引用变量 支持圆括号定义元组, 并使用tuple._n的形式访问元组的第n个元素(第一个元素是_1) 支持元组拆包 使用&#39;定义一个符号(同Scheme语言) 单参数函数调用可以省略.和括号, 例如a.to(b)等价于a to b或者a + b等价于a.+(b) 支持默认参数和命名参数传递(同Python) 控制语句Scala的控制语句基本与Java一致, 但for循环有额外的格式 123for( i &lt;- 1 to 5) &#123; println(s&quot;i=$i&quot;)&#125; 其中的变量i不需要定义, 编译器能够自动推断i的类型. 表达式部分要求是任意的Range类型. to函数是包含右边界的, 如果不需要包含右边界, 可以使用until函数. 对于For循环的控制, Scala不提供break和continue关键字, 但提供类似Python列表推导格式的循环控制 123for(i &lt;- 1 to 5 if i &gt; 2; if i &lt; 4) &#123; println(s&quot;i=$i&quot;)&#125; 与Python相同, 可以使用yield关键字实现序列 数据结构Scala区分可变集合与不可变集合, 且默认情况下, 所有的集合都是不可变集合. 不可变集合是函数变成的一个基本设置. 默认情况下, Scala会自动导入不可变集合的相关包, 如果需要可变集合, 则需要手动导入scala.collection.mutable包中的相关类. 常用的集合类如下所示 不可变集合 可变集合 Array ArrayBuffer List ListBuffer / LinkedList, DoubleLinkedList List MutableList / Queue Array ArraySeq Stack Stack HashMap HashMap HashSet HashSet / ArrayStack 与Java一样, 集合类型都是泛型, 但Scala使用[]指定泛型的具体类型, 例如 123456789// 显式创建数组&gt; val numberArray = new Array[Int](10)numberArray: Array[Int] = Array(0, 0, 0, 0, 0, 0, 0, 0, 0, 0)// 自动推断数组类型&gt; val strArray = Array(&quot;Hello&quot;, &quot;Scala&quot;)strArray: Array[String] = Array(&quot;Hello&quot;, &quot;Scala&quot;) 对于List类型, Scala还提供了一个类似Scheme的创建方法, 形式如下 123&gt; val nums = 1::2::3::4::Nilnums: List[Int] = List(1, 2, 3, 4) 集合操作相关的API与JAVA大同小异, 具体使用时, 可以查阅API文档 函数一个标准的函数具有如下的结构 123456def gcd(x:Int, y:Int): Int = &#123; if (x % y == 0) y else gcd(y, x%y)&#125; 函数体的最后一个表达式的值将作为函数的返回值, 并且通常情况下返回值类型可以自动推导, 但如果显式使用return或者递归则无法推导返回值类型, 此时需要明确指定返回值类型. Lambda函数Scala支持Lambda函数, 格式与Java类似 12&gt; val sum = (x:Int, y:Int) =&gt; &#123;x+y&#125;sum: (Int, Int) =&gt; Int = &lt;function2&gt; Lambda函数可以作为其他函数的参数, 使用方式与大部分语言类似 12345&gt; val arrInt = Array(1,2,3,4)arrInt: Array[Int] = Array(1, 2, 3, 4)&gt; arrInt.map(x =&gt; x+1)res7: Array[Int] = Array(2, 3, 4, 5) 由于部分操作十分经典, 因此Scala提供了更简单的输入方式, 以上面的对所有元素执行+1操作为例, 可以进一步简化为 1234// 集合是不可变的, 因此重复执行map操作结果是一致的&gt; arrInt.map(_+1)res8: Array[Int] = Array(2, 3, 4, 5) 高阶函数Scala支持高阶函数, 定义形式如下 123456def higher(f: (Double) =&gt; Double) = f(100)import java.lang.Math // NoteBook需要手动导入Math,否则没有sqrt函数def sqrt(x: Double) = Math.sqrt(x)higher(sqrt) // res16: Double = 10.0 高阶函数的另一个常见的用法是将函数作为返回值, 例如 12def higher2(factor:Int) = (x:Double) =&gt; factor * xhigher2(10)(2) 注意: =是分割函数声明和函数体的标志, 明确这一点有助于阅读复杂的高阶函数 函数柯里化对于将函数作为返回值的高阶函数, 通常具有f(A)(B)的调用形式, Scala可以直接定义柯里化函数实现上述形式的函数调用, 例如上一节的函数可以直接定义为 12def multiply(factor:Int)(x: Double) = factor * xmultiply(10)(2.2) 此时虽然看起来与高阶函数有相同的调用形式, 但如果单独调用multiply(10)会报错, 因为柯里化函数并不是高阶函数, 不能分步调用. 如果需要此特性, 可以使用部分应用函数, 格式如下 12345val paf = multiply(10) _paf(2.4)val paf2 = multiply _ //这就相当于原来的高阶函数paf2(10)(2.4) 对于普通函数, 也能够使用部分应用函数, 例如 123def product(x1:Int, x2:Int, x3:Int) = 100*x1 + 10*x2 + x3product_1 = product(_:Int, 2, 3) // _后面的类型不能省略且需要与原函数匹配, 否则不能编译product_1(1) 通过函数柯里化和部分应用函数, 可以使得部分参数直接固定到函数之中, 从而提高函数的复用性, 减少重复输入. 柯里化的其他应用可以参考如下的一些资料 简述几个非常有用的柯里化函数使用场景 偏函数偏函数是处理定义域子集的函数, 如果参数不在子集内, 则抛出异常, 这一特点通常与Scala的模式匹配结合. 偏函数的定义模式为 123456789val isEven: PartialFunction[Int, String] = &#123; case x if x % 2 == 0 =&gt; x + &quot;is even&quot;&#125;val receive:PartialFunction[Any,Unit] = &#123; case x:Int =&gt; println(&quot;Int Type&quot;) case x:String =&gt; println(&quot;String Type&quot;) case _ =&gt; println(&quot;Other Type&quot;)&#125; 面向对象编程123456class Person &#123; val name:String = null; // 不可变变量不生成set方法 var age:Int = null; // 可变变量自动生成set方法&#125;class Person(val name:String, var age:Int); 上述代码均可实现对成员变量的定义, 并且Scala会同时自动生成Scala风格的get和set方法. Scala风格的get与set使用方法类似于C#的属性, 在实现上, Scala定义了与成员变量同名的函数实现get功能, 重载了=运算符实现了set功能, 例如 123var p = new Person(&quot;Scala&quot;,23)var name = p.namep.age = p.age + 1 单例对象Scala不支持Java中的静态类成员, 类似的功能需要使用单例对象实现, 单例对象使用object关键字定义. 具体形式如下 1234567891011object Student &#123; private var studentNo = 0; def uniqueStudentNo() = &#123; studentNo += 1 studentNo &#125;&#125;Student.uniqueStudentNo() // res38_0: Int = 1Student.uniqueStudentNo() // res38_1: Int = 2Student.uniqueStudentNo() // res38_2: Int = 3 包含main方法的单例对象也称为应用实例对象. 与Java一样, 此main函数可以作为程序的入口函数. 此外, 如果继承了App类, 也可以直接执行代码, 而不用定义main函数 12345678910111213object AppTest extends App &#123; // 这里写的代码直接执行 var num = 12; println(&quot;Hello World&quot;+num);&#125;object TestOut &#123; def main(args:Array[String])&#123; // 按照Java的方式定义main函数 println(args) &#125;&#125; 伴生对象Scala可以分别使用class关键字和object关键字定义同名的类和对象. 这组对象分别称为伴生类和伴生对象. 伴生类和伴生对象内部可以无视访问权限控制而直接访问私有字段. 伴生对象定义apply方法可以是伴生类不使用new创建对象. 伴生对象定义unapply方法可以在模式匹配中使伴生类实现构造函数匹配. 构造函数在前面定义Person对象时, 如果只需要一个简单的数据结构, 那么只有函数声明部分即可实现全部功能, 如果需要重写其他内容, 则可以按照如下的方式重写 123class Person(val name:String, var age:Int) &#123; override def toString() = name + &quot;:&quot; + age&#125; 这种定义类的方法称为 主构造函数. Scala支持默认参数和辅助构造函数. 无论这个类的名称如何, 辅助构造函数都定义为this(argA,argB)的形式 TraitTrait的含义是特质, 其基本作用是代替Java中的Interface, 例如 123456789trait Closeable &#123; def close(): Unit&#125;class File(val name:String) extends Closeable &#123; def close() = println(s&quot;File $name has been closed&quot;)&#125;new File(&quot;a.txt&quot;).close() 类实现Trait被称为混入, 如果只需要混入一个Trait, 则可以使用extends关键字, 如果需要混入多个Trait, 则可以使用with关键字, 例如 123class File(val name:String) extends java.io.File with Closeable with Cloneable &#123; def close() = println(s&quot;File $name has been closed&quot;)&#125; Trait可以像Java中的接口类一样使用, 不过Trait在使用上可以更加灵活, 可以有具体的成员变量和成员函数, 因此与Java中的抽象类更接近. 在Java中, 一个类只能继承一个类, 而Trait具有抽象类的特性, 同时Scala允许混入多个Trait, 因此在Scala中存在多继承问题. 模式匹配模式匹配是Scala的一个重要的语言特性, 在开发过程中被广泛应用. 常见的元组解包就是模式匹配的一个应用. 模式匹配通常具有如下的结构 1234567for(i &lt;- 1 to 5) &#123; i match &#123; case 1 =&gt; println(&quot;这是数字1&quot;) case x if (x %2 == 0) =&gt; println(s&quot;$&#123;x&#125;能被2整除&quot;) case _ =&gt; &#125;&#125; 相比于Jave的switch语法, Scala的模式匹配能够支持更多不同的类型, 从而提高的这一语法的表达能力. 在前面的偏函数章节也可以看到, 模式匹配语法除了作为语句使用外, 也可以作为函数体. 模式匹配类型上面演示了模式匹配对常量和变量的匹配格式, 下面介绍模式匹配的几种其他用法. 使用构造函数解构对象 12345678910case class Dog(val name:String, var age:Int);val dog = Dog(&quot;Pet&quot;,2)def patternMatching(x:AnyRef) = x match &#123; case Dog(name, age) =&gt; println(s&quot;Dog name = $name, age = $age&quot;) case _ =&gt;&#125;patternMatching(dog) // Dog name = Pet, age = 2 序列匹配与元组匹配 123456789val arrInt = Array(1,2,3,4)def patternMatching(x:AnyRef) = x match &#123; case Array(first, second) =&gt; println(s&quot;first is $first, second is $second&quot;) case Array(fisrt, _, thrid, _) =&gt; println(s&quot;first is $fisrt, thrid is $thrid&quot;) case Array(fisrt, _*) =&gt; println(s&quot;first is $fisrt&quot;)&#125;patternMatching(arrInt) // first is 1, thrid is 3patternMatching(arrMore) // first is 1 1234567val tupleInt = (1,2,3,4)def patternMatching(x:AnyRef) = x match &#123; case (first, second) =&gt; println(s&quot;first is $first, second is $second&quot;) case (fisrt, _, thrid, _) =&gt; println(s&quot;first is $fisrt, thrid is $thrid&quot;)&#125;patternMatching(tupleInt) // first is 1, thrid is 3 类型匹配 1234567def patternMatching(x:Any) = x match &#123; case s:String =&gt; println(&quot;This is String&quot;) case i:Int =&gt; println(&quot;This is Int&quot;)&#125;patternMatching(&quot;Hello&quot;) // This is StringpatternMatching(123) // This is Int 变量绑定模式 变量绑定模式相当于将指定的变量绑定到任意的表达式 1234567val list = List(List(1,2,3,4), List(4,5,6,7,8,9))def patternMatching(x: AnyRef)= x match &#123; case e1@List(_, e2@List(4, _*)) =&gt; println(s&quot;e1=$e1 e2=$e2&quot;)&#125;patternMatching(list) // e1=List(List(1, 2, 3, 4), List(4, 5, 6, 7, 8, 9)) e2=List(4, 5, 6, 7, 8, 9) 上述模式匹配规则表明, e2需要匹配一个任意长度的List, 且第一个元素是数字4. e1需要匹配一个有两个元素的List, 且第二个元素需要时e2对应格式的List. 这种操作非常类似正则表达式中的变量捕获. For循环 For循环支持所有格式的模式匹配, 例如 123for((language, e@&quot;Spark) &lt;- Map(&quot;Java&quot; -&gt; &quot;Hadoop&quot;.length, &quot;Closure&quot; -&gt; &quot;Storm&quot;, &quot;Scala&quot; -&gt; &quot;Spark&quot;)) &#123; println(s&quot;$e is development by $language language)&#125; 类型参数Scala的泛型与Java泛型基本上存在一一对应的关系, Java的泛型特性Scala都支持, 并且在Java泛型的基础上, Scala提供了更多特性. 特性 Java泛型 Scala泛型 泛型 List&lt;String&gt; Array[String] 通配符 List&lt;?&gt; Array[_] 下界 List&lt;? extends String&gt; Array[T &lt;: String] 上界 List&lt;? super String&gt; Array[T &gt;: String] 协变 &lt;T extends U&gt; [+T] 逆变 &lt;T super U&gt; [-T]","categories":[{"name":"Scala笔记","slug":"Scala笔记","permalink":"https://lizec.top/categories/Scala%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Scala","slug":"Scala","permalink":"https://lizec.top/tags/Scala/"}]},{"title":"矩阵论简明笔记","slug":"矩阵论简明笔记","date":"2019-11-30T07:44:32.000Z","updated":"2020-06-26T14:45:57.128Z","comments":true,"path":"2019/11/30/矩阵论简明笔记/","link":"","permalink":"https://lizec.top/2019/11/30/%E7%9F%A9%E9%98%B5%E8%AE%BA%E7%AE%80%E6%98%8E%E7%AC%94%E8%AE%B0/","excerpt":"","text":"这是关于矩阵论的简要笔记. 本来在博客中输入公式并不是一件容易的事情, 但是与手写笔记比起来, 似乎还是使用键盘输入比较轻松. 考虑到以后迟早都要会LaTeX, 现在可以多练习一下. 第一章 线性空间1.1 基与坐标设V是数域F的线性空间, 如果V中存在有限元素集\\( \\{α_1, α_2, …, α_n\\} \\)满足 \\( α_1, α_2, …, α_n \\)线性无关 V中任意向量都可以由\\( α_1, α_2, …, α_n \\)线性表示 则称\\( {α_1, α_2, …, α_n} \\)为V的一组基, 并称空间V的维数为n, 同时对任意向量α, 必有 \\( x_1, x_2, …, x_n\\)满足 $$α = x_1α_1 + x_2α_2 + … + x_nα_n$$ 一组向量线性相关的充要条件是这组向量的坐标构成的数值向量线性相关. 同理可以证明线性无关. 过渡矩阵如果有两组基 \\( α_1, α_2, …, α_n \\) 和 \\( β_1, β_2, …, β_n \\), 如果有 $$\\begin{align}β_1 &amp;= a_{11}α_1 + a_{21}α_2 + … + a_{n1}α_n \\\\β_2 &amp;= a_{12}α_1 + a_{22}α_2 + … + a_{n2}α_n \\\\… \\\\β_1 &amp;= a_{1n}α_1 + a_{21}α_2 + … + a_{nn}α_n\\end{align}$$ 即 $$(β_1, β_2, …, β_n) = (α_1, α_2, …, α_n)A$$ 那么A称为基a到基b的过渡矩阵, 并且显然可知 $$(α_1, α_2, …, α_n) = (β_1, β_2, …, β_n)A^{-1}$$ 求过渡矩阵就是分别求b在a的坐标. 然后将坐标值按照列向量组成矩阵. 坐标变换如果某个向量γ在基α和基β的坐标分别为X和Y, 则有 $$γ = (α_1, α_2, …, α_n)X = (β_1, β_2, …, β_n)Y=(α_1, α_2, …, α_n)AY$$ 因此可以获得坐标变换关系为 $$X=AY$$ 即X的坐标乘以X的过渡矩阵就是Y的坐标. 只要是坐标, 就一定是列向量 1.2 子空间设V是数域F上的向量空间, U是V的一个非空子集, 则U是V的子空间的充分必要条件是 对\\(\\forall α, β \\in U \\), 有\\( α + β \\in U \\) 对\\( \\forall x \\in F, α \\in U\\), 有 \\( xα \\in U \\) 还要证明U是V的非空子集 子空间的基取决于子空间的结构, 子空间一般可以转化为一个线性方程组的解空间, 此时子空间的基就是基础解系. 子空间的和设\\(V_1\\), \\(V_2\\)是线性空间V的两个子空间, 令 $$V_1 + V_2 = \\{ α_1+α_2 | α_1 \\in V_1, α_2 \\in V_2 \\}$$ 则称\\(V_1+V_2\\)是子空间\\(V_1\\)和\\(V_2\\)的和 从两个空间中各取一个向量, 所有的组合即为和空间 维数公式设\\( W_1\\)和 \\( W_2\\) 是线性空间的子空间, 则有 $$dim W_1 + dim W_2 = dim(W_1 \\cap W_2) + dim(W_1 +W_2) $$ 对于子空间和子空间的交空间, 和空间有 $$(W1 \\cap W2) \\subset (W1 or W2) \\subset W1 + W2$$ 交空间中的向量满足两个子空间各自的定义 直和设\\(V_1\\), \\(V_2\\)是线性空间V的两个子空间, 如果\\(V_1\\)和\\(V_2\\)的交集只有零向量, 则称\\(V_1+V_2\\)是子空间\\(V_1\\)和\\(V_2\\)的直和. \\(V_1+V_2\\)是直和, 当且仅当对\\( \\forall α \\in (V_1+V_2)\\), 只有唯一的\\(α_1\\)和\\(α_2\\), 使得\\( α_1 \\in V1, α_2 \\in V2, α=α_1+α_2 \\) V1和V2是V的子空间, 则以下命题等价 V1和V2的和是直和 向量分解唯一 零向量分解唯一 \\(dim(V_1+V_2) = dim V_1 + dim V_2\\) 线性空间的同构设V和W是线性空间, 若存在双射σ: V-&gt;W, 满足 σ(α+β) = σ(α) + σ(β) σ(kα) = kσ(α) 则称线性空间V和W是同构的 1.3 线性变换证明是线性变化需要证明三点 是V到V的映射 T(α+β) = T(α) + T(β) T(kα) = kT(α) 线性变换是V到V的映射, 而同构是任意两个线性空间的映射 核与像$$\\begin{align}Ker(T) &amp;= \\{ α \\in V | T(α)=0 \\} \\\\Im(T) &amp;= \\{ T(α) | α \\in V \\}\\end{align}$$ \\(Im(T) = Span\\{T(α_1), T(α_2), …, T(α_n)\\}\\) 线性变换矩阵设T是V上的线性变换, \\(α_1, α_2, …, α_n\\)是V的一组基. 类比基变换的过程, 可以得到线性变换的矩阵 $$T(α_1, α_2, …, α_n) = (α_1, α_2, …, α_n)A$$ A的构成与基变换相同, 求出每个\\(T(α_i)\\)在α的坐标, 按列排成矩阵即为矩阵A. 同一个线性变换在不同基下的矩阵相似, 且矩阵P为两组基之间的过渡矩阵 设α和β是空间V的两组基, 且α到β的过渡矩阵为P. 线性变换T在α和β的变换矩阵为A和B, 则 \\( B=P^{-1}AP\\) 第二章 内积与实内积空间2.1 内积与欧式空间 (α, β) = (β, α) (λα, β) = λ(α, β) (α+β, γ) = (α, γ) + (β, γ) (α, α) &gt;= 0, 当且仅当 α = 0时等号成立 柯西-施瓦兹不等式$$\\left| (α, β) \\right| &lt;= \\left\\| α \\right\\| \\left\\| β \\right\\|$$ 注意: 不等式的左侧是绝对值符号, 不等式的右侧是向量长度符号. 欧式空间的长度的定义为 $$\\left\\| α \\right\\| = \\sqrt{(α,α)}$$ 即先与自己做向量内积, 然后开根号. 向量正交化$$\\begin{matrix}β_1 = &amp;α_1 &amp; &amp; &amp;, γ_1 = \\frac{β_1}{\\left \\| β_1 \\right \\| } \\\\β_2 = &amp;α_2 &amp;-(α_2,γ_1)γ_1 &amp; &amp;, γ_2 = \\frac{β_2}{\\left \\| β_2 \\right \\| } \\\\β_3 = &amp;α_3 &amp;-(α_3,γ_1)γ_1 &amp;-(α_3,γ_2)γ_2 &amp;, γ_3 = \\frac{β_3}{\\left \\| β_3 \\right \\| }\\end{matrix}$$ 对单位向量的内积等价于在单位向量上的投影. 对于\\( β_3 \\)的求解过程, \\( (α_2,γ_1) \\)相当于\\( α_2 \\)在\\( γ_1 \\)方向上投影的长度. 投影长度乘以这个方向的单位向量, 就等于\\( α_2 \\)在\\( γ_1 \\)方向上投影的向量, 那么\\( α_2 \\)减去这个向量, 剩下的就是\\( α_2 \\)相对于\\( γ_1 \\)方向正交的分量. \\( β_3 \\)的求解过程可以按照同样的方式理解. 向量的傅里叶展开设向量组\\( ε_1, ε_2, …, ε_n\\)是欧式空间V的一组标准正交基, 则对任意向量\\( α \\in V\\), 有 $$α=(α,ε_1)ε_1 + (α,ε_2)ε_2 + … +(α,ε_n)ε_n$$ 如果\\( ε_1, ε_2, …, ε_n\\)是子空间V的一组基, 则上式为α在子空间V上的投影 正交补设W是欧式空间V的子集, 称 $$W^\\perp = \\{ α \\in V | α \\perp W\\}$$ 为W的正交补. 容易证明,\\( W^\\perp \\)是子空间. \\(W\\)和\\( W^\\perp \\)的直和是整个欧式空间V. 如果需要求解给定空间W的正交补, 可以先求出W的基向量, 则\\( W^\\perp \\)的基向量与W的基向量正交. 从而获得\\( W^\\perp \\)的基向量的表达式. 最小二乘解设\\(A = (α_1, α_2, …, α_n)\\), y=Ax, 求解x使得b与y的偏差最小. 则有 $$A^TAx=A^Tb$$ 2.2 正交变换设T是欧式空间V上的线性变换, 若满足 $$(Tα, Tβ) = (α, β)$$ 则称T是V上的正交变换. 正交变换对应了空间的旋转和镜像 2.3 复内积空间复数域上的内积与实数域上的内积定义基本相同, 但交换律有所变换, 具体为 $$(α, β) = \\overline{(α, β)}$$ 由此定义的内积的坐标表达式为 $$(α, β) = x_1\\overline{y_1} + x_2\\overline{y_2} + … + x_n\\overline{y_n}$$ 满足此内积定义的空间称为酉空间. 酉空间中的正交变换称为酉变换, 酉空间的正交矩阵称为正规矩阵(酉矩阵) 第三章 矩阵的标准型3.1 Jordan标准型设A为矩阵, 则 \\( \\lambda E - A \\) 是A的特征矩阵, 记为 A(λ). 依次求解行列式因子, 不变因子, 初级因子. 后一个不变因子整除前一个不变因子 可逆矩阵P的求解若已知矩阵A和相应的Jordan标准型J为 $$\\left(A = \\left[\\begin{matrix}-1 &amp; -2 &amp; 6\\\\-1 &amp; 0 &amp; 3\\\\-1 &amp; -1 &amp; 4\\end{matrix}\\right], \\ J = \\left[\\begin{matrix}1 &amp; 0 &amp; 0\\\\0 &amp; 1 &amp; 1\\\\0 &amp; 0 &amp; 1\\end{matrix}\\right]\\right)$$ 设可逆矩阵\\( P = (p_1, p_2, p_3)\\), 则有AP=PJ. 带入可得$$\\begin{align}Ap_1 &amp;= p_1 \\\\Ap_2 &amp;= p_2 \\\\Ap_3 &amp;= p_2 + p_3\\end{align}$$ 对于第一个和第二个等式, 相当于求解 (E-A)x=0 的解. \\( p_1 \\)可以任意取值, 但 \\( p_2 \\)还要保证第三个等式有解. 第三个等式相等于求解\\( (E-A)x = -p2 \\). 因此求解步骤如下 求(E-A)x=0 的解, 得到通解 \\( ξ_1 = (-1,1,0)^T, ξ_2 = (3,0,1)^T \\). 取 \\( p_1 = ξ_1 \\) 设\\( p_2 = c_1ξ_1 + c_2ξ_2\\), 带入\\( (E-A)x = -p2 \\). 要使等式三有解, 因此\\( (E-A)x = -p2 \\)的增广矩阵的秩与系数矩阵的秩相同, 可得\\( c_1=c_2 \\), 取\\( c_1=c_2=1 \\), 得到\\( p_2 = (2,1,1)^T\\) \\( p_3 \\)为等式\\( (E-A)x = -p2 \\)解. 其中的自由未知量可以全部取0, 可得\\( p_3 = (-1,0,0)\\) 基础解系的求解方法 写出方程的矩阵表达 行化简为最简 对于所有的自由变量, 例如\\( x_1, x_2, x_n\\), 分别取值(1,0,0), (0,1,0), (0,0,1) 带入化简后的方程, 求出其余的非自由未知量 3.2 Smith标准型λ-矩阵A(λ), B(λ)满足 $$A(λ)B(λ) = B(λ)A(λ) = E$$ 则称A(λ)是可逆的, 且称B(λ)为A(λ)的逆矩阵. A(λ)可逆的充要条件是\\( \\left| A(λ) \\right| \\)是非零常数. A(λ)的λ取任何值时, 矩阵A都可逆, A(λ)才可逆 λ-矩阵有三种类似的初等变换, 分别是 交换两行(列) 第i行(列)乘以非零常数k 第i行(列)加上第j行(列)的φ(λ)倍. 其中φ(λ)为λ的多项式 如果λ-矩阵A(λ)经过若干次初等变换变为B(λ), 则称A(λ)与B(λ)等价. 等价的λ-矩阵的秩相等 3.3 Cayley-Hamilton定理设A为n阶方阵, \\(f(λ) = \\left| λE - A \\right|\\), 则\\(f(A) = O\\). 首先按照行列式的定义展开, 然后将λ替换为A. 常数项要乘以单位矩阵E 零化多项式设A为n阶方阵, 若多项式 $$φ(λ) = a_kλ^k + … + a_1λ + a_0$$ 满足 $$φ(A) = a_kA^k + … + a_1A + a_0E$$ 则称φ(λ)是矩阵A的零化多项式. 最小多项式矩阵A的最小多项式\\( m_A(λ)\\)和特征多项式\\(f(λ) = \\left| λE - A \\right|\\)具有相同的根(但重数不同). 若特征多项式为\\( (λ-λ_0)^2(λ-λ_1) \\). 则依次尝试计算 \\((A-λ_0E)(A-λ_1E)\\)和\\((A-λ_0E)^2(A-λ_1E)\\). 乘积为0的次数最低的表达式即为最小多项式. 最小多项式\\( m_A(λ)\\)是A的特征矩阵\\( λE-A \\)的第n个不变因子 对于一个给定的三阶矩阵, 首先求出特征多项式, 由于给定的矩阵不可对角化, 必定存在次数大于1的根. 因此只需要根据情况进行一次计算就可以求出最小多项式. 由上面的定理, 最小多项式是最大的不变因子. 第四章 矩阵分解4.1 LU分解设A为矩阵, 则A可以分解为下三角矩阵L与上三角矩阵U的乘积, 且L的对角线元素为1. 设需要分解的矩阵为A 对(A,E)执行行化简操作, 变为(U,P) 对(P,E)执行行变换操作, 变为(E,L) A = LU, 且L对角线元素均为1 执行第一步时, 只能将上一行的倍数加到下一行, 从而保证最后的结果是一个上三角矩阵 LU分解可以通过Python代码实现, 例如 123from sympy import *M = Matrix([[1,2,3], [2,5,1], [3,2,5]])L,U,_ = M.LUdecomposition() 计算结果为 $$\\left (L = \\left[\\begin{matrix}1 &amp; 0 &amp; 0\\\\2 &amp; 1 &amp; 0\\\\3 &amp; -4 &amp; 1\\end{matrix}\\right], \\quad U = \\left[\\begin{matrix}1 &amp; 2 &amp; 3\\\\0 &amp; 1 &amp; -5\\\\0 &amp; 0 &amp; -24\\end{matrix}\\right]\\right )$$ 4.2 QR分解设A是m行n列的矩阵, 且Rank A = n (A的列向量线性无关). 可以将A的列向量表示为一组单位正交向量的形式, 这就是QR分解. 令 \\(A=(α_1, α_2, …, α_n)\\), 对三个向量进行正交化处理, 其中 $$(γ_1, γ_2, …, γ_n)\\begin{bmatrix}\\left \\| β_1 \\right \\| &amp; (α_2,γ_1) &amp; \\cdots &amp; (α_n,γ_1) \\\\ &amp; \\left \\| β_2 \\right \\| &amp; \\cdots &amp; (α_n,γ_2) \\\\ &amp; &amp; \\ddots &amp; \\vdots \\\\ &amp; &amp; &amp; \\left \\| β_n \\right \\|\\end{bmatrix}$$ QR分解同样可以通过Python代码实现, 例如 1234567891011import numpy as npfrom sympy import *# 基于符号计算的QR分解raw = [[1,2,2], [1,0,2], [0,1,1]]M = Matrix(raw)Q1,R1 = M.QRdecomposition()# 基于数值计算的QR分解M = np.array(raw)Q2,R2 = np.linalg.qr(M) 计算结果分别如下 $$\\left ( Q1 = \\left[\\begin{matrix}\\frac{\\sqrt{2}}{2} &amp; \\frac{\\sqrt{3}}{3} &amp; - \\frac{\\sqrt{6}}{6}\\\\\\frac{\\sqrt{2}}{2} &amp; - \\frac{\\sqrt{3}}{3} &amp; \\frac{\\sqrt{6}}{6}\\\\0 &amp; \\frac{\\sqrt{3}}{3} &amp; \\frac{\\sqrt{6}}{3}\\end{matrix}\\right], \\quad R1 = \\left[\\begin{matrix}\\sqrt{2} &amp; \\sqrt{2} &amp; 2 \\sqrt{2}\\\\0 &amp; \\sqrt{3} &amp; \\frac{\\sqrt{3}}{3}\\\\0 &amp; 0 &amp; \\frac{\\sqrt{6}}{3}\\end{matrix}\\right]\\right )$$ $$Q2 =\\left[\\begin{matrix}-0.707106781186547 &amp; 0.577350269189626 &amp; -0.408248290463863\\\\-0.707106781186547 &amp; -0.577350269189626 &amp; 0.408248290463863\\\\0.0 &amp; 0.577350269189626 &amp; 0.816496580927726\\end{matrix}\\right]$$ $$R2 = \\left[\\begin{matrix}-1.4142135623731 &amp; -1.41421356237309 &amp; -2.82842712474619\\\\0.0 &amp; 1.73205080756888 &amp; 0.577350269189626\\\\0.0 &amp; 0.0 &amp; 0.816496580927726\\end{matrix}\\right]$$ 4.3 满秩分解设A是m行n列的复矩阵, rank A = r &gt; 0, 则必然存在秩为r的两个矩阵 \\( P_1 \\in C^{m \\times r} \\), \\( Q_1 \\in C^{r \\times n} \\), 使得\\( A = P_1 Q_1\\). 这里A显然不是必须满秩的, 因此满秩可能指的是P和Q都是满秩矩阵. 满秩分解首先对A行变换, 变成行阶梯形矩阵H. 由于行变换不改变列向量的线性关系, 因此满秩分解实际上是说明矩阵A的列向量可以使用其中的一组线性无关的向量表示. 例如下面的矩阵A进行行变换后结果如下 $$\\begin{pmatrix}1 &amp; -1 &amp; 3 &amp; 7\\\\1 &amp; 0 &amp; 6 &amp; 5\\\\0 &amp; 2 &amp; 6 &amp; -4\\end{pmatrix}\\rightarrow\\begin{pmatrix}1 &amp; 0 &amp; 6 &amp; 5\\\\0 &amp; 1 &amp; 3 &amp; -2\\\\0 &amp; 0 &amp; 0 &amp; 0\\end{pmatrix}$$ 这说明A的列向量\\( α_3 \\) = 6\\( α_1 \\) + 3\\( α_2 \\). 因此取出\\( α_1 \\)和\\( α_2 \\)作为矩阵B, 取出行阶梯形矩阵的前两行组成矩阵C, 则A = BC, 即 $$\\begin{pmatrix}1 &amp; -1 &amp; 3 &amp; 7\\\\1 &amp; 0 &amp; 6 &amp; 5\\\\0 &amp; 2 &amp; 6 &amp; -4\\end{pmatrix}=\\begin{pmatrix}1 &amp; -1 \\\\1 &amp; 0 \\\\0 &amp; 2\\end{pmatrix}\\begin{pmatrix}1 &amp; 0 &amp; 6 &amp; 5\\\\0 &amp; 1 &amp; 3 &amp; -2\\end{pmatrix}$$ 行阶梯形要求枢纽元素值为1 4.4 奇异值分解设矩阵\\(A \\in C^{m \\times n} \\), rankA=r, 则存在酉矩阵\\(U \\in C^{m \\times m} \\), \\(V \\in C^{n \\times n} \\), 使得 $$A=U \\Sigma V^H$$ 其中\\(\\Sigma\\)对角线为矩阵A的奇异值, 其余元素为零. 奇异值分解按照如下的步骤完成 求解\\( A^HA\\) 的特征值与特征向量, 其中所有正特征值的平方根即为矩阵A的奇异值. 将特征向量矩阵单位正交化, 构成矩阵V, 并且将其中正特征值对应的向量记为矩阵V1 \\( U_1 = AV_1D^{-1}\\), 选取矩阵U2, 使得U=(U1,U2)为标准正交矩阵 关于奇异值的更多内容, 可以参考 奇异值的物理意义是什么？ - 知乎 4.5 广义逆矩阵设矩阵\\(A \\in C^{m \\times n} \\), \\(X \\in C^{n \\times m} \\), 使得 \\(AXA = A\\) \\(XAX = X\\) \\((AX)^H = AX\\) \\((XA)^H = XA\\) 则称矩阵X为矩阵A的Moore-Penrose逆, 记为\\( A^+ \\). 易得 $$X=C^H(CC^H)^{-1}(B^HB)^{-1}B^H$$ 其中B和C是矩阵A满秩分解后的结果. 如果矩阵A是列满秩, 则显然有\\(A=AE\\), 从而有 $$A^+=(A^HA)^{-1}A^H$$ 4.6 最小二乘解设Ax=b是不相容线性方程组, 则此方程组的最小二乘解为 $$x=A^+b+(E-A^+A)C$$ 其中C为任意的列向量. 相应的极小范数最小二乘解为 $$x_0=A^+b$$ 第五章 范数理论5.1 向量范数任意向量范数都需要满足以下的三个条件 正定性. 当 \\( α \\neq 0\\)时, \\( \\left\\| α \\right\\| &gt; 0 \\) 齐次性. \\( \\left\\| kα \\right\\| = \\left| k \\right| \\left\\| α \\right\\| \\) 三角不等式. \\( \\left\\| α + β \\right\\| \\leq \\left\\| α \\right\\| + \\left\\| β \\right\\|\\) 所有关于是否是范数的证明都等价于证明上面的三个条件 常见的向量范数有: 1范数, 2范数, \\( \\infty \\)范数, 以及p范数. 其中p范数要求 \\( 1 \\leq p &lt; +\\infty \\). 由于范数的范围不再针对实数, 因此在计算之前, 所有的数都需要先取模. 5.2 矩阵范数任意矩阵范数都需要满足四个条件, 前面三个与向量范数类似 正定性. 当 \\( A \\neq 0\\)时, \\( \\left\\| A \\right\\| &gt; 0 \\) 齐次性. \\( \\left\\| kA \\right\\| = \\left| k \\right| \\left\\| A \\right\\| \\) 三角不等式. \\( \\left\\| A + B \\right\\| \\leq \\left\\| A \\right\\| + \\left\\| B \\right\\|\\) 相容性. \\( \\left\\| AB \\right\\| \\leq \\left\\| A \\right\\| \\left\\| B \\right\\|\\) 常见的矩阵范数有如下两类 \\( m_1 \\)范数, \\( m_2 \\)范数(F范数), \\( m_\\infty \\)范数 1范数, \\( m_\\infty \\)范数, 2范数 \\( m_1 \\)范数和\\( m_2 \\)范数的定义与向量范数相似, \\( m_\\infty \\)范数为矩阵中最大元素与矩阵阶数的乘积, 只有方阵具有\\( m_\\infty \\)范数. \\( m_\\infty \\)范数为矩阵中最大元素与矩阵阶数的乘积 1范数为列模和最大者, \\( m_\\infty \\)范数为行模和最大者, 2范数为矩阵\\( A^HA \\)的最大特征值的平方根. 这一类的范数先求每一行或者列的和, 然后取最大值 第六章 矩阵分析及其应用6.1 矩阵序列与矩阵级数矩阵序列的极限等于矩阵中各元素的极限构成的矩阵. 设A为矩阵, \\(λ_1, λ_2, …, λ_n \\) 为A的特征值, 则称 $$ρ(A) = max|λ_i|$$ 为A的谱半径. 矩阵A为收敛矩阵的充要条件为 \\( ρ(A) \\leq 1\\) 设A为矩阵, \\( \\left\\| A \\right\\| &gt; 0 \\)为A的任意一种范数, 则 $$ρ(A) \\leq \\left\\| A \\right\\|$$ 由此可以得到一个推论. \\( \\left\\| A \\right\\| &gt; 0 \\)为A的任意一种范数, 若 $$\\left\\| A \\right\\| &lt; 1$$ 则A为收敛矩阵. 使用此推论时, 优先计算\\( m_\\infty \\)范数, \\( m_1 \\)范数, 行范数和列范数. 设A为矩阵, c为复数, 则 $$\\sum_{k=0}^{\\infty} c_kA^k = c_0E + c_1A + c_2A^2 + … + c_kA^k + …$$ 为矩阵幂级数. 常数项需要乘单位矩阵. 表达式中所有k次方的常数都应该视为矩阵的一部分. 设幂级数 \\( \\sum_{k=0}^{\\infty} c_kz^k\\)的收敛半径为R, 则 当 \\( ρ(A) &lt; R\\)时, 矩阵幂级数绝对收敛 当 \\( ρ(A) &gt; R\\)时, 矩阵幂级数发散 其中 幂级数\\( \\sum_{k=0}^{\\infty} c_kz^k\\)的收敛半径为 $$ R = \\lim_{k \\to \\infty} \\left| \\frac{c_k}{c_{k+1}} \\right|$$ 收敛半径是系数的比值 设A为矩阵, 则A的幂级数 $$\\sum_{k=0}^{\\infty} A^k = E + A + A^2 + … + A^k + …$$ 称为Neumann级数. 且此级数的的收敛条件为 \\( ρ(A) &lt; 1 \\). 当此级数收敛时, 级数和为 \\( (E-A)^{-1} \\). 6.2 矩阵函数的计算6.2.1 Jordan标准型法$$f(A) = P \\begin{bmatrix}f(J_1) &amp; &amp; \\\\ &amp; \\ddots &amp; \\\\ &amp; &amp; f(J_s)\\end{bmatrix}P^{-1}$$ 其中 $$f(J_i) = \\begin{bmatrix}f(λ_i) &amp; f’(λ_i) &amp; \\frac{1}{2!} f’’(λ_1) &amp; \\cdots &amp; \\frac{1}{(r-1)!} f^{(r-1)}(λ_i)\\\\ &amp; \\ddots &amp; \\ddots &amp; \\ddots &amp; \\vdots \\\\ &amp; &amp; \\ddots &amp; \\ddots &amp; \\frac{1}{2!} f’’(λ_i)\\\\ &amp; &amp; &amp; \\ddots &amp; f’(λ_i) \\\\ &amp; &amp; &amp; &amp; f(λ_i)\\end{bmatrix}$$ 6.2.2 最小多项式法设A为矩阵, \\(λ_1, λ_2, …, λ_n \\) 为A的特征值, 最小多项式为 \\( m_A(λ) \\). 设r(λ)是次数比\\( m_A(λ) \\)低一次的多项式. 则有 $$f(λ_i) = r(λ_i)$$ 如果\\( λ_i \\)为2次, 则还有 $$f’(λ_i) = r’(λ_i)$$ 根据上面的方程组, 即可解出r(λ)的系数. 同时有 $$f(A) = r(A)$$ 注意: 常数项需要乘单位矩阵 6.3 函数矩阵微积分函数矩阵的微分和积分是各元素的微分和积分. 函数矩阵的和与乘积的微分也与函数的微分形式相同, 对于函数矩阵的逆矩阵有 $$\\frac{\\mathrm{d} }{\\mathrm{d} t}(A^{-1} (t))=-A^{-1}(t)(\\frac{\\mathrm{d} }{\\mathrm{d} t}A(t))A^{-1}(t)$$ 一阶常系数线性齐次微分方程组 $$\\begin{cases}\\dot{x}(t) &amp;=Ax(t) \\ x(t_0) &amp;=c &amp;\\end{cases}$$ 的解为 $$x(t) = e^{A(t-t_0)}x(t_0)$$","categories":[{"name":"数学","slug":"数学","permalink":"https://lizec.top/categories/%E6%95%B0%E5%AD%A6/"}],"tags":[{"name":"线性代数","slug":"线性代数","permalink":"https://lizec.top/tags/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/"}]},{"title":"复变函数笔记","slug":"复变函数笔记","date":"2019-10-08T14:48:34.000Z","updated":"2019-10-10T14:44:30.238Z","comments":true,"path":"2019/10/08/复变函数笔记/","link":"","permalink":"https://lizec.top/2019/10/08/%E5%A4%8D%E5%8F%98%E5%87%BD%E6%95%B0%E7%AC%94%E8%AE%B0/","excerpt":"","text":"复数的基本概念设复数\\(z=x+iy\\), 则复数的模为$$|z| = |\\vec{OP}|=\\sqrt{x^2+y^2}$$ 复数的幅角为$$Arg z = \\theta + 2k\\pi$$其中, \\( \\theta \\)为Ox轴到复数对应的向量\\(\\vec{OP}\\)沿逆时针方向所形成的角, 因此复数的幅角有无穷多个. 当z=0时, 则没有幅角. 如果将幅角限定在\\( 0 &lt; arg z &lt; 2\\pi \\), 或者 \\( -\\pi &lt; arg z &lt; \\pi \\), 则此部分称为复数的主值. 此时幅角也可以表示为 $$Arg z = arg z + 2k\\pi$$ 复数的乘幂和方根如果$$z=|z|(cos\\theta+isin\\theta)$$ 则有 $$z^n=|z|^n(cos n\\theta+isin n\\theta)$$ 特别在z的模为1时, 有$$(cos\\theta+isin\\theta)^n=cos n\\theta+isin n\\theta$$ 这也被称为棣莫弗公式. 对于复数的方根, 有 $$w=\\sqrt[n]{|z|}(cos \\frac{arg z+2k\\pi}{n}+isin \\frac{arg z+2k\\pi}{n} )$$ 复数的乘法可以认为是模相乘,幅角相加. 而复数的除法相反, 是模相除, 幅角相减. 任意的一个复数开n次方后, 都有n个根. 虽然从表达式看, 由于幅角有无穷多个, 因此根也有无穷多个. 但实际上只有n个不相同的幅角, 其他的幅角都只是与这n个幅角中的某个幅角相差\\(2k\\pi\\). 例如\\(\\sqrt[4]{(1+i)}\\)可以表示为如下的四个根 $$\\sqrt[4]{(1+i)}=w_0,iw_0,-w_0,-iw_0$$","categories":[{"name":"数学","slug":"数学","permalink":"https://lizec.top/categories/%E6%95%B0%E5%AD%A6/"}],"tags":[]},{"title":"再读概率论","slug":"再读概率论","date":"2019-10-05T02:41:47.000Z","updated":"2020-06-19T13:29:02.009Z","comments":true,"path":"2019/10/05/再读概率论/","link":"","permalink":"https://lizec.top/2019/10/05/%E5%86%8D%E8%AF%BB%E6%A6%82%E7%8E%87%E8%AE%BA/","excerpt":"","text":"在以往我已经在几个不同的领域, 学习了好几次概率论了. 但始终感觉没有把握到概率论的本质, 总是停留在各种概念上. 在这一次, 我再一次学习概率论. 我希望能够寻找一种真正理解概率的方法, 从一个更高的层次理解概率问题. 本文的主要内容来自&lt;&lt;程序员的数学: 概率统计&gt;&gt;, 并结合这本书给出一些自己的理解. 概率的定义与线性代数一样, 在数学上并不讨论什么是概率, 而是给出了一个概率空间三元组. 只要满足给出的几条性质的东西, 就可以视为概率. 这就相当于在编程中, 只要实现了给定的接口, 就可以直接使用, 而不必关系具体是哪一个类实现. 由于线性代数抽象程度高, 因此经常出现在各种意想不到的地方, 而概率论研究的问题比较集中, 通常可以明显的感觉到是一个概率问题. 概率的上帝视角由于概率论具有一定的抽象性, 因此引入上帝视角来思考问题. 任意的概率事件, 在上帝视角看来, 都是确定的事件, 只是存在不同的平行世界. 人看起来的概率, 在上帝视角看起来, 实际上是某些世界所占的比例. 上帝视角可以描述成下图的关系. $$\\begin{matrix}上帝视角 &amp; \\rightarrow &amp; 完全确定的面积问题 &amp; \\rightarrow &amp; 面积的答案 \\\\—— &amp; &amp; \\updownarrow &amp; &amp; \\updownarrow \\\\人类视角 &amp; \\rightarrow &amp; 结果不确定的概率问题 &amp; \\rightarrow &amp; 概率的答案\\end{matrix}$$从上帝视角看来, 所有的事情都是确定的剧本, 从而消除了所有的不确定性. 三种概率的区别与联系从连续变量的概率密度函数可以更好的理解联合概率, 边缘概率, 以及条件概率. 例如, 对于一个有两个随机变量的概率密度函数, 其函数图像是三维空间中的一个二维曲面. 联合概率实际上就对应了曲面上的一个点, 而边缘概率对应了图像在xOz屏幕和yOz平面上的投影(当然还需要进过积分运算). 联合概率对应曲面上的一个点, 条件概率对应某一个切面的情况(同样也需要进行处理,才是条件概率的密度函数). 上图为概率密度曲面在Y=2时的切面情况, 这表征了Y=2时,X的分布情况, 也就是条件概率. 独立性独立性实际上体现的是一种均匀性. 如果随机变量X与Y相互独立, 则说明Y对X的各个值的影响相同, 即对于X的每个具体取值x, Y的各个取值分布相同. 如果是连续变量, 则对于每个具体的x对应的切面, Y的各部分比例都是相同的. 因此独立性不等于互斥, 两个事件互斥, 则不会同时发生, 这显然是不均匀的. 而且不会同时发生也说明了两个之间之间存在某种联系. 贝叶斯公式贝叶斯公式常用于从结果反推原因的问题. 通常原因X无法被直接观测, 需要通过结果Y来反推. 即已知所有的P(原因)与P(结果|原因), 求P(原因|结果). 如果设原因为A, 结果为B, 则贝叶斯公式可以按照如下的方式推导产生 $$ P(A|B) = \\frac{P(A, B)}{P(B)} = \\frac{P(B|A)P(A)}{\\sum P(B|A_i)P(A_i)}$$ 从公式的构成可以发现, 整个公式使用了原因A自身的分布, 以及所有的A-&gt;B(原因发生时结果)的概率分布, 求出了B-&gt;A(结果发生时原因)的概率分布 期望与方差对于随机变量X和Y, 有$$E[X+Y] = E[X] + E[Y]$$ 例如, 对于二项分布Bn(n, p), 有$$E[X] = E[Z1+Z2+…+Zn] = E[Z1]+E[Z2]+…+E[Zn] = p + p + …+ p = np$$ 如果随机变量X与Y相互独立, 那么有$$E[XY] = E[X]E[Y]$$ 因为 E[XY] 表示每个位置的X增加Y倍, 如果X与Y相互独立, 则对于每个X而言, Y的分布都是相同的, 因此每个X都扩大Y的平均倍, 即 E[Y] 倍, 因此上式显然成立. 如果X与Y不独立, 则通常不满足上面的等式. 例如统计发现某些人平均每月喝酒8次, 每次平均喝酒1.5瓶, 但每月平均喝酒瓶数为15瓶. 如果随机变量X与Y相互独立, 那么有$$V[XY] = V[X]+V[Y]$$ 将 V[XY] 带入方差表达式, 并展开可知 $$V[XY] = E[(X+Y)-(\\mu + \\nu)] = V[X]+V[Y]+2E[(X- \\mu)(Y - \\nu)]$$ 由于X与Y独立, 因此等式最后一项值为零. 对随机变量X, 有 $$V[X]=E[X^2]-E[X]^2$$ 或者表示为 $$E[X^2]= \\mu^2 + \\sigma^2$$ 大数定理假设随机变量X1, X2, …, Xn独立同分布, 其平均值定义为 $$Z \\equiv \\frac{X_1+X_2+…+X_n}{n}$$ 于是有 $$E[Z] = E\\left [ \\frac{X_1+X_2+…+X_n}{n} \\right ] = \\frac{E[X_1]+E[X_2]+…+E[X_n]}{n} = \\frac{n \\mu}{n} = \\mu$$ 由于随机变量X1, X2, …, Xn独立同分布, 因此随机变量和的方差等于各随机变量方差的和, 因此有 $$V[Z] = V\\left [ \\frac{X_1+X_2+…+X_n}{n} \\right ] = \\frac{V[X_1]+V[X_2]+…+V[X_n]}{n^2} = \\frac{n \\sigma^2}{n^2} = \\frac{\\sigma^2}{n}$$ 这说明对同一个事件进行n次重复, 可以使得方差减少到原来的\\(\\frac{1}{n}\\), 也即标准差减少到原来的\\( \\frac{1}{\\sqrt{n}}\\). 因此如果一项实验希望将误差减少到原来的\\(\\frac{1}{10}\\), 则需要进行原来的100倍的实验. 通过以上方差的公式, 我们可以发现, 如果 \\( n \\rightarrow \\infty \\), 则 \\( V[Z] \\rightarrow 0 \\) . 方差为零意味着没有随机性, 这说明如果随机变量的数量趋向于无穷, 则他们的平均值将收敛到\\( \\mu \\). 这就是大数定理. 从上帝视角来看, 期望相当于对所有的世界求平均值, 而Z相当于对一个世界的n次重复求平均值. 而大数定理说明这两个平均值在重复次数无限大时会相等. 因此通过大数定理, 在人类视角, 仅观察一个世界的平均值就可以知道全部世界的平均值. 条件期望与条件方差对于随机变量X和Y, 在X=a时的条件期望是$$E[Y|X=a] \\equiv \\sum_{b}P(Y=b|X=a)$$ 显然, 当X取值不同的时候, E(Y|X=a)可以取不同的值. 类似地, 也可以定义条件方差, 具体的表达式省略. 中心极限定理考虑n个独立同分布随机变量X1, X2, …, Xn. 假设这些变量代表各种微小的差异, 为了使其满足误差的含义, 这些随机变量具有以下的特征$$\\left\\{\\begin{matrix}E[X_1]=E[X_2]=…=E[X_n] = 0 \\\\V[X_1]=V[X_2]=…=V[X_n] = \\sigma^2 &gt; 0\\end{matrix}\\right.$$如果考虑对上述随机变量和进行标准化操作, 即 $$ W_n = \\frac{X_1+X_2+…+X_n}{\\sqrt{V[X_1+X_2+…+X_n]}}=\\frac{X_1+X_2+…+X_n}{\\sqrt{n}\\sigma}$$ 则\\( n \\rightarrow \\infty \\)时, \\(W_n\\)将趋近于标准正态分布N(0,1). 这说明大量微小的误差叠加后的结果将符合正态分布. 另外, 即使n个独立同分布随机变量X1, X2, …, Xn的期望不等于零, 只要进行标准化操作后, 还是满足上述结论, 即定义$$W_n = \\frac{(X_1-\\mu)+(X_2-\\mu)+…+(X_n-\\mu)}{\\sqrt{V[X_1+X_2+…+X_n]}}$$ 大数定理和中心极限定理的表达式很接近, 但其中的含义并不相同. 大数定理表明随机变量的和除以n以后收敛于期望值, 而中心极限定理描述了随机变量和的分布情况. 协方差与相关系数有随机变量X, Y, 其期望分别为\\( \\mu \\), \\( \\nu \\), 则协方差定义为$$Cov[X,Y] \\equiv E\\left[(X-\\mu)(Y-\\nu)\\right]$$ 可以注意到, 协方差为正数时, 具有以下的特点 一方取值大于期望时, 另一方取值大于期望的概率也更大 一方取值小于期望时, 另一方取值小于期望的概率也更大 同样, 协方差为负数时, 也有相对应的特点. 如果协方差为零, 则不存在这样的相关性. 当X与Y相互独立时, 协方差为零. 因为X与Y独立, 所以Y相对X而言分布均匀, 则对于X大于均值和X小于均值的部分Y放大的倍数相同. 因此最后计算时, X必然在均值上相互抵消, 最后结果为0. 但是反过来, 协方差为零并不能说明X与Y相互独立. 协方差相当于一个评价X与Y线性相关性的指标, X与Y独立时, 必然没有线性相关性. 但没有线性相关性不代表一定没有相关性, 只有存在某种相关关系, 则X与Y就不独立. 对比方差的定义, 协方差显然具有以下的特点 $$Cov[aX+b,cY+d] = acCov[X,Y]$$ 由于将随机变量的取值放大, 就可以放大协方差的值, 因此协方差数值的大小无法表现相关性的大小. 针对这一问题, 可以在计算协方差之前, 分别对X和Y进行标准化. 由于期望的偏移不影响协方差的值, 因此可以只进行缩放, 即求解 $$Cov[\\widetilde{X},\\widetilde{Y}]=Cov\\left[ \\frac{X}{\\sqrt{V[X]}},\\frac{Y}{\\sqrt{V[Y]}} \\right]=\\frac{Cov[X,Y]}{\\sqrt{V[X]}\\sqrt{V[Y]}}$$ 这一除去比例干扰的指标称为相关系数\\( \\rho_{XY}\\). 可以验证, 对X和Y进行缩放将不会改变\\( \\rho_{XY}\\)的大小. 相关系数具有如下的特点 取值范围在-1和+1之间 相关系数绝对值越大,(X,Y)就越接近于一条直线 如果X和Y相互独立, 则相关系数为0 相关系数存在以下的缺陷 相关系数只能表现线性相关性, 而不能体现更加复杂的相关性 相关关系不能说明因果关系 协方差矩阵设有任意三个随机变量X1, X2, X3, 那么协方差矩阵的定义为 | X1 | X2 | X3–|——————–|——————–|——————–X1| \\(Cov[X_1,X_1]\\) | \\(Cov[X_1,X_2]\\) | \\(Cov[X_1,X_3]\\)X2| \\(Cov[X_2,X_1]\\) | \\(Cov[X_2,X_2]\\) | \\(Cov[X_2,X_3]\\)X3| \\(Cov[X_3,X_1]\\) | \\(Cov[X_3,X_2]\\) | \\(Cov[X_3,X_3]\\) 如果令\\(X=(X_1,X_2,…,X_n)^T\\), 则可以用X表示这几个随机变量构成的列向量, 此时可以得到如下的一些结论 $$E[X] = E[(X_1,X_2,…,X_n)^T] = (E[X_1],E[X_2],…,E[X_n])^T\\\\V[X] = E[(X-\\mu)(X-\\mu)^T]$$ 可以验证, V[X]与前面定义的协方差矩阵具有同样的形式. 对于任意取值确定的常向量a和矩阵A, 有$$E[a \\cdot X] = a \\cdot E[X] \\\\E[AX] = AE[X]$$ 如果将X换成随机变量构成的矩阵, 上述关系依然成立. 对于方差, 同样可以用矩阵形式得到如下的一组性质$$V[a^TX]=a^TV[X]a \\\\V[AX]=AV[X]A^T$$ 对于矩阵性质, 可以按照如下的方式证明: $$V[AX] = E[(AX-A\\mu)(AX-A\\mu)^T] = E[A(X-\\mu)((X-\\mu)^TA^T)] = E[A(X-\\mu)(X-\\mu)^TA^T] = AV[X]A^T$$ 多元正态分布对于一个列向量\\(Z = (Z1,Z2, …, Zn)^T\\), 如果其中每个分类都是服从标准正态分布的i.i.d变量, 则称Z服从n元标准正态分布. 相应的概率密度函数可以表达为 $$f_Z=g(z_1)g(z_2) \\cdots g(z_n)=c exp\\left(-\\frac{z_1^2}{2}\\right) \\cdot cexp\\left(-\\frac{z_2^2}{2}\\right)\\cdots cexp\\left(-\\frac{z_n^2}{2}\\right) = d exp\\left(-\\frac{1}{2} ||z||^2 \\right)$$ 由此可以显然的得到一个结论, 概率密度的等值面是一个圆(或者球面,超球面). 因为概率密度的表达式中只与Z的模相关,而与具体的Z取值无关. 通过简单计算可知, n元正态分布的期望向量是0向量, 协方差矩阵是单位矩阵. 参数估计没有给出分布的具体函数形式的问题成为非参数估计. 期望值和方差不确定, 但遵从正态分布的问题称为参数估计. 在参数估计问题中, 通常将n个实际观测的数据记为\\( X=(X_1,X_2,…,X_n)\\), 需要估计的参数\\(\\theta\\)的估计值记为\\(\\hat{\\theta}\\). 由于数据X取值随机, 因此\\(\\hat{\\theta}\\)也是随机值. 为了强调这一点, 有时将\\(\\hat{\\theta}\\)成为估计量, 或记为\\(\\hat{\\theta}(X)\\). 最小无偏估计$$E[\\hat{\\theta}(X)] = \\theta$$ 贝叶斯估计根据前面提到的贝叶斯公式, 我们有 $$ P(A|B) = \\frac{P(A, B)}{P(B)} = \\frac{P(B|A)P(A)}{\\sum P(B|A_i)P(A_i)}$$ 如果我们现在有A事件的概率分布(称为先验概率), 现在想要知道在B事件发生后A的概率变化(称为后验概率), 那么实际上就是求解\\(P(A|B)\\). 关于贝叶斯估计在更新对违禁药物使用嫌疑的怀疑这一例子上, 可以参考文章 贝叶斯统计2. 其他检验方法 交叉检验法(cross validation, CV) 赤池信息量准则(Akaike’s information criterion, AIC) 贝叶斯信息量准则(Bayesian information criterion, BIC) 最小描述长度(minimum description length, MDL) 检验理论假设甲乙两人共进行了100场比赛, 其中甲61胜39负, 现在希望证明甲对乙的胜率大于\\(\\frac{1}{2 }\\). 此时可以建立两种假设 虚无假设\\(H_0\\): 甲获胜的概率=\\(\\frac{1}{2 }\\) 对立假设\\(H_1\\): 甲或是的概率&gt;\\(\\frac{1}{2 }\\) 这里涉及到这样一个逻辑: 如果\\(H_0\\)成立, 则出现现在的结果的概率为p, 如果p的值非常小, 则\\(H_0\\)很有可能是错误的, 因此\\(H_1\\)更有可能正确. 我们需要支持的是\\(H_1\\), 但我们通过证明\\(H_0\\)可能是错误的来证明\\(H_1\\). 上面提到的\\(H_0\\)成立的概率称为p值. 我们先设定一个很小的值\\(\\alpha\\), 并且通过比较p值是否大于\\(\\alpha\\)作为判断依据 p值 &lt; \\(\\alpha\\) -&gt; 拒绝\\(H_0\\) (reject) p值 &gt;= \\(\\alpha\\) -&gt; 无法拒接\\(H_0\\) (accept) 由此可以产生两种术语 第一类错误(false reject): 本应为\\(H_0\\)却错误的拒绝了. 也称为弃真错误 第二类错误(false accept): \\(H_0\\)不是正确答案却错误的接受了. 也称为存伪错误 对于第一类错误, 我们做出了\\(H_0\\)不对的判断, 而对于第二类错误, 我们做出了\\(H_0\\)证据不足无法反驳的判断, 因此通常而言, 我们都希望先限制第一类错误发生的概率, 然后选择第二类错误发生概率小的方案.","categories":[{"name":"数学","slug":"数学","permalink":"https://lizec.top/categories/%E6%95%B0%E5%AD%A6/"}],"tags":[{"name":"概率论","slug":"概率论","permalink":"https://lizec.top/tags/%E6%A6%82%E7%8E%87%E8%AE%BA/"}]},{"title":"宏观经济学笔记","slug":"宏观经济学笔记","date":"2019-10-04T01:12:49.000Z","updated":"2020-06-26T14:44:47.338Z","comments":true,"path":"2019/10/04/宏观经济学笔记/","link":"","permalink":"https://lizec.top/2019/10/04/%E5%AE%8F%E8%A7%82%E7%BB%8F%E6%B5%8E%E5%AD%A6%E7%AC%94%E8%AE%B0/","excerpt":"","text":"本文的主要内容来自西南财经大学在中国大学MOOC上开设的宏观经济学课程. 在学习此课程之前, 应该具备基本的微观经济学基础. 我学习这一门课的主要原因是在阅读《代谢增长论》的过程中, 作者提及了若干主流的宏观经济学理论, 并对这些理论表示质疑. 因此, 我认为有必要了解一些宏观经济学的基础知识. 经过这几个月的学习, 我认为《代谢增长论》中对主流的宏观经济学理论的质疑有一定的合理性. 宏观经济学中确实非常强调均衡, 如果从数学的角度观察, 这可以认为是一个简化问题的手段, 但这个简化可能导致理论过于简单, 而无法指导实际. 整个课程中使用的数学不多, 基本上只涉及一点与微积分相关的知识. 至于学的这些东西到底有多少意义, 那就需要以后在实际的检验了. 此课程的参考教材是 马工程《西方经济学》下册(宏观部分)以及曼昆的《宏观经济学》, 不过随便看一本宏观经济学的书, 内容上也不会有太大的差别. 宏观经济学的研究对象宏观经济学的研究对象宏观经济学的宏表示的是大和广, 是描述经济的总体行为的经济学, 研究的是各种总量. 总量可以通过简单的加总求和获得(例如GDP), 也可以通过平均总量(例如人均GDP)获得. 人均GDP虽然是一个平均量, 但由于其反应的是总体的平均水平, 而不是某个个体的平均水平, 因此这仍然是一个总量. 宏观经济学的研究方法实证与规范的方法. 实证研究是对宏观经济现象是什么, 将会是什么的描述性方法. 规范研究是对宏观经济学应该是什么, 不应该是什么进行规范的方法. 两者的区别是对研究问题进行价值判断. 定性与定量的方法. 定性研究是揭示所研究宏观经济学问题具有什么性质, 具备什么特征的研究方法. 定量研究是揭示所研究宏观经济学具有什么数量特点的研究方法. 归纳与演绎的方法. 归纳是从个别到一般的研究方法. 演绎是从一般到特殊的研究方法. 宏观经济模型宏观经济模型是揭示宏观经济理论的简化框架, 用来揭示经济变量之间的内在关系. 需要模型解释的变量称为内生变量, 被看做给定值的变量称为外生变量. GDP核算理论国内生产总值GDP, 是指一定时期内一国或者地区范围内所有常驻单位生产的产品和服务的市场价值. 由以上定义可以获得以下推论 GDP是一个流量, 对应一段时间. 对应一个时间点的量称为存量 GDP是一个地理概念, 存在一个边界范围 GDP是产出概念, 而不是市场销售的概念. 生产存货也计入GDP GDP反应最终产品价值, 不核算中间投入 GDP核算市场经济活动, 不反应非市场活动, 例如福利政策. GDP核算方法为了简化分析, 现在假定经济活动只涉及两个部门, 即企业和家庭. 并且经济是一次性的. 全部生产要素来自家庭, 企业购买生产要素生产产品和服务, 家庭消费企业生产的产品和服务. 由以上假设可以得到 1总产出 = 总收入 = 总支出 由于所有的产品都在两个部分中循环, 因此上式显然成立. 由于上式始终成立, 因此GDP可以有三种核算方法. 分别是 支出法, 核算方法 核算内容 支出法 统计所有的支出, 包括家庭消费支出, 投资支出, 政府支出, 净出口等 产出法 统计所有的产出, 既可以统计最终价值, 也可以统计每个生产环节的增加值 收入法 统计所有的收入, 包括家庭, 企业, 政府和外国要素的收入 注意: 投资支出包括住宅投资, 非住宅类的固定支出投资和存货投资, 但不包括股票等金融投资. 净出口是出口值减去进口值, 是外国对本国国内所生产的产品和服务的支出. 12GDP = 总支出 = C(消费支出) + I(投资支出) + G(政府支出) + NX(净出口)GDP = 总消费 + 总储蓄 = C(家庭消费) + S(家庭和企业储蓄/私人储蓄) + T(政府储蓄) 家庭收入由家庭储蓄和家庭消费构成, 企业收入构成企业储备, 政府收入相当于政府获得的储蓄, 来自政府的净税收 GDP相关收入概念 名称 计算方法 GNP(国民生产总值) GDP + 本国要素从外国取得收入 - 外国要素从本国取得收入 NDP(国内生产净值) GDP - 折旧 NNP(国民生产净值) GNP - 折旧 NI(国民收入) NI = NDP - 间接税 + 政府对厂商补贴(转移支付) PI(个人收入) NI - 社会保险 - 企业利润留存 + 非商业利息(例如国债利息) + 转移支付 DPI(个人可支配收入) PI - 所得税 NI是要素报酬之和, 包括工作, 租金, 利润, 利息等. DPI按照用途又可以分为家庭消费和家庭储蓄. 宏观经济恒等关系用Y表示产出, S表示私人储蓄, TN表示政府储蓄, NX表示净出口, 则对应不同的经济模型, 有如下的恒等关系 模型 恒等关系 两部门经济 C + S = Y = C + I 三部门经济 C + S + TN = Y = C + I + G 四部门经济 C + S + TN = Y = C + I + G + NX 上述的不同模型实际上就是对 总收入 = 总支出 = 总产出 不同理解. 如果一国的收入水平等于实际的产出水平等于实际的支出水平, 那么经济就处于均衡状态. 如果投资中存在非意愿的存货投资, 那么经济是非均衡的. 此时恒等关系的构成发生了变换, 但 总收入 = 总支出 = 总产出 的恒等关系始终成立 GDP的福利缺陷核查GDP的目的是为了反映经济水平和资源利用情况, 是一个反映经济福利水平的指标. 但GDP不一定能够准确的反映经济的福利水平, 主要表现在: GDP不仅统计好产出, 也统计坏产出 地下经济活动对福利的影响没有反映在GDP上 公共产品(例如国防, 教育)没有价格, 无法计入GDP 家务劳动与闲暇的价值没有反映在GDP中 人均GDP有时候什么也不是 物价指数核算名义GDP与实际GDPGDP表示市场价值, 可以分解为 产业数量 x 价格 , 这两个因素各自改变时, 都可以影响GDP的值. 当价格不变时, 由产出造成的变化是实际GDP的变化. 当产出不变时, 有价格造成的变化是名义GDP的变化. 名义GDP是用当前市场价格所计算的GDP. 实际GDP是以基期价格或者某一固定价格计算的GDP, 排除了价格因素的影响. GDP平减指数GDP平减指数可以反映整体价格水平的变化, 定义如下 $$GDP平减指数=\\frac{名义GDP}{实际GDP} \\times 100%$$ 如果固定某一个时期的产量, 可以得到以下的两种关于GDP平减指数的计算方法 $$GDP平减指数_1=\\frac{第一期产出 \\times 第二期价格}{第一期产出 \\times 第一期价格} \\times 100%$$ $$GDP平减指数_2=\\frac{第二期产出 \\times 第二期价格}{第二期产出 \\times 第一期价格} \\times 100%$$ 由于参数的各自产品的数量不同, 按照两种方式计算的平减指数也不相同, 此时可以使用几何平均法消除误差, 即 $$GDP平减指数 = \\sqrt{GDP平减指数_1 \\times GDP平减指数_2}$$ 最终可以由GDP平减指数计算通货膨胀率 $$通货膨胀率 = GDP平减指数 - 1$$ 类比上面的操作, 也可以固定某一个时期的价格, 比较两个时期的产量的变化. 类似地, 这样可以得到两个GDP增长率, 也同样可以使用几何平均法得到一个最终的平均增长率. 消费价格指数消费价格指数CPI是消费者对一篮子固定消费品与服务支持的变化的指数, 定义如下 $$CPI = \\frac{一篮子消费品的预测期价格}{相同篮子的基期价格} \\times 100%$$ CPI中消费品的种类和比例是固定的, 而GDP平减指数的统计范围是可以变动的. 使用CPI也可以定义通货膨胀率 $$通货膨胀率 = CPI - 1$$ CPI可能会高估物价变化. 当某种商品的价格显著升高是, 若此商品存在价格不变的替代品时, 通过购买替代品, 实际的花费可能不会明显升高, 但CPI指数会显著升高. CPI存在以下的几个缺陷 CPI衡量通货膨胀不一定准确 CPI无法反映家庭的消费结构的变化 CPI无法反映消费的产品的质量和技术水平的变化 失业率 名称 符号和计算方法 劳动适龄人口 L 劳动力 N = 就业人口E + 失业人口U 自愿失业者 L - N 失业率 \\(\\frac{U}{N}\\) 劳动参与率 \\(\\frac{N}{L}\\) 消费支出前面已经知道了总产出 = 总收入 = 总支出. 总产出指出了收入来自何方, 总收入说明了收入去向何方, 总支出说明了用在何处. 不同的经济学派对上面三者的决定关系有不同的观点.古典经济认为产出决定收入, 而凯恩斯主义认为支出决定收入. 因此凯恩斯主义认为经济衰退的原因是需求不足. 影响消费支出的因素消费受到如下几个因素的影响 收入 价格水平 利率 收入分配情况 家庭财富存量 短期消费函数与储蓄函数用\\( C_a\\)表示由非收入因素决定的自主性消费, \\(bY\\)表示由收入水平决定的引致性消费, 其中Y表示收入水平, b表示边际消费倾向(增加单位收入消费的变化), 则消费函数为 $$C = C_a + bY$$ 此函数也称为凯恩斯消费函数, 此函数具有如下的特点 短期消费函数 边际消费倾向递减 隐含政府可以在反衰退中有所作为的政策主张 边际消费倾向mpc的定义为 $$mpc=b=\\frac{\\Delta c}{\\Delta y}$$ 即, 增加单位收入消费的变化. 由于家庭的流动性偏好, 边际消费倾向是递减的. 由此可以显然得到, 消费函数C是非线性的. 平均消费倾向apc的定义为 $$apc = \\frac{c}{y} = \\frac{C_a}{y}+b$$ 表示消费占收入的比例 储蓄函数是储蓄与收入之间的关系, 由于两部门经济中Y=C+S, 因此有 $$S=Y-C=-C_a+(1-b)Y$$ 当收入为0时, 储蓄的减少来自于自主性消费, 而随着收入增加, 储蓄也能够随之增加. 对比mpc和apc的定义, 可以类似的定义mps和aps. 由于边际消费倾向是递减的, 所以边际储蓄倾向是递增的. 投资支出资本的边际效率资本的边际效率是投资形成的资本的预期收益率, 其表达式为 $$MEC=f\\left(\\frac{R}{P_k}\\right)$$ R是投资形成的资本的各年预期的收益的流量, \\(P_k\\)是资本品的价格, 表达式的分式部分可以简单的理解为收益除以成本. 由此可知, 收益的预期越大, 投资的需求也越大. 资本的边际效率是递减的, 原因在于 短期看, 资本品供给没有弹性, 投资增加会导致资本品价格上升 长期看, 即使资本平有弹性, 投资增加会导致产品市场中产品供给增加, 价格下降 资本边际效率递减也是一种心理预期 利率和投资需求用I表示投资需求, r表示利率, e为投资需求对利率变化的敏感程度, 那么投资与利率的表达式为 $$I = I_a - er$$ 投资需求与利率反方向变化. 通过投资最优原则(投资的边际收益等于投资的边际成本), 可以得到 $$mpk=1+r$$ 其中mpk是资本的边际产量, \\(1+r\\)表示单位投资的边际成本. mpk是递减的, 即增加单位资本的投资产生的收益是递减的. 由mpk和利率的关系可知, 利率和投资也是反向变化. 对产品的市场的需求预期, 投资成本变化, 政府的投资激励, 投资风险, 融资条件等非利率因素也会影响投资需求. 产出变化与投资变化设Y为产出, Y1和Y2分别是两期产出, K为资本存量, K1和K2分别是两期资本存量. 设k为资本产出比, 即单位产出需要的资本, 则有 $$K=kY$$ 新增投资体现为资本存量增加, 所以 $$\\Delta K=K_2-K_1=k(Y_2-Y_1)=k\\Delta Y$$ 总投资可以表示为新增投资 + 重置投资, 其中重置投资是为了补充资本的消耗, 需要计提折旧, 并使用折旧进行投资. 如果设d为折旧率, 则重置投资为dK, 如果令I为总投资, 则有 $$I=\\Delta K + dK= k\\Delta Y+ dk$$ 托宾Q托宾Q可以表示为 $$q=\\frac{公司股票市值}{公司的重置价格}$$ 公司的重置价格是再造一个相同的公司需要的价钱. q&gt;1时,通过购买股票控制企业更加不合算, 因此更愿意重置公司, 投资需求越大 均衡收入决定与乘数根据前面定义的消费函数与投资函数, 则总支出函数为 $$AE = C + I = (C_a + bY)+(I_a-er)$$ 如果将投资设为外生变量, 即令\\(I=I_a\\), 则有 $$AE=C_a + by + I_a$$ 经济均衡时, 有\\(AE=y\\), 可解得 $$y=\\frac{1}{1-b}(C_a+I_a)$$ 由于利率取决于货币市场, 而不在产品市场中考虑, 因此将投资部分视为外生变量 如果现在考虑有税收的存在, 且税收是一个比例税, 则家庭可支配收入变为 \\(y(1-t)\\), 此时可以重新求得均衡收入为 $$y=\\frac{1}{1-b(1-t)}(C_a+I_a)$$ 乘数原理乘数是外生变量变化引起内生变量变化的倍数. 以均衡收入例, 因为 $$y=\\frac{1}{1-b}(C_a+I_a)$$ 如果令\\(A=C_a+I_a\\), 则当A增大\\(\\Delta A\\)时, y相应的增加\\(\\Delta y\\)倍, 则称 $$\\frac{\\Delta y}{\\Delta A}=\\frac{1}{1-b}$$ 为简单支出乘数. 同理可以计算有比例税时相应的乘数 政府收支乘数假定政府的收入全部来自税收T, 政府的支出分为转移支付Tr以及购买支出G. 如果政府预算收支平衡, 则有 $$T=T_r+G$$ 令政府的净税收\\(T_n=T-T_r\\), 则有 $$T-T_r=T_n=G$$ 如果\\(T_n\\)大于G, 则说明政府税收有盈余, 反之则说明政府税收有亏损. 下面推导政府的税收乘数. 设政府的税收收入为T(总量), 则可支配收入为Y-T, 此时有 $$AE=C+I=C_a+b(Y-T)+I_a$$ 求出均衡解 $$Y=\\frac{1}{1-b}(C_a+I_a)-\\frac{b}{1-b}T$$ 然后求Y对T的乘数, 类似偏微分, 无关的量可以视为常数, 因此有税收乘数为 $$-\\frac{b}{1-b}$$ 下面推导转移支付乘数. 设政府的转移支付为Tr, 则收入为Y+Tr, 参考上面的推导过程, 求出均衡解并求Y对Tr的乘数, 可得转移支付乘数为 $$\\frac{b}{1-b}$$ 从上述表达式来看, 如果政府收税100单位, 然后全部进行支付转移, 似乎最后可以将对收入的影响正负抵消. 但实际上, 由于被收税和被转移支付的人群并不完全相同, 两种人群可能具有不同的边际消费倾向, 即b的取值不相同, 因此最后的效果不一定能够正负抵消. 假定政府购买支出为G, 此时有 $$AE=C+I=C_a+bY+I_a+G$$ 可以类似的得到, Y对G的乘数, 即政府购买支出乘数为 $$\\frac{1}{1-b}$$ 通过对比乘数的值, 可以发现同样的投入, 政府直接购买产生的效果优于政府支付转移. 不过现实生活中, 并非所有的支付转移都可以使用政府直接购买来替代, 因此现实世界总是政府购买和政府支付转移共存. 当政府收支平衡时, 有 $$AE=C_a+b(Y-T+T_r)+I_a+G$$ 求出均衡解为 $$Y=\\frac{1}{1-b}(C_a+I_a)+\\frac{1}{1-b}G+\\frac{b}{1-b}T_n$$ 由于政府收支平衡, \\(T_n\\)=G, 因此有 $$Y=\\frac{1}{1-b}(C_a+I_a)+\\left(\\frac{1}{1-b}+\\frac{b}{1-b}\\right)G$$ 此时, 如果始终保持收支平衡, 则G变换时, 观察表达式可知, 相应的平衡预算收支乘数始终等于1. 因此, 如果政府出于收支平衡状态, 则经济的增长直接受到政府支出的影响. 货币市场均衡能够执行支付手段和流通手段的资产称为货币, 用货币反应的变量称为名义变量, 用产品反应的变量称为实际变量. 这种分类方法也称为古典二分法. 货币具有三种职能, 分别是 流通手段: 解决了交换中一厢情愿的问题 支付手段: 可以用于支付工资和债务 储藏手段: 可以将当期的收入储藏起来, 形成未来的购买力 货币供给量与分类按照货币流动性的强弱, 可以分为 M0: 流通的现金 M1(狭义货币): M0 + 具有活期存款性质的存款 M2(广义货币): M1 + 具有定期存款性质的存款 货币供给量是由中央银行控制的指标, 通常视为外生变量. 中央银行调节货币供给量的工具有 法定存款准备金率: 法定准备金与对应存款的比例 中央银行再贴现或再贷款利率: 中央银行为商业银行提供票据贴现业务时的贴现率 公开市场操作: 中央银行在公开市场买进或者卖出有价证券 贴现：指商业票据的持票人在汇票到期日前，为了取得资金，贴付一定利息将票据权利转让给银行的票据行为，是持票人向银行融通资金的一种方式。转贴现：指商业银行在资金临时不足时，将已经贴现但仍未到期的票据，交给其他商业银行或贴现机构给予贴现,以取得资金融通。再贴现：指中央银行通过买进商业银行持有的已贴现但尚未到期的商业汇票，向商业银行提供融资支持的行为 货币乘数货币创造乘数(货币乘数)是指将基础货币放大的倍数. 假设货币供给量为M = C(现金) + D(各类存款), 基础货币为B = C(现金) + R(存款准备金), 则 存款准备金率为 $$r=\\frac{R}{D}$$ 现金漏出率为 $$k=\\frac{C}{D}$$ 由此可得, 货币供给量为 $$M=kD+D=\\frac{1+k}{r+k}B$$ 因此货币乘数为 $$m=\\frac{1+k}{r+k}$$ 货币需求理论货币数量论货币数量论是从长期看流通货币的理论.货币从长期来看, 其目的是满足交易的需要. 由此可得 $$MV=PY$$ 其中Y为实际的产出, P是产品的平均价格. 因此等式右侧表示所有需要交易的产出的价值. M是流通的货币, V是货币的流通速度或者周转次数. 例如1块钱交易十次就等价于10块钱交易一次. 因此, 流通的实际货币需求为 $$\\frac{M}{P} = \\frac{1}{V} Y$$ 流通的名义货币需求为 $$M=P \\cdot \\frac{1}{V} \\cdot Y$$ PS: 通常名义变量除以价格水平就是实际变量 从表达式可以看到, 产出越高, 需要的实际货币也就越多. 价格水平越高, 需要的名义货币也就越多 鲍莫尔-托宾平方根理论设家庭收入为Y且全部存入银行, 银行利率为r, 家庭每次支取M, 支取成本为C, 设物价水平为P. 则根据货币成本最小化原则, 可得家庭平均持有货币量(即名义货币需求)为 $$M=P \\cdot \\frac{1}{2} \\cdot \\sqrt{\\frac{2Yc}{r}}$$ 凯恩斯货币需求理论凯恩斯认为人们持有货币的动机可分为三类, 即交易动机, 谨慎动机以及投机动机. 因此货币的需求可以分为货币的交易性需求(记为L1)以及货币的投机性需求(记为L2). 影响交易性需求的因素有两个 收入水平Y 单位收入中需要持有的余额k k能够表现货币的流通程度, k越小, 则持有的货币越少,货币的流通性就越强. 交易性需求与利率无关. 影响投机性需求的因素有两个 利率r 投机对利率的敏感程度h 假定现在的投机方式只有购买债券. 购买债券是一种低买高卖赚取价差的行为, 因此当债券价格低时, 就更愿意购买债券(此时利率高), 而持有的货币数量就会减少, L2表征的货币数量也会减少.由此可知投机需求与利率水平反向变化, 有 $$L_2=-hr$$ h不一定是常数, 因此L2的曲线也不一定是直线, 而有可能是一个趋近于某个定值的递减曲线. 由于利率无法无限降低, 当利率接近某个利率临界值后, 人们就宁愿持有货币也不购买债券, 此时可以有任意大小的L2需求. 均衡利率的形成货币供给等于货币需求时的利率称为货币的均衡利率. 货币的供给量M由央行控制, 货币的需求量由上一节介绍的各种模型给出. 如果货币供给量不变, 而货币的需求量上升, 需求曲线上移, 均衡利率上升. 如果货币的需求量不变, 货币的供给量上升, 则供给曲线右移, 均衡利率下降. 央行使用货币工具调整货币供给量, 则有如下的影响过程 $$货币供给量 =&gt; 利率水平 =&gt; 消费和投资 =&gt; 总支出 =&gt; 收入水平$$ 当经济处于衰退期时, 利率水平很低. 此时增加货币供给, 由于均衡利率已经趋近于临界值, 因此增加的货币只能被L2吸收, 而不会使利率发生变化, 也就无法按照上面的逻辑改变经济状况. 这也就是为什么经济衰退时, 货币政策无效. 凯恩斯认为货币政策无效时, 应该采取财政政策. LM方程LM方程是货币市场均衡是的收入与利率的关系方程. 即 $$M=ky-hr$$ 从而有 $$y=\\frac{M}{k}+\\frac{h}{k}r$$ 如果考虑到价格因素, 则有 $$y=\\frac{M}{k} \\cdot \\frac{1}{p}+\\frac{h}{k}r$$ 从货币市场看, 收入与利率成正方向变化. 利率低则交易货币少, 则收入相应减少. LM曲线可以分为三个部分. 当利率非常高时, 投机需求L2减少到0, 而L1不随利率变化, 此时利率增加也不会使收入增加. 当利率处于中间水平时, 利率增加, 收入也响应的增加. 当利率非常低时, L2可以吸收大量货币, 直到收入变为0 当利率水平低时, 有无限的投机需求, 此时h趋向于无穷大. 利率高时, 投机需求趋向于没有, 此时h趋向于0. 从方程的斜率进行分析, 也可以获得上面的结论 低利率区间称为凯恩斯区间, 高利率区间称为古典区间, 中间利率区间称为中间区间. 产品市场的均衡产品市场均衡是指产品市场中, 收入等于支出. 产品市场中收入为Y, 且有Y=C+S. 产品市场中支出为AE, 且有AE=C+I. 由前面的知识可知 $$Y=AE=(C_a+bY)+(I_a-er)$$ 当市场均衡是, 有C+S=Y=C+I, 即S=I. 类比前面解出Y, 有 $$Y=\\frac{1}{1-b}(C_a+I_a)-\\frac{e}{1-b}r$$ 反映产品市场均衡时收入与利率的关系的曲线称为IS曲线 利率变化影响IS曲线上点的移动, IS曲线移动受到 家庭自主性消费(例如家庭认为预期收入增加) 政府支出 进出口的变化 宏观经济均衡宏观经济均衡条件产品市场和货币市场同时均衡, 即 产品市场均衡条件IS $$y=\\frac{1}{1-b}(C_a+I_a)-\\frac{e}{1-b}r$$ 货币市场均衡条件LM $$y=\\frac{M}{k}+\\frac{h}{k}r$$ 由此可以求出均衡收入和均衡利率. 外生变量对均衡的影响产品市场外生变量变化移动IS: 例如宏观财政政策变化货币市场外生变量变化移动LM: 例如宏观货币政策变化 两条曲线都可以有左移, 不变, 右移三种情况, 因此两两组合可以产生额外8种结果. IS-LM模型的的应用宏观财政政策效果常见的宏观财政工具有国家预算, 税收, 政府购买支出, 政府转移支付以及财政补贴 财政政策的效果需要根据LM曲线的区间划分成三种情况. 凯恩斯区间 处于凯恩斯区间时, IS曲线应该比较陡峭(因为投资对利率极度不敏感). 如果此时执行扩张货币政策, LM曲线右移, 但此时交点基本不变. 如果政府执行扩张政策, 则IS右移, 此时收入增加, 但利率基本不变. 因此, 此时扩张性财政政策有效. 古典范围 处于古典区间, IS曲线比较平缓(利率高, 投资对利率敏感). 此时政府执行扩张政策, IS右移. 此时利率上升, 但收入基本不变. 因此, 在此区间扩张性财政政策无效. 这里存在一种完全挤出效应. 由于利率高, 大家手上几乎没有投机性的货币, 如果此时政府发放债券, 则只要大家购买的政府债券增加了一个单位, 就等于大家购买的企业债券减少了一个单位. 中间区间 收入增加, 利率上升. 此时认为财政政策部分有效. 财政政策是否有效, 取决于财政乘数. $$\\frac{dy}{dG}=\\frac{1}{(1+b)+\\frac{ek}{h}}$$ 分析这个表达式在三个区间的取值情况, 也可以得到上面的结论. 宏观财政政策存在局限性, 包括 挤出效应; 时滞; 利益集团阻扰; 人们的预期抵消政策效果 宏观货币政策的效果 凯恩斯区间 LM右移， 货币扩张政策无效 古典区间 LM右移, 利率下降,收入增加, 货币扩张政策有效 总需求AD结合第一章的内容可知, 总需求AD = C + I + G +NX. 总需求曲线是总需求与价格水平之间的关系. 其中收入Y作为横轴, 价格水平作为竖轴. 特定的需求水平决定特定的收入水平, 因此用收入表示需求.需求曲线总是向右下方倾斜. 总需求曲线向右下方倾斜的利率解释 价格的利率效应 价格水平下降但货币需求不变 -&gt; 利率下降 -&gt; 消费和投资上升 价格的真实余额效应 货币的名义余额 -&gt; 支付能力与价格相关 -&gt; 价格下降支付能力上升 价格的税收效应 税收针对名义收入 -&gt; 价格水平越高, 实际收入可能不变(价格和工资同样上升) -&gt; 但税收绝对上升 -&gt; 实际收入减少 以下的因素可以影响AD曲线的移动 消费的改变 / 投资的改变 宏观财政政策 / 宏观货币政策 净出口及其政策的变换 例如 减税 -&gt; 家庭可支配收入上升 -&gt; 消费和投资上升 -&gt; 曲线右移 货币供给增加 -&gt; 利率下降 -&gt; 投资增加 -&gt; 消费增加 -&gt; 曲线右移 总供给AS总供给可以分为三种形态, 即 古典总供给函数, 一般凯恩斯总供给函数, 极端凯恩斯总供给函数. 宏观生产函数可以表示为 $$Y=zF(N,K) \\rightarrow Y=F(N) \\rightarrow AS$$ Y表示供给, z表示技术水平, F表示某个函数关系, N表示劳动力, K表示投入的资本. 如果假设技术水平不变, 且经济中投入的资本是常数, 则宏观生成函数可以进一步简化. 劳动市场有 $$N^d = f \\left( \\frac{w}{p} \\right)$$$$N^s = f \\left( \\frac{w}{p} \\right)$$ 其中 \\( N^d \\)表示劳动需求, \\( N^d \\)表示劳动供给, w为名义工资, p为价格水平, 因此 \\(\\frac{w}{p} \\)也表示了实际工资. 当劳动需求等于劳动供给时劳动市场达到均衡. 结合宏观生产函数和劳动市场, 可以有 $$Y=F(N) \\rightarrow Y=F\\left( \\frac{w}{p} \\right)$$ 名义工资可以分为几种情况, 例如分为弹性和刚性. 从而可以从价格水平分析劳动力的变化, 进而分析供给的变化 古典总供给古典总供给有两个基本假设 劳动市场是竞争的 工资是弹性的(随着供求关系调整) 假定此时价格水平上述, 则实际工资减少. 因此家庭提供的劳动力减少, 企业需要的劳动力增加. 又工资是弹性的, 因此名义工资上升, 实际工资也有随之上升, 最终又稳定在均衡点. 结论: 无论价格水平为多少, 名义工资都会随之调整到均衡点, 即始终都会充分就业(愿意工作的人都有工作) 此时长期总供给曲线是一条垂直的直线(即供给与价格水平无关). 长期总供给曲线可以移动. 当技术进步或者资本增加时, 都会使得长期总供给曲线向右移动. 凯恩斯主义总供给凯恩斯主义总供给有 几个假设 工资刚性(粘性) 人们有货币幻觉 即工资始终维持在某个值\\(W=\\overline{W} \\). 由于合同,工会等因素, 人们可以阻止名义工资的下降, 但无法阻止实际工资的下降. 基本凯恩斯曲线(短期)向右上方倾斜. 极端凯恩斯曲线保持水平. 总供求模型AD-AS从上图对应的模型来看, 此时长期和短期都处于均衡. 因此既是均衡又是充分就业. 但也有可能三条线并不交于一点, 此时已然存在均衡, 但不是充分就业(或者过度就业). 价格刚性的原因 垄断 工资刚性 信息不对称 政府管制 菜单成本(改变价格有成本) 菜单成本可以分为基本成本, 信息传递成本, 风险成本. 总供给冲击如果供给左移, 例如受到加税, 大宗商品价格上升等原因. 此时供给减少, 就业减少, 通货膨胀. 这也就是滞涨现象. 如果此时降低总需求, 使得价格恢复, 则失业率进一步扩大. 如果扩大需求, 则失业率可以减少, 但通货膨胀率进一步上升. 因此, 现在认为通过减低供给成本才能够好改善这个问题(供给侧改革). 如果供给左移, 此时供给增加, 就业增加, 价格水平下降. 失业失业是愿意就业, 能够工作的适龄人口没有获得工作. 自愿失业是不考虑在失业的情况之中的. 在某一工资率下, 劳动供给=劳动需求, 则此时认为充分就业. 此时有 $$U_n=\\frac{s}{s+f}$$ 其中s是离职率, f是就职率. E是就职人口,N是失业人口 失业的成因周期性失业: 由于经济衰退引起的失业, 或者说由总需求减少引起的失业.结构性失业: 由于劳动市场不完全, 工资刚性引起的失业. 摩擦性失业: 企业寻找合适的工人, 工人寻找合适的企业花费的时间引起的失业. 通货膨胀在一定的时期内, 整体价格水平持续上升的过程或货币价值持续下降的过程. 通货膨胀是一个整体的效果, 而不是单一的物品的价格变化. 通货膨胀是一个时期的变化, 短时波动不是通货膨胀. 通货膨胀的类型需求拉上型: 由于总需求扩张引起的通货膨胀. 政府的财政政策和货币政策都可以引起总需求的扩张. 虽然最终往往是通过增发货币导致通货膨胀, 但其根本原因是政府的财政扩张政策. 成本推进型: 由于总供给成本引起的通货膨胀, 此时总供给曲线左/上移. 原油价格上涨, 农作物产量下降都会导致成本上升. 结构型: 产出率存在结构性差异, 但要求工资使用同一最高水平增长, 由此产生的差异. 输入型: 如果两个国家的市场完全自由, 这同一商品的价格应该相同. 此时如果外国发生通货膨胀, 则会相应的传递到本国. 未预期通货膨胀的影响未预期通货膨胀对收入与财富的分配有影响. 通货膨胀可以解决政府赤字, 通货膨胀越高, 可以弥补的赤字越多. 政府通过印钞票来弥补赤字称为通胀税. 但是政府并不能无限印钞票, 否则可能导致放弃使用钞票交易. 穷人的财富构成单一, 且更多以货币形式持有, 因此更容易受到通货膨胀的影响. 预期通货膨胀的影响鞋底成本:菜单成本: 菲利普斯方程菲利普斯曲线是通货膨胀与失业率的关系 $$w’=v-bu$$ w是工资变化率, b是失业率 经济增长核算经济增长与经济发展经济增长的表达式可以定义为 $$g_r=\\frac{Y_t - Y_{t-1}}{Y_{t-1}}$$ 这里既可以是大写Y(表示总收入), 也可以是小写y(表示人均收入). 根据生产函数, 经济增长率可以分解为 $$\\frac{\\Delta Y}{Y} = \\frac{\\Delta z}{z} + s_n \\frac{\\Delta N}{N} + s_k {\\Delta K}{K}$$ 其中第一项表示技术的进步率, 第二项可以认为是劳动产量权重乘以劳动增长率, 第三项可以认为是资本产量权重乘以资本增长率. 并且由于只有两个要素, 因此 \\( s_n+s_k=1 \\). 索洛剩余如果将生产函数写成柯布-道格拉斯形式, 例如 $$Y=zN^{0.3}K^{0.7}$$ 则有 $$z=\\frac{Y}{N^{0.3}K^{0.7}}$$ 此时z称为索洛剩余, 表示了除了资本和劳动退产出的直接贡献以外, 还剩下的需要解释的产出. 新古典增长模型新古典增长模型有称为索洛模型. 在此模型中有如下的假定 封闭经济 技术水平不变 生产函数为Y=zF(K,N), 且规模报酬不变 储蓄是收入的函数 人口等于劳动力, 且人口增长率为常数n 资本折旧率为常数 规模报酬不变指自变量等比变换时, 因变量等比变化. 经过变量代换可以得到 $$y=zf(k)$$ 即人均收入是人均资本的函数. 这一结论可以简化后续一系列关于人均量的讨论. 人均收入与人均储蓄函数上面已经得到了人均收入的表示, 又假定储蓄是收入的函数, 即 $$S=sy=sf(k)$$ 其中s表示储蓄率, 是一个总体的概念. 索洛稳态增长条件经济均衡时候, 有 C+S=Y=C+I, 即 I=S. 又由于 $$I=\\Delta K + dK$$ 其中第一项是资本的增量, 即期末资本量减去期初资本量. 第二项表示重置投资, 即资产损耗导致的补充投资. $$\\Delta K = I - dk = sY -dK$$ $$k = \\frac{\\Delta K}{N} = s \\frac{Y}{N}-d\\frac{K}{N} = sy-dk$$ 此时可以得到 $$k’=\\left(\\frac{\\Delta K}{N}\\right)’=K’ - N ‘ = \\frac{\\Delta K}{K} - n$$ 所以 $$\\Delta K = \\left(\\frac{\\Delta k}{k} \\right)K+nK$$ $$k=\\frac{\\Delta K}{N} = \\frac{\\Delta k}{k} {K}{N} + n \\frac{K}{N} = \\Delta k + nk$$ 比较两个关于k的表达式, 可以得到 $$\\Delta k + nk = sy -dk$$ 即 $$\\Delta k = sy -(n+d)k$$ 即人均资本的增量可以分为两个部分, 第一部分是人均储蓄, 人均储蓄扣除资产折旧和新增人口的人均资本量以后剩下的部分, 就是人均资本增量. 如果令 \\( \\Delta k = 0\\), 则有稳态条件为 $$sy=(n+d)k$$ 上述几个函数的关系如下图所示 容易验证, 但k不处于均衡位置时, 将会收敛到均衡位置. 索洛模型的应用通过的模型的分析, 可以获得如下的结论 在储蓄率方面有 储蓄率提高, 储蓄曲线上移, 稳态人均资本提高 储蓄率上述不改变经济增长率(依然等于人口增长率) 不断提高储蓄率并不能导致收入的不断提高, 因为边际产量递减 提高储蓄率会导致人均消费下降, 因为储蓄率提高导致的收入提升最终将不能抵消储蓄的提高, 最终导致消费减少 由此可以分析人均消费最大的情况. 因为c=y-s, 带入表达式, 求解导数为零的即为所求的点. 经济增长的趋同由于 产品与资本的国际流动净出口与国际资本流动由于引入了国际资本的概念, 因此 根据前面学习的概念, 我们有 $$Y = C^d+I^d+G^d+X$$ 其中上标d表示本国的成分, 即本国的消费, 本国的投资,本国的政府支出. X表示本国的出口. 上述四项构成的本国的总收入. 如果将上式使用总量和国外成分表示, 则有 $$Y= C+I+G+X - (C^f+I^f+G^f)$$ 最后的三项分别是本国人对外国的消费, 投资, 政府支出, 可以统一的表示为进口. 因此 出口X减去进口IM即为净出口NX. $$NX = (Y-C-G) - I=(Y-T-C)+(T-C) -I$$ 上式第一项表示私人储蓄, 第二项表示政储蓄. 因此有 $$S-I=NX$$ 这个表达式的含义是: 开放经济下, 一国的经济的净出口必须等于其储蓄和投资之间的差额 储蓄与投资以小型开放经济(SOE)为例, 小型开放经济具有以下的两个特点 资本与要素自由流动 小国是世界利率的接受者, 即\\(r = r^*\\) 现在假设小国的储蓄是外生变量, 则有 $$\\overline{S} - I(r^*) = NX$$ 其中, 小国由于无法控制国际资本的流动, 其国家利率必须与国际利率相同, 否则会使国际基本投机或者外逃. 贸易余额与汇率名义汇率是两个国家货币交换的比例, 或者说是一国货币表示的另一个国家货币的价格(用钱来表示钱). 标价方法可以分为 直接标价法/应付标价法: 以本国货币表示的外国货币的价格 间接标价法/应收标价法: 以外国货币表示的本国货币的价格 美元标价法/通用方法: 以美元为基础的标价方法 实际汇率是用一国商品表示的另一国家商品的价格. 实际汇率表示了一个国际的贸易条件, 实际汇率越高, 则贸易余额(净出口)越少. 实际汇率可以表示为 $$\\epsilon = e \\times \\frac{P}{P^*}$$ 其中e为名义汇率, 分式为本国商品价格与外国商品价格的比值. 蒙代尔-弗莱明模型蒙代尔-弗莱明模型就是开放环境下的IS-LM方程. 这里的关键假设就是开发经济下的利率有 $$r = r^*$$ 此时用开放经济的IS方程为 $$Y=C(Y-T)+I(r^*)+G+NX(e)$$ 其中Y-T是可支配收入, e表示汇率. 宏观政策效果浮动汇率下的财政与货币效果 固定汇率下的财政和货币效果 浮动汇率时, 汇率由货币的供求关系决定的汇率制度. 财政扩张时会移动IS, 货币扩张时会一定LM. 由此可以分析 此时财政扩张会挤出出口, 导致财政政策无效.","categories":[{"name":"经济学","slug":"经济学","permalink":"https://lizec.top/categories/%E7%BB%8F%E6%B5%8E%E5%AD%A6/"}],"tags":[{"name":"经济学","slug":"经济学","permalink":"https://lizec.top/tags/%E7%BB%8F%E6%B5%8E%E5%AD%A6/"}]},{"title":"分布式系统之分布式锁","slug":"分布式系统之分布式锁","date":"2019-08-29T10:25:25.000Z","updated":"2019-09-02T08:11:22.181Z","comments":true,"path":"2019/08/29/分布式系统之分布式锁/","link":"","permalink":"https://lizec.top/2019/08/29/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/","excerpt":"","text":"关于分布式锁的基本概念和相应的实现方法, 可以阅读以下的一些文章. 分布式锁简单入门以及三种实现方式介绍 再有人问你分布式锁，这篇文章扔给他","categories":[],"tags":[]},{"title":"RabbitMQ学习笔记","slug":"RabbitMQ学习笔记","date":"2019-08-29T09:52:14.000Z","updated":"2020-06-19T13:30:42.000Z","comments":true,"path":"2019/08/29/RabbitMQ学习笔记/","link":"","permalink":"https://lizec.top/2019/08/29/RabbitMQ%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","excerpt":"","text":"RabbitMQ是一个消息队列, 消息队列最主要的特点是实现解耦合, 即消息发送方和消息接收方都只面向消息队列编程, 而不必相互了解, 从而双方都可以独立的进行修改. 基本概念 名称 解释 Broker 消息队列服务器 Connection 应用程序与消息队列的连接 Channel 在Connection上虚拟的连接 Queue 收发消息的实体 Exchange 转发消息的实体 Connection代表一个真实的TCP连接, Channel代表构建在Connection上的虚拟的连接. 一个Connection上可以存在多个Channel连接. RabbitMQ的所有操作都在Channel级别, 而不直接涉及Connection. 如果只有一个线程,则可以使用一个Channel处理所有事情, 如果有多个线程, 最好是每个线程持有一个Channel. 多线程时,任意时刻只有一个线程的Channel发送的命令被执行. 交换机定义了转发的规则, 例如是匹配还是直接转发, 是单播还是广播. 一个交换机可以绑定多个队列, 一个队列也可以绑定多个交换机. RabbitMQ基本概念和使用 交换机规则RabbitMQ提供了几种交换机规则. 不同的交换机规则有不同的性能开销, 需要根据使用场景选择合适的规则. 规则 转发方式 解释 Direct 单播 只有Key完全匹配时才进行转发 Topic 组播 将消息转发给匹配规则的队列 Fanout 广播 将消息转发给所有注册在此交换机的队列 RabbitMQ基本概念和使用 Spring RabbitMQ SupportSpring RabbitMQ Support是一个关于RabbitMQ的Spring库, 提供了@RabbitListener, @RabbitHandler等注解, 从而可以方便的使用Java接受RabbitMQ发送的消息. @RabbitListener可以标注在类上面，配合@RabbitHandler注解一起使用. 一个类中可以有多个@RabbitHandler注解的方法, 收到消息后根据消息的类型调用相应的方法. RabbitMQ：@RabbitListener 与 @RabbitHandler 及 消息序列化 Spring-rabbit之@RabbitListener解析 AMQPAMQP 0-9-1 (Advanced Message Queuing Protocol) 是一个中间件消息协议. RabbitMQ使用这一协议. 关于这一协议的内容, 可以参考官网文档AMQP 0-9-1 Model Explained. 这篇文档除了介绍AMQP协议以外, 也解释了RabbitMQ中的很多基本概念. 包括交换机类型, 队列特点, 消息应答机制等, 因此在学习更多RabbitMQ高级特性之前, 都可以考虑先阅读此文档.","categories":[],"tags":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"https://lizec.top/tags/RabbitMQ/"},{"name":"Spring","slug":"Spring","permalink":"https://lizec.top/tags/Spring/"}]},{"title":"Spring笔记之事务隔离与传播","slug":"Spring笔记之事务隔离与传播","date":"2019-08-14T07:25:04.000Z","updated":"2019-08-17T08:39:37.825Z","comments":true,"path":"2019/08/14/Spring笔记之事务隔离与传播/","link":"","permalink":"https://lizec.top/2019/08/14/Spring%E7%AC%94%E8%AE%B0%E4%B9%8B%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB%E4%B8%8E%E4%BC%A0%E6%92%AD/","excerpt":"","text":"Sping事务隔离级别和传播机制实际上只是一套规则, 对于这套规则的定义和使用, 我认为以下的三篇文章已经进行了充分的解释. 因此, 本文不需要再补充相关内容. 深入理解 Spring 事务原理 Spring事务隔离级别和传播特性 【技术干货】Spring事务原理一探","categories":[{"name":"Spring","slug":"Spring","permalink":"https://lizec.top/categories/Spring/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://lizec.top/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"Spring","slug":"Spring","permalink":"https://lizec.top/tags/Spring/"}]},{"title":"Spring笔记之WebMVC常用注解","slug":"Spring笔记之WebMVC常用注解","date":"2019-08-12T02:39:53.000Z","updated":"2020-09-20T08:05:28.000Z","comments":true,"path":"2019/08/12/Spring笔记之WebMVC常用注解/","link":"","permalink":"https://lizec.top/2019/08/12/Spring%E7%AC%94%E8%AE%B0%E4%B9%8BWebMVC%E5%B8%B8%E7%94%A8%E6%B3%A8%E8%A7%A3/","excerpt":"","text":"依赖配置本文涉及的Web相关注解都需要导入如下的依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt;&lt;/dependency&gt; 由于此项目来自于SpringBoot, 因此可以用SpringBoot相关的依赖进行统一版本控制, 否则容易造成冲突. 请求绑定@RequestMapping此注解将一个HTTP请求与Controller中的一个方法进行绑定, 既可以注释在类上, 也可以注释在一个方法上, 最终的效果等于类注解和方法注解的组合. 例如 1234567@RequestMapping(&quot;/gasMeter&quot;)public class GasMeterWeb &#123; @RequestMapping(&quot;/get&quot;) public GasMeter getGasMeterById(String meterId) &#123; return service.getGasMeterById(meterId); &#125;&#125; 则访问/gasMeter/get时, Spring会接受HTTP请求, 并调用getGasMeterById方法. 除了简单的字符串匹配以外, @RequestMapping还支持多种匹配方式, 具体方法可以参考以下的文章 超详细 Spring @RequestMapping 注解使用技巧 请求参数绑定@RequestParam此注解用于绑定HTTP请求中提供的参数. 无论是以GET请求发送的参数, 还是以POST请求发送的参数, 此注解都可以提取相应的参数. 注意: 无论以GET方式发送数据, 还是以POST方式发送数据, 都应该将Content-Type设置为application/x-www-form-urlencoded. 对于浏览器而言, 这是默认值, 但其他的第三方库不一定满足此要求. 如果HTTP中的参数名称和方法中的参数名称相同, 则可以省略此注解. @RequestBody此注解用于HTTP请求发送的JSON对象和Java对象之间的绑定. 当HTTP请求发送JSON对象是, 应该将Content-Type设置为 application/json. 当Controller接收到JSON对象后, 会自动完成JSON和Java对象的转换. 对于非JSON格式的数据, 只要位于HTTP Body之中, 也可以使用此注解提取参数. @PathVariable此注解用于路径变量与函数参数的绑定, 即绑定@RequestMap中使用大括号定义的变量和方法中的变量. 例如 12@GetMapping(&quot;/&#123;id&#125;&quot;)public User findById(@PathVariable(&quot;id&quot;) Long id) 如果两个变量的名称是一致的, 那么@PathVariable就不必在指定大括号定义的变量的名称. 默认行为与语义首先, @RequestParam注解通常情况下有没有都不影响使用. 除非需要绑定不同的名称, 否则按照名称绑定GET参数是默认行为, 其次, 通常POST方法与@RequestBody绑定使用, 此时需要将对象的字段转化为JSON格式并放置到HTTP Body之中. 这种方法在HTTP Body之中只能放置一个对象, 因此函数接口上也只能有一个参数有@RequestBody注解. 在实践上, 一般传递少量简单对象时, 使用GET方法+直接定义参数, 需要传递大量复杂对象时, 使用POST方法+@RequestBody注释的对象. 参考文献和扩展阅读 Spring mvc中Controller参数绑定注解详解 【SpringMVC学习05】SpringMVC中的参数绑定总结 响应参数绑定@ResponseBody此注解表示将返回值放入HTTP的请求体中. 默认情况下, Controller返回的是视图的名称, 使用此注解后, 控制器返回的结果将直接转化为字符串, 并放入到HTTP Response Body之中. 在字符串转化过程中, 可能涉及到Java对象与JSON对象的转化. 其他组合注解@RestController@RestController相当于@Controller和@ResponseBody, 因此当Controller中返回一个对象时, 会自动将其转化为JSON, 并放入HTTP Body之中. @GetMapping系列对于HTTP的GET, POST等方法, 都提供了一个特殊化的注解, 例如@GetMapping就等于@RequestMapping(method = {RequestMethod.GET}) Spring参数绑定过程虽然经过上述的归纳, 各种注解在语义上没有理解的障碍, 但如果想要搞清楚各个注解具体有什么效果, 默认情况下相当于什么注解, 那么还是需要从Spring的参数绑定过程入手. 这一部分的内容正在学习之中, 可以参考以下的一些文章 https://blog.csdn.net/eson_15/article/details/51718633 https://blog.csdn.net/iwillbeaceo/article/details/72878114 https://blog.csdn.net/u013310119/article/details/79776708","categories":[{"name":"Spring","slug":"Spring","permalink":"https://lizec.top/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://lizec.top/tags/Spring/"}]},{"title":"HTTP协议解析","slug":"HTTP协议解析","date":"2019-08-08T06:09:32.000Z","updated":"2020-06-26T14:42:18.637Z","comments":true,"path":"2019/08/08/HTTP协议解析/","link":"","permalink":"https://lizec.top/2019/08/08/HTTP%E5%8D%8F%E8%AE%AE%E8%A7%A3%E6%9E%90/","excerpt":"","text":"HTTP协议结构网络上已经存在了大量关于HTTP协议的优质文章, 我就不重复. 关于HTTP协议结构的介绍, 可以阅读以下的文章. HTTP请求行、请求头、请求体详解 关于HTTP的发展历史, 可以参考以下的文章. HTTP 协议入门 HTTP HeaderHTTP是基于文本的, 所以很多属性看名字就可以知道含义. 但由于HTTP Header中属性太多, 因此本文显然无法记录全部的属性, 对于大部分属性, 在需要的时候再去查询其含义也不会消耗太多时间. 下面介绍一些最常用的参数. 请求头参数 参数 含义 Accept 可接受的响应格式 Accept-Encoding 可接受的编码格式 Accept-Language 可接受的语言 Cache-Control 指示服务器端的Cache保存策略 Connection 表示连接类型,例如持续连接 Cookie 客户端传输给服务端的Cookie Host 请求服务器的域名 Referer 发送此请求时来自的页面 User-Agent 使用的客户端名称 Accept开头的一组参数都是表示可接受的响应类型, 这些参数可以指定多种类型, 类型之间使用;分割. 此外, 其中还会包含一些类似q=0.9样式的字段, 此字段用于表示优先级, 例如zh-CN,zh;q=0.9,en;q=0.8就表示接受中文的优先级为0.9,而接受英文的优先级为0.8 Referer用于指定请求的来源页面, 例如在知乎页面上点击一个外部链接, 向目标网站发送请求时, Referer字段就是知乎的网址. 使用Referer可以用来防止盗链(即如果Referer不是自己的网站, 就拒绝请求). Content-Type用于指定传输的内容的格式. HTTP协议既可以用来传输HTML代码, 也可以传输二进制的图片和视频. 文本和二进制文件的解析方式完全不同, 浏览器和服务器通过此属性来标记传输的内容. 常见的取值有 取值 含义 text/html HTML文本 application/x-www-form-urlencoded 键值对格式的表单参数 image/jpeg JPEG格式的图片 multipart/form-data 包含多个部分的数据 application/json JSON格式的文本 三种常见的http content-type详解 HTTP Content-Type对照表 响应头参数 参数 含义 Cache-Control 指示客户端的Cache保存策略 ETag 指示服务器端资源是否发生变化 Location 重定向时的重定向目标地址 如果某个Cache-Control取值情况是Cache-Control: max-age=600, public, must-revalidate, 则表明Cache的最大保存时间为600秒, 且过期后必须从服务器端重新获取 HTTP BodyHTTP的数据部分必须存放在Body之中. HTTP Header和HTTP Body之间空一行, 因此读取到连续的\\r\\n\\r\\n即表示后续内容属于HTTP Body. HTTP协议并没有规定数据必须以某种方式进行编码, 因此通常使用前面介绍的Content-Type属性来决定编码的内容. 传输单个数据HTTP可以传输文本数据或者二进制数据. 对于文本数据, 文本虽然都是可读的, 但也存在多种组织数据的方式. 例如XML文件和JSON文件都可以表达同样的信息, 但文件的组织方式就完全不同. 在浏览器提交表单数据时, 默认采取x-www-form-urlencode格式, 此时参数以key1=value1&amp;key2=value2的方式编码数据. 如果只传输一个二进制文件(例如单文件上传), 则传输过程与传输文本并没有区别, 直接将二进制数据放入Body之中即可. 传输多个数据如果既要传输二进制信息, 又要传输一部分文本进行, 那么也可以使用混合传输的方式. 此时需要将Content-Type属性指定为multipart/form-data, 即向接收端表明HTTP Body中存在多个部分的数据, 需要分开处理. 指定编码方式的同时, Content-Type还需要附带一个boundary属性, 此属性为一个任意的随机字符串, 用来分割HTTP Body的不同部分. 只要boundary属性的值不出现在各部分数据之中, boundary可以取任意值. 在这种情况下的HTTP协议具有如下的样式 12345678910111213POST http://www.example.com HTTP/1.1Content-Type:multipart/form-data; boundary=----WebKitFormBoundaryrGKCBY7qhFd3TrwA------WebKitFormBoundaryrGKCBY7qhFd3TrwAContent-Disposition: form-data; name=&quot;file&quot;; filename=&quot;chrome.png&quot;Content-Type: image/png&lt;...此处为二进制数据...&gt;------WebKitFormBoundaryrGKCBY7qhFd3TrwAContent-Disposition: form-data; name=&quot;text&quot;title------WebKitFormBoundaryrGKCBY7qhFd3TrwA-- 可以看到, HTTP Body被boundary指定的字符串分割为多个部分, 而每个部分中, 又可以分割为Header和Body. 参考文献和扩展阅读以下的几篇文章中, 第一篇文件介绍了application/x-www-form-urlencoded, multipart/form-data, application/json 三种取值的具体含义. 第二篇文章对这三种属性与POST, GET方法的关系进行了讨论, 并且补充了更多关于multipart/form-data的特性. 网络协议学习——HTTP协议POST方法的格式 http–body编码的方式 HTTP请求GET/POST与参数小结 HTTP方法方法的区别 方法 主要特点 方法 主要特点 GET 只获得服务器端的数据, 不对服务器进行修改 DELETE 删除资源 POST 创建资源, 对应服务器上的一个动作, 多次操作会可以创建多个结果 PUT 替换资源, 对应服务器上的一个资源, 多次操作结果不变(幂等) PATCH 局部资源更新, 对PUT方法的补充 HEAD 获得资源的头部信息 结合前面的HTTP Header和HTTP Body可知, 确定请求方法的是HTTP头部的动词, 与是否传递数据无关, 因此使用GET方法也能够在HTTP Body中传递数据. 因此, 本质来说, 这些方法都是一样的, 更多的是语义上的区别. 浅谈http协议六种请求方法，get、head、put、delete、post、options区别 99%的人都理解错了HTTP中GET与POST的区别 其他内容查看原始的HTTP数据虽然使用浏览器的检查功能, 也可以查看网络请求的内容, 但其中的分隔符等细节还是被隐藏了, 所以如果想看到二进制级别的HTTP报文, 最直接的方法还是直接抓包. 抓包的工具很多, 例如Ethereal或者Wireshark. 如何使用这些工具偏离本文的主题太远了, 就不详细介绍了. 但需要说明, 新版本的Wireshark支持抓取本地回环数据, 所以如果想抓取本地运行的多个服务之间的HTTP数据包, 那么还是建议安装Wireshark. 最终, 我们可以得到抓包的结果, 以下是一个HTTP响应的抓包结果: 123456789101112131415160000 9a aa b0 ee 57 25 00 1a 1e 02 0a 00 08 00 45 00 ....W%.. ......E.0010 00 e7 0a 79 40 00 3b 06 70 6f ac 1e 10 22 0a 8b ...y@.;. po...&quot;..0020 fd 5d 00 50 f8 6c ab 15 24 0c 80 c2 54 5d 50 18 .].P.l.. $...T]P.0030 66 79 e6 07 00 00 48 54 54 50 2f 31 2e 31 20 32 fy....HT TP/1.1 20040 30 30 20 4f 4b 0d 0a 53 65 72 76 65 72 3a 20 6e 00 OK..S erver: n0050 67 69 6e 78 0d 0a 44 61 74 65 3a 20 4d 6f 6e 2c ginx..Da te: Mon,0060 20 31 32 20 41 75 67 20 32 30 31 39 20 30 32 3a 12 Aug 2019 02:0070 35 32 3a 31 30 20 47 4d 54 0d 0a 43 6f 6e 74 65 52:10 GM T..Conte0080 6e 74 2d 54 79 70 65 3a 20 74 65 78 74 2f 68 74 nt-Type: text/ht0090 6d 6c 0d 0a 43 6f 6e 74 65 6e 74 2d 4c 65 6e 67 ml..Cont ent-Leng00a0 74 68 3a 20 31 34 0d 0a 43 6f 6e 6e 65 63 74 69 th: 14.. Connecti00b0 6f 6e 3a 20 63 6c 6f 73 65 0d 0a 53 52 75 6e 46 on: clos e..SRunF00c0 6c 61 67 3a 20 53 52 75 6e 20 70 6f 72 74 61 6c lag: SRu n portal00d0 20 73 65 72 76 65 72 20 6e 65 77 20 76 65 72 73 server new vers00e0 69 6f 6e 0d 0a 0d 0a 75 6e 6b 6e 6f 77 6e 20 75 ion....u nknown u00f0 73 65 72 28 29 ser() 除去MAC协议,IP协议和TCP协议的头部信息, 可以看到第0030行的第7个字节开始, 对应的文字为HTTP/1.1 200 OK. 这正是HTTP响应的第一行信息. 依次往后看, 还可以发现很多前面介绍过的头部属性, 并且可以清晰的看到, 每个属性结束后都有两个字节0d 0a, 这正是\\r\\n的二进制编码. 最后, 在第00e0行的第4到第7个字节是0d 0a 0d 0a, 也就是\\r\\n\\r\\n, 即Header与Body的分隔符. 因此最后的unknown user()是位于HTTP Body之中的内容. HTTP缓存控制浏览器缓存涉及到HTTP协议中的三个属性 Last-modified: Web服务器自动添加, 浏览器在此请求时携带此数据, 如果无变化, 服务器返回403 Etag: 类似文件的Hash值, 文件多次修改后内容不变时, Etag不变 Expires: 服务器或程序直接控制过期时间, 控制能力最强 更多内容可以参考下面的文章-最常被遗忘的Web性能优化：浏览器缓存","categories":[],"tags":[{"name":"HTTP","slug":"HTTP","permalink":"https://lizec.top/tags/HTTP/"}]},{"title":"数据库原理之事务并发控制","slug":"数据库原理之事务并发控制","date":"2019-08-06T01:07:36.000Z","updated":"2020-06-26T14:27:22.619Z","comments":true,"path":"2019/08/06/数据库原理之事务并发控制/","link":"","permalink":"https://lizec.top/2019/08/06/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%8E%9F%E7%90%86%E4%B9%8B%E4%BA%8B%E5%8A%A1%E5%B9%B6%E5%8F%91%E6%8E%A7%E5%88%B6/","excerpt":"","text":"事务事务(Transction)是用户定义的一个数据库操作序列，这些操作要么全做，要么全不做。一个事务是一个不可分割的工作单位。 事务结束方式 名称 状态 具体操作 COMMIT 事务正常结束 提交事务所有的操作，事务中所有对数据库的更新写回磁盘 ROLLBACK 事务异常终止 撤销全部的操作，事务回滚到开始状态 ACID特性 特性 解释 原子性(Atomicity) 要么做，要么不做，不可拆分 一致性(Consistency) 数据库中只包含事务成功提交的结果 隔离性(Isolation) 一个事务的执行不受其他事务的干扰 持续性(Durability) 一个事务一旦提交，永久的修改数据库，后续的操作对事务执行结果没有影响 并发事务是并发控制的基本单位。并发控制机制的任务是对并发操作进行正确的调度, 保证事务的ACID特性一级数据库的一致性 并发类型 执行状态 交叉并发(Interleaved Concurrency) 单处理机, 事务轮流执行 同时并发(Simultaneous Concurrency) 多处理机, 每个处理机运行一个事务 交叉并发虽然没有真是的并行, 但是能减少处理机空闲时间, 提高系统效率. 同时并发是最理想的并发, 但受硬件环境限制. 不一致性并发操作会带来不一致性, 包括如下的几种类型： 类型 解释 丢失修改(Lost Update) T1修改数据后, T2修改数据, 导致T1的修改覆盖 不可重复读(Non-repeatable Read) T1读取数据后, T2更新数据, T1无法再现之前的读取结果 幻影(phantom row) T1读取数据后, T2加入新的数据, T1再次读取发现记录数量变化 读”脏”数据(Dirty Read) T1修改数据后写回, T2读取数据, T1撤回修改, 此时T2读到了错误的数据 幻影是不可重复读的一个子集. 读”脏”数据和不可重复读的区别在于脏数据是没有提交的数据, 而不可重复读,读取的是提交的数据. 针对上述的不一致问题, 数据库产生了相应的隔离级别, 不同的隔离级别要求如下所示: 隔离级别 丢失更新 脏读 不可重复读 幻影 读未提交(Read Uncommitted) 可能 可能 可能 可能 读已提交(Read Committed) 可能 不可能 可能 可能 可重复读(Repeatable Read) 可能 不可能 不可能 可能 可串行化(Serializable) 不可能 不可能 不可能 不可能 读未提交显然会导致脏读, 而读已提交解决了脏读问题却不能保证可重读读. 可重复读保证了数据可重复读取, 但不能解决幻影问题. 但通过多版本并发控制(MVCC)可以在这一级别解决幻影问题. 最终, 可串行化放弃了所有并发性, 解决了所有的问题. 上述隔离级别仅仅是定义, 并没有规定实现方法, 常见的实现方法有封锁(locking), 时间戳(timestamp), 多版本并发控制(MVCC)等. 封锁封锁技术 封锁类型 加锁策略 锁互斥关系 排它锁(eXclusive Locks, X锁, 写锁) 写入数据时, 加X锁 T对A加X锁后, 只有T可以读取和修改A 共享锁(Share Locks, S锁, 读锁) 读取数据时, 加S锁 T对A加S锁后, 其他事务可以对A加S锁, 但不能加X锁 为了保证调度是可串行化的, 目前的数据库通常采用两段锁(TwoPhase Locking, 2PL)协议来实现并行调度的可串行性, 即 扩展阶段: 事务可以申请任何数据项上的任何类型的锁, 但是不能释放任何锁 收缩阶段: 事务可以释放任何数据项上的任何类型锁, 但是不能再申请任何锁 通过这两个阶段, 才能保证加锁的有效性并且避免发生死锁. 封锁协议 协议等级 解释 一级封锁协议 事务T在修改数据R之前必须对其加X锁, 并直到事务结束才释放 二级封锁协议 在一级封锁协议的基础上, 事务T在读取数据R之前必须对其加S锁, 读取完毕即可释放 三级封锁协议 在一级封锁协议的基础上, 事务T在读取数据R之前必须对其加S锁, 直到事务结束才释放 对数据加入X锁后, 其他事务只能等待当前事务完成修改后才能读写, 从而保证了当前事务的更新不会丢失 对数据加入S锁后, 当前事务只能等待其他事务完成更新后才能读取, 并且当前事务在读取过程中, 其他事务不能对数据进行修改, 从而保证了不会读取到脏数据 只到事务结束再释放, 可以保证数据在整个事务阶段不被修改, 从而保证可重复读 采用封锁协议 丢失更新 脏读 不可重复读 幻影 不使用封锁 可能 可能 可能 可能 一级封锁协议 不可能 可能 可能 可能 二级封锁协议 不可能 不可能 可能 可能 三级封锁协议 不可能 不可能 不可能 可能 如果在三级封锁协议的基础上, 还对范围进行锁定, 则阻止了新数据的插入, 从而保证了不发生幻影. 解除死锁根据操作系统中提到的死锁的四个必要条件, 即互斥条件、部分分配、不可剥夺和环路等待出发, 抛弃其中的任意一个即可解除死锁, 即 抛弃条件 对应方案 抛弃部分分配 事务一次性对所有需要的数据加锁, 否则不能执行 抛弃不可剥夺 死锁时选择一个处理代价最小的事务, 将其撤销并释放资源 抛弃环路等待 所有资源进行排序, 按照一定的顺序申请资源 注意： 互斥条件是任务的固有属性, 不可抛弃。 选择封锁粒度原则 封锁粒度越大, 数据库可以封锁的单元越少, 并发度就越小, 系统开销也小 封锁粒度越小, 并发度较高, 但系统开销也高 系统通常可以提供多种封锁粒度, 从而供不同的事务选择, 这种方法也称为多粒度封锁(multiple granularity locking) 参考资料与扩展阅读 深入学习MySQL事务：ACID特性的实现原理 MySQL事务之丢失更新问题","categories":[],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://lizec.top/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"}]},{"title":"博客加入新的模块","slug":"博客加入新的模块","date":"2019-08-03T05:59:00.000Z","updated":"2020-02-07T07:54:19.775Z","comments":true,"path":"2019/08/03/博客加入新的模块/","link":"","permalink":"https://lizec.top/2019/08/03/%E5%8D%9A%E5%AE%A2%E5%8A%A0%E5%85%A5%E6%96%B0%E7%9A%84%E6%A8%A1%E5%9D%97/","excerpt":"","text":"经过最近几天的改造, 本博客正式加入了Slide模块和Notebook模块. 这两个模块已经添加到博客的头部菜单栏, 分别点击Slides和Notebook就可以进入相应的界面 点击Slides后就进入了Slides模块: 目录也是以slide的模式组织的. 通过方向键就可以切换slide. 点击NoteBook后进入NoteBook模块: 这里的目录还是按照普通的博客文章的样式构成的. 点击相应的连接就可以进入相应的NoteBook. 技术分析Slide采用Reveal-md技术构建, 而Reveal-md的本质是Reveal.js的Markdown版本, 因此Reveal-md具有几乎所有Reveal.js的特性. Reveal-md支持动态预览和编译项目为HTML, 所以只需要将相应的Markdown文件编译为HTML文件, 在将这些文件放置到指定的文件夹中, 就可以从博客访问这些slide NoteBook是指Jupyter NoteBook, Jupyter本身的功能已经非常完善, 并且提供了将NoteBook编译为HTML的指令. 所以只需要将相应的NoteBook编译为HTML, 并放置到指定的文件夹中, 就可以从博客访问这些NoteBook. 项目结构最初的hexo的source目录结构如下 12345_drafts/_posts/ about/images/others/ 其中_drafts/存放文章草稿, _posts/存放文章源文件, about/存在博客头部菜单栏About选项用到的文件, images/存放博客中的图片, others/存放其他文件. 按照Hexo的规则, 所有以_开头的目录内的内容都不会直接出现在输出目录中, 而其他的目录中的文件, 即使无法被渲染(例如非文本文件)也会被复制到最后的输出目录中. 结合这一特性, 加入slide模块和notebook模块后目录结果如下 123456789_drafts/_notebook/_posts/ _slides/about/images/notebook/others/slides/ 其中_notebook/和_slides/存放源代码, 即.ipynb文件和.md文件. 对应地, notebook/和slides/存放编译为HTML之后的文件. 经过hexo渲染以后, 访问博客的/slides和/notebook路径就可以查看相应的文件. 博客页面设置本博客采用了MiHo主题, 在相应的配置文件中, 有如下的一段内容 1234567891011121314# Menu setting | 菜单设置# name: Font Awesome icon | Font Awesome 图标# title: Home Title | 标题# url: //minhow.com Url, absolute or relative path | 链接，绝对或相对路径# target: true Whether to jump out | 是否跳出menu: archive: title: Archives url: /archives target: false user: title: About url: /about target: false 因此只要在menu下加入两个新的项, 就可以在博客的头部菜单栏添加两个新的选项, 具体内容如下 1234567891011121314151617menu: archive: title: Archives url: /archives target: false tv: title: Slides url: /slides target: false sticky-note: title: NoteBook url: /notebook target: false user: title: About url: /about target: false 在博客的页面上点击选项, 就能跳转到url指定的地址上, 只有在对应的位置加入index.html文件, 就完成了模块的添加. Reveal-md新建Reveal-md和hexo的博客文章一样, 需要使用一些头部的信息, 所以可以考虑创建一个文章模板, 使用hexo指令创建新的文章, 然后将创建的文件复制到Reveal-md的源文件目录中. 这样一方面不需要添加额外的文件新建机制, 又充分使用了hexo的特性. 首先在hexo的scaffolds目录下新建一个slide.md文件, 内容如下 123456789101112131415---title: &#123;&#123; title &#125;&#125;date: &#123;&#123; date &#125;&#125;theme: solarizedrevealOptions: transition: &#x27;fade&#x27;---## Title---## Content--- 这里指定了主题和切换方式的默认值, 并且利用hexo的特性, 自动获得了文件名和创建时间. 每当需要创建新的slide时, 可以执行如下的指令 123read FILENAMEhexo new slide $FILENAMEmv source/_posts/$&#123;FILENAME&#125;.md source/_slides/$&#123;FILENAME&#125;.md 使用hexo, 指定使用slide目标创建新文件, 然后将此文件移动到存放slide的目录. 当然这一段指令可以写成脚本, 下次使用的时候, 双击就能使用. Reveal-md编译Reveal-md编译脚本如下所示: 123@echo offcd hexo\\sourcereveal-md .\\_slides\\ --static slides --theme solarized &amp; pause 所有的参数含义都可以在Reveal-md的官网上获得.这里要注意的是指令末尾的&amp; pause. reveal-md命令执行完毕会自动结束进程, 进而导致后续的指令无法执行, 所以一定要使用&amp;符号组合pause指令才能实现暂停效果. Reveal-md实时预览Reveal-md提供了一个实时预览功能, 本地做出的修改可以实时的展示到页面之上. 指令如下 123@echo offcd hexo\\sourcereveal-md .\\_slides\\ -w --theme solarized --listing-template _template\\list.html 其中-w指令表示监控本地目录的变化. 但Reveal-md存在一个bug, 当文件名为中文是, 无法在实时预览模式下访问相应的文件. 联想到Hexo的草稿发布模式, 我额外编写了一个小脚本, 代码如下 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455import osimport sysimport jsonimport randomconfigPath = &quot;../_config/currentSlideName.json&quot;def makeNewSlide(filename:str): if os.path.exists(configPath): info = readDictFromFile(configPath) else: info = &#123;&quot;currentName&quot;:[]&#125; if len(info[&quot;currentName&quot;]) != 0: n = len(info[&quot;currentName&quot;]) os.system(f&quot;mv current.md current_&#123;n&#125;.md&quot;) info[&quot;currentName&quot;].append(filename) os.system(f&quot;mv ../_posts/&#123;filename&#125;.md current.md&quot;) writeDictToFile(configPath,info) def readDictFromFile(filename): with open(filename,&quot;r&quot;,encoding=&quot;utf8&quot;) as f: return json.loads(f.read())def writeDictToFile(filename, data): with open(filename,&quot;w&quot;,encoding=&quot;utf8&quot;) as f: f.write(json.dumps(data))def publishSlide(): if os.path.exists(configPath): info = readDictFromFile(configPath) else: raise EOFError(&quot;No File Need to be published&quot;) if len( info[&quot;currentName&quot;]) == 0: raise EOFError(&quot;No File Need to be published&quot;) filename = info[&quot;currentName&quot;].pop() os.system(f&quot;mv current.md &#123;filename&#125;.md&quot;) writeDictToFile(configPath,info) # 如果有前面创建的文件, 则恢复前面的文件 if len(info[&quot;currentName&quot;]) != 0: n = len(info[&quot;currentName&quot;]) os.system(f&quot;mv current_&#123;n&#125;.md current.md&quot;) if __name__ == &quot;__main__&quot;: if len(sys.argv) &gt;= 2: if sys.argv[1] == &quot;new&quot;: makeNewSlide(sys.argv[2]) elif sys.argv[1] == &quot;publish&quot;: publishSlide() 这个脚本实现了两个功能, 分别是新建和发布. 当创建一个新的slide时, 此脚本将slide的真实名称保存起来, 然后将slide重命名为current.md, 从而在实时预览模式下也可以正常查看. 当slide创建完毕以后, 执行发布指令, 此脚本恢复slide原本的文件名. 考虑到一个slide的编写过程中, 可能有创建新的slide的需求, 此脚本也支持连续多次执行新建和发布执行, 创建的文件按照栈结构保存.. NoteBook编译NoteBook提供了编译的指令, 但是使用BAT执行时, 会产生原因不明的死循环, 且每次只能编译一个文件. 针对这一情况, 我编写了一个python文件来实现NoteBook相关的指令, 代码如下 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354import osimport sysdef makeHTML(): doNothing = True for name in os.listdir(): if &quot;.ipynb&quot; in name and os.path.isfile(name): core = name.split(&quot;.ipynb&quot;)[0] if hasUpdated(core): doNothing = False cmd = &quot;jupyter nbconvert --output-dir=&#x27;../notebook&#x27; --to html &quot; + name os.system(cmd) if hasUpdated(&quot;index&quot;,&quot;.md&quot;,&quot;.md&quot;): doNothing = False print(&quot;[PyConvertApp] Update index.md&quot;) os.system(&quot;cp index.md ../notebook/index.md&quot;) if doNothing: print(&quot;Everything up-to-date&quot;) def hasUpdated(name, srcSuffix=&quot;.ipynb&quot;, dstSuffix=&quot;.html&quot;): src = name + srcSuffix dst = &quot;../notebook/&quot; + name+dstSuffix try: ts = os.path.getmtime(src) ds = os.path.getmtime(dst) return ts &gt; ds except FileNotFoundError: # 文件不存在时都重新生成文件 # 如果出现没有考虑到的异常, 则应该使程序崩溃 return Truedef startJupyter(): os.system(&quot;jupyter notebook&quot;)def genIndex(): # 为项目提供一个Index文件 # 自动生成或者手动维护 passif __name__ == &quot;__main__&quot;: if len(sys.argv) &gt;= 2: if sys.argv[1] == &quot;start&quot;: startJupyter() elif sys.argv[1] == &quot;build&quot;: makeHTML() else: # 默认生成文件 makeHTML() 将此文件和NoteBook源文件放置在同一个目录下, 就可以实现启动Jupyter Notebook以及将所有的NoteBook编译为HTML的功能. 脚本中做了更新检测, 通过对比HTML和源文件之间的修改时间来确定是否需要重新编译源文件. 忽略编译结果由于Hexo会自动渲染所有位于source下的文件, 因此经过Reveal-md编译后的html文件会被Hexo再次渲染, 进而导致slide样式出现问题. Hexo的配置文件中提供了一个跳过渲染的选项, 按照如下的方式, 则可以忽略slides目录和others目录下的所有目录和文件, 以及notebook文件夹下所有的HTML文件. 1234skip_render: - slides/** - notebook/*.html - others/** 创建index文件使用Reveal-md编译一个文件夹时, 会自动为这个文件夹产生一个index.html文件, 不过这个文件只是简单的展示了全部的文件, 因此使用不够友好. 由于在slide源文件中创建的index.md文件也会编译成index.html文件, 所以只需要在源文件目录中创建一个index.md文件, 并且手动维护这个文件, 就可以为整个Slide系统提供一个目录. 在NoteBook系统中, 显然并不存在默认生成的index文件, 同时也不适合使用NoteBook格式创建一个目录. 所以还是可以创建index.md文件, 并且手动维护这个文件中的链接. 与Reveal-md不同的是, NoteBook系统并不自己编译这个md文件, 而是由hexo负责渲染, 所以在配置文件中只忽略了HTML文件, 而md文件还是照常渲染. 1234skip_render: - slides/** - notebook/*.html - others/** 经过这样的设置以后, NoteBook的index页面就和普通的博客文章页面具有同样的页面结构了. Notebook添加目录安装NoteBook插件, 执行如下指令 12pip install jupyter_contrib_nbextensionsjupyter contrib nbextension install --system 安装完成以后, 在Jupyter主界面上, 可以看到多了一个标签页, 名称为Nbextensions. 在其中开启插件Table of Contents(2)即可为NoteBook添加目录. 更多关于Jupyter插件的内容, 可以参考以下文章 Jupyter Notebook界面也可以如此炫酷？有人把Notebook玩出了新花样 Notebook修改字体和背景 更改jupyter 代码字体大小及自动补全 Jupyter Notebook 设置背景主题、字体大小以及输出部分显示不全的问题 Github: dunovank/jupyter-themes 1jt -f fira -t onedork -fs 13 -cellw 90% -ofs 11 -dfs 11 -T -N 如果希望还原设置, 可以执行 1jt -r","categories":[{"name":"公告","slug":"公告","permalink":"https://lizec.top/categories/%E5%85%AC%E5%91%8A/"}],"tags":[{"name":"公告","slug":"公告","permalink":"https://lizec.top/tags/%E5%85%AC%E5%91%8A/"}]},{"title":"Java小知识合集","slug":"Java小知识合集","date":"2019-07-26T07:31:29.000Z","updated":"2019-08-20T01:34:19.079Z","comments":true,"path":"2019/07/26/Java小知识合集/","link":"","permalink":"https://lizec.top/2019/07/26/Java%E5%B0%8F%E7%9F%A5%E8%AF%86%E5%90%88%E9%9B%86/","excerpt":"","text":"本文是一些关于Java的各种小知识的合集, 由于这些知识比较零散, 因此暂时不能确定它们所属的类别以及是否需要专门写一篇文件进行介绍. 在内容方面, 当某些知识变成尝试或者达到了写一篇文章的标准, 那么相应的内容就会从这里删除. 一些Java对象的名称 名称 全称 含义 PO Persistent Object 对应数据库记录的Java对象 VO Value Object 业务层之间传递数据的的对象 DAO Data Access Object 控制数据库访问的对象, 通常与PO结合 DTO Data Transfer Object 数据传输对象, 与数据库传递数据 BO Business Object 封装业务逻辑的对象, 调用DAO的方法 序列化IDserialVersionUID 用于标记序列化类的版本, 如果对类进行了修改, 那么也应该同步的修改serialVersionUID. IDEA可以直接提供随机值. 手动检查Null手动检查是否为Null, 并手动抛出NullPointException可以视为一种防御性编程, 即如果可能发生错误, 则应该尽可能早的产生. Lombok lombok @Slf4j 自动生成LOG对象 JDK前几天更新Intellij IDEA的时候发现, 新版本已经支持JDK 11了, 于是下载了JDK 11 体验了一下. 相较于JDK 8, JDK 11的改动比较大, 目前很多第三方库还没有针对JDK 11做调整, 因此不建议直接把JDK升级, 最好还是先同时保留JDK 8 和JDK 11. JDK 新特性介绍 Java 9 新特性概述 Java 10 新特性介绍 Java 11 新特性介绍 JDK集合类归纳 Java语法总结–Java集合类 排序算法时间复杂度、空间复杂度、稳定性比较","categories":[{"name":"Java特性","slug":"Java特性","permalink":"https://lizec.top/categories/Java%E7%89%B9%E6%80%A7/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://lizec.top/tags/Java/"}]},{"title":"使用LaTeX进行学术写作","slug":"使用LaTeX进行学术写作","date":"2019-07-20T03:42:32.000Z","updated":"2020-06-26T14:50:18.110Z","comments":true,"path":"2019/07/20/使用LaTeX进行学术写作/","link":"","permalink":"https://lizec.top/2019/07/20/%E4%BD%BF%E7%94%A8LaTeX%E8%BF%9B%E8%A1%8C%E5%AD%A6%E6%9C%AF%E5%86%99%E4%BD%9C/","excerpt":"","text":"以前的文章已经介绍过如何使用LaTeX语法在Markdown中输入数学公式, 但输入数学公式只是LaTeX的一个基本功能, LaTeX的本质是一个排版工具. 本文将正式的介绍LaTeX的语法, 以及如何使用LaTeX进行学术写作. 基础知识LaTex的一些基础特性如下表所示 特性 解释 空格 源文件中的多个连续的空白字符均视为一个空白字符 指令 以\\开始的一个词(只包含字母) 注释 以%开始的一行 特殊字符 # $ % ^ &amp; _ &#123; &#125; \\ 每个特殊字符的具体的作用在之后会有介绍, 因此不需要特别记忆. 源文件结构12345678910\\documentclass&#123;article&#125;\\usepackage&#123;...&#125;% 这一部分称为导言区\\begin&#123;document&#125;% 这里是正文\\end&#123;document&#125; 在导言区可以设置使用的包, 文档的元信息等. 常见文件格式 类型 作用 类型 作用 tex LaTeX源文件 sty 宏包文件 dtx 文档化TeX文件 ins dtx文件对应的安装文件 cls 定义文档外观的文件 fd 字体描述文件 dvi 设备无关文件, 编译的主要结果 log 编译的日志信息 toc 存储章节标题的文件 lof 存储图像目录的文件 lot 存储表格目录的文件 aux 向下一次编译传递的信息, 主要是交叉引用信息 idx 存储索引的文件 ind 处理过的idx文件 ilg 记录makeindex指令执行日志 本文排版与Markdown相同, 两段文字之间直接换行并不会产生分段效果, 而是直接合并成一段. 如果想要分成两段, 则必须有一个空行. 以下是一些常见的排版指令 指令 效果 \\\\ 换行 \\newpage 分页 标题和章节 指令 含义 \\section&#123;...&#125; 创建一个节, 并且指定小节名称 \\subsection&#123;...&#125; 二级节 \\subsubsection&#123;...&#125; 三级节 \\paragraph&#123;...&#125; 创建一个段落, 并且指定段落名称 \\subparagraph&#123;...&#125; 二级段落 \\maketitle 生成标题 注意: 在执行生成标题操作前, 必须使用\\title,\\author等指令提供必要的信息. 交叉引用 指令 含义 \\label&#123;...&#125; 给标题, 图片等资源添加一个引用名称 \\ref&#123;...&#125; 根据名称获得被应用资源的序号 \\pageref&#123;...&#125; 根据名称获得被应用资源的页码 \\label可以跟随在包括\\section在内的各种可引用的标签后面, 从而给这些资源添加一个可以被引用的名称. 插入图片首先导入图片的包 1\\usepackage&#123;graphicx&#125; 然后使用如下的格式导入图片 12345\\begin&#123;figure&#125;[htbp] %htbp 代表图片插入位置的设置\\centering\\includegraphics[scale=0.5]&#123;SearchEnginAtchitecture.jpg&#125;\\caption&#123;搜索引擎架构&#125; \\label&#123;SearchEnginAtchitecture&#125;\\end&#123;figure&#125; 参考资料 LaTeX常用操作 Latex中插图总结","categories":[{"name":"学术写作","slug":"学术写作","permalink":"https://lizec.top/categories/%E5%AD%A6%E6%9C%AF%E5%86%99%E4%BD%9C/"}],"tags":[{"name":"LaTeX","slug":"LaTeX","permalink":"https://lizec.top/tags/LaTeX/"}]},{"title":"Effective Java Reading Notes","slug":"EffectiveJavaReadingNotes","date":"2019-07-18T01:13:03.000Z","updated":"2021-05-08T08:56:07.546Z","comments":true,"path":"2019/07/18/EffectiveJavaReadingNotes/","link":"","permalink":"https://lizec.top/2019/07/18/EffectiveJavaReadingNotes/","excerpt":"","text":"The book, “Effective Java“, is designed to help us make the most effective use of the Java programming language and its fundamental libraries. And this is the reading notes of that book. I am not sure what will be written in the note, but there are two reason for me to write: learning the most effective use of Java learning the expression of English Therefor, this article’s grammar may not be fully correct. I will try my best to ensure the expression of this note is correct and clear. 然而事实证明, 想要一步完成阅读和笔记是不可能的, 勉强完成也没有效率的. 由于目前的英语水平还没有达到流畅表达的地步, 因此强行使用英文只会变成抄写摘要. 所以, 在之后的内容中, 我考虑按照两个步骤完成这篇文章. 第一阶段, 使用中文总结每个部分的主要内容. 第二阶段, 将中文表述转换为英文. Content 创建和销毁对象 Item 1 使用静态工厂方法代替构造器 Item 2 面对很多构造器参数时使用builder模式 Item 3 单例模式使用私有构造器或枚举 Item 4 不可实例化的类强制使用私有构造函数 Item 5 使用依赖注入来管理资源 Item 6 避免创建不必要的对象 Item 7 消除无效的引用 Item 8 避免使用finalizers和cleaners Item 9 使用try-with-resources替代try-finally 对象的共有方法 Item 10 重写equals方法的规则 Item 11 重写equals的同时重写hashCode方法 Item 12 始终重写toString方法 Item 13 谨慎的重写clone方法 Item 14 考虑实现Comparable接口 类和接口 Item 15 最小化类和成员的可见性 Item 16 在public类使用访问器而不是public字段 Item 17 最小化可变性 Item 18 组合优于继承 Item 19 设计并说明继承否则禁止继承 Item 20 接口优于抽象类 Item 21 为后续设计接口 Item 22 只使用接口定义类型 Item 23 继承优于Tagged类 Item 24 使用静态成员类替代非静态成员类 Item 25 一个文件只定义一个顶级类 泛型 Item 26 不要使用原始类型 Item 27 消除unchecked警告 Item 28 偏向使用list而不是array Item 29 偏向使用泛型参数 Item 30 偏向使用泛型方法 Item 31 使用bounded wildcards来增加API的灵活性 Item 32 谨慎的组合泛型和可变参数 Item 33 枚举和注解 Item 34 使用枚举类型替代整数常量 Item 35 使用枚举实例而不要使用枚举的顺序 Item 36 使用EnumSet代替bit模式 Item 37 Item 38 Item 39 注解优于命名模式 Item 40 一致地使用Override注解 Item 41 使用标记接口定义类型 Lambdas和Streams Item 42 Lambda方法优于匿名类 Item 43 方法引用优于Lambda方法 Item 44 使用标准函数接口 Item 45 谨慎的使用Streams Item 46 在Stream中使用无副作用的函数 Item 47 返回Collection而不是Stream Item 48 谨慎使用Stream的并行化 方法 Item 49 检查参数的有效性 Item 50 在必要时进行防御性拷贝 Item 51 仔细的设计方法签名 Item 52 谨慎的重载方法 Item 53 谨慎使用可变参数 Item 54 返回空集合而不是null Item 55 谨慎的使用Optional Item 56 一般性编程 Item 57 最小化局部变量作用域 Item 58 使用for-each代替传统的for循环 Item 59 了解和使用库 Item 60 需要精确值时避免使用float和double类型 Item 61 偏向使用基本类型而不是装箱类型 Item 62 其他类型更合适时不要使用字符串 Item 63 注意字符串连接的性能 Item 64 通过接口引用对象 Item 65 偏向使用接口而不是反射 Item 66 谨慎的使用native方法 Item 67 Item 68 异常 Item 69 在需要使用异常的场合使用异常 Item 70 对可恢复的条件使用受检异常, 对编程错误使用运行时异常 Item 71 避免不必要的受检异常 Item 72 使用标准异常 Item 73 抛出匹配抽象程度的异常 Item 74 对所有方法抛出的异常编写文档 Item 75 Item 76 Item 77 不要忽略异常 并发 Item 78 同步访问共享的可变数据 Item 79 避免过度使用synchronization Item 80 使用Executors, Tasks和Streams代替线程 Item 81 使用concurrency工具类代替wait和notify Item 82 在文档中标记是否线程安全 Item 83 谨慎使用惰性初始化 Item 84 不要依赖线程调度器 序列化 Item 85 考虑使用序列化的替代品 Item 86 Item 87 Item 88 Item 89 Item 90 Item 1使用静态工厂方法代替构造器. A class can provide a static factory methods, which is simply a static methods that return an instance of the class. Note that a static factory method is not the same as the Factory Method pattern from Design Patterns. A class can provide its clients with static factory methods instead of, or in addition to, constructors. There are 3 reasons to ues static factory methods: 静态方法可以具有一个自定义的名字. 构造函数的名称必须与类名一直, 当构造函数的重载版本较多时, 会导致比较难以区分. 静态方法不必每次都创建新的对象, 静态方法可以可以缓存结果, 返回不可变对象 静态方法可以返回声明类型的子类 一些常见的静态工厂方法如下表所示 名称 方法举例 from Date.from(instance) of EnumSet.of(JACK, QUEEN) valueOf BigInteger.valueOf(...) instance / getInstance A.getInstance(options) create / newInstance Array.newInstance(...) getType Files.getFileStore(path) newType Files.newBufferedReader(...) type Collections.list(...) Item 2当构造器有很多参数时使用builder Item 3单例模式使用私有构造器或使用枚举. 1234567891011public enum Elvis &#123; INSTANCE; private String name; Elvis()&#123; name = &quot;LiZeC&quot;; &#125; public String getName() &#123; return name; &#125;&#125; 使用枚举可以利用JVM的类加载机制实现线程安全和单例加载, 是通常情况下的最优解. 由于枚举类型无法继承, 因此这种方案的单例无法继承其他的类. Item 4不可实例化的类强制使用私有构造函数 Item 5使用依赖注入来管理资源 Item 6避免创建不必要的对象. 由于String是不可变的, 因此在String相关的操作时, 应该避免毫无意义的调用String的构造函数, 或者重复的执行String的连接操作. 与此类似, 数字的自动装箱和自动拆箱机制使得数字的基本类型和原始类型可以混合使用. 但数字装箱操作既耗费时间又耗费空间, 因此要尽量避免自动装箱操作. 对于Adapter, 由于Adapter本身不包含任何多余的状态信息, 因此完全可以所有的Adapter使用一个实例. 对于轻量级的对象, 自己实现一个对象池并不是一个好主意, 通常垃圾回收系统可以做的更好 Item 7消除无效的引用. 垃圾回收系统根据引用关系决定一个对象是否需要回收, 因此不需要的对象需要及时的置为null. 尤其是容器类型的类, 内部的数据在删除后, 引用一定要置为null, 否则相关的对象无法正确的释放. 另一个常见的内存泄露常见就是Cache, Cache保存了对象的强引用, 而对象并不一定总是被使用, 而Cache中的引用阻止了垃圾回收系统. 通常可以使用WeakHashMap实现Cache的功能, 从而在相关对象不被其他对象引用时能够被回收. Item 8避免使用finalizers和cleaners. 从Java 9开始, finalizers函数已经被标记为废弃, 任何时候都不要使用此函数. 对于需要回收资源的场景, 使用try-with-resources语句. Item 9使用try-with-resources替代try-finally Item 10重写equals方法的规则. 以下条件下, 可以不重写equals方法 所有的实例都不相同 不需要提供逻辑上的相等 父类已经合适的重写了equals方法 可以肯定不会调用equals方法 不满足以上条件时, 可以考虑重写一个equals方法. 例如, 通常表示值类型的对象, 在进行相等判断时, 往往期望判断两个值是否相等, 而不是判断是否是同一对象. 由于equals是一个等价关系, 因此需要满足如下的一些要求 自反性: 对任意非空引用的x, x.equals(x)必须返回true 对称性: 对任意非空引用的x和y, x.equals(y)返回true当且仅当y.equals(x)返回true 传递性: 对任意非空引用的x,y和z, 如果x.equals(y)返回true且y.equals(z)返回true, 则x.equals(z)返回true 一致性: 对任意非空引用的x和y, 多次调用x.equals(y)时, 返回结果应该始终为true或始终为false 空条件: 对任意非空引用的x, x.equals(null)始终返回false Item 11重写equals的同时重写hashCode方法. 相等的对象必须具有相同的哈希值. Item 12始终重写toString方法. 合适的toString方法有利于代码的理解和调试. Item 13谨慎的重写clone方法. clone机制的设计存在瑕疵, Cloneable接口是一个标记接口, 其中不包含任何方法, 而对象的clone方法来自Object对象, 但在Object对象中, clone方法又是protected方法. 因此存在实现了Cloneable接口, 但是由于没有正确的重写clone方法导致不可调用或者调用出现错误的情况. Item 14考虑实现Comparable接口. Item 15最小化类和成员变量的可见性. 对于非final, 可变对象的引用, 一定要严格控制可见性, 否则容易造成内部数据泄露到类外部的情况. 在Java 9中引入了模块(module)的概念,模块是一组包(package)的集合. 模块可以通过导出列表明确的执行需要导出那些API. 位于导出列表的API可以被模块外部的其他类访问, 而不在导出列表的类, 即使是public或者protected也不能被模块外的其他类访问. 模块对应的jar只有放置在模块搜索路径上才能以模块的方式生效, 如果直接放置在classpath上, 则依然按照普通的jar进行加载. 这一模式仅有一个例外, 即JDK中的模块, 无论放置在那个路径上, 都只能以模块的方式加载. Item 16在public类使用访问器而不是public字段. 不使用访问器会导致后期的修改余地较小. Item 17最小化可变性. 如果需要一个类不可变, 则需要满足如下的5个条件: 不要提供修改类状态的方法 确保类不可被继承 确保所有字段都是final 使所有字段为private 确保不访问任何可变对象 不可变对象更加简单, 且天然具有线程安全的特性. 因为一个线程不会观察到不可变对象被修改, 因此不可变对象可以安全的在不同线程中共享. 此外, 由于不可变对象内部的各个部分也是不可变的, 因此不可变对象的内部属性也能够直接在多个线程中共享. 不可变对象也可以作为构建其他对象的基本模块, 无论一个对象是否可变, 对于其他的一部分属性, 如果能够组成一个不可变对象, 也能够降低做这个对象的维护难度. 不可变对象的主要缺点是需要大量的对象表示不同的值. **实现细节:**根据不可变性的五条规则, 需要将类声明为final使得其不能被继承. 但将类的构造函数声明为private并使用工厂方法创建对象是一种更有效的方法. 因为构造函数为private, 这使得包外的类都无法继承此类, 间接的实现了final效果. 而工厂方法相比于构造器又能够实现对象缓存等其他优化措施. 此外, 不可变对象并不要求对象绝对不可变, 在对象内部可以有一些可变的字段, 他们可以用来缓存一些计算代价较高的函数的结果. 这是一种称为惰性加载的优化措施. 因为对象不可变, 因此可以保证这些缓存结果有意义. JDK的缺陷: 在编写BigInteger和BigDecimal时, 不可变对象应该不可继承这一点并没有被广泛的认识, 因此这两个类都可以被继承,其中的方法也可以被子类重写. 如果以这两个类作为接口, 并且运行在一个可能存在恶意代码的环境, 则最稳妥的方法是判断输入参数的类型, 并进行适当的转换, 例如 123public static BigInteger safeInstance(BigInteger val) &#123; return val.getClass() == BigInteger.class ? val : new BigInteger(val.toByteArray())&#125; Item 18组合优于继承. 继承是一个强大的复用代码的工具, 但如果不正确的使用, 会造成代码非常脆弱. 一般而言, 将继承限制在一个包内, 从而使一个程序员维护继承类是安全的. 或者继承一个明确标记为可以继承的类也认为是安全的. 而跨越包的随意继承具体的一个类是危险的. 继承的主要问题是违背了封装性, 子类的实现依赖了父类的具体实现, 如果父类发生了变化, 子类也会相应的受到影响. 继承的另外一个问题是父类可以随意的添加新的方法, 如果子类对父类的方法进行限制来实现功能, 那么新加入的方法可能因为子类没有适当的重写而导致子类的功能被破坏. 使用继承的时候应该问自己一个问题, 如果B希望继承A, 那么是否有 B is a A? 如果不能肯定的回答, 或者回答是否定, 那么就不应该使用继承. 例如在JDK中, Stack不是一个Vector, Properties也不是一个Hashtable, 那么这两个类也不应该使用继承. Item 19设计并说明继承否则禁止继承. 对于每一个创建的类, 要么通过设计使其满足继承条件并在文档中进行说明, 否则就应该禁止其被继承. Item 20接口优于抽象类. Item 21为后续设计接口. Java 8引入了默认方法, 可以对接口添加默认的方法, 而实现这些接口的类不需要进行任何修改即可自动继承这些方法. 默认方法使得实现接口具有了一点继承的特性. 正如继承中父类随机添加方法可能导致子类的功能出现问题, 默认方法也会导致这种结果, 相关的子类在接口加入默认方法后, 必须对默认方法进行适当的重写才能保证功能的正确性. 虽然默认方法一定程度上可以对已经发布的接口进行修改, 但精心设计接口依然是最重要的. 接口在发布后虽然可能被修改, 但不能指望这一点. Item 22Use interfaces only to define types. When a class implements an interface, the interface servers as a type that can be used to refer to instances of the class. That a class implements an interface should therefore say something about what a client can do with instances of the class. One kind of interface that fails this test is the so-called constant interface. Such an interface contains no methods; it contains solely of static final fields, each exporting a constant. Classes using these constants implements the interface to avoid the need to qualify constant names with a class name. The constant interface patter is a poor use of interfaces. That a class uses some constants internally is an implementation detail. If you want to export constants, there are several reasonable choices. If the constants are strongly tied to an existing class or interface, you should add them to the class or interface. For example, all of the boxed numerical primitive classes export MIN_VALUE and MAX_VALUE constants. If the constants are best viewed as members of an enumerated type, you should export them with an enum type. Otherwise, you should export the constants with a noninstantiable utily class. 123456public class PhysicalConstants&#123; private PhysicalConstants() &#123; &#125; public static final double AVOGADROS_NUMBER = 6.022_140_857e34; public static final double BOLTZMANN_CONST = 1.380_648_52e-23; public static final double ELECTRON_MASS = 9.109_383_56e-32;&#125; 123456789// Use of static import to avoid qualifying constants bimport PhysicalConstants.*;public class Test &#123; double atoms(double mols)&#123; return AVOGADROS_NUMBER * mols; &#125;&#125; Item 23继承优于Tagged类. Tagged类是指通过在类上进行Tag标记来区分不同的类型的类. 由于这一需求正好可以被继承代替, 因此没有任何必要手动标记来区分类, 完全可以通过继承系统自动的实现类型的区分. Item 24Favor static member class over non-static. A nested class is a class defined within another class. A nested class should exist only to server its enclosing class. If a nested class would be useful in some other context, then it should be a top-level class. There are four kinds of nested classes: static member classes, nonstatic member classes, * anonymous classes*, and local classes. All but the first kind are known as inner classes. A static member class is the simplest kind of nested class. It is best thought of as an ordinary class that happens to be declared inside another class and has access to all of the enclosing class’s members, even those declared private. One common use of a static member class is as a public helper class, useful only in conjunction with its other class. For example, consider an enum describing the operations supported by a calculator(Item 34). The Operation enum should be a public static member class of the Calculator class. Clients of Calculator could then refer to operation using names like Calculator.Operation.PLUS. One common use of a non-static member class is to define an Adapter that allows an instance of the outer class to be viewed as an instance of some unrelated class. For example, implementations of the Map interface typically use non-static member classes to implement their collection.views. If you declare a member class that done not require access to an enclosing instance, always pus the static modifier in its declaration If you omit this modifier, each instance will have a hidden extraneous reference to its enclosing class. Storing this reference takes time and space. More seriously, it can result in the enclosing instance being retained when it would otherwise be eligible for garbage collection. Item 25Limit source files to a single top-level class. Definitions multiple top-level classes in a source file makes it possible to provide multiple definitions for a class. Which definition gets used is affected by the order in which the source file are passed to the compiler. Item 26不要使用原始类型. 原始类型存在的意义是与以前的代码兼容, 在新的代码中一定要指定泛型的类型, 从而由编译器检查类型和自动转换. List类型与List&lt;Object&gt;类型都可以加入任意对象, 但List&lt;Object&gt;与List&lt;String&gt;没有任何继承关系, 可以确保不会因为继承操作导致类型错误. 如果一个方法只需要一个集合, 而不关心具体是什么元素, 那么可以声明为Set&lt;?&gt;的形式. 这种形式的集合会拒绝插入除null以外的任何类型的元素, 且无法从此集合获得任何的类型信息. Item 27消除unchecked警告. 在编写代码的时候, 尽可能的消除unchecked警告, 没有unchecked警告意味着代码是类型安全的, 不会在运行时出现ClassCastException. 如果确实有无法消除的unchecked警告, 但是又确认确实是可以安全转换的, 可以使用@SuppressWarnings(&quot;unchecked&quot;) 注解, 以免这些warning掩盖了其他真的代表某些问题的warning. 这个注解可以控制使用范围, 因此需要确保使用范围尽可能的小, 最好是针对一个语句或者一个很短的函数使用此注解. 并且在使用时通过注释表明为什么可以保证这个转换是安全的. 如果不能简单的说明这一点, 最好仔细考虑一下是不是真的能够保证转换是类型安全的. Item 28偏向使用list而不是array. array与list的最大区别是array是可变的, 而list是不可变的. 这意味着如果Sub是Super的子类, 那么Sub[]是Super[]的子类, 而任意两个不同的类型T1和T2, List&lt;T1&gt;和List&lt;T2&gt;不会有任何继承关系. array的这一特性导致运行时会出现类型错误, 而List则不会有这样的问题, 例如 12345Object[] objectArray = new Long[1];objectArray[0] = &quot;str&quot;; //抛出ArrayStoreExceptionList&lt;Object&gt; ol = new ArrayList&lt;Long&gt;(); // 不兼容类型, 无法编译ol.add(&quot;str&quot;) 由于list与array的差异, 两种不太能混合使用, 例如无法new List&lt;String&gt;[]或者new E[]. 如果允许这些操作, 就可以通过array的特性绕过list的类型检查, 导致运行时错误. 因此如果在混合使用array和list时, 出现了无法创建的错误, 或者有类型转换不安全的警告, 那么可以考虑全部使用list. 虽然这可能导致代码变得冗长或者有一些性能损失, 但这样可以保证类型安全. Item 29偏向使用泛型参数. 虽然Object是所有对象的父类, 设计Object类型的容器可以容纳任意类型的对象, 但将对象从Object转换回去的时候就无法进行编译时检查. 因此在这种场合应该使用泛型参数, 从而获得编译时检查类型的能力. Item 30偏向使用泛型方法. 如果一个方法需要对任意的类型进行操作, 或者需要对泛型集合进行操作但又不关心集合中的具体元素类型, 那么相比于直接使用Raw类型, 定义泛型方法来处理更加安全. Item 31使用bounded wildcards来增加API的灵活性. 规则是PECS原则, 即producer-extend, consumer-super. 即如果一个参数是想向对象的内部传递数据, 那么应该声明为&lt;? extend T&gt;, 如果参数是想从对象内取出数据, 那么应该声明为&lt;? super T&gt;. 针对第一种情况, 通过extend声明, 使得T的子类也能传递进来(符合子类替换原则). 而针对第二种情况, 通过super声明, 可以将对象类的数据放置到其父类的容器之中(这也符合子类替换原则). 推论: 以Comparable接口为例, 由于这个接口只能消费对象内的数据, 因此Comparable接口几乎总是声明为Comparable&lt;? super T&gt;的形式 如果一个泛型参数只出现一次, 那么可以考虑将其替换为&lt;?&gt;, 例如以下两个表示交换列表中数据的API 12public static &lt;E&gt; void swap(List&lt;E&gt; list, int i, int j);public static void swap(List&lt;?&gt; list, int i, int j); 相比于第一种较为复杂的API, 第二种API更为简单, 因此交换操作本来就不关心元素的具体类型, 因此直接使用&lt;?&gt;表达这一不关心元素类型的含义更加准确. Item 32谨慎的组合泛型和可变参数. 由于可变参数的实现是数组, 而这种实现是可见的, 因此当泛型和可变参数一同使用时, 就会出现前面提到的泛型和数组组合的问题. Item 33Item 34使用枚举类型替代整数常量. 枚举类型具有类型, 而整数常量都是int类型, 因此使用枚举能获得更多语义信息, 从而为代码提供更多语法检查. 枚举类型实际上就是一个Java中的类, 其中声明的每个枚举值都是这个类对应的final static实例. 枚举天然的实现了单例模式, 每个枚举值都是一个单例. 实际上Java的枚举很好的实现了Object中定义的方法, 并且实现了Comparable和Serializable接口. Java枚举的序列化经过了设计, 能够适应大部分对枚举进行修改的情况. Java的枚举可以加入任何的方法, 实现任意的接口. 这种需求通常源于对实例值附加更多属性. 例如表示水果类型的枚举值可能希望能获得一个获得水果颜色的方法. 一个包含了各种特性的枚举值具有如下的样式. 12345678910111213141516171819202122232425public enum Plant &#123; MERCURY(3.302e+23, 2.439e6), VENUS(4.869e+24, 6.052e6), EARTH(5.975e+24,6.378e+6), MARCH(6.419e+23,3.393e+6); // 注意这里的分号表示结束枚举值 private final double mass; private final double radius; private final double surfaceGravity; private static final double G = 6.67300E-11; Plant(double mass, double radius) &#123; this.mass = mass; this.radius = radius; surfaceGravity = G * mass / (radius * radius); &#125; public double mass() &#123; return mass; &#125; public double radius() &#123; return radius; &#125; public double surfaceGravity() &#123; return surfaceGravity; &#125; public double sufaceWeight(double mass) &#123; return mass* surfaceGravity; &#125;&#125; 可以按照如下的方式使用上面的枚举类 1234567public static void main(String[] args) &#123; double earthWeight = 70; double mass = earthWeight / Plant.EARTH.surfaceGravity(); for (Plant plant : Plant.values()) &#123; System.out.printf(&quot;Weight on %s is %f%n&quot;, plant, plant.sufaceWeight(mass)); &#125;&#125; Item 35使用枚举实例而不要使用枚举的顺序. 直接获取枚举的int值对后续添加和修改枚举值造成了不利的影响. 如果一定需要使用枚举的int值, 可以在构造枚举实例的时候明确指定取值. Item 36使用EnumSet代替bit模式. 在Linux操作系统中, 文件权限就采取了bit模式, 分别用1 bit表示文件是否可读, 是否可写, 是否可执行. 在Java开发过程中, 完全可以使用EnumSet代替这种模式. 例如, 对于一个需要接受多个枚举值组合的接口, 可以按照如下的形式定义. 12345public class Text &#123; public enum Style &#123;BOLD, ITALIC, UNDERLINE, STRIKETHOUGH&#125; public void applyStyle(Set&lt;Style&gt; styles) &#123; ... &#125;&#125; 在需要使用的地方, 使用EnumSet的of函数构建一个Set. 1text.applyStyle(EnumSet.of(Style.BOLD, Style.ItALIC)); 当枚举的数量小于64时, EnumSet在内部仅使用一个long值, 因此在性能上与手动实现bit模式没有区别, 但在其他情况, EnumSet也能更加妥当的处理. Item 37Item 38Item 39注解优于命名模式. 命名模式指示通过某种命名方式使得某些类或者方法具有一些额外的属性. 例如在Junit测试框架的早期版本中, 要求需要被测试的方法以test字符开头或者结尾. 这种模式虽然一定程度上可以附加额外的属性, 但是由于存在拼写错误的可能性, 因此不够好用. 使用注解可以更好的替代这种模式. Item 40一致地使用Override注解. Item 41标记接口是指一类只用于标记, 而不包含任何方法的接口. 典型的标记接口是Serializable接口, 此接口不包含任何方法, 只用来标记一个类可以被序列化.相比于Item 39中介绍的使用注解引入额外信息, 使用标记接口最主要的优势在于, 标记接口定义了一种类型, 而注解没有定义任何类型. 这使得使用标记接口时, 与类型相关的错误可以在编译器就被发现. 而如果使用注释, 这类错误则需要在运行期才能够被发现. 标记接口的第二个优势是标记接口只能应用到类或者接口上, 因此可以将应用范围限制在更小的范围内, 而注解如果没有进行限制, 可以注解到任何位置. 注解的优势是存在大量以注解为基础的框架, 使用这些框架的时候, 就需要一致地使用注解. 关于何时使用标记接口, 何时使用注解, 可以概括为如下的情况. 如果这个额外信息针对的不是类或者接口, 那么只能使用注解. 如果额外信息针对的是类或者接口, 那么考虑一个问题, 即是否存在以这种信息为要求的方法, 如果是, 那么使用标记接口可以将标记接口作为方法的参数, 从而获得编译时检查. 否则可以考虑使用注解. 本条与Item 22正好是一个相对应的关系. Item 22概括来说就是如果不想定义类型, 不要使用接口. 而本条相当于说如果想定义一个类型, 那么就使用接口. Item 42偏向使用Lambda而不是匿名类. Lambda函数是针对需要一个函数的场景设计的, 在这种场景下Lambda表达式比同等的匿名类更短, 更能清晰的表达代码的意图. 但在另一方法, Lambda表达式缺少名字和文档. 如果一个计算过程不是可以自我解释的, 或者长度较长, 那么就不适合使用Lambda表达式. Lambda表达式最适合的长度是一行, 三行是可以接受的最大长度, 否则应该思考一下是否合适. Item 43偏向使用方法引用而不是Lambda方法. 方法引用比Lambda方法更简洁(succinct). 123map.merge(key, 1, (count, incr) -&gt; count + incr);map.merge(key, 1, Integer::sum); 以上面的两行代码为例, 第二行使用方法引用, 更简明的表达了计算含义, 而且代码长度更短. 一个函数接口需要的参数越多, 使用方法引用可以消除的代码就越多. 除非使用Lambda更简洁, 否则就应该使用方法引用(例如identity操作就是Lambda更简洁). 基本上所有使用Lambda的地方都可以使用方法引用替换, 而且IDE也提供了将Lambda转化为方法引用的功能. Item 44使用标准函数接口. Java的java.util.Function包提供了43个函数接口. 这43个接口可以分成6个基础接口, 和相应的基础类型派生接口. 6个基础接口分别是 Interface Function Signature Example UnaryOperation&lt;T&gt; T apply(T t) String::toLowerCase BinaryOperation&lt;T&gt; T apply(T t1, T t2) BigIntgeter::add Predicate&lt;T&gt; boolean test(T t) Collection::isEmpty Function&lt;T,R&gt; R apply(T t) Arrays::asList Supplier&lt;T&gt; T get() Instant::now Consumer&lt;T&gt; void accept(T t) System.out.println 对于上面的6中基本类型, 都有三种基础类型的派生类型(int, long和double). 三种派生类型通过加入前缀的方式产生, 例如针对long版本的UnaryOperation名称为LongUnaryOperation. Function的派生版本稍微有些特殊, LongFunction&lt;int[]&gt;表示参数为long, 返回值为int[]的函数. ToLongFunction&lt;int[]&gt;表示参数为int[], 返回值为Long的函数. 通过这一派生方法, 产生了5x3+3+3=21种新接口. 针对Function接口, 根据不同的参数和返回值, 产生了6种从一个基础类型转换到另外一个基础类型的接口, 例如从long到int的Function定义为LongToIntFunction. 同种类型的转换不需要派生, 因为这种情况可以使用UnaryOperation的派生接口. 对于6种基本接口类型中的3种, 提供了二元函数版本. 分别是BiPrediction&lt;T,U&gt;, BiFunction&lt;T,U, R&gt;, BiConsumer&lt;T,U&gt;. BiFunction根据返回值类型, 可以派生三种类型, 例如ToIntBiFunction. BiConsumer派生三种接受Object和基本类型的接口, 例如ObjLongConsumer. 3种二元函数和6种派生类型构成了9种新接口. 最后, BooleanSupplier提供了boolean版本的Supplier, 加上这一个接口即可得到6+21+6+9+1=43个接口. 由于装箱类型与基础类型存在一些差异(例如==的效果), 以及装箱带来的性能问题, 因此要尽可能的使用基础类型. 由于基础类型和封装类型并不是完全等价的, 因此IDEA并不会分析某个接口能否替换为基础类型的版本. 但当Stream本身就是基础类型时, 相应的接口就自动使用基础类型, 从而不用考虑选择问题. 大部分时候应该直接使用标准函数接口, 但如果存在如下的一些情况, 也可以考虑使用自定义接口 此函数接口被广泛的使用, 值得使用一个更有意义的名称. 可以从接口的默认方法获得收益. 自定义的函数接口应该始终使用@FunctionalInterface进行标记, 此标记可以保证 向读者表明此接口是函数接口, 应该传递函数 使编译器检查此接口有且只有一个方法 Item 45谨慎的使用Streams. Stream存在一定的局限性, 不要在不适合的场景下强行使用Stream. 使用了Stream后, 代码应该更加简洁易懂, 而不是相反的情况. 在缺少类型的情况下, 应该谨慎的定义Lambda表达式的变量名, 使其具有一定的类型信息. Stream缺少对char类型的支持, 此时应该控制Stream的使用. Item 46在Stream中偏向使用无副作用的函数, 以确保Stream能够正确的并行执行. Item 47偏向返回Collection而不是Stream. Stream需要通过链式操作使代码易于理解, 如果一个接口只返回Stream类型, 那么当用户希望显式迭代时, 就不太容易操作. 虽然Stream实现的iterator实现了迭代器的功能, 但这一接口不能使用for循环. 如果需要使用for循环, 只能以如下的方式进行处理. 123for (String s : (Iterable&lt;? extends String&gt;) Arrays.stream(words)::iterator) &#123;&#125; Iterable要求实现iterator方法, Stream实质上已经实现了Iterable接口, 但由于没有声明此接口, 因此只能如上面的代码一样迂回一下, 或者按照如下的方式实现一个转换的适配器 123public static &lt;E&gt; Iterable&lt;E&gt; iterableOf(Stream&lt;E&gt; stream) &#123; return stream::iterator;&#125; 但是在另一方面, Stream具有一定的延迟计算的特性, 当需要返回一个巨大的集合时, 使用Stream构建一个类似生成器的结构则有助于减少内存消耗. Item 48谨慎使用Stream的并行化. Stream并行化使用fork/join框架, 需要数据能够容易一分为二的处理. 如果一个Stream使用iterate方法创建, 或者使用了limit方法, 那么并行化基本不可能使性能提升. 使用合适的数据结构才可能提升并行化的性能. 合适的数据结构包括 ArrayList, HashMap, HashSet和ConcurrentHashMap等对象, 数组, int/long range. 在终止操作方面, 最适合并行的终止操作是reduce操作, 或者内置的类似reduce的操作, 包括 min, max, count等. 其次是短路操作, 包括anyMatch, allMatch等. 如果计算的大部分时间都在终止操作, 那么并行化中间的计算过程显然不是一个有价值的操作. 一个粗略的估计是, 如果需要处理的元素数量乘以处理这些元素的操作行数大于10万, 那么考虑进行并行化才是有价值的. Item 49检查参数的有效性. 尽可能早的检查错误是一条通用的编程原则, 否则错误的扩散将导致错误难以发现. 对于一个参数是否为null, 可以使用Object.requireNonNull进行处理, 这比手动检查更方便一点. 如果是类中的私有方法, 可以使用assert来进行处理, 因为此类私有方法可以控制调用环境, 因此不应该出现值为空的情况. Item 50在必要时进行防御性拷贝. 在编程时, 需要你编写的类会被使用他们的用户尽可能修改. 例如Java中的Date类由于不是可变的, 因此一个类将Date作为参数存储后, 外部对Data的修改都会导致内部的变量也被修改. 解决这一问题的方法是使用Instant类代替(不可变的类), 或者进行防御性拷贝, 在类的内部拷贝一份Date类. 例如 12345678public Period(Date start, Date end) &#123; this.start = new Date(start.getTime()); this.end = new Date(end.getTime()); if(this.start.compareTo(this.end) &gt; 0) &#123; throw new IllegalArgumentException(this.start + &quot;after &quot; + this.end); &#125;&#125; 注意: 这里首先进行拷贝, 然后在拷贝的变量上检查参数有效性, 而不是直接检查参数有效性. 这一操作的目的是确保在检查参数有效性和拷贝的间隙内, 参数的值不会被其他线程修改. 这一问题在计算机安全领域被称为time-of-check/time-of-use攻击(TOCTOU攻击). 在另一方法, 可以注意到上面的代码没有使用clone方法获取拷贝. 因为Date类是非final的, 因此clone可能被子类实现, 而导致调用clone后返回了一个不可信的子类. Preiod类现在虽然可以抵抗输入参数的修改, 但如果Preiod类直接返回Date类, 那么外部的代码还是可以通过修改Date类影响Preiod类的内部状态. 因此Preiod类返回时也需要进行防御性拷贝, 例如 1234567public Date start() &#123; return new Date(start.getTime());&#125;public Date end() &#123; return new Date(end.getTime());&#125; 无论何时, 只要编写的方法保存了客户端提供的参数, 那么都需要考虑提供的参数是否需要防御性拷贝. 在返回内部可变组件时, 也需要考虑外部代码是否可能影响内部的状态. Item 51仔细的设计方法签名. 方法签名的首要目的是保证签名容易理解且与包内的其他方法签名一致. 一个方法的名称并不是越长越好. 不要在一个类中实现过多的便捷方法. 这一点对于接口尤其重要, 如果一个接口内方法太多, 会导致实现此接口和使用此接口更加困难. 对于每一个操作, 提供一个完整功能的方法. 只有当某些便捷方法非常常用时, 才考虑实现这种便捷方法. 避免设计过长的参数列表. 一个方法最好只有四个以内的参数. 如果参数过多, 可以考虑三种方法进行处理 将一个方法拆分为多个方法, 从而每个方法仅使用原方法参数列表中的一部分参数 设计一个帮助类存储需要的参数 使用Builder模式构建对象 方法的参数偏向使用接口类型而不是具体类型. 具体内容可以参考Item 64. 考虑使用两个元素的枚举类型替换boolean参数. 使用枚举能够更加清晰的表达含义. 例如, 对于包含两个元素的温度类型枚举 1public enum TemperatureScale &#123; FAHRENHEIT, CELSIUS &#125; 使用枚举就比使用布尔值更能清晰的表达温度类型的含义. 而且后续如果加入新的温度类型, 也能够更方便的进行修改. Item 52谨慎的重载方法. Java的方法重载是静态的, 在编译器就根据声明的类型完成了函数调用选择. 泛型和自动装箱模糊了标准库中可重载的API. Set接口存在一个移除对象的方法remove(E), 在Set&lt;Integer&gt;上调用remove(2)时, 会自动对2进行自动装箱. 但List接口存在两个移除对象的方法, 分别是remove(E)和remove(int), 在List&lt;Integer&gt;上调用remove(2)时, 不会自动装箱, 而是直接移除第二个元素. 在Java8中, lambda方法的引入也会进一步导致一些函数重载出现问题, 例如下面的代码 123456// 方案一new Thread(System.out::println).start();// 方案二ExecutorService exec = Executors.newCachedThreadPool();exec.submit((Runnable) System.out::println); 方案一可以正常的编译运行, 而方案二会因为无法确定重载版本而报错. 因为Thread的构造函数只能接受Runnable接口的参数, 但sumbit方法可以接受Runnable和Callable&lt;T&gt;, 虽然System.out::println的所有重载都是void, 不可能重载Callable&lt;T&gt;, 但编译器并不能除以这种两个方法都可以重载的情况. 重载相关联的类时要确保重载行为一致. 以String方法为例, 此方法提供了valueOf(char[])和value(Object)重载, 但一个char[]对象分别以这两种方法进行调用时, 就会出现不一致的行为. 在程序中应该避免出现这样的重载. Item 53谨慎使用可变参数. 在使用可变参数时, 方案二比方案一更好. 尤其在一个方法至少需要有一个参数时. 12345678910111213141516171819202122232425// 方案一static int min(int... args) &#123; if (args.length == 0) &#123; throw new IllegalArgumentException(&quot;Too few Arguments&quot;); &#125; int min = args[0]; for (int i = 1; i &lt; args.length; i++) &#123; if (args[i] &lt; min) &#123; min = args[i]; &#125; &#125; return min;&#125;// 方案二static int min(int firstArg, int... remainingArgs) &#123; int min = firstArg; for (int arg : remainingArgs) &#123; if (arg &lt; min) &#123; min = arg; &#125; &#125; return min;&#125; Item 54返回空集合而不是null. 可以使用Collections.emptyList()代替每次创建一个新的空集合. Item 55谨慎的使用Optional. Optional与Checked Exception非常类似, 只有在确定客户端代码必须要处理空值问题的时候才应该使用Optional. 有几种情况下不应该使用Optional 集合类型不应该使用Optional, 而应该直接返回集合 基本类型应该使用特殊化的Optional, 例如OptionalInt, 否则包装成本太高 不应该将Optional对象作为map类型的key, value或者集合类型的元素 Item 56Item 57最小化局部变量作用域. 在需要的地方声明变量, 而不要在一个方法的开头声明变量. 每个变量都应该尽可能在声明的时候就完成初始化, 否则应该考虑能够延后这个变量的声明. Item 58Item 59了解和使用库. Java的标准库都是专家编写的, 经过广泛验证的代码, 因此能够使用标准库结解决问题就不要自己实现. 虽然标准库中的类很多, 无法一一了解, 但对于Java.lang, java.util, java.io包中的类应该有充分的认识. 对于集合类, Stream类和java.util.concurrent包也应该有充分的认识. Item 60需要精确值时避免使用float和double类型. 对于涉及货币的领域, 使用BigDecimal是默认的选择. 但对于非货币领域, 使用BigDecimal可能有一些繁琐, 此时使用int或者long来表示可能更简单. Item 61偏向使用基本类型而不是装箱类型. 虽然自动装箱和自动拆箱模糊了基本类型和装箱类型的界限, 但并没有消除两者的区别. 因此基础类型和装箱类型有三个重要的区别 基本类型只有值, 但装箱类型有值和地址, 装箱类型可以具有同样的值和不同的地址 基本类型只有值, 但装箱类型有null值 装箱类型有更高的性能开销 下面是一个简单的整数比较代码, 似乎也能够正确的工作 12Comparator&lt;Integer&gt; naturalOrder = (i, j) -&gt; (i &lt; j) ? -1 : (i == j ? 0 : 1) 但当执行下面的语句 1naturalOrder.compare(new Integer(42), new Integer(42)) 时, 程序并不会返回0, 而是返回1. 其原因就是&lt;会自动拆箱, ==并不会自动拆箱, 而是进行对象比较. 对装箱类型使用==进行比较几乎总是错误操作 针对上面的代码, IDEA会报告Warning以及提示使用内置函数进行替换 Item 62其他类型更合适时不要使用字符串. 字符串是用来表示一段文本的, 在其他的场景应该使用更合适的工具. 最典型的场景就是不要使用字符串代替枚举类型. 关于枚举参考Item 43. 另一个场景是使用字符串表示一个聚合类型, 例如 1String compoundKey = className + &quot;#&quot; + i.next(); 对于上面这种通过拼接字符串表示类型的情况, 定义一个专用的类可能更合适. Item 63注意字符串连接的性能. 字符串是不可变的, 循环拼接字符串的性能非常差, 此时应该使用StringBuilder代替. Item 64通过接口引用对象. 通过接口引用对象使得程序具有更换实现的灵活性. 当需要更换实现时, 只需要修改构造函数这一个地方. 有三种主要情况下, 应该使用类直接引用对象. 第一种情况是值类型(例如String和BigInteger), 这种类一般没有多种实现, 因此可以直接引用. 第二种情况是来自框架的基础类, 这一类框架一般使用抽象基类, 此时可以使用基类引用对象. 第三中情况是具体的实现类中有额外的方法, 如果需要使用这些额外方法, 则只能使用具体类. 一般情况下,如果一个类有对应的接口, 那么就应该直接使用对应的接口. 如果一个类没有对应的接口, 那么就应该使用最符合实际需要的子类. Item 65偏向使用接口而不是反射. 相比于使用接口, 使用反射将导致三个问题. 第一, 使用反射将无法在编译时检查类型. 第二, 反射的代码非常复杂, 且需要处理大量运行时异常, 这导致代码非常臃肿. 第三, 反射调用的性能低于直接调用的性能. 一般情况下, 只有一定要在运行时动态决定创建那个类的时候, 才应该使用反射技术, 而且应该在创建之后使用接口访问这个对象, 而不是使用反射API直接调用方法. Item 66谨慎的使用native方法. 有三种使用native方法的场景, 分别是访问平台相关的方法, 使用只有native实现的库, 提高某些方法的执行性能. 对于前两种场景, 使用native方法是允许的. 但是使用native方法提升性能几乎永远是不利的. JVM本身就在不断的提高执行性能, 大部分时候已经不需要通过调用native方法提供性能. 而且native方法中的代码bug还会导致整个应用程序出现错误. Item 67Item 68Item 69在需要使用异常的场合使用异常. 不要将异常用于正常的流程控制. Item 70对可恢复的条件使用受检异常, 对编程错误使用运行时异常. 每一个受检异常都表明这种异常也是调用方法可能的一种出口. 运行时异常用于表明程序存在错误. 使用受检异常还是运行时异常取决于能否从异常状态恢复. 能够从异常状态恢复的情形使用受检异常, 否则使用运行时异常. 如果不能明确能否从异常状态恢复, 那么先使用运行时异常比较稳妥. Item 71避免不必要的受检异常. 如果一个方法只抛出一个异常, 并且只会抛出这种异常, 那么就应该考虑是否有必要在这里使用异常. 这种情况下, 使用Optional可以替代异常. 但相对地, 使用Optional无法携带错误的原因, 是否替换需要根据实际情况进行取舍. Item 72使用标准异常. 使用标准异常可以使代码更容易阅读, 更符合一般认识, 并且是JVM加载更少的类. 以下是一些常见的可复用异常. Exception Occasion For Use IllegalArgumentException 不合适的非空参数 IllegalStateException 在方法调用时, 对象状态不正确 NullPointerException 参数为null IndexOutOfBoundsException 索引参数越界 ConcurrentModificationException 禁止并发操作的对象探测到并发修改 UnsupportedOperationException 对象不支持的方法 原则上, 所有的错误都可以归纳为 IllegalArgumentException 或者 IllegalStateException, 但使用一个更详细, 更合适的异常有助于提高代码的可读性. 一般地, 如果两种异常都可以抛出的场景下, 如果所有参数都不能使方法正确的执行, 则抛出 IllegalStateException, 否则抛出 IllegalArgumentException. Item 73抛出匹配抽象程度的异常. 高层次的方法不应该抛出低层次的异常, 这种情况下, 应该catch低层次的异常, 并重新包装为高层次的异常. 如果高层次异常需要携带低层次异常的信息, 可以使用Exception(Throwable cause)方法将低层次异常作为高层次异常的参数. Item 74对所有方法抛出的异常编写文档. Item 75在异常中加入错误的详细信息 Item 76Item 77不要忽略异常. Item 78同步访问共享的可变数据. Java规范保证了除了long和double变量以外的任何变量的读写操作都是原子的, 但由于Java虚拟机的内存模型, 这不代表任何对变量的读写都是线 1234567891011121314private static boolean stopRequest;public static void main(String[] args) throws InterruptedException &#123; Thread backgroundThread = new Thread(()-&gt; &#123; int i=0; while (!stopRequest) &#123; i++; &#125; &#125;); backgroundThread.start(); TimeUnit.SECONDS.sleep(1); stopRequest = true;&#125; 以上的代码并不会终止, 因为一般情况下, 在backgroundThread线程看来, stopRequest在循环过程中是不变的, 因此循环会被优化为 12345if(!stopRequest) &#123; while(true) &#123; i++ &#125;&#125; 解决这一问题的方法是将stopRequest声明为volatile变量, 从而使其他线程的修改对当前线程可见. 解决线程问题的最好方法是不共享可变数据, 如果所有的可变数据都限制在一个线程之中, 线程之间仅共享不可变数据, 那么线程之间就不会出现任何读写问题. Item 79避免过度使用synchronization. 永远不要在同步块中将控制权交给客户端代码, 由于无法得知客户端代码会做什么, 因此在同步块中调用客户端代码可能导致异常和死锁. 由于同步块具有可重入性, 因此如果在一个同步块中调用客户端代码, 而客户端代码又调用其他同步方法, 则会因为可重入性而直接获得锁, 这种同时修改可能导致数据不一致或者抛出异常. 考虑内部加锁和外部加锁, 如果一个类不考虑多线程使用, 那么可以由客户端代码在外部加锁来保证线程安全. 如果一个类在内部加锁, 虽然可能可以更高效的实现加锁, 但由于外部环境可能根本不需要加锁而导致性能反而降低. Item 80使用Executors, Tasks和Streams代替线程. Executor类提供了很多不同的实现, 从而能够满足各种不同的场景. 相比于直接使用线程, 使用这些工具类能够使代码更加灵活. 这些工具类同时将线程控制和执行代码分析, 因此也能降低代码的复杂度, 提高代码的可维护性. Item 81使用concurrency工具类代替wait和notify. Item 82在文档中标记是否线程安全. 线程安全可以分为不同的等级, 包括不可变, 无条件线程安全, 条件线程安全, 无线程安全. 如果一个对象是不可变的, 那么他必然是线程安全的, 例如String和Long. Java并行集合类中的对象通常是无条件线程安全的, 即任意多线程条件下使用都可以保证线程安全, 例如ConcurrentHashMap和AtomicLong. 使用Collections.synchronized包裹的类都是条件线程安全的, 其中的大部分方法是线程安全的, 但部分方法需要额外加锁才能保证安全. 其他的大部分Java类都没有考虑线程问题, 因此是无线程安全的. Item 83谨慎使用惰性初始化. 惰性初始化通常视为一种优化方式, 与其他任何优化方式一样, 只有在你需要的时候才采取这种优化方式. 惰性加载是否能够提高性能要实际测量才能确定. 多线程的引入导致惰性初始化更容易出现问题. 如果需要惰性初始化静态变量, 那么可以采用下面的holder方案. 12345private static class FieldHolder &#123; static final FieldType field = computerFieldValue();&#125;private static FieldType getField() &#123; return FieldHolder.field&#125;; 这种方案利用JVM的类加载机制, 保证了第一次调用getField方法时, JVM才加载这个类. JVM加载此类时会自动保证初始化的线程安全, 并且一旦完成初始化, 后续访问就与直接访问一个字段等价. 如果需要初始化一个实例变量, 那么可以考虑使用double-check方案, 12345678910111213private volatile FieldType field;private FieldType getField() &#123; FieldType result = field; if(result == null) &#123; synchronized(this) &#123; if(field == null) &#123; field = result = computeFieldValue(); &#125; &#125; &#125; return result;&#125; 这段代码有两个要点: 使用volatile修饰变量, 保证线程之间的可见性 使用result保存field的值, 保证正常流程时field只读取一次 Item 84不要依赖线程调度器. 依赖线程调度器来保证正确性或者性能的程序是不可移植的. 为了减少线程的调度代价, 每个检查的工作应该足够短但又不至于太短. 不要使用Thread.yield来保证程序的性能或正确性. 这个方法不具备可测试性, 在一个JVM上能提高性能不代表在另一个JVM上也能取得同样的效果. 不要调整线程优先级, 通过调整线程优先级来保证程序的性能也是不可靠的, 应该从程序的结构上避免这种问题. Item 85Item 86Item 87Item 88Item 89Item 90","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://lizec.top/tags/Java/"}]},{"title":"学术写作工具介绍","slug":"学术写作工具介绍","date":"2019-07-17T07:46:16.000Z","updated":"2020-06-26T14:50:11.377Z","comments":true,"path":"2019/07/17/学术写作工具介绍/","link":"","permalink":"https://lizec.top/2019/07/17/%E5%AD%A6%E6%9C%AF%E5%86%99%E4%BD%9C%E5%B7%A5%E5%85%B7%E4%BB%8B%E7%BB%8D/","excerpt":"","text":"本文介绍学术写作过程中使用的工具, 包括LaTeX写作环境TexStudio, 文献管理工具JabRef等. TexStudio使用TexStudio之前需要安装LaTeX环境, 可以在这里下载. 切换语言TexStudio默认的拼写检测并不是英语, 因此直接打开一片文章, 会满屏幕红色波浪线. 将拼写检查切换为英文即可解决这一问题. 依次选择Options -&gt; Configure TeXStudio -&gt; Language Checking -&gt; Default Language, 将Default Language修改为en_US 调整字体大小TexStudio的默认的文本字体很小, 只有10号, 依次选择Options -&gt; Configure TeXStudio -&gt; Editor -&gt; Font Size, 即可修改字体大小. 由于不是写代码, 每一行的文字比较多, 所以字体大小选择14左右即可. 字体太大会导致每行的词数太少, 不利于阅读. 此外, 依次选择Options -&gt; Configure TeXStudio -&gt; General -&gt; Font Size可以修改TexStudio界面字体的大小,可以将字体稍微设置的大一点, 保存在12左右即可. 添加参考文献在TexStudio中添加参考文献需要两个文件, 分别是 文件后缀 含义 .bst 参考文献样式模板 .bib 包含参考文献信息的源文件 通常.bst文件由会议举办方提供, 而.bib文件由下面将要介绍的软件JabRef创建. 在文档的最后, 添加如下两条LaTeX指令, 其中的参数分别是.bst文件和.bib文件的名称. 12\\bibliographystyle&#123;splncs04&#125;\\bibliography&#123;bibliography/recommendation&#125; 添加这些指令后, 在TexStudio中依次选择Tools -&gt; Bibliography, 使用Bibliography的编译器预先编译一次文档. 接下来再使用LaTex编译器进行编译, 就可以看到包含参考文献的文档. 在上述编译过程中, 只会导入文章中实际引用的文章, 而.bib文件中没有被引用的文章并不会出现在最后的引用列表之中. 支持中文默认情况下, TexStudio并不支持在文档中使用中文. 如果需要编辑中文, 首先需要引入相关的包(例如ctex), 其次需要对编译器进行配置, 默认的编译器不支持中文. 最后对软件的拼写检查进行配置, 相关文章如下: 依赖配置 编译配置 禁用拼写检查 设置背景颜色TexStudio默认的背景颜色是白色, 可以修改为豆绿色. 在TexStudio中依次选择OPtions -&gt; Syntax Highlighting进入颜色设置页面, 然后设置以下的属性 Basic Highlighting分组下的normal(常规文字)和background(背景)的Background Color设置为#c7edcd Line Highlighting分组下的current(当前行)的Background Color设置为#c7edcd. 由于豆绿色属于比较浅的颜色, 因此修改背景颜色不太会和其他默认的配色产生冲突, 属于轻量级的修改. 如果想要被背景换成深色系列, 那么就需要参考网上已有的配色方案了. JabRefJabRef是一个文献管理工具, 安装过程比较简单, 就直接跳过了. 导入文献JabRef可以直接导入学术网站的BibTex信息. 过程如下 使用学术网站搜索论文 点击引用, 在弹出的页面上选择BibTex格式 复制BibTex格式的论文信息 在JabRef主界面直接按下粘贴键 经过上述步骤以后, 就可以将一个从学术网站搜索得到的论文添加到JabRef之中. JabRef也可以使用搜索添加. 过程如下 点击Toggle web search interface按钮, 打开搜索页面 选择搜索引擎 输入关键字 在搜索结果页面选择合适的论文 通过这样的方法, 也可以直接将论文的信息添加到JabRef之中. JabRef内置的搜索引擎包括ArXiv, IEEEXplore, DBLP等, 如果论文来自这些领域, 选择相应的搜索引擎还可以导入论文链接地址, 摘要, 关键字等信息. 自动关联文件JabRef提供了下载功能, 给定一个论文的URL, 可以自动下载论文, 保存到本地, 并将此文件与数据库中的条目进行管理. 因此如果没有其他需求, 首选此方案关联论文. JabRef保存的是相对路径, 所以应该将Bib文件和论文放在同一目录下. 如果以后更换了目录的位置, 由于相对位置不变, 也能保证Bib文件中的数据正常. 添加代理服务器JabRef提供了代理服务器功能, 如果有需要, 直接在Options-&gt;Preference-&gt;Network选项卡中进行设置. 创建矢量图片使用LaTeX写论文的时候, 通常使用eps格式的矢量图片. 由于LaTeX并不关心图片从何而来, 所以无论使用那种方法, 只要最后图片变成了eps格式, 就可以嵌入到文章之中. 下面介绍几种已知的eps文件创建方法. 使用Visio创建图片创建矢量图形需要使用Visio和Adobe Acrobat Pro, 具体过程可以参考以下内容 详解visio制作的图转化为.eps格式的图 使用Matplotlib创建图片Matplotlib是Python的一个绘图库, 提供了一个类似MATLAB的绘图接口. 所有使用Matplotlib创建的图片, 在保存的时候, 都可以直接指定为eps格式, 从而一步创建矢量图片. 关于Matplotlib的有关知识, 可以参考Python笔记之科学计算的Matplotlib章节. MATLAB显然也可以直接创建eps格式的图片, 而且操作更简单, 保存图片时, 选择eps格式即可. 具体可以参考Matlab导出eps或jpg图片的四种方法","categories":[{"name":"学术写作","slug":"学术写作","permalink":"https://lizec.top/categories/%E5%AD%A6%E6%9C%AF%E5%86%99%E4%BD%9C/"}],"tags":[{"name":"LaTeX","slug":"LaTeX","permalink":"https://lizec.top/tags/LaTeX/"}]},{"title":"Spring笔记之SpringCloud","slug":"Spring笔记之SpringCloud","date":"2019-07-14T07:24:27.000Z","updated":"2021-01-09T11:26:13.000Z","comments":true,"path":"2019/07/14/Spring笔记之SpringCloud/","link":"","permalink":"https://lizec.top/2019/07/14/Spring%E7%AC%94%E8%AE%B0%E4%B9%8BSpringCloud/","excerpt":"","text":"项目依赖一致性由于Spring Cloud涉及的组件太多, 各个组件之间的依赖关系比较复杂, 因此为了保证项目的一致性, 需要通过引入合适的parent文件来规定各个组件的版本. 手写pom文件比较复杂, 任何时候都不建议手写这些配置文件. 可以使用SpringBoot官网上的Spring Initializr来获得初始项目的结构和pom文件. 如果使用IDEA, 也可以在创建的时候使用Spring Initializr工具创建项目. 官方帮助我们解决版本问题, 不用白不用啊! 如果是父子项目结构, 由于子项目继承父项目, 因此上述配置都应该写在父项目中(由于只是声明, 因此不会造成额外的空间占用) SpringCloud–第一篇 搭建maven子母项目 Actuator 配置项 值 依赖 spring-boot-starter-actuator 配置属性 management.endpoint.health.show-details=always 在新版本的Actuator中, 默认显示的信息很少, 需要在配置上表的属性, 才可以显示完整的信息. 配置完成后, 就可以直接访问项目的/actuator/health路径, 获取项目的健康状态. 此外还可以在配置文件中, 以info.*的方式引入任意属性, 例如 1234567info: app: name: @project.artifactId@ encoding: @project.build.sourceEncoding@ java: source: @java.version@ target: @java.version@ 之后就可以访问项目的/actuator/info路径获得这些信息. SpringBoot2.x中Actuator的health响应信息不完整的解决方法 EurekaEureka是服务发现组件, 各个微服务启动的时候, 将自己的信息注册到Eureka Server上, 从而由Eureka提供的管理. 配置项 值 服务端依赖 spring-cloud-starter-netflix-eureka-server 客户端依赖 spring-cloud-starter-netflix-eureka-client Eureka Server对于服务器端, 在启动Class上加上注解@EnableEurekaServer并且在配置文件中添加如下的配置 12345678server: port: 8761eureka: client: register-with-eureka: false fetch-registry: false service-url: defaultZone: http://localhost:8761/eureka register-with-eureka表示是否把自己注册到Eureka Server, fetch-registry表示是否从其他Eureka Server获得信息, 当Eureka以单节点方式启动时, 这两个配置都需要置为flasedefaultZone表示与Eureka Server交互的地址, 可以加入以逗号分隔的多个地址 Eureka Client对于客户端, 在启动Class上加上注解@EnableDiscoveryClient并且在配置文件中添加如下的配置 123456789spring: application: name: microservice-consumer-movieeureka: client: service-url: defaultZone: http://localhost:8761/eureka instance: prefer-ip-address: true spring.application.name用于给这个微服务指定一个名称, 此名称将会显示在Eureka的管理页面上, 并且作为其他微服务调用此微服务的依据.service-url指定Eureka Server的位置. prefer-ip-address表示优先将IP地址注册到Eureka Server, 否则注册微服务所在操作系统的hostname. 高可用Eureka Server通过加入多个Eureka Server节点可以实现Eureka Server的高可用. 12345678910111213141516171819202122232425spring: application: name: microservice-discovery-eureka-ha---spring: profiles: peer1server: port: 8761eureka: instance: hostname: peer1 client: serviceUrl: defaultZone: http://peer2:8762/eureka---spring: profiles: peer2server: port: 8762eureka: instance: hostname: peer2 client: serviceUrl: defaultZone: http://peer1:8761/eureka 以上配置文件由---分割成三段, 其中第一段没有指定profiles名称, 因此对所有的profile生效. 第二段和第三段的Profile分别命名为peer1和peer2. 将项目打包以后, 可以按照如下的方式启动两个不同配置的节点 12java -jar microservice-discovery-eureka-ha-0.0.1-SNAPSHOt.jar --spring.profiles.active=peer1java -jar microservice-discovery-eureka-ha-0.0.1-SNAPSHOt.jar --spring.profiles.active=peer2 多节点与单节点相比, 主要是设置hostname,并且在defaultZone指定每一个其他的Eureka节点. 对于客户端, 也只需要在defaultZone指定所有的Eureka Server节点即可. 由于Eureka Server节点之间会同步信息, 因此仅指定一个Eureka节点也可以满足需求, 但指定多个节点时, 稳定性更好. 用户认证 配置项 值 依赖 spring-boot-starter-security 在配置文件中加入以下内容 12345spring: security: user: name: user password: 123 创建一个WebSecurityConfig, 内容如下: 1234567891011@EnableWebSecuritypublic class WebSecurityConfig extends WebSecurityConfigurerAdapter &#123; @Override protected void configure(HttpSecurity http) throws Exception &#123; http.csrf().disable().authorizeRequests() .anyRequest() .authenticated() .and() .httpBasic(); &#125;&#125; 原来的配置security.user.name等属性已经废弃, 现在应该使用spring.security.user.name. 此外, 还需要通过Java配置禁用csrf. eureka配置了spring security后，客户端启动报错，请求不到服务器 以上述配置为例, 在客户端, 将eureka.client.serviceUrl.defaultZone设置为http://user:123@localhost:8761/eureka即可访问加密的Eureka服务器. RibbonRibbon是一个负载均衡器, 此项目借助于Eureka Server的信息, 可以自动将请求均衡的发送到不同的目标服务器. 配置项 值 依赖 spring-cloud-starter-ribbon 负载均衡方法注解 @LoadBalanced 注意: Eureka的依赖包含此依赖. 在需要使用负载均衡的RestTemplate上直接加入注解即可实现负载均衡. 12345@Bean@LoadBalancedpublic RestTemplate restTemplate()&#123; return new RestTemplate();&#125; 通过此RestTemplate发送的请求, 将会自动具备负载均衡能力. 此时在调用端,使用微服务的名称指定需要调用的微服务. 1234@GetMapping(&quot;/user/&#123;id&#125;&quot;)public User findById(@PathVariable Long id)&#123; return this.restTemplate.getForObject(&quot;http://microservice-provider-user/&quot;+id,User.class);&#125; Ribbon会在Eureka Service上查询指定名称的微服务, 并由此实现负载均衡. Ribbon可以使用@Configuration进行Java配置, 使用&lt;clientName&gt;.ribbon在配置文件中进行配置. 在没有Eureka Service时, 可以使用&lt;clientName&gt;.ribbon.listOfServers来指定各个服务的URL, ribbon在这些URL的基础上实现负载均衡. FeignFeign是一个用来提供HTTP API调用的组件. 配置项 值 依赖 spring-cloud-starter-openfeign 启动类注解 @EnableFeignClients 注意: feign已经被标记为废弃, 需要使用openfeign代替. 123456@FeignClient(name=&quot;microservice-provider-user&quot;)public interface UserFeignClient &#123; @RequestMapping(value = &quot;/&#123;id&#125;&quot;,method = RequestMethod.GET) User findById(@PathVariable Long id);&#125; @FeignClient注解指定Feign需要调用的微服务的名称. 这里需要注意, 方法上的@RequestMapping指示的是Feign需要调用的API的URL格式. 接口类提供的方法只由其他Java类调用, 而不从网络上调用. Feign根据结构自动实现相应的网络请求功能. 在相应的Controller类上, 按照如下的方式使用 12345678910@RestControllerpublic class MovieController &#123; @Autowired private UserFeignClient userFeignClient; @GetMapping(&quot;/user/&#123;id&#125;&quot;) public User findById(@PathVariable Long id)&#123; return this.userFeignClient.findById(id); &#125;&#125; 关于Feign配置和日志等内容, 参考以下文章 跟我学Spring Cloud（Finchley版）-10-Feign深入 注意: 在@EnableFeignClients的扫描范围内的, 被@FeignClient注解的类才会进入容器, 可以通过@EnableFeignClients指定要扫描的包名 回退方法@FeignClient注解可以指定一个fallback属性, 指定一个实现了当前接口的实现类, 当相应的方法调用失败时, 改为调用实现类中的对应方法. 实现这一功能需要引入Hystrix的依赖. 此外, @FeignClient注解也可以指定fallbackFactory属性, 指定一个实现了FallbackFactory&lt;T&gt;接口的实现类. FallbackFactory&lt;T&gt;接口提供了返回T类型的方法, 从而可以直接使用匿名类的构造方式创建回退的实现类. 例如 123456789101112131415public class BookAuthUserServiceFallbackFactory implements FallbackFactory&lt;BookAuthUserService&gt; &#123; private static final Logger LOGGER = LoggerFactory.getLogger(BookAuthUserServiceFallbackFactory.class); @Override public BookAuthUserService create(Throwable cause) &#123; LOGGER.info(&quot;fallback reason was: &quot; + cause.getMessage()); return new BookAuthUserService() &#123; @Override public ResponseEntity&lt;ResponseDto&lt;Boolean&gt;&gt; checkIsHaveAuthWithServer(Long bookId, Long channelId, Long adviserId, Long wecharUserId, Long serverId) &#123; return ResponseHandleUtil.toResponse(false); &#125; &#125;; &#125;&#125; 这样就可以避免同一接口有多个实现而导致的需要手动调整注入规则的问题. 多参数请求方案一: 使用@RequestMapping和@RequestParam的映射功能, 有几个参数就填几个参数 12345@FeignClient(name=&quot;microservice-provider-user&quot;)public interface UserFeignClient &#123; @RequestMapping(value = &quot;/getone&quot;,method = RequestMethod.GET) User findById(@RequestParam(&quot;id&quot;) Long id,@RequestParam(&quot;username&quot;) Long username);&#125; 方案二: 使用Map传入多个参数 12345@FeignClient(name=&quot;microservice-provider-user&quot;)public interface UserFeignClient &#123; @RequestMapping(value = &quot;/getone&quot;,method = RequestMethod.GET) User findById(@RequestParam Map&lt;String,Object&gt; map);&#125; 注意: Feign无视@RequestMapping注解的method参数, @RequestParam不可省略, 否则始终按照POST方法发送请求 post请求12345678910111213// 服务提供者的Controllerpublic class UserController &#123; @PostMapping(&quot;/p&quot;) public User post(@RequestBody User user)&#123; &#125;&#125;// Feign的调用方法@FeignClient(name=&quot;microservice-provider-user&quot;)public interface UserFeignClient &#123; @RequestMapping(value = &quot;/p&quot;,method = RequestMethod.GET) User findById(@RequestBody User user);&#125; 在Feign客户端, 使用@RequestBody将User对象添加到待发送的Request之中, 而在服务提供端, 同样使用@RequestBody从收到的Request中提取参数绑定到User对象. HystrixHystrix是一个断路器组件, 用于隔离远程访问体现, 防止级联失效, 从而提高系统的可用性和容错性. 配置项 值 依赖 spring-cloud-starter-netflix-hystrix, hystrix-javanica 启动类注解 @EnableCircuitBreaker 123456789101112@HystrixCommand(fallbackMethod = &quot;findByIdFallback&quot;)@GetMapping(&quot;/user/&#123;id&#125;&quot;)public User findById(@PathVariable Long id)&#123; return this.restTemplate.getForObject(&quot;http://microservice-provider-user/&quot;+id,User.class);&#125;public User findByIdFallback(Long id)&#123; User user = new User(); user.setId(-1L); user.setName(&quot;默认用户&quot;); return user;&#125; 其中@HystrixCommand注解来自依赖hystrix-javanica, 此项目是Hystrix的子项目, 主要用于简化Hystrix的使用. 在/actuator/health可以查看Hystrix的状态. 注意, 一次调用失败并不会导致Hystrix的状态变为CIRCUIT_OPEN, 只有达到了阈值(默认5秒内失败了20次)后才会变为CIRCUIT_OPEN状态. 进入开启状态一段时间以后, Hystrix进入半开状态, 此时只要发生了一次调用成功, 则会进入关闭状态, 否则再次进入开启状态. @HystrixCommand提供了丰富了配置, 可以使用@HystrixPreoperty 进行配置, 具体的选项可以参考项目官网的README 监控 配置项 值 端点依赖 spring-boot-starter-actuator 监控依赖 hystrix-metrics-event-stream 开启端点 management.endpoints.web.exposure.include=hystrix.stream 注意: spring-cloud-starter-netflix-hystrix不包含监控依赖, 需要额外添加才能生效. 访问/actuator/hystrix.stream即可查看监控信息. Hystrix会自动监控使用@HystrixCommand等注解标记的方法. Feign监控 配置项 值 启动类注解 @EnableCircuitBreaker 启动Hystrix feign.hystrix.enabled=true 在Feign环境下使用Hystrix, 除了添加依赖和开启端点以外, 还需要配置上表的属性来启用Hystrix. 启用后Feign会自动包裹所有的方法, 因此不需要再添加@HystrixCommand注解 Dashboard对于每一个启用了Hystrix的项目, 都可以访问项目的/actuator/hystrix.stream端点查看访问信息, 但这一信息是文本的, 不便于阅读. Hystrix Dashboard 是一个可视化Hystrix结果的组件. 配置项 值 依赖 spring-cloud-starter-netflix-hystrix-dashboard 启动类注解 @EnableHystrixDashboard 此项目通过访问Hystrix项目的端点获得信息, 因此不需要注册到Eureka, 因此在配置文件中指定启动端口即可. 项目启动后, 访问/hystrix, 会出现如下的图形界面 在启动输入Hystrix项目的端点地址(例如http://localhost:8010/actuator/hystrix.stream)和任意的Title即可进入监控界面. TrubineTurbine是一个可视化Hystrix结果的组件. 配置项 值 依赖 spring-cloud-starter-netflix-turbine 启动类注解 @EnableTurbine 除了常规的端口,应用名称, Eureka配置以外, 配置文件添加如下内容 123turbine: app-config: microservice-consumer-movie-feign,microservice-consumer-movie cluster-name-expression: &quot;&#x27;default&#x27;&quot; # 注意双层引号 其中app-config指定了需要监控的微服务的名称. 配置完成以后, 启动项目并访问/turbine.stream就可以看到聚合了多个项目的监控信息. 启动Hystrix Dashboard并且输入Turbine的端点地址, 即可访问包含全部项目的监控页面 ZuulZuul是微服务网关, 核心是过滤器, 完成身份认证, 审查, 动态路由, 负载分配等功能. 配置项 值 依赖 spring-cloud-starter-netflix-zuul 启动类注解 @EnableZuulProxy 完成上面的两步以后, 在配置文件中加入Eureka的配置, 将Zuul注册到Eureka即可完成创建工作. 123456789server: port: 8040spring: application: name: microservice-gateway-zuuleureka: client: service-url: defaultZone: http://localhost:8761/eureka Zuul会自动代理所有注册在Eureka的微服务, 并且将发送到 http://ZUUL_HOST:ZUUL_PORT/微服务名/* 的请求转发到相应的微服务, 并且自动使用Ribbon实现负载均衡. 如果希望使用Hystrix Dashboard监控Zuul, 则按照Hystrix的监控章节, 添加两个依赖并在配置文件中启用端点即可. 配置路由使用zuul.routes.&lt;serverID&gt;=&lt;path&gt;的方式可以将指定的路径映射到指定的微服务, 例如 123zuul: routes: microservice-provider-user: /user/** 此时访问/user/1就相当于访问microservice-provider-user/1. 使用zuul.ignored-services可以忽略指定名称的微服务. 按照如下的方案可以实现只代理指定的服务 1234zuul: ignored-services: &#x27;*&#x27; # 忽略所有的服务, 但是明确指定的服务除外 routes: microservice-provider-user: /user/** zuul.prefix可以添加前缀, zuul.ignoredPatterns可以忽略指定的路径. 最后, 也可以通过Java配置实现更复杂的正则匹配等功能. 文件上传对于1M以内的小文件, 可以直接上传. 对于10M以上的大文件, 需要在上传路径之前加上/zuul前缀, 例如/zuul/microservice-file-upload/upload 对于超大文件(500M), 需要提升超时设置 1234hystrix.command.default.execution.isolation.thread.timeoutInMilliseconds: 60000ribbon: ConnectTimeout: 3000 ReadTimeout: 60000 过滤器Zuul可以在一个请求的请求之前, 请求中, 请求之后, 以及发生错误时执行用户指定的代码. 创建一个过滤器只需要继承ZuulFilter,并在启动类中创建一个相应的Bean即可, 代码如下: 123456789101112131415161718192021222324252627282930313233343536373839public class PreRequestLogFilter extends ZuulFilter &#123; private static final Logger LOGGER = LoggerFactory.getLogger(PreRequestLogFilter.class); @Override public String filterType() &#123; // 过滤器类型 return &quot;pre&quot;; &#125; @Override public int filterOrder() &#123; //过滤器优先级 return 1; &#125; @Override public boolean shouldFilter() &#123; // 是否启动过滤器 return true; &#125; @Override public Object run() &#123; // 过滤器执行逻辑 RequestContext ctx = RequestContext.getCurrentContext(); HttpServletRequest request = ctx.getRequest(); LOGGER.info(String.format(&quot;send %s request to %s&quot;,request.getMethod(),request.getRequestURL().toString())); return null; &#125;&#125;@SpringBootApplication@EnableZuulProxypublic class MicroserviceGatewayZuulApplication &#123; @Bean public PreRequestLogFilter preRequestLogFilter() &#123; return new PreRequestLogFilter(); &#125; public static void main(String[] args) &#123; SpringApplication.run(MicroserviceGatewayZuulApplication.class, args); &#125;&#125; 容错与回退使用FallbackProvider替代ZuulFallbackProvider， 12345678910111213141516171819202122232425262728293031323334353637383940414243@Componentpublic class UserFallbackProvider implements FallbackProvider &#123; @Override public String getRoute() &#123; return &quot;microservice-provider-user&quot;; &#125; @Override public ClientHttpResponse fallbackResponse(String route, Throwable cause) &#123; return new ClientHttpResponse() &#123; @Override public @NonNull HttpStatus getStatusCode() &#123; return HttpStatus.OK; &#125; @Override public @NonNull int getRawStatusCode() &#123; return getStatusCode().value(); &#125; @Override public @NonNull String getStatusText() &#123; return getStatusCode().getReasonPhrase(); &#125; @Override public void close() &#123; &#125; @Override public @NonNull InputStream getBody() &#123; return new ByteArrayInputStream(&quot;用户微服务不可用, 请稍微再试&quot;.getBytes()); &#125; @Override public @NonNull HttpHeaders getHeaders() &#123; HttpHeaders headers = new HttpHeaders(); MediaType mt = new MediaType(&quot;application&quot;, &quot;json&quot;, Charset.forName(&quot;UTF-8&quot;)); headers.setContentType(mt); return headers; &#125; &#125;; &#125;&#125; 实现此功能需要依赖Hystrix, 但此依赖已经内置到Zuul之中, 因此不需要重复添加. ConfigSpring Cloud Config 是配置管理模块, 用于统一的管理各个微服务的配置, 并提供动态修改配置的功能. Config组件分为Server和Client, 其中Server使用Git保存配置信息, Client通过访问Server获得配置信息. Config Server 配置项 值 依赖 spring-cloud-config-server 启动类注解 @EnableConfigServer 123456789101112server: port: 8080spring: application: name: microservice-config-server cloud: config: server: git: uri: # Git仓库 username: # Git用户名 password: # Git密码 配置文件如上所示, 只读的访问Git仓库时, 可以省略用户名和密码. Config Server提供了如下的端点 /&#123;application&#125;/&#123;profile&#125;[/&#123;label&#125;] &#123;application&#125;-&#123;profile&#125;.yml /&#123;label&#125;/&#123;application&#125;-&#123;profile&#125;.yml &#123;application&#125;-&#123;profile&#125;.properties /&#123;label&#125;/&#123;application&#125;-&#123;profile&#125;.properties label对应的是git的分支名. 无论使用那种后缀, 都可以访问同名的文件, 但文件格式并不会跟随后缀名进行转换. 指定文件后缀时返回文件的文本信息, 不指定后缀时返回信息中还会包含分支名等额外信息的JSON数据. Config Client 配置项 值 依赖 spring-cloud-starter-config 创建以下两个配置文件, 并填写如下的内容 1234# 文件名: application.ymlspring: application: name: microservice-foo 1234567# 文件名: bootstrap.ymlspring: cloud: config: uri: http://localhost:8080/ profile: dev label: master 其中spring.application.name就对应配置文件的&#123;application&#125;部分, spring.cloud.config.profile和spring.cloud.config.label分别对应配置文件的&#123;profile&#125;和&#123;label&#125;部分. 1234567891011@RestControllerpublic class ConfigClientController &#123; @Value(&quot;$&#123;profile&#125;&quot;) private String profile; @GetMapping(&quot;/profile&quot;) public String hello()&#123; return profile; &#125;&#125; 在项目中使用@Value注解提取需要的属性. 仓库配置Git仓库支持使用占位符, 例如仓库的uri可以设置为http://github.com/xxx/&#123;application&#125;, 从而使一个项目对应一个Git仓库. 此外也可以通过配置实现模式匹配或者搜索子目录. clone-on-start属性可以使Server在启动时就clone仓库, 从而尽早的发现配置中存在的问题. DEBUG将以下包的日志设置为DEBUG可以便于快速定位问题 1234logging: level: org.springframework.cloud: DEBUG org.springframework.boot: DEBUG","categories":[{"name":"Spring","slug":"Spring","permalink":"https://lizec.top/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://lizec.top/tags/Spring/"},{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://lizec.top/tags/SpringCloud/"}]},{"title":"JDK类库源码分析之HashMap","slug":"JDK类库源码分析之HashMap","date":"2019-07-11T01:11:57.000Z","updated":"2020-06-26T14:42:01.735Z","comments":true,"path":"2019/07/11/JDK类库源码分析之HashMap/","link":"","permalink":"https://lizec.top/2019/07/11/JDK%E7%B1%BB%E5%BA%93%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8BHashMap/","excerpt":"","text":"以下的几篇参考资料中, 第一篇重点分析了HashMap的插入过程, 解释了其中使用的一些二进制技巧, 并且提供了插入过程的流程图. 第二篇重点介绍了插入过程中, 红黑树的操作, 从红黑树的基本操作开始, 详细介绍了HashMap的红黑树创建和插入过程. 第三篇完整的介绍了HashMap的插入, 删除过程, 对源代码的注解比较详细.第四篇文章在对源代码进行注释的同时, 还提供了操作逻辑的总结, 看文字总结更容易理解. 第五篇介绍了JDK1.7中为什么HashMap会产生死循环. Java8系列之重新认识HashMap HashMap分析之红黑树树化过程 面试必备：HashMap源码解析（JDK8） HashMap源码分析（基于JDK8） 老生常谈，HashMap的死循环 以下几篇参考资料中, 第一篇介绍了红黑树的插入和删除过程, 不过全程使用伪代码描述, 直接看可能看不懂. 教你初步了解红黑树 JDK类库源码分析 HashMap? ConcurrentHashMap? 相信看完这篇没人能难住你！ 多线程环境DEBUG IntelliJ IDEA - Debug 调试多线程程序 IDEA 多线程Debug 可以对所有线程在指定的位置进行断点, 所以即使是多线程环境, 也能够一步步的执行代码","categories":[{"name":"JDK笔记","slug":"JDK笔记","permalink":"https://lizec.top/categories/JDK%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://lizec.top/tags/Java/"}]},{"title":"Maven笔记之使用插件","slug":"Maven笔记之使用插件","date":"2019-07-09T02:36:09.000Z","updated":"2020-06-26T14:51:54.769Z","comments":true,"path":"2019/07/09/Maven笔记之使用插件/","link":"","permalink":"https://lizec.top/2019/07/09/Maven%E7%AC%94%E8%AE%B0%E4%B9%8B%E4%BD%BF%E7%94%A8%E6%8F%92%E4%BB%B6/","excerpt":"","text":"回顾Maven生命周期Maven在编译项目时, 按照一定的生命周期进行, 一个主要的生命周期的各个阶段如下所示 阶段名称 操作 validate 检测项目正确性 compile 将源代码编译为二进制文件 test 执行单元测试 package 将二进制文件打包 integration-test 运行集成测试 verify 检测打包的项目正确性 install 将打包的项目安装到本地仓库 deploy 将打包的项目部署到服务器或仓库 maven有一个约定，如果插件的名字叫maven-xxxx-plugin或xxxx-maven-plugin的话。可以直接用mvn xxxx:goal的方式调用其提供的功能 Maven 插件Maven的核心是一个基于插件的框架(Maven is - at its heart - a plugin execution framework). Maven在声明周期的各个阶段都提供了一些插件, 用于对具体的行为进行精细化的操作. Maven的插件可以分成两类, 即Build plugins和Reporting plugins. 其中Build plugins将会在软件构建的声明周期中执行并且需要在&lt;build /&gt;标签内声明. 插件示例复制依赖这是一个将所有依赖复制到lib文件夹下的插件示例, 这一操作通常用于Web项目, 以便于将项目打包后放入容器 12345678910111213141516&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-dependency-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;copy&lt;/id&gt; &lt;phase&gt;install&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;copy-dependencies&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;outputDirectory&gt;src/main/webapp/WEB-INF/lib&lt;/outputDirectory&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt;&lt;/plugin&gt; 关于Maven支持的插件, 可以阅读官网上的列表 Available Plugins 关于Maven的插件基本知识, 可以阅读官网上的指导Guide to Configuring Plug-ins 关于Dependency阶段的插件示例, 可以阅读官网提供的Examples Spring Boot的Maven插件Spring Boot Maven plugin详解","categories":[{"name":"Maven笔记","slug":"Maven笔记","permalink":"https://lizec.top/categories/Maven%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://lizec.top/tags/Java/"},{"name":"Maven","slug":"Maven","permalink":"https://lizec.top/tags/Maven/"}]},{"title":"Maven笔记之依赖管理","slug":"Maven笔记之依赖管理","date":"2019-07-09T01:50:02.000Z","updated":"2020-06-26T14:51:57.105Z","comments":true,"path":"2019/07/09/Maven笔记之依赖管理/","link":"","permalink":"https://lizec.top/2019/07/09/Maven%E7%AC%94%E8%AE%B0%E4%B9%8B%E4%BE%9D%E8%B5%96%E7%AE%A1%E7%90%86/","excerpt":"","text":"本文介绍Maven的依赖相关的内容, 包括如何获取依赖, 版本一致性控制等内容. 查询可用的依赖可以在MavenRepository搜索可用的依赖库. 此网站提供了每一个可用依赖的基本介绍, 使用量统计, 以及引用依赖的XML代码. 依赖管理继承依赖每一个Maven项目都可以在pom文件中使用&lt;parent&gt;标签指定一个父项目, 从而直接继承父项目中定义的依赖和属性. 12345&lt;parent&gt; &lt;groupId&gt;baeldung&lt;/groupId&gt; &lt;artifactId&gt;Baeldung-BOM&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;&lt;/parent&gt; 依赖管理在父项目中可以创建&lt;dependencyManagement&gt;标签, 并在其中声明依赖. 子项目继承父项目后, 获得&lt;dependencies&gt;标签声明的依赖, 但不会获得&lt;dependencyManagement&gt;标签中声明的依赖. 子项目必须显式的声明才能够获得这些依赖, 但此时不再需要指定&lt;version&gt;和&lt;scope&gt;, 而是直接继承父项目中的属性. 通过这样的方法, 可以将必要的依赖配置集中到一个文件之中, 从而能够统一的管理. Maven BOM本节内容来自Baeldung的文档Spring with Maven BOM. BOM是Bill Of Materials的缩写, 所谓Maven BOM实际上也是一个普通的pom文件, 此文件用于解决依赖的版本一致性问题. 一个包含dependencyManagement标签的pom文件称为BOM文件, 以下是一个示例 123456789101112131415161718192021222324&lt;project ...&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;baeldung&lt;/groupId&gt; &lt;artifactId&gt;Baeldung-BOM&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;name&gt;BaelDung-BOM&lt;/name&gt; &lt;description&gt;parent pom&lt;/description&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;test&lt;/groupId&gt; &lt;artifactId&gt;a&lt;/artifactId&gt; &lt;version&gt;1.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;test&lt;/groupId&gt; &lt;artifactId&gt;b&lt;/artifactId&gt; &lt;version&gt;1.0&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt;&lt;/project&gt; 有两种使用BOM文件的方法, 第一种是继承父项目 12345678910111213&lt;project ...&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;baeldung&lt;/groupId&gt; &lt;artifactId&gt;Test&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;name&gt;Test&lt;/name&gt; &lt;parent&gt; &lt;groupId&gt;baeldung&lt;/groupId&gt; &lt;artifactId&gt;Baeldung-BOM&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/parent&gt;&lt;/project&gt; 由于pom文件是单继承的, 因此无法再其中导入多个BOM, 对于这种情况, 可以考虑使用import方式. 1234567891011121314151617181920&lt;project ...&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;baeldung&lt;/groupId&gt; &lt;artifactId&gt;Test&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;name&gt;Test&lt;/name&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;baeldung&lt;/groupId&gt; &lt;artifactId&gt;Baeldung-BOM&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt;&lt;/project&gt; 这里的pom类型和import范围表示将指定的BOM导入此项目. 由于import可以出现任意次, 因此可以导入多个BOM. 版本优先级关于一个依赖的版本的选择的优先级由高到低如下确定 直接在当前项目中声明的版本 父项目中声明的版本 导入的BOM文件中声明的版本 版本协调机制 版本协调机制当有两个依赖B和C同时依赖D, 但依赖的D的版本不同的时候, Maven会优先选择离依赖树顶部最近的版本. 例如有如下的两个依赖 12A - B - C - D (1.2)A - E - D (1.0) 上面的依赖关系中, A依赖B和E, B和E最终都依赖D, 由于D(1.0)在依赖树中离A更近, 因此Maven最终会选择D(1.0) Spring依赖管理Spring Framework BOM在使用Spring的过程中, 我们多少都有过版本冲突的问题, 如果我们没有明确指定冲突的版本, 很容易产生一些意料之外的错误. 为了克服这种问题, 我们可以导入spring-framework-bom 1234567891011&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-framework-bom&lt;/artifactId&gt; &lt;version&gt;4.3.8.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 导入此文件后, 我们使用Spring依赖时不再需要指定版本, 由BOM文件保证所有的Spring依赖使用同样的版本. Spring Boot Starter Parent如果创建Spring Boot应用, 可以将spring-boot-starter-parent作为父项目, 从而基础一些配置和依赖, 实现编译控制, 打包支持, 插件配置等功能. 12345&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.6.RELEASE&lt;/version&gt;&lt;/parent&gt; 使用这种方案继承spring-boot-starter-parent后, 也不再需要指定spring boot相关项目的依赖版本. 导入dependency如果需要使用Spring Boot 和Spring Cloud等组件, 由于POM的单继承, 不能同时继承, 此时可以使用导入的方式导入相应的依赖. 123456789101112&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;!-- Import dependency management from Spring Boot --&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;2.2.0.BUILD-SNAPSHOT&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 导入依赖以后, 同样不需要指定版本, 但关于 理解spring-boot-starter-parent","categories":[{"name":"Maven笔记","slug":"Maven笔记","permalink":"https://lizec.top/categories/Maven%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://lizec.top/tags/Java/"},{"name":"Maven","slug":"Maven","permalink":"https://lizec.top/tags/Maven/"}]},{"title":"Maven笔记之基本概念","slug":"Maven笔记之基本概念","date":"2019-07-09T01:49:51.000Z","updated":"2020-06-26T14:51:49.169Z","comments":true,"path":"2019/07/09/Maven笔记之基本概念/","link":"","permalink":"https://lizec.top/2019/07/09/Maven%E7%AC%94%E8%AE%B0%E4%B9%8B%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/","excerpt":"","text":"构建一个Java项目, 通常需要下载依赖, 复制jar到类路径, 编译项目, 运行项目测试用例, 打包项目, 将项目部署到服务器等操作. Maven是一个自动完成上述工作的工具, 从而减少项目构建过程的复杂度. 本文介绍如何通过Maven管理Java项目. Project Object ModelMaven管理一个项目的核心就是Project Object Model(POM), 这是一个名为pom.xml的文件. POM描述了项目的基本信息, 管理项目的依赖, 以及控制项目构建过程. 一个典型的pom.xml文件如下所示 123456789101112131415161718192021222324&lt;project&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;top.lizec&lt;/groupId&gt; &lt;artifactId&gt;usemaven&lt;/artifactId&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;name&gt;UseMaven&lt;/name&gt; &lt;url&gt;http://maven.apache.org&lt;/url&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; //... &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 上述的xml可以分成如下的几个部分 项目标识信息项目标识信息包含以下的几项内容, 这也被称为坐标信息(coordinates), 这些信息唯一的确定一个项目 名称 含义 groupId 组织名称,通常是一个反写的域名 artifactId 这个项目(模块)的名称 version 这个项目的版本号 packaging 项目的打包类型,默认为jar 注意: packaging还可以指定为war格式(Web Application Resource)或者pom格式(表示这是一个父项目). 依赖信息依赖信息放置在&lt;dependencies&gt;&lt;/dependencies&gt;标签对中, 当项目需要依赖一个外部的库时, 需要提供这个库的groupId, artifactId和version 123456&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;5.1.2.RELEASE&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt;&lt;/dependency&gt; 其中groupId, artifactId, version是依赖的项目的坐标信息, 对于scope有如下的选项 scope选项 含义 compile 默认值, 表示编译和打包阶段都需要此依赖 test 仅单元测试阶段需要此依赖 provided 编译阶段需要此依赖, 但打包时不包含此依赖(运行环境提供了此依赖) runtime 编译和打包时不需要, 运行时需要此依赖 提供这些必要信息以后, Maven会自动去中央仓库下载需要的依赖包到本地的仓库. 可以在MavenRepository搜索可用的依赖库. 仓库Maven有一个默认的中央仓库和一个默认的本地仓库. 本地仓库位于用户目录下的 .m2/repository 目录. 通常情况下不需要对仓库进行配置. 但是如果项目需要引用一些中央仓库没有的库, 可以在POM中指定额外的仓库地址. 123456&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;JBoss repository&lt;/id&gt; &lt;url&gt;http://repository.jboss.org/nexus/content/groups/public/&lt;/url&gt; &lt;/repository&gt;&lt;/repositories&gt; 注意: 一个项目可以指定多个仓库地址. 属性可以在POM中使用自定义属性来提高项目的可维护性. 例如 12345678910111213141516&lt;properties&gt; &lt;spring.version&gt;4.3.5.RELEASE&lt;/spring.version&gt;&lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-core&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 上面定义了一个名为spring.version的变量, 之后两个spring的依赖都使用同样的版本值, 这样当后续需要升级spring版本时, 只需要简单的修改spring.version即可. Maven指令基本指令 指令 含义 mvn compile 编译整个项目 mvn test 运行项目的测试用例 mvn package 编译项目,运行测试用例并打包 mvn install 编译项目,运行测试用例,打包代码,最后将代码复制到本地的依赖代码仓库中 mvn clean 清理项目生成的各种文件 打包文件的名称由artifactId和version决定. install以后的代码可以被其他项目引用 生命周期Maven在编译项目时, 按照一定的生命周期进行, 一个主要的生命周期的各个阶段如下所示 阶段名称 操作 validate 检测项目正确性 compile 将源代码编译为二进制文件 test 执行单元测试 package 将二进制文件打包 integration-test 运行集成测试 verify 检测打包的项目正确性 install 将打包的项目安装到本地仓库 deploy 将打包的项目部署到服务器或仓库 Maven版本号版本号规则一个项目的版本应该具有MAJOR.MINOR.PATCH的格式. 其中 MAJOR: 主版本号, 表示与前一个版本有不兼容的更新 MINOR: 次版本号, 表示与前一个版本有功能增强, 且与之前的版本兼容 PATCH: 修订号, 可以向前或向后移动, 表示修复了一些BUG 除了数字的版本号以外, 版本号还可以加入一个后缀, 后缀的类型如下 后缀类型 含义 SNAPSHOT 表示当前版本还处于开发过程中 M1 里程碑版, 表示即将发布, 也可以是M2, M3等 RC(Release Candidate) 发布候选版本 GA(General availability) 基本可用版本 RELEASE 正式发布版本 此外, 如果一个库使用SNAPSHOT后缀, 则每次构建项目时, Maven都会从中心仓库重新下载依赖库, 从而保证依赖库可以及时的更新. Maven项目结构一个标准的Maven项目具有如下的结构 123456789101112/src/ - main/ - java/ - resources/ - test/ - java/target/ - classes/ - generated-sources/ - annotationpom.xml 其中/src/main/java用来存放项目的代码, /src/main/resources用来存放使用的资源文件(例如MyBatis的配置文件). /test目录存放测试相关的代码, 而且此目录应该和/main目录具有同样的结构, 且每个Java文件都对应一个测试文件. 编译阶段,Maven会自动将/src/main/java下的代码编译成class文件,并且存放在/target/classes目录下 , 并且将/src/main/resources的全部文件直接复制到/target/classes目录下. 这里可以显然地发现, 如果在/src/main/java和/src/main/resources下创建同样结构的目录, 那么相应的文件最终就会合并到同一个目录下. 例如文件/src/main/java/top/lizec/main.java和/src/main/resources/top/lizec/database.properties编译之后就会产生/target/classes/java/top/lizec/main.class和/target/classes/java/top/lizec/database.properties 7天学会Maven（第二天——Maven 标准目录结构） Maven创建聚合项目聚合项目是指在一个父项目下包含多个子模块 先创建一个项目, 删除src, 修改为pom格式, 创建module, 注意父项目指向子项目, 子项目指向父项目 maven在父级项目文件夹下创建子项目 IntelliJ IDEA创建maven多模块项目 参考资料和扩展阅读 Apache Maven Tutorial Building Java Projects with Maven Maven Getting Started Guide 理解Maven中的SNAPSHOT版本和正式版本 Maven pom.xml中的元素modules、parent、properties以及import Spring with Maven BOM","categories":[{"name":"Maven笔记","slug":"Maven笔记","permalink":"https://lizec.top/categories/Maven%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://lizec.top/tags/Java/"},{"name":"Maven","slug":"Maven","permalink":"https://lizec.top/tags/Maven/"}]},{"title":"如何优雅的输入矩阵公式","slug":"如何优雅的输入矩阵公式","date":"2019-07-03T00:34:51.000Z","updated":"2019-07-03T03:22:30.398Z","comments":true,"path":"2019/07/03/如何优雅的输入矩阵公式/","link":"","permalink":"https://lizec.top/2019/07/03/%E5%A6%82%E4%BD%95%E4%BC%98%E9%9B%85%E7%9A%84%E8%BE%93%E5%85%A5%E7%9F%A9%E9%98%B5%E5%85%AC%E5%BC%8F/","excerpt":"","text":"在之前的文章中, 我已经介绍过如何通过插入LaTeX代码来输入矩阵, 但是矩阵的语法比较复杂, 如果需要输入大量矩阵, 则输入过程还是比较繁琐. 针对这一问题, 我使用Python编写了一个小工具来辅助矩阵的输入. 项目介绍对于如下的一个矩阵 $$\\begin{bmatrix}1 &amp; 2 &amp; 3 \\\\4 &amp; 2 &amp; 1 \\\\6 &amp; 7 &amp; 2 \\\\\\end{bmatrix}\\begin{bmatrix}x \\\\y \\\\z \\\\\\end{bmatrix}=\\begin{bmatrix}12 \\\\65 \\\\-1 \\\\\\end{bmatrix}$$ 只需要如下的几步, 即可产生相应的LaTex代码 123456789101112131415请输入矩阵表达式的形式:Ax=b请输入矩阵 A1 2 34 2 16 7 2请输入矩阵 xxyz请输入矩阵 b1265-1 生成的代码如下所示 123456789101112131415161718$$\\begin&#123;bmatrix&#125;1 &amp; 2 &amp; 3 \\\\\\\\4 &amp; 2 &amp; 1 \\\\\\\\6 &amp; 7 &amp; 2 \\\\\\\\\\end&#123;bmatrix&#125;\\begin&#123;bmatrix&#125;x \\\\\\\\y \\\\\\\\z \\\\\\\\\\end&#123;bmatrix&#125;=\\begin&#123;bmatrix&#125;12 \\\\\\\\65 \\\\\\\\-1 \\\\\\\\\\end&#123;bmatrix&#125;$$ 表达式解析第一步输入矩阵表达式, 例如需要产生一个形如AX=b的矩阵表达式, 则在此阶段输入AX=b. 表达式中的任意单个字母都会视为一个矩阵, 而任何的非字母符号都会原样输出. 输入矩阵完成表达式后, 程序会依次询问各个矩阵的取值. 这一阶段根据需要输入即可. 输入一个空行表示结束. 矩阵内容可以是任何的数字, 字符, 或者LaTex代码 宏替换程序提供了一些宏来代替一些复杂的输入, 具体内容如下所示 宏 值 - \\cdots &#124; \\vdots \\ \\ddots 项目源代码文件名称为i2l.py , 也可以在我的Github仓库miniTool查看完整代码. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253def main(): expr = input(&quot;请输入矩阵表达式的形式:&quot;) doPrint(list(map(doExprParse,expr))) input(&quot;输入任意键结束程序&quot;)def doExprParse(element:str): &quot;&quot;&quot;解析表达式, 如果是矩阵符号则要求用户输入矩阵, 否则保持不变&quot;&quot;&quot; if element.isalpha(): print(&quot;请输入矩阵&quot;,element) return getMatrix() else: return elementdef getMatrix(): matrix = [] raw = input() while raw != &quot;&quot;: matrix.append(list(map(doMacro,raw.split()))) raw = input() return matrixdef doMacro(element): &quot;&quot;&quot;解析宏, 如果是宏则进行相应的替换,否则保持不变&quot;&quot;&quot; if element == &quot;|&quot;: return r&quot;\\vdots&quot; elif element == &quot;-&quot;: return r&quot;\\\\cdots&quot; elif element == &quot;\\\\&quot;: return r&quot;\\ddots&quot; else: return elementdef doPrint(expr): print(&quot;$$&quot;) for v in expr: if type(v) == type(&quot;&quot;): print(v) else: printMatrix(v) print(&quot;$$&quot;)def printMatrix(matrix): print(r&quot;\\begin&#123;bmatrix&#125;&quot;) for line in matrix: # 元素之间插入分割符, 末尾添加换行符 print(&quot; &amp; &quot;.join(line), r&quot;\\\\\\\\&quot;) # 插入分隔符的标准做法 print(r&quot;\\end&#123;bmatrix&#125;&quot;)if __name__ == &quot;__main__&quot;: main()","categories":[],"tags":[{"name":"LaTeX","slug":"LaTeX","permalink":"https://lizec.top/tags/LaTeX/"},{"name":"Python","slug":"Python","permalink":"https://lizec.top/tags/Python/"}]},{"title":"Shell编程笔记","slug":"Shell编程笔记","date":"2019-06-09T06:32:19.000Z","updated":"2021-01-28T11:36:03.652Z","comments":true,"path":"2019/06/09/Shell编程笔记/","link":"","permalink":"https://lizec.top/2019/06/09/Shell%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/","excerpt":"","text":"在使用Linux系统的过程中, 经常会用到shell, 本文介绍shell编程. 本文按照创建一个Shell脚本的顺序,依次介绍各个环节涉及的知识. 帮助系统如果当前存在一个Shell环境, 那么获得一个指令的用法的第一方案是使用man指令进行查询, 绝对能比任何其他搜索方法更快的获得搜索结果. 如果可以安装第三方软件, 那么首先安装tldr(Too long, don’t read). 此指令可以给出各种常见的指令组合的文档, 例如 123456789101112131415161718192021root@iZ:~# tldr pspsInformation about running processes. - List all running processes: ps aux - List all running processes including the full command string: ps auxww - Search for a process that matches a string: ps aux | grep &#123;&#123;string&#125;&#125; - List all processes of the current user in extra full format: ps --user $(id -u) -F - List all processes of the current user as a tree: ps --user $(id -u) f - Get the parent pid of a process: ps -o ppid= -p &#123;&#123;pid&#125;&#125; 指定脚本解释器在Shell脚本的第一行需要指定执行此脚本的解释器, 通常可以指定为 1#!/bin/bash bash是Bourne Again Shell, 是很多Linux系统的默认脚本解释器. 创建变量变量规则在Shell中使用name=value的格式来创建变量,而且在等号的两端不能包含空格,例如 1234567$ EXNAME=&#x27;Hello World&#x27; #等号两端一定不能有空格,否则是执行指令的含义$ echo $EXNAMEHello World$ echo $&#123;EXNAME&#125;Hello World 由于Shell使用空格分隔参数, 因此如果等号两端有空格, 就会将变量名当做指令名, 将等号和值当做第二和第三个参数 创建变量时不需要$符号, 引用变量时加入$符号 大括号用于区分变量名的边界, 在不产生歧义的时候可以不加, 但建议始终加入大括号 特殊变量 变量名 含义 $0 当前脚本的文件名 $n 传递给脚本或函数的参数 $# 传递给脚本或函数的参数个数 $* 传递给脚本或函数的所有参数 $@ 传递给脚本或函数的所有参数 $? 上个命令的退出状态, 或函数的返回值 $$ 当前 Shell 进程 ID 字符串与变量规则 Shell中的字符串可以使用单引号, 双引号或者不使用引号 单引号内的内容原样输出, 而双引号中可以使用变量和转义字符 1234567$ foo=bar$ echo &quot;foo is $foo&quot;foo is bar$ echo &#x27;foo is $foo&#x27;foo is $foo 引号中无法使用~表示当前路径, 应该使用$HOME变量代替 结果作为变量Shell中可以将一个指令的返回结果作为另一个指令的参数, 只需要将待执行的指令使用$()包裹即可, 例如 1appId=$(lsof -i:4567 | awk &#x27;$1 == &quot;python3&quot; &#123;print $2&#125;&#x27;) 将一个指令使用反引号包裹, 也具有同样的效果, 不过我觉得这样不够明显, 容易看错 Shell运算符由于Shell的语法限制, Shell的运算符非常的反常规, 因此就不逐一记录了, 以后用到了在来查下面的链接 Shell 运算符：Shell 算数运算符、关系运算符、布尔运算符、字符串运算符等 流程控制语句if-else123456789101112if [ expression 1 ]then Statement(s) to be executed if expression 1 is trueelif [ expression 2 ]then Statement(s) to be executed if expression 2 is trueelif [ expression 3 ]then Statement(s) to be executed if expression 3 is trueelse Statement(s) to be executed if no expression is truefi 注意 由于Shell的设计, [是一个指令, 因此[两端都需要有空格, 否则会解析错误 表达式部分直接写变量等价于判断此变量是否为空 Shell常用判断语句判断变量是否为空123456para1= if [ ! $para1 ]; then echo &quot;IS NULL&quot; else echo &quot;NOT NULL&quot; fi 判断文件和目录是否存在12345678910111213141516171819#如果文件夹不存在，创建文件夹if [ ! -d &quot;/myfolder&quot; ]; then mkdir /myfolderfi# -x 参数判断 $folder 是否存在并且是否具有可执行权限if [ ! -x &quot;$folder&quot;]; then mkdir &quot;$folder&quot;fi# -d 参数判断 $folder 是否存在if [ ! -d &quot;$folder&quot;]; then mkdir &quot;$folder&quot;fi# -f 参数判断 $file 是否存在if [ ! -f &quot;$file&quot; ]; then touch &quot;$file&quot;fi shell bash判断文件或文件夹是否存在 函数函数的格式如下所示 12345function &lt;funname&gt; () &#123; action; ... return &lt;int&gt;&#125; 其中关键字function以及函数名后的()均可以省略. 可以向函数传递参数, 在函数内部使用$1等变量访问参数, 调用函数的方式与调用命令的方式相同, 例如 1234567891011funWithParam()&#123; echo &quot;第一个参数为 $1 !&quot; echo &quot;第二个参数为 $2 !&quot; echo &quot;第十个参数为 $10 !&quot; echo &quot;第十个参数为 $&#123;10&#125; !&quot; echo &quot;第十一个参数为 $&#123;11&#125; !&quot; echo &quot;参数总数有 $# 个!&quot; echo &quot;作为一个字符串输出所有参数 $* !&quot;&#125;funWithParam 1 2 3 4 5 6 7 8 9 34 73 设置可执行权限给上一步创建的脚本赋予执行权限, 此操作可以在图像界面上通过右键设置熟悉来完成, 也可以在Shell中执行如下的指令 1$ chmod +x shell.sh 注意shell.sh是需要设置的文件的文件名 添加到搜索目录此步骤不是必须的, 但是如果希望在任意位置都可以执行此脚本, 则可以将脚本放置在一个PATH变量包含的路径之中, 可以使用echo $PATH查看系统全部的搜索路径, 例如 12lizec@ideapad:~$ echo $PATH/home/lizec/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin 将脚本添加到任意一个显示的目录中即可 设置环境变量 【Ubuntu】Ubuntu设置和查看环境变量 Shell其他常见功能以下是一些常见的功能的Shell实例. 向文件写入多行数据1234567891011# 创建 hook 钩子函数cat&gt;~/repos/&quot;$&#123;ProjectName&#125;.git&quot;/hooks/post-receive&lt;&lt;EOF#!/bin/sh# 拉取最新代码git --work-tree=/home/git/projects/&quot;$&#123;ProjectName&#125;&quot; --git-dir=/home/git/repos/&quot;$&#123;ProjectName&#125;.git&quot; checkout -f# 执行项目自定义更新重启操作cd ~/projects/&quot;$&#123;ProjectName&#125;&quot;./service.sh restartEOF cat&gt;表示覆盖写入文件, ~/repos/&quot;$&#123;ProjectName&#125;.git&quot;/hooks/post-receive是文件名, 文件名中可以使用变量, &lt;&lt;EOF表示结束符为EOF. 中间需要写入的的内容也可以使用变量. shell脚本，将多行内容写入文件中","categories":[],"tags":[{"name":"Shell","slug":"Shell","permalink":"https://lizec.top/tags/Shell/"}]},{"title":"如何阅读论文和源代码","slug":"如何阅读论文和源代码","date":"2019-02-11T07:07:02.000Z","updated":"2020-06-26T14:46:47.207Z","comments":true,"path":"2019/02/11/如何阅读论文和源代码/","link":"","permalink":"https://lizec.top/2019/02/11/%E5%A6%82%E4%BD%95%E9%98%85%E8%AF%BB%E8%AE%BA%E6%96%87%E5%92%8C%E6%BA%90%E4%BB%A3%E7%A0%81/","excerpt":"","text":"本文介绍如何阅读学术论文和项目的源代码, 其中的观点分别来自于台湾清华彭明辉教授的研究生手册以及李峰在 GitChat 上分享的文章&lt;&lt;利用开源代码和读相关论文来提高写代码能力&gt;&gt;. 如何写一篇有价值的论文 论文的主要内容是叙述一套方法在一个特定场合中的应用 这套方法必须有创新或者突破. 它或者是对既有问题的新方法, 或者是既有方法的新应用, 或者是一个新方法开启一个新的领域 论文中, 必须有足够的证据使读者信服在这个应用下,论文中的新方法有比其他文献中的既有方法更优越的地方. 论文中必须能指出这个方法在应用上的限制, 并且充分的证明主要满足论文中提出的前提条件, 此方法就一定可以适用, 其中的优点就一定会存在 论文中必须清楚的指出这个方法的限制和可能的缺点 行文风格上必须保证论证严谨, 逻辑关系清楚, 而且结构有条理. 使得这个专业领域的任何读者, 都有办法根据你的描述, 在他的实验室中复制出你的研究成果 方法中的每一步都必须提供充分的理由, 说明为什么非要如此不可 论文应当在适当的位置注明所有和你研究题目相关的文献 注意: 论文研究领域的所有文献(尤其是学术期刊的论文)都应该阅读过, 否则无论是否参考过这些论文, 都是重大过失. 完成硕士论文需要的能力1. 数据检索能力在给定的访问内, 必须有能力利用数据检索系统查出所有相关的文论, 而没有任何遗漏.到达此目的的关键是选择合适的关键词和程序. 如果关键词不恰当, 可能导致集合太小, 忽略重要的文献. 如果关键词太一般化, 则又会导致集合过大, 除了相关文献还包含了太多无关的内容. 2. 资料筛选能力即使使用正确的策略, 通常找到的文献数量还是比需要的多. 通常情况下会搜索到一两百篇甚至数百篇文献, 而其中与研究问题密切相关的文论, 通常只有二三十篇左右. 因此需要通过 只读论文题目, 摘要, 简介和结论, 在没有完全读懂全文时, 就可以判断是否有进一步阅读的价值. 只有通过这样的筛选过程才能使需要仔细阅读的论文从数百篇降低到二三十篇. 3. 期刊论文的阅读能力期刊论文是没头没尾的十几页文献, 只交代最核心的创意, 并援引许多其他论文的研究成果(但只注明文献出处, 而完全不交代其内容). 因此, 要读懂一片论文, 一定要同时读懂数篇或数十篇援引的论文. 相比于大学的教科书, 期刊论文是一个极端没有系统的知识, 必须依靠读者从几十篇论文中汲取相关的片段, 自己组织成一个有系统的知识, 然后才有办法开始阅读和吸取.这种能力需要大量而持续的时间去摸索和体会. 4. 期刊论文的分析能力为了保证论文的研究成果确实比所有的相关的学术期刊论文都适合拟定的场景, 首先需要有能力逐篇分析所有的相关论文的优点与缺点, 以及自己研究成果的优点和缺点, 然后在进行比较, 总结自己论文的优点和限制. 但是好的论文都是名师和一流的博士生共同的研究成果, “打败”他们是一个极端困难的挑战. 本科生通常是只有理解的能力, 而没有批判的能力. 硕士生则必须要有对一切既有进行精确批判 的能力. 这种批判不是个人的好恶或者情绪化的批判, 而是真的找到充分的理由去支持的批判. 一个严格训练过的硕士, 他做事的时候应该是不需要其他人在背后替他做验证, 他自己就应该要有能力分析自己的优缺点, 主动向上级或平行单位要求支持. 如何阅读期刊论文一般而言, 好的期刊论文有较多的创意. 虽然阅读比较累, 但是收获也较多且深入. 在阅读前, 有必要参考SCI Impact Factor以及学长的意见. 一篇期刊论文可以分成四个部分. 1. Abstract说明这篇论文的主要贡献, 方法特色和主要内容. 需要学会只看Abstract和Introduction就可以判断论文的重点和研究有没有直接关系的能力, 从而决定是否要读完. 如果能从每三十篇文章中筛选出五篇最密切的论文, 那么效率就比别人高五倍. 以后不管是做事还是做研究, 都比别人有能力从更广泛的文献中挑出最有价值的资料. 2. Introduction介绍问题的背景和起源, 交代前人在这个题目上已有的主要贡献, 说清楚前人留下的问题, 以及在这个背景下这篇论文想要解决的问题和它的重要性. 对一个领域不了解时, 可以先收集可能相关的论文30~40篇, 每篇都只读Abstract和Introduction, 不读Main Body, 只在必要的时候参考Illustrative examples和Conclusions, 直到能够回答以下的三个问题 (2A): 在这个领域最常被引述的方法有那些?(2B): 这些方法可以分成那些主要派别?(2C): 每个派别的主要特色(以及优缺点)是什么? 有一种称为 review paper 的论文, 这种论文会在一种题目下整理所有相关的论文, 并且做一个简单的回顾, 在搜索的时候加上 review 关键字可以帮助筛选出这种论文. 借助于这种论文, 在集合相关论文的title和Abstract, 可以更容易的选择出比较合适的30~40篇论文. 通常只需要阅读30~40篇论文的Abstract和Introduction, 就可以回答(2A)和(2B). 在试图回答这两个问题时, 一定要选择Introduction写的比较有观念的论文(如果论文写的像流水账, 则开始的时候不要读). 如果阅读了30~40篇论文的Abstract和Introduction之后, 还是无法回答(2C), 则做如下的工作. 根据(2A)的答案, 把这个领域内最常被引述的论文找齐, 在把他们根据(2B)的答案分成派别, 每个派别按日期先后次序排好. 然后每次重新读一派的Abstract和Introduction(必要时简略参考内文, 但目的是读懂Introduction中与这派有关的陈述, 而不是真的读懂内文), 按照日期先后读, 每次只试图回答一个问题:这一派的创意与主要诉求是是? 这样逐派逐派的把每一派的Abstract和Introduction读完, 总结出这一派别的主要诉求, 方法特色和优点(每一篇论文都会说出自己的优点) 其次, 再次把论文拿出来, 只读Introduction, 认真回答问题:每篇论文对其他派别有什么批评? 然后把读到的重点记录到各派别的缺点栏. 通过以上步骤, 获得(2A), (2B)和(2C)的答案以后, 对于这个领域内的主要方法和文献之间的关系应该是比较熟悉了. 此时可以用这些论文来测试之前使用的keywords是否合适并进行修正. 使用修正的keywords再次搜索论文, 把主要的论文补齐, 并且将原来的30~40篇论文中关系较远的论文删除, 最后只保留大约20篇关系最密切的论文. 如果有把握, 可以删除一两个不使用的派别(但是要与充分的理由), 只保留两, 三个派别(也要有充分的理由). 在(2C)的基础上, 再进一步回答一个问题 (2D): 这个领域内大家认为重要的关键问题有那些? 有那些特性是大家重视的优点? 有那些特性是大家在意的缺点? 这些优点与缺点通常在那些应用场合会比较被重视? 在那些应用场合不会被重视? 根据这个问题, 就可以整理出这个研究领域主要的应用场合, 以及这些应用场合上应该注意的事项. 最后, 在真正阅读main body之前, 应该依据(2A)和(2C)的答案, 按照派别将论文分类, 然后以研究的密切程度和时间次序一个派别一个派别的阅读. 3. Main body在第一次阅读某个派别的论文的main body时, 只需要理解 (3A): 这篇论文的主要假设是什么(什么条件下是有效的)? 假设条件在现实条件下成立的难度是多少?(3B): 在这些假设条件下, 这篇论文主要有什么好处?(3C): 这些好处主要表现在那些公式的那些项目的简化上? 一个前提条件越难成立, 则其参考价值也越低. 整篇论文的详细推导并不需要懂, 除了最关键的几个公式之外(是实际应用相关的公式, 用于评估方法的方便程度或计算效率), 其他的公式不懂也没有关系. 公式之间的恒等变化完全可以忽略过去.如果需要看公式, 重点是看公式推导过程中引入的假设条件, 而不是恒等式的转换 注意, 在详细阅读论文前, 应该先把这个派别的所有论文拿出来, 初略的阅读一遍, 从中挑出容易的论文和经常被引用的论文, 先阅读这些论文. 阅读时只需要记住回答(3A), (3B)和(3C)三个问题, 不需要读的太细致. 这样完成一个派别的阅读之后, 应该依据这一派的发展过程, 主要假设, 主要理论依据, 以及主要的成果, 做一个完整的整理. 其次, 在(2D)的基础上, 结合这一派的主要假设, 进一步的回答 (3D)这一派的主要缺点有那些? 最后根据这四个问题整理出这一派最适合什么时候使用, 最不适合什么场合使用. 当评估一个方法的优缺点时, 需要参考提供的examples, 但更应该考虑方法的基本假设, 主要公式的适用条件, 并且分析某些场合无法满足相应条件时, 这个方法是否会出现某些状况. 尝试分析这个方法在那些条件下表现优异, 又在那些条件下出状况? 根据猜测在检验一下论文提供的examples是否覆盖了这些情况, 并且充分的展现出来. 永远不需要完全理解一篇论文, 硕士生必须学会选择性的阅读, 而且必须锻炼出选择的准确度和选择的速度, 不要浪费时间学用不到的细节知识. 多吸收点子比细节知识更重要. 补充说明阅读论文应该是一批一批的读到某一个层次, 而不是一篇一篇的读懂. 读论文的时间永远是不够的, 一定要带着问题阅读, 每次阅读只需要根据论文尝试回答问题. 读论文一定要有选择的读, 一定要逐渐由粗到细地一层一层的了解. 这样一轮一轮的阅读过程中, 可以根据学到的知识, 逐渐的筛选掉不相关的论文, 从而进一步提高阅读效率. 不要读不会用到的东西, 白费的力气必须极小化. 按批次粗略阅读还可以使得之后阅读论文时, 对阅读顺序进行规划, 从而规划出一个最容易阅读的顺序. 理解A论文的内容并不一定必须阅读A论文, 阅读B论文时, 也可能帮助理解A论文的思想. 读论文要有想象和猜测, 读论文的时候, 猜测作者的思想, 并从论文中寻找依据. 如果猜对了, 可以加速论文阅读, 即使猜错了, 也能够加深理解. 方法特性表在阅读了大量论文之后, 应该形成一个方法特性表和一个问题特性表, 方法特性表形式如下 方法特性表 方法一 方法二 方法三 方法四 特性1 o x x v 特性2 v o v o 特性3 o v x x 特性4 x o o x 问题特性表形式如下 问题特性表 应用甲 应用乙 应用丙 特性1 o x x 特性2 o o o 特性3 o x x 特性4 x o o 不同的方法有不同的特性, 而不同的应用场景对特性的要求也不相同. 方法没有好坏, 只有优缺点. 一个方法应用在合适场景就是一个好的方法, 反之则是一个糟糕的方法. 如果想要一个新的方法, 可以先分析应用场景对各种特性的需求, 找到其中的关键特性, 根据这些特性再去寻找表现优异的方法. 将一些可以互补的方法尝试组合就是一种新的方法. 论文报告的要求与技巧一篇论文, 按照报告先后次序, 完成以下的要求 第一页列出论文的题目, 作者, 论文出处与年份 每一页只讲一个观念 说明论文研究问题的重点, 以及这个问题可能与工业界的那些应用相关 说明论文的主要假设, 主要公式, 主要应用方式 说明这篇论文中的例子在不同场合下可能的准确度或好用的程度 个人的分析,评价与批评 这篇论文主要创意是什么 这些创意在应用上有什么好处 这些创意和应用上的好处是那些条件下才成立的 这篇论文最主要的缺点或局限是什么 这些缺点或局限在应用上有什么坏处 这些缺点和应用的坏处是因为哪些因素而引入的 建议学长学弟什么时候参考这篇论文的那些部分 如何阅读源代码1. 熟悉阶段遇到一个新的软件时, 首先一定要阅读文档, 了解其需要解决的问题, 设计的核心概念, 每一个模块的功能等. 通常可以阅读如下的一些文档资源 官方文档: 项目对应的官方网站提供的文档 wiki: 项目对应的wiki文档 相关论文: 比较有名的项目同时也会有相关的论文发表 完成相关论文的阅读以后, 一定要能够把项目运行起来. 通常在项目的starter或者example文件夹中会提供官方的使用示例, 首先尝试运行这些示例. 最后, 在示例的基础上, 可以尝试根据自己的需求, 简单的修改其中的业务逻辑. 能够正确运行代码以后, 就可以进行下一个阶段: 构建数据流运行图. 通过阅读文档和实际运行代码来分析数据的流动过程, 先分析核心概念, 然后逐步的细化. 分析数据流图有如下的一些优点 理解概念, 了解系统的运行机制 产生问题, 从而阅读源代码时有目标 了解实现细节, 从而后续能够为系统添加需要的细节 遇到问题时, 更容易找到问题模块的位置, 获得切入点 2. 阅读阶段首先分析项目的外部依赖库, 对其中的依赖的模块都要有基本的了解, 否则应该先去了解依赖库的基本信息. 学习依赖库也是知识储备的一个环节, 以后需要类似的问题, 就可以节省时间. 具有一定的知识储备以后, 就可以开始阅读源代码了. 关于切入点的选择, 可以考虑如下的几点 从数据的依赖库入手, 查看它在项目中的使用. 从使用中的bug入手, 分析日志和代码 从概念模型入手, 阅读相应的实现类, 在依据这些类进行扩展 从问题出发, 查看相应的文章和代码, 从而解决疑惑 从demo代码开始debug 在阅读过程中, 没有必要一行行的阅读, 可以适当的忽略不太相关的部分. 在阅读过程中, 可以适当的进行总结, 例如完善前面的数据流图. 3. 应用阶段在平常的项目设计阶段, 可以积极的尝试借鉴开源系统中的一些概念. 这些开源软件通常都具有优秀的概念模型和系统架构. 开源系统中使用的优秀基础库也可以应用到自己的系统之中. 开源系统中部分优秀的代码也可以引入到自己的代码之中. 部分源代码在注释中还会引入一些论文, 如果想了解算法的具体内容, 也可以下载阅读. 很多有名的开源系统都会提供相应的论文. 参考文献 台湾清华彭明辉教授的研究生手册(简体完全版) 利用开源代码和读相关论文来提高写代码能力 如何收集和整理论文（面向CS专业）","categories":[],"tags":[{"name":"论文阅读","slug":"论文阅读","permalink":"https://lizec.top/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"}]},{"title":"机器学习之卷积神经网络","slug":"机器学习之卷积神经网络","date":"2019-02-07T04:33:28.000Z","updated":"2019-02-26T09:06:22.687Z","comments":true,"path":"2019/02/07/机器学习之卷积神经网络/","link":"","permalink":"https://lizec.top/2019/02/07/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/","excerpt":"","text":"Convolutional networks, also known as convilutional neural networks or CNNs, are a sepcialized kind of neural network for processing data that has a known, grid-like topology. Examples include time-series data, which can be thought of as a 1D grid taking samples at regular time intervals, and image data, which can be thought of as a 2D grid of pixels. 卷积In its most general form, convolution is an operation on two functions of a real-valued argument. Suppose we are tracking the location of a spaceship with a laser sensor. Our laser sensor provides a single output x(t), the position of the spaceship as time t. Both x and t are real-valued, i.e., we can get a different reading from the laser sensor at any instant in time. Now suppose than out laser sensor is somewhat noisy. To obtain a less noisy estimate of the spaceship’s position, we would like to average together several measurements. Of course, more recent measurements are more relevant, so we will want this to be a weighted average that gives more weight to recent measurements. We can do this with a weighting function w(a), where a is the age of a measurement. If we apply such a weighted average operation at every moment, we obtain a new function s providing a smoothed estimate of the position of the spaceship: $$s(t) = \\int{x(a)w(t-a)}da$$ This operation is called convolution. The convolution operation is typically denoted with a asterisk: $$s(t)=(x*w)(t)$$ In our example, w needs to be a valid probability density function, or the output is not a weighted average. Also, w need to be 0 for all negative arguments, or it will look into the future. In general, convolution is defined for any functions for which the above integral is defined, and may be used for other purposes besides taking weighted averages. In convolutional network terminology, the first argument to the convolution is often referred to as the input and the second argument as the kernel. The output is sometimes referred to as the feature map In our example, it might be more realistic to assume that our laser provides a measurement once per second. The time index t can than take on only integer values. If we now assume that x and w are defined only on integer t, we can define the discrete convolution: $$s(t)=(x*w)(t)=\\sum_{a=-\\infty}^{\\infty}x(a)w(t-a)$$ We usually assume that these functions are zero everywhere but the finite set of points for which we store the values. This meaus that in practice we can implement the infinite summation as a summation over a finite number of array elements. Finally, we often use convolutions over more than one axis at a time. For example, if we use a two-dimensional image I ass our input, we probably also want to use a two-dimensional kernel K: $$S(i,j)=(I*K)(i,j) = \\sum_m\\sum_nI(m,n)K(i-m,j-n)$$ Convolution is commutative, meaning we can equivalently write: $$S(i,j)=(I*K)(i,j) = \\sum_m\\sum_nI(i-m,j-n)K(m,n)$$ Usually the latter formula is moew straighforward to implement in a machine learing library, because there is less ariation in the range of valid values of m and n. (注: 如果K的取值范围比较小, 那么在第二种方式下的m和n则始终是在一个固定的返回取值, 而第一种方式下m和n的取值范围受到i和j的影响, 因此从编程实现上来说, 第二种方式更容易实现.) The commutative property of convolution arises beacuse we have flipped the kernel relative to the input, in the sense that as m increases, the index into the input increases, but the index into the kernel decreases. The only reson to flip the kernel is to obtain the commutative property. While the commutative property is useful for writing proofs, it is not usually an important property of a neural network implementation. Instead, many neural network libraries implement a related function called the cross-correlation, which is the same as convolution but without filpped the kernel: $$S(i,j)=(I*K)(i,j) = \\sum_m\\sum_nI(i+m,j+n)K(m,n)$$ 优化Convolution leverages three important ideas that can help improve a machine learning system: sparse interations, paramteter sharing and equivariant representations. Convolutional networks typically have sparse interactions. This is accomplished by making the kernel smaller than the input. For example, when processing an image, the input image might have thousands or millions of pixels, but we can detect small, meaningful features such as edges with kernels that occupy only ten or hundreds of pixels. This means that we need to store fewer parameters, which both reduces the memory requirements of the model and improves its statistical efficiency.. Paramteter sharing regers to using the same parameter for more than one function in a model. In a convolutional neural net, each member of the kernel is used at every positon of the input. (注:以上两个特性都是卷积核逐一扫描输入面的直接结果) In the case of convolution, the particular form of parameter sharing causes the layer to have a property called equivariance to translation. To say a function is equivariant means that if the input changes, the output changes in the same way. 池化A pooling function repalces the output of the net at a certain location with a summary statistic of the nearby outputs. For example, the max pooling opearation reports the maximum output within a rectangular neighborhood. Other popular pooling function include the average of a recangular neighbothood, the \\( L^2 \\) norm of a rectangular neighborhood, or a weighted average based on the distance from the central pixel. In all cases, pooling helps to make the representation become approximately invariant to small translations of th input. Invariance to translation means that if we translate the input by a small amount, the values of most of the pooled outputs do not change. Invariance to local translation can be a very useful property if we care more about whether some feature is present than exactly where it is. 基本卷积函数CNN的基本结构由输入层, 卷积层, 池化层, 全连接层和输出层组成. 卷积层和池化层通常可以交替的出现多次. 卷积层由多个特征面组成, 每个特征面由多个神经元组成. 每个神经元通过卷积核与上个特征面的局部连接. 卷积核是一个权值矩阵","categories":[{"name":"机器学习","slug":"机器学习","permalink":"https://lizec.top/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://lizec.top/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}]},{"title":"Python笔记之高级特性","slug":"Python笔记之高级特性","date":"2019-02-02T04:37:14.000Z","updated":"2021-04-28T06:42:10.016Z","comments":true,"path":"2019/02/02/Python笔记之高级特性/","link":"","permalink":"https://lizec.top/2019/02/02/Python%E7%AC%94%E8%AE%B0%E4%B9%8B%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7/","excerpt":"","text":"本文介绍Python语言中相对比较高级的一些特性, 包括列表解析, 生成器, 函数式编程,装饰器,类型注解等. 列表解析列表解析是一种简单的生成一个列表的方法, 格式如下 123456[&lt;exp&gt; for &lt;expr1&gt; in &lt;sequence1&gt; for &lt;expr2&gt; in &lt;sequence2&gt; ... if &lt;condition&gt;] 每次迭代时将产生的&lt;expr&gt;值应用到&lt;exp&gt;, 如果满足&lt;condition&gt;, 则将值放入列表, 例如 123[x ** 2 for x in range(10) if x**2 &lt; 50]# output# [0, 1, 4, 9, 16, 25, 36, 49] 列表解析本质是产生了一个可迭代的对象, 然后被list的构造函数转化为一个list. 生成器直接生成器使用类似列表推导的语法, 但如果直接使用小括号包裹, 则按照语法是一个迭代对象, 例如 123456789101112131415In [1]: L = [x ** 2 for x in range(10) if x**2 &lt; 50]In [2]: type(L)Out[2]: listIn [3]: T = (x ** 2 for x in range(10) if x**2 &lt; 50)In [4]: type(T)Out[4]: generatorIn [5]: next(T)Out[5]: 0In [6]: next(T)Out[6]: 1 yield关键字对于一些比较复杂的迭代过程, 可能无法简单的使用列表推导的语法来产生迭代器, 此时可以先创建一个函数来表述迭代过程, 然后将输出的语句替换为yield来创建迭代器, 例如 1234567def fib(max): n, a, b = 0, 0, 1 while n &lt; max: print(b) a, b = b, a + b n = n + 1 return &#x27;done&#x27; 上述函数定义了一个斐波拉契数列, 可以依次输出输出指定返回内的斐波拉契数, 此时只需要将print语句改为yield语句, 即 1234567def fib(max): n, a, b = 0, 0, 1 while n &lt; max: yield b a, b = b, a + b n = n + 1 return &#x27;done&#x27; 每当执行到yield语句时, Python自动将函数当前的执行状态保存, 并且返回yield后面的值, 当程序下一次访问此函数时, Python在将函数的状态恢复, 使得函数从yield语句之后继续执行. 1234In [16]: f = fib(100)In [17]: fOut[17]: &lt;generator object fib at 0x000001B4EEB70EB8&gt; 函数式编程和很多语言一样, Python支持函数式编程. 在Python中, 任意的函数也都是一个对象, 可以像变量一样进行传递, 一个函数可以作为参数传递给另外一个函数, 也可以为做返回值被一个函数返回. 例如 1234567def lazy_sum(*args): def sum(): ax = 0 for n in args: ax = ax + n return ax return sum 关于函数式编程的有关特性, 实际上与Java或者JavaScript中的各种API并无本质区别, 后续仅介绍一些与Python语法有关的内容. Lambda函数各种函数式编程的特性中都经常使用lambda函数, 其Python语法定义如下 123&gt;&gt;&gt; r = lambda x:x+x&gt;&gt;&gt; r(5)10 即首先以lambda取代原来的函数名, 然后是参数列表, 在冒号定义函数的函数体. 装饰器基本原理与使用Python中的装饰器类似于Spring的AOP, 即在不改变函数代码的基础上, 对函数的功能进行增强. 装饰器的一个常见的使用场景是对函数添加调用日志. 首先定义装饰器, 其代码如下 123456def log(func): @wraps(func) def wrapper(*args, **kw): print(&#x27;call %s():&#x27; % func.__name__) return func(*args, **kw) return wrapper 之后对于需要被装饰的函数, 按照如下的方式使用 123@logdef now(): print(&#x27;Hello World&#x27;) 其中@使得下面的函数now作为参数传入log函数之中, 并使用log函数返回的函数替换now函数, 从而使now函数在外围增强了需要的功能. 由于now函数被替换, 因此now函数的一些元信息在替换过程中被丢失了, 这些元信息包括now函数的函数名, doc字符串等. 为了防止这些信息被丢失, 需要在wapper函数上加入@wraps装饰器, 此装饰器帮助我们重新恢复now函数的相关信息. 反正一直加上这个注解就是了 装饰器参数可以注意到, 装饰器函数以被装饰的函数作为参数, 因此按照上面的方法, 装饰器函数本身并不能要求输入额外的参数了. 如果需要使装饰器可以接受参数, 那么需要引入一些技巧, 具体代码如下 12345678910111213from functools import wraps, partialimport loggingdef logged(func=None, level=logging.DEBUG, name=None, message=None): if func is None: return partial(logged, level=level, name=name, message=message) @wraps(func) def wrapper(*args, **kwargs): log.log(level, logmsg) return func(*args, **kwargs) return wrapper 这里的核心技巧是: 如果直接使用装饰器, 那么func参数有取值, 而其他参数为默认值, 而如果使用有参数的装饰器, 那么func为默认值None, 而其他参数有具体的取值. 那么根据func是否为None就可以判断是直接使用了装饰器还是使用了有参数的装饰器. 在装饰器使用了参数的情况下, 可以使用partial生成一个其他参数都被初始化了, 仅func没有初始化的偏函数, 将这个偏函数应用到被装饰的函数上, 就等价于上一节定义了基本的装饰器. 而如果装饰器没有使用参数, 也能够使用默认参数完成装饰器的功能. 最后可以使用如下的两种形式使用装饰器: 123456789# 无参数装饰器@loggeddef add(x, y): return x + y# 有参数装饰器@logged(level=logging.CRITICAL, name=&#x27;example&#x27;)def spam(): print(&#x27;Spam!&#x27;) 第九章：元编程 9.6 带可选参数的装饰器 类型注解从Python3.6开始, Python提供了类型注解功能, 可以为变量提供一个类型, 从而便于IDE进行语法检查. 例如 12def add(a: int, b: int) -&gt; int: return a + b 如果是集合类型, 可以导入相关的集合类型, 并且可以根据这些类型定义新的类型名称, 例如 12345678from typing import Listdef read(names : List[str]) -&gt; str : return names[0]Vector = List[str]def write(names: Vector) -&gt; int: pass 函数类型如果需要一个函数作为参数, 可以按照如下的方式定义 1def update(where: Callable[[dict], bool], update=Callable[[int, int], NoReturn]) 可空类型和特殊类型Python标记的类型默认是不可为None的, 如果一个变量需要为None, 则需要标注为Optional类型 12def f() -&gt; Optional[str]: return None 则f函数的返回值类型为str并且允许返回None. Python还提供了两种新的类型Any和NoReturn, 其中Any表示可以返回任意类型, 而NoReturn表示函数没有返回值. 这两个标记都有助于IDE对函数的调用情况进行检查. Python官方文档: 26.1. typing — 类型标注支持 异步编程与协程从 Python 3.7 开始, Python支持使用async和await关键字定义协程以使用异步编程. 一个简单的例子如下所示 12345678910111213141516171819202122import asynciofrom datetime import datetime# 使用async表示此函数是异步操作async def say_hi_after(second, name): # 使用await等待其他异步操作 print(f&quot;&#123;datetime.now()&#125;: &#123;name&#125; -&gt; Hi!&quot;) await asyncio.sleep(second) print(f&quot;&#123;datetime.now()&#125;: &#123;name&#125; -&gt; Done.&quot;)async def main(): print(f&quot;&#123;datetime.now()&#125;:Begin Main&quot;) # 将多个异步任务合并成一个新的异步任务并等待结果 await asyncio.gather(say_hi_after(1, &#x27;Task1&#x27;), say_hi_after(2, &quot;Task2&quot;)) print(f&quot;&#123;datetime.now()&#125;:Finished Main&quot;)if __name__ == &#x27;__main__&#x27;: # 启动异步任务 asyncio.run(main()) 最后的执行结果如下所示 12345613:58:21.353098:Begin Main13:58:21.353098: Task1 -&gt; Hi!13:58:21.353098: Task2 -&gt; Hi!13:58:22.361652: Task1 -&gt; Done.13:58:23.357971: Task2 -&gt; Done.13:58:23.357971:Finished Main 可以注意到, 多个任务之间并没有顺序执行, 而是在发生异步操作时进行了切换. 通过这一方式Python实现了在单线程模式下的多任务效果. 基础概念以async修饰的函数称为协程(Coroutines), 直接调用协程函数并不会执行此函数, 而是产生了一个协程对象. 大量关于协程的接口都需要使用awaitable对象, Python中协程和任务(Task)都是awaitable对象. 高级APIPython异步编程的核心是asyncio, 其中提供了一组高级API, 名称和效果如下表所示: API 作用 run 创建一个事件循环, 启动一个协程, 然后关闭事件循环 create_task 开始一个异步任务(使用默认的事件循环) await sleep 休眠指定的时间(秒), 放弃执行权 await gather 同时执行给定的多个协程 await wait_for 已给定的超时时间执行协程 await shield 防止给定的awaitable对象被取消 await wait 运行一组aws, 并根据设置的条件进行等待 current_task 返回当前的任务 all_tasks 返回事件循环中的所有任务 to_thread 以线程模式运行异步任务 扩展阅读 Coroutines and Tasks Python 异步编程，看这个教程就够了~ 扩展阅读 Python教程 -廖雪峰","categories":[{"name":"Python笔记","slug":"Python笔记","permalink":"https://lizec.top/categories/Python%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://lizec.top/tags/Python/"}]},{"title":"CMake使用笔记","slug":"CMake使用笔记","date":"2019-01-31T14:37:56.000Z","updated":"2019-02-07T13:10:38.339Z","comments":true,"path":"2019/01/31/CMake使用笔记/","link":"","permalink":"https://lizec.top/2019/01/31/CMake%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/","excerpt":"","text":"CMake是一个跨平台的构建工具, 通过编写CMakeList.txt文件, 可以轻松的产生需要的Makefile文件, 从而简化构建脚本的编写难度. 和make类似, CMake需要一个名为CMakeLists.txt的文件, 通过编写此文件来制定编译过程中的各种细节, CMake在依据这个文件来产生相应的Makefile. 使用CMake对于一个CMake的系统而言, 通常执行如下的几步来完成软件的编译 123cmake .makemake install 其中cmake后面的参数是CMakeLists.txt的路径. 在本例中, 此文件正好位于当前目录. 使用cmake生成Makefile时, 会产生很多中间文件. 因此也可以先创建一个build目录, 然后在build之中进行编译. 之前尝试对原来使用功能Makefile维护的一个C++项目使用CMake替换, 但实际操作后发现CMake并没有对原来的问题给出更好的解决, 而对于部分问题甚至还需要一些不太优雅的方式来完成. 因此以下仅给出两篇质量较高的CMake相关的博客, 不再具体介绍CMake的有关内容. 博客如下: CMake 入门实战 -HaHack VS Code与CMake真乃天作之合 -知乎专栏","categories":[],"tags":[{"name":"CMake","slug":"CMake","permalink":"https://lizec.top/tags/CMake/"}]},{"title":"机器学习之概率论","slug":"机器学习之概率论","date":"2019-01-24T01:36:35.000Z","updated":"2020-06-26T04:45:52.634Z","comments":true,"path":"2019/01/24/机器学习之概率论/","link":"","permalink":"https://lizec.top/2019/01/24/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%A6%82%E7%8E%87%E8%AE%BA/","excerpt":"","text":"Probability theory is a mathematical framework for representing uncertaion statements. It provides a means of quantifying uncertainty and axioms for deriving new uncertain statements. 边缘分布Sometimes we know the probability distribution over a set of variables and we want to know the probability distribution over just a subset of them. The probability distribution over the subset is known as marginal probability. For continuous variables, we need to use integration: $$p(x) = \\int{p(x,y)}dy$$ The name “marginal probability” comes from the process of computing marginal probabilities on paper. When the values of P(x,y) are written in a grid with different values of x in rows and different values of y in columns, it is natural to sum across a row of the grid, then write P(x) in the margin of the paper just to the right of the row. 所以边缘分布和密度函数的边缘并没有关系, 不要被这个名词误导了. 条件概率In many cases, we are interested in the probability of some event, given that some other event has happened. This is called a conditional probability. We denote the conditional probability that \\( y = y_1\\) given \\( x = x_1\\) as \\( P(y=y_1|x=x_1) \\). This conditional probability can be computed with the formula: $$P(y=y_1|x=x_1) = \\frac{P(y=y_1, x=x_1)}{P(x=x_1)}$$ 条件概率链式法则Any joint probability distribution over many random variables may be decomposed into conditional distributions over only one variable: $$P(x^{(1)}, \\cdots, x^{(n)}) = P(x^{(1)}) \\prod_{i=2}^n P(x^{(i)}|x^{(1)}, \\cdots, x^{(n-1)})$$ This obsservation is known as the chain rule or product rule of probability. It follows immediately from the definition of conditional probability. For example, applying the definiton twice, we get $$\\begin{align} P(a,b,c) &amp;= P(a|b,c)P(b,c) \\\\ P(b,c) &amp;= P(b|c)P(c) \\\\ P(a,b,c) &amp;= P(a|b,c)P(b|c)P(c) \\\\\\end{align}$$ 独立和条件独立Two random variables x and y are independent if their probability distribution can be expressed as a product of tow factors, one involing only x and one involving only by y: $$\\forall x \\in X,y \\in Y, p(x=x_0,y=y_0)=p(x=x_0)p(y=y_0)$$ Two random variables x and y are conditionally independent given a random variables z if the conditional probability distribution over x and f factorizes in this way for every value of z: $$\\forall x \\in X,y \\in Y, z \\in Z,p(x=x_0,y=y_0|z=z_0)=p(x=x_0|z=z_0)p(y=y_0|z=z_0)$$ 期望,方程,协方差The expection or expected value og some function f(x) with respect to a probability distribution P(x) is the arerage or mean value that f takes on when x is drawn from P. For continuous variables, it is computed with an integral: $$E_x[f(x)] = \\int{p(x)f(x)}dx$$ Expections are linear, for example, $$E_x[\\alpha f(x)+\\beta g(x)] = \\alpha E_x[f(x)]+ \\beta E_x[g(x)]$$ When α and β are not dependent on x. The variance gives a measure of how much the values of a function of a random variable x vary as we sample different values of x from its probability distribution: $$Var(f(x)) = E[(f(x)-E[f(x)])^2]$$ When the variance is low, the values of f(x) vluster near their expected value. The square root of the variance is known as the standard deviation The covariance gives some sense of how much two values are linearly related to each other, as well as the scale of these variables: $$Cov(f(x),g(x)) = E[(f(x)-E[f(x)])(g(x)-E[g(x)])]$$ High absolute values of the covariance mean that the values change very much and are both far from their respective means at the same time. If the sign of the covariance is positive, then both variables tend to take on relatively high values simultaneously. if the sign of the covariance is negative, then one variable tends to take on a relatively high value at the same times that the other takes on a relatively low values and vice versa. The notions of covariance and dependence are related, but are in fact distince concepts. They are related because two variables that are independent have zero covariance, and two variables that have non-zero covariance are dependent. However, independence is a distinct property from covariance. For two variables to have zero covariance, there must be no linear dependence between them. Independence is a stronger requirement than zero covariance, because independence also excludes nonlinear relationships. 如何通俗易懂地解释「协方差」与「相关系数」的概念？（转） 常用函数Certain functions arise often while working with probability distributions, especially the probability distributions used in deep learning models. Logistic函数One of those function is the logistic sigmoid: $$\\sigma(x) = \\frac{1}{1+exp(-x)}$$ The logistic sigmoid is commonly used to produce the \\( \\phi \\) parameter of a Bernoulli distribution beacuse its range is (0,1), which lies within the valid range of values for the \\( \\phi \\) parameter. Softplus函数Another commonly encountered function is the softplus function: $$\\xi(x) = log(1+exp(x))$$ The softplus function can be useful for producing the \\( \\beta \\) or \\( \\alpha \\) parameter of a normal distribution beacuse its range is (0, \\( \\infty \\)). It also raises commonly when manipulating expressions involving sigmoids. The name of the softplus function comes from the fact that it is a smoothed or softened version of $$x^+ = max(0,x)$$ There is a graph of softplus function: 函数性质These are some useful propertoes: $$\\sigma(x)$$ $$\\xi(x)$$ $$\\sigma(x) = \\frac{exp(x)}{exp(x)+exp(0)}$$ $$log \\sigma(x) = -\\xi(-x)$$ $$\\frac{d}{dx}\\sigma(x) = \\sigma(x)(1-\\sigma(x))$$ $$\\frac{d}{dx}\\xi(x) = \\sigma(x)$$ $$\\forall x \\in (0,1),\\sigma^{-1}(x) = log(\\frac{x}{1-x})$$ $$\\forall x&gt;0, \\xi^{-1}(x) = log(exp(x)-1)$$ $$1 - \\sigma(x) = \\sigma(-x)$$ $$\\xi(x)-\\xi(-x) = x$$ 贝叶斯法则We often find overselves in a situation where we know P(y|x) and need to know P(x|y). Fortunately, if we also know P(x), we can compute the desired quantity using Bayes’ Rule $$P(x|y) = \\frac{P(x)P(y|x)}{P(y)}$$ Note that while P(y) appears in the formula, it is usually feasible to compute $$P(y) = \\sum_x P(y|x)P(x)$$","categories":[{"name":"数学","slug":"数学","permalink":"https://lizec.top/categories/%E6%95%B0%E5%AD%A6/"}],"tags":[{"name":"概率论","slug":"概率论","permalink":"https://lizec.top/tags/%E6%A6%82%E7%8E%87%E8%AE%BA/"},{"name":"机器学习","slug":"机器学习","permalink":"https://lizec.top/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}]},{"title":"动态链接原理和使用方法","slug":"动态链接原理和使用方法","date":"2019-01-21T12:09:46.000Z","updated":"2019-02-07T09:41:21.666Z","comments":true,"path":"2019/01/21/动态链接原理和使用方法/","link":"","permalink":"https://lizec.top/2019/01/21/%E5%8A%A8%E6%80%81%E9%93%BE%E6%8E%A5%E5%8E%9F%E7%90%86%E5%92%8C%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/","excerpt":"","text":"本文介绍动态链接的原理以及在各个平台上创建和使用动态链接库的方法. 附带地, 本文也会涉及静态库的原理以及如何创建和使用静态库. 静态连接与动态链接静态库实际上是一组二进制的代码, 在编译的时候, 我们引用的静态库函数会直接复制到我们的程序之中. 动态库也是一组二进制代码, 但是编译的时候我们的程序并不包含相关的代码, 而是在运行的时候动态的去获得需要的代码. Windows下的创建方法在Windows下, 对于静态库, 通常只需要发布一个.lib文件. 其中就包含了全部的代码. 而对于动态库, 则需要同时发布.lib文件和.dll文件. 其中.lib文件仅包含一些链接的信息, 仅在程序的链接阶段使用. 而.dll文件包含实际的代码, 在程序运行的时候使用. 如果使用Visual Studio进行开发, VS在创建Win32项目时, 可以直接选择创建DLL或者静态库. 选择相应的项目后直接编译就可以产生相应的库文件. 其中的一些细节可以参考一下的文章 手把手教你如何制作和使用lib和dll - CSDN DLLs in Visual C++ -Microsoft Docs Linux下的创建方法与Windows平台相对应, 在Linux平台上, 静态库以.a结尾, 而动态库以.so结尾. 由于我懒, 就不多介绍了, 可以阅读以下的博客 linux 中的.so和.a文件 -CSDN 关于linux下的.a文件与 .so 文件 -暴力的轮胎 Java调用C++本节介绍如何通过Java调用C++编译出来的DLL. 步骤如下: 创建Java类, 使用native关键字声明相关的函数 编译Java文件, 产生class文件 使用JDK中的javah工具指定相应的class文件来产生需要的头文件 使用VS创建DLL项目, 引入第三步产生的头文件,并且导入JDK中的jni.h和jni_md.h 根据头文件实现相应的函数, 然后编译C++程序, 产生相应的DLL 将编译产生的DLL放置到PATH变量包含的路径之中 Java中使用loadLibrary加载DLL 更细致的步骤可以参考以下的内容 Java调用C++动态链接库dll -成都汇智动力","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://lizec.top/tags/Java/"},{"name":"动态链接","slug":"动态链接","permalink":"https://lizec.top/tags/%E5%8A%A8%E6%80%81%E9%93%BE%E6%8E%A5/"}]},{"title":"机器学习之线性代数","slug":"机器学习之线性代数","date":"2019-01-15T13:35:32.000Z","updated":"2020-06-26T04:46:04.664Z","comments":true,"path":"2019/01/15/机器学习之线性代数/","link":"","permalink":"https://lizec.top/2019/01/15/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8B%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/","excerpt":"","text":"Linear algebra is a branch of mathematics that is widely uesd throughout science and engineering. A good understanding of linear algebra is essential for understanding and working with many machine learning algorithms, especially deep leaning algrothms. 线性无关Determining whether Ax=b has a solution thus amounts to testing whether b is in the span of the columns of A. A set of vectors is linear independtent if no vector in the set is a linear combination of the other vectors. 范数Formally the p Norms is given by $$ ||x||_{p} = (\\sum |x|^{p})^{\\frac{1}{p}} $$ Sometimes we may also wish to measure the size of a matrix. The most common way to do this is with the otherwise obscure Frobenius norm $$ ||A||_F = \\sqrt{\\sum_{i,j} A_{i,j}^2}$$ 特殊矩阵对角矩阵Diagonal matrices consist mostly of zeros and have non-zero entries only along the main diagonal. 对称矩阵A symmetric matrix is any matrix that is equal to tis own transpose: $$ A = A^T $$ Symmetrix matrices often arise when the entries are generated by some function of two arguments that does not depend on the order of the arguments. 正交矩阵An orthogonal matrix is a square matrix whose own rows are mutually orthonormal and whose columns are mutually orthonormal: $$ A^TA= AA^T = I $$ This implies that $$ A^T = A^{-1} $$ 因为任意两个向量都是垂直的, 所以这个矩阵相当于对坐标系进行旋转. 又因为任意一个向量都是单位向量, 因此这个矩阵是纯粹的旋转操作, 这个矩阵代表的变化不改变向量的长度(即只旋转向量的方向) 通过代数分析可知, 正交矩阵的转置对应的正好就是原矩阵反方向的旋转 特征分解An eigenvector of a square matrix A is a non-zero vector v such that multiplication by A alters only the scale of v: $$ Av = \\lambda v $$ Suppose that a matrix A has n linearly independent eigenvectors, we may concatenate all of the eigenvectors to form a matrix V with one eigenvector per column: $$ V = [v^{(1)},v^{(2)},\\cdots,v^{(n)}] $$ Likewise, we can concatenate the eigenvalues to form a vectors $$ \\lambda = [\\lambda_{1},\\lambda_{2},\\cdots,\\lambda_{n}] $$ The eigendecompositon of A is then given by $$ A = Vdiag(\\lambda)V^{-1} $$ Because: $$\\begin{align} Vdiag(\\lambda)V^{-1} &amp;= diag(\\lambda)VV^{-1} \\\\ &amp;= [\\lambda_{1}v^{(1)},\\lambda_{2}v^{(2)},\\cdots,\\lambda_{n}v^{(n)}]V^{-1} \\\\ &amp;= [Av^{(1)},Av^{(2)},\\cdots,Av^{(n)}]V^{-1} \\\\ &amp;= AVV^{-1} \\\\ &amp;= A\\end{align}$$ 对于一个实对称矩阵, 始终满足 $$ A = Q \\Lambda Q^T $$ 其中, Q是一个正交矩阵, 由A的特征向量构成(即A的特征向量相互正交), 中间的矩阵是一个单位矩阵, 是各个特征向量对于的特征值. 上述性质可以用来求解以下形式的函数极值 $$ f(x) = x^TAx $$ 当x为A的特征向量时, f(x)的值为相应的特征值. 因此x为最大特征值对应的特征向量时, f(x)取最大值. 当x为最小特征值对应的特征向量时, f(x)取最小值. 奇异值分解 The singular value decomposition(SVD) provides an way to factorize a matrix into singular vector and singular values. Every real matrix has a singular value decomposition, but the same is not true of the eigenvalue decomposition. For example, if a matrix is not square, the eigendecomposition is not defined, and we must use a singular value decomposition instead. The singualr value decomposition is similar to eigendecomposition, except this time we will write A as a product of three matrices: $$A=UDV^T$$ Suppose that A is an \\(m \\times n \\) matrix. Then U is defined to be an \\(m \\times m \\) matrix, D to be an \\(m \\times n \\) matrix, and V to be an \\(n \\times n \\) matrix. Each of these matrices is defined to have a special structure. The matrices U and V are both defined to be orthogonal matrices. The matrix D is defined to be a diagonal matrix. Note that D is not necessarily square. The elements along the diagonal of D are known as the singular values of the matrix A. The columns of U are known as the left-singular vector. The columns of V are konw as the right-singular vector. We can actually interpret the singular value decomposition of A in terms of the eigendecomposition of funtions of A. The left-singular vectors of A are the eigenvectors of \\( AA^T \\). The right-singular vectors of A are the eigenvectors of \\( A^TA \\). The non-zero singular values of A are the square roots of the eigenvalues of \\( AA^T \\) or \\( A^TA \\). 关于SVD(Singular Value Decomposition)的那些事儿 A Singularly Valuable Decomposition: The SVD of a Matrix 摩尔－彭若斯广义逆Matrix inversion is not defined for matrices that are not square. Suppose we want to make a left-inverse B of a matrix A, so that we can solve a linear equation $$Ax=y$$ by left-multiplying each side to obtain $$x=By$$ Depending on the structure of the problem, it may not be possible to design a unique mapping from A to B. If A is taller than it is wide, then it is possible for this equation to have no solution. If A is wider than it is tall, then there could be multiple possible solution. The Moore-Penrose pseudoinverse allows us to make some headway in these cases. The pseudoinverse of A is defined as a matrix: $$A^+=\\lim_{\\alpha \\rightarrow 0} (A^TA + \\alpha I)^-1A^T$$ 迹操作The trace operator gives the sum of all of the diagonal entries of a matrix: $$ Tr(A) = \\sum_i A_{i,j}$$ The trace operator is useful for a variety of reasons. Some operations that are difficult to specify without resorting to summation notation can be specified using matrix products and the trace operator. For example, the trace operator provides an alternative way of writing the Frobenius norm of a matrix: $$ ||A||_F = \\sqrt{Tr(AA^T)} $$ 一个矩阵乘积序列的迹等于将最后一个矩阵提到第一个位置后组成的序列的迹. 即使最后的矩阵形状不同, 只要这个操作是允许的, 都满足此性质, 即 $$ Tr(ABC) = Tr(C AB) = Tr(BC A) $$ 扩展阅读 线性代数的本质 - 系列合集 MIT 18.06 Linear Algebra, Spring 2005 中英双语字幕 强烈推荐线性代数的本质 - 系列合集, 作者从可视化的角度由浅入深的介绍了线性代数的诸多概念, 非常有助于对线性代数中各种基础概念的直观理解.","categories":[{"name":"数学","slug":"数学","permalink":"https://lizec.top/categories/%E6%95%B0%E5%AD%A6/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://lizec.top/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"线性代数","slug":"线性代数","permalink":"https://lizec.top/tags/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/"}]},{"title":"Spring笔记之访问数据库","slug":"Spring笔记之访问数据库","date":"2019-01-13T06:16:38.000Z","updated":"2020-06-26T14:53:29.564Z","comments":true,"path":"2019/01/13/Spring笔记之访问数据库/","link":"","permalink":"https://lizec.top/2019/01/13/Spring%E7%AC%94%E8%AE%B0%E4%B9%8B%E8%AE%BF%E9%97%AE%E6%95%B0%E6%8D%AE%E5%BA%93/","excerpt":"","text":"本文介绍Spring框架中与数据库操作相关的内容, 主要包括数据库连接池以及MyBatis的基本知识. 在本文的前半部分, 假定已经按照之前的文章Spring笔记之Spring Web完成了基础的配置, 本文将此基础上介绍Spring框架下的数据库配置方法. 在本文的后半部分, 将会介绍Spring Boot环境中如何进行同样的配置. 最后, 本文还将介绍一些可以帮助我们简化MyBatis配置和数据库访问的第三方库. 配置连接池首先导入必要的依赖 123456789101112&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;8.0.13&lt;/version&gt;&lt;/dependency&gt;&lt;!-- https://mvnrepository.com/artifact/org.apache.commons/commons-dbcp2 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-dbcp2&lt;/artifactId&gt; &lt;version&gt;2.5.0&lt;/version&gt;&lt;/dependency&gt; 然后在DAOConfig中配置如下的Bean 12345678910@Bean(destroyMethod=&quot;close&quot;)public BasicDataSource dataSource() &#123; BasicDataSource dataSource = new BasicDataSource(); dataSource.setUsername(username); dataSource.setPassword(password); dataSource.setUrl(url); dataSource.setDriverClassName(driverClassName); dataSource.setMaxIdle(maxIdle); return dataSource;&#125; BasicDataSource是DataSource的一个实现, 实现了完整的连接池功能. 上述配置信息(用户名,密码等)可以通过Spring的常量注入方式进行注入, 也可以直接作为Java代码中的常量直接引用. 这里将BasicDataSource声明为一个Bean, 因此后续任何需要使用功能数据库的地方, 都可以通过向Spring声明, 从而将这个Bean注入其中, 从而保证所有的数据库访问都统一的通过连接池管理. 配置MyBatis导入依赖123456789101112131415161718192021222324252627&lt;!-- https://mvnrepository.com/artifact/org.mybatis/mybatis-spring --&gt;&lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;version&gt;1.3.1&lt;/version&gt;&lt;/dependency&gt;&lt;!-- https://mvnrepository.com/artifact/org.mybatis/mybatis --&gt;&lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.4.1&lt;/version&gt;&lt;/dependency&gt;&lt;!-- https://mvnrepository.com/artifact/org.springframework/spring-orm --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-orm&lt;/artifactId&gt; &lt;version&gt;5.1.1.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;!-- https://mvnrepository.com/artifact/org.springframework.data/spring-data-commons --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.data&lt;/groupId&gt; &lt;artifactId&gt;spring-data-commons&lt;/artifactId&gt; &lt;version&gt;2.1.1.RELEASE&lt;/version&gt;&lt;/dependency&gt; 同时导入以上四个模块才能保证@MapperScan等注解的正常使用. 之后在DAOConfig中配置SqlSessionFactoryBean和@MapperScan注解. 需要注意相关的模块直接版本号的问题, 如果没有特别的需求, 就尽量都使用最新版. 配置Config1234567891011121314151617181920212223242526272829@Configuration@MapperScan(&quot;top.lizec.mapper&quot;)@PropertySource(&quot;classpath:database.properties&quot;)public class DAOConfig &#123; // 省略数据库参数的注入代码 @Bean(destroyMethod=&quot;close&quot;) public BasicDataSource dataSource() &#123; BasicDataSource dataSource = new BasicDataSource(); dataSource.setUsername(username); dataSource.setPassword(password); dataSource.setUrl(url); dataSource.setDriverClassName(driverClassName); dataSource.setMaxIdle(maxIdle); return dataSource; &#125; @Bean // SqlSessionFactoryBean 是mybatis的类,从而连接dbcp的连接池 public SqlSessionFactoryBean sqlSessionFactory(DataSource dataSource) throws Exception &#123; SqlSessionFactoryBean sessionFactoryBean = new org.mybatis.spring.SqlSessionFactoryBean(); sessionFactoryBean.setDataSource(dataSource); PathMatchingResourcePatternResolver resolver = new PathMatchingResourcePatternResolver(); //指定mybatis的xml文件路径, 匹配mapper目录下任意位置的文件 sessionFactoryBean.setMapperLocations( resolver.getResources(&quot;classpath:/mapper/**/*.xml&quot;)); sessionFactoryBean.setTypeAliasesPackage(&quot;top.lizec.entity&quot;); return sessionFactoryBean; &#125;&#125; 以上代码有如下的几个要点 使用@MapperScan指定需要扫描的mapper类位置 通过注入包含连接池的DataSource, 使得MyBatis的连接也被连接池管理 通过setMapperLocations方法指定MyBatis配置文件的位置 使用setTypeAliasesPackage方法指定xml文件的类别名 配置XML文件MyBatis通过XML文件完成相关操作的配置. 首先可以创建一个mapper包, 其中专门放置进行数据映射的接口类. 由于具体的方法由MyBatis实现, 因此只需要对相关的方法进行声明即可, 例如 1234567891011package top.lizec.mapper;import org.springframework.stereotype.Repository;import top.lizec.entity.GasMeter;import java.util.List;@Repositorypublic interface GasMeterMapper extends AbstractMapper&lt;GasMeter&gt;&#123; GasMeter getGasMeterById(String meterId); List&lt;GasMeter&gt; getGasMeterList();&#125; 其中AbstractMapper也是一个自定义的类, 其中包含了对GasMeter的基本增删改操作, 代码如下 12345public interface AbstractMapper&lt;T&gt; &#123; void insert(T t); int update(T t); int delete(T t);&#125; 接下来创建对应的XML文件, 内容如下 123456789101112131415161718192021222324252627282930313233343536373839404142434445&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE mapper PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt;&lt;mapper namespace=&quot;top.lizec.mapper.GasMeterMapper&quot;&gt; &lt;!--通过代码指定类别名, 从而不用写全路径,且类名变为小写--&gt; &lt;!--gasMeter就是top.lizec.entity.GasMeter--&gt; &lt;resultMap id=&quot;gasMeterResultMap&quot; type=&quot;gasMeter&quot;&gt; &lt;id property=&quot;meterId&quot; column=&quot;meter_id&quot; /&gt; &lt;result property=&quot;type&quot; column=&quot;type&quot; /&gt; &lt;result property=&quot;orientation&quot; column=&quot;orientation&quot;/&gt; &lt;result property=&quot;batch&quot; column=&quot;batch&quot; /&gt; &lt;result property=&quot;producedDate&quot; column=&quot;produced_date&quot;/&gt; &lt;/resultMap&gt; &lt;insert id=&quot;insert&quot; parameterType=&quot;gasMeter&quot;&gt; INSERT INTO gas_meter(meter_id, type, orientation, batch, produced_date) VALUES (#&#123;meterId&#125;,#&#123;type&#125;,#&#123;orientation&#125;,#&#123;batch&#125;,#&#123;producedDate&#125;); &lt;/insert&gt; &lt;update id=&quot;update&quot; parameterType=&quot;gasMeter&quot;&gt; UPDATE gas_meter &lt;set&gt; &lt;if test=&quot;meterId!=null&quot;&gt;meter_id=#&#123;meterId&#125;,&lt;/if&gt; &lt;if test=&quot;type!=null&quot;&gt;type=#&#123;type&#125;,&lt;/if&gt; &lt;if test=&quot;orientation!=null&quot;&gt;orientation=#&#123;orientation&#125;,&lt;/if&gt; &lt;if test=&quot;batch!=null&quot;&gt;batch=#&#123;batch&#125;,&lt;/if&gt; &lt;if test=&quot;producedDate!=null&quot;&gt;produced_date=#&#123;producedDate&#125;&lt;/if&gt; &lt;/set&gt; WHERE meter_id = #&#123;meterId&#125;; &lt;/update&gt; &lt;delete id=&quot;delete&quot; parameterType=&quot;gasMeter&quot;&gt; DELETE FROM gas_meter WHERE meter_id = #&#123;meterId&#125; &lt;/delete&gt; &lt;select id=&quot;getGasMeterById&quot; resultMap=&quot;gasMeterResultMap&quot; parameterType=&quot;java.lang.String&quot; &gt; SELECT * FROM gas_meter WHERE meter_id = #&#123;meterId&#125; &lt;/select&gt; &lt;select id=&quot;getGasMeterList&quot; resultMap=&quot;gasMeterResultMap&quot; &gt; SELECT * FROM gas_meter ORDER BY produced_date ASC; &lt;/select&gt;&lt;/mapper&gt; 开头4行的内容总是一样的, 从第5行开始, namespace指定了这个XML文件与之对应的Java类, resultMap定义了数据库中的属性名和Java类的属性名直接的对应关系. 接下来的各种语句实现了各种增删改查操作, 具体语法不再详细介绍, 可以参考官方文档 XML 映射配置文件 Spring Boot模式Spring Boot的Spring的很多配置进行了封装, 节省了很多的工作量, 引入数据库连接池和MyBatis只需要导入如下的依赖 123456789101112&lt;!-- mybatis --&gt;&lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.3.2&lt;/version&gt;&lt;/dependency&gt;&lt;!-- 数据源 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.1.10&lt;/version&gt;&lt;/dependency&gt; 和各种starter一样, mybatis-spring-boot-starter提供了需要的全部依赖和相关的默认配置. 由于不需要编写任何的XML文件, 因此只需要在启动类加上@MapperScan注解即可完成MyBatis的配置. druid是alibaba创建了一种数据库连接池, 在配置文件中进行如下的配置 123456spring: datasource: url: jdbc:mysql://127.0.0.1:3306/document?serverTimezone=UTC&amp;allowMultiQueries=true username: root password: 123456 type: com.alibaba.druid.pool.DruidDataSource 上述配置中的大部分字段的含义都是显然的, 其中spring.datasource.type属性用于指定数据库连接池的类型, 这里指定的就是之前导入的druid. 根据日志给出的提示, 数据库驱动类会自动加载, 因此不需要手动配置driver-class-name属性. mysql-connector-java依赖的配置和前面介绍的过程一致, 此处不再赘述. TK MyBatis基本配置TK MyBatis是一个第三方库, 可以帮助我们简化MyBatis的开发. Tk提供了大量的组件, 通过直接继承这些组件, 再加上少量的配置, 就可以实现大部分的数据库功能. 首先导入依赖 12345&lt;dependency&gt; &lt;groupId&gt;tk.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mapper-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;版本号&lt;/version&gt;&lt;/dependency&gt; 接下来, 在启动类上加入扫描的注解 123@tk.mybatis.spring.annotation.MapperScan(basePackages = &quot;扫描包&quot;)@SpringBootApplicationpublic class SampleApplication &#123; ... &#125; 完成上述配置以后, 就可以创建需要的实体类和Mapper类, 例如 123456789101112131415// User.java@Datapublic class User implements Serializable &#123; private static final long serialVersionUID = -3748212043335093479L; private Integer id; private String name; private Integer sex;&#125;// mapper.java@Mapperpublic interface UserMapper extends tk.mybatis.mapper.common.Mapper&lt;User&gt; &#123;&#125; Mapper类不需要任何代码就自动实现了大量的基础功能, 常见的增删改查操作都可以直接调用. 扩展方法如果默认提供的方法不能满足要求, 还可以通过扩展来实现自己的方法. 扩展可以通过注解进行配置, 也可以使用XML文件进行配置. 具体的配置方法可以参考以下的官方文档: 2.1 simple PageHelperPageHelper是一个分页插件 SSM框架集成PageHelper插件，实现分页功能 pagehelper/Mybatis-PageHelper","categories":[{"name":"Spring笔记","slug":"Spring笔记","permalink":"https://lizec.top/categories/Spring%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://lizec.top/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"Spring","slug":"Spring","permalink":"https://lizec.top/tags/Spring/"}]},{"title":"Python笔记之符号计算","slug":"Python笔记之符号计算","date":"2019-01-12T12:45:22.000Z","updated":"2019-12-27T08:19:15.000Z","comments":true,"path":"2019/01/12/Python笔记之符号计算/","link":"","permalink":"https://lizec.top/2019/01/12/Python%E7%AC%94%E8%AE%B0%E4%B9%8B%E7%AC%A6%E5%8F%B7%E8%AE%A1%E7%AE%97/","excerpt":"","text":"在学习机器学习等内容时, 我们经常遇到需要公式推导的情景. 但实际上我们往往只需要理解其中的概念, 具体的计算过程并不重要. 因此如果符号推导过程可以由计算机完成, 则可以节省很多时间, 从而把精力集中到最核心的部分. 文本介绍Python中两个与符号计算相关的第三方库, 即Sympy库和Linalg库. 其中Sympy库用于符号计算, Linalg库是Scipy的一个子包, 用于线性代数的计算. 本文只展示部分函数的计算结果, 更多API调用和计算结果可以参考Sympy使用示例补充 基本概念由于Sympy库中主要以单独的方法为主, 较少提供类, 因此在单独使用的场景下, 可以直接导入其中所有的方法. 1from sympy import * 如果在Jupyter notebook环境中使用, 还可以执行 1init_printing(use_latex=True) 从而使输出变为LaTex格式, 由于notebook本身支持LaTeX格式的输出, 因此这样可以获得最佳的公式表现形式. 在IPython环境中, 使用此参数也可以获得更好的分数表达式效果. 如果需要输入LaTeX代码, 可以使用latex()函数, 直接从Python命令行输出的LaTeX代码已经正确的处理了部分转义字符的问题, 可以直接输出矩阵. Sympy中所有的符号对象都是不可变的, 因此所有的运算都会产生新的符号对象. 创建变量有如下的一些方式来创建符号变量 12345678910111213# 简单变量可以直接导入from sympy.abc import x,y# 使用symbols函数导入任意的表达式x, t, z, nu = symbols(&#x27;x t z nu&#x27;)# 创建函数f = Function(&#x27;f&#x27;)g = Function(&#x27;g&#x27;)(x)# 从字符串创建任意表达式str_expr = &quot;x**2 + 3*x - 1/2&quot;expr = sympify(str_expr) 基础运算由于Python支持运算符重载, 因此包括幂运算在内的所有算数运算都可以直接使用. 可以使用如下的两个方法将符号结果转化为数值结果. 方法示例 功能 expr.subs(x, 2) 将x等于2带入表达式并求表达式的值 pi.evalf(100) 计算表达式的结果并指定精度 subs方法本质是做了一个替换, 因此既可以将一个变量替换为一个常数, 也可以将一个变量替换为另外一个表达式, 甚至将一个表达式替换为另外一个表达式. 如果有多个替换, 则应该传入一个列表. evalf方法可以对表达式求任意精度的浮点结果, 例如 12&gt;&gt;&gt; pi.evalf(100)3.141592653589793238462643383279502884197169399375105820974944592307816406286208998628034825342117068 同时, 此函数也支持subs的替换功能, 从而能够更简单的求数值结果, 例如 123&gt;&gt;&gt; expr = cos(2*x)&gt;&gt;&gt; expr.evalf(subs=&#123;x: 2.4&#125;)0.0874989834394464 默认情况下, evalf提供15位小数的精度. 微积分 方法示例 功能 diff(sin(x)*exp(x), x) 导数 Derivative(expr, x, y) 创建一个不计算的导数对象 integrate(exp(x)*sin(x) + exp(x)*cos(x), x) 不定积分 integrate(sin(x**2), (x, -oo, oo)) 定积分 Integral(expr, x, y) 创建一个不计算的积分对象 doit() 求不计算对象的实际结果 limit(sin(x)/x, x, 0) 极限 更多关于极限, 扩展等内容, 可以参考官方文档的Calculus章节. 以下仅介绍导数和计算的有关内容 导数运算将自变量多次传入, 可以对一个表达式求多阶导入, 例如 1234&gt;&gt;&gt; diff(x**4, x, x, x)24⋅x&gt;&gt;&gt; diff(x**4, x, 3)24⋅x 同样, 如果要求偏导数, 也只需要按照顺序依次传入自变量即可 12expr = exp(x*y*z)diff(expr, x, y, y, z, z, z, z) 不计算结果的导数对象可以用于延迟计算或者展示中间结果. 如果Sympy对于某个表达式无法计算导数, 也会采用这种格式. 积分运算默认情况下, Sympy按照不定积分进行计算, 但是也可以指定上下限来完成定积分计算. 在Sympy中使用两个连续的小写字母o来表示无穷大, 即oo. 和导数计算类似, 可以传入多组积分上下限构成的元组来完成多次积分的运算, 例如一个经典的二重积分 $$ \\int_{-\\infty}^\\infty \\int_{-\\infty}^\\infty{e^{-x^2-y^2}} dxdy $$ 可以执行如下的代码 1integrate(exp(-x**2 - y**2), (x, -oo, oo), (y, -oo, oo)) 和导数一样, 不可积分的对象会使用一个不计算的积分结果. 当然, 这个积分结果也是可以参与后续的导数运算的, 如果最后微分和积分抵消了, 则后续结果就还是一个计算后的符号对象. 求解等式Sympy既可以求解基本的线性方程组, 也可以求解微分方程, 一些方法如下所示 方法示例 功能 Eq(x+1,4) 创建一个等式 solveset(Eq(x**2, 1), x) 求解等式的结果 linsolve([x + y + z - 1, x + y + 2*z - 3 ], (x, y, z)) 求解线性方程组 nonlinsolve([a**2 + a, a - b], [a, b]) 求解非线性方程组 dsolve(diffeq, f(x)) 求解微分方程 Python中的赋值=和==不便于重载, 因此当需要创建一个等式的时候, 需要使用Eq函数. 由于理论证明, 没有通用的方法可以判断两个符号表达式是否相等. 因此如果想判断相等, 只能使用减法, 即如果A-B等于0, 则A等于B. 或者使用equals函数, 此函数通过随机选取若干点来判断两个表达式是否相等. 1234&gt;&gt;&gt; a = cos(x)**2 - sin(x)**2&gt;&gt;&gt; b = cos(2*x)&gt;&gt;&gt; a.equals(b)True 在所有的求解方法中, 如果直接传入一个表达式, 而不是一个等式, 则默认是求解表达式等于0的时候的值. 以下内容可以参考官方文档的Solvers章节 限定解的范围, 例如在实数范围求解 求解包含三角函数的非线性方程 LambertW 求解集solveset方法本质是返回解的集合, 因此返回结果可能是包含若干个解的集合, 也可以是由实数构成的一段连续的集合. 如果无解, 则返回一个空集, 如果无法求解, 则返回一个等式构成的条件集合. 线性方程组使用linsolve可以求解任意形式的线性方程组, 参数既可以以数组的方式传入, 也可以使用矩阵的方式传入, 例如 1linsolve(Matrix(([1, 1, 1, 1], [1, 1, 2, 3])), (x, y, z)) 非线性方程组使用nonlinsolve可以求解非线性方程组, 求解范围默认是复数, 如果需要, 也可以指定为实数. 如果表达式带有参数, 也可以求解基于参数的结果, 例如下面的方程中c是一个参数, 依然可以获得解集. 123system = [a**2 + a*c, a - b]&gt;&gt;&gt; nonlinsolve(system, [a, b])&#123;(0, 0), (-c, -c)&#125; 微分方程首先创建不定的函数对象 1f, g = symbols(&#x27;f g&#x27;, cls=Function) 然后创建微分方程的等式, 例如 1diffeq = Eq(f(x).diff(x, x) - 2*f(x).diff(x) + f(x), sin(x)) 最后指定函数对象来求解最终的结果 1dsolve(diffeq, f(x)) 线性代数矩阵基础 方法示例 功能 Matrix([[1, -1], [3, 4], [0, 2]]) 创建一个矩阵 diag(1,2,3) 创建对角线为1,2,3的对角矩阵 M.shape 获得矩阵的维度信息 M.row(0) 获得第0行的内容 M.col(-1) 获得从右数第一列的内容 M.col_del(0) 删除列 M.row_del(1) 删除行 M = M.row_insert(1, Matrix([[0, 4]])) 插入列 M = M.col_insert(0, Matrix([1, -2])) 插入行 输入多个数据时, 使用嵌套的列表, 列表中的每组数据视为矩阵的一行. 而为了方便, 单层的列表会视为一个列向量. 矩阵的加法和乘法运算可以直接使用运算符, 幂运算和逆运算也可以直接使用幂运算符号. 矩阵操作 方法示例 功能 M.T 转置 det() 求行列式 rref() 执行行化简 nullspace() 求nullsapce columnspace() 求columnspace eigenvals() 求特征值 eigenvects() 求特征向量 diagonalize() 求对角矩阵 pinv() 广义逆 jordan_form() 约当标准型 对于特征值, 具有如下的结构 1234567891011&gt;&gt;&gt; M = Matrix([[3, -2, 4, -2], [5, 3, -3, -2], [5, -2, 2, -2], [5, -2, -3, 3]])&gt;&gt;&gt; M⎡3 -2 4 -2⎤⎢ ⎥⎢5 3 -3 -2⎥⎢ ⎥⎢5 -2 2 -2⎥⎢ ⎥⎣5 -2 -3 3 ⎦&gt;&gt;&gt; M.eigenvals()&#123;-2: 1, 3: 1, 5: 2&#125; 这是一个列表, 第一个参数是特征值, 第二个参数是特征值对应的跟数量, 例如上面的结果表明M有三个特征值, 分别是-2, 3, 5, 其中-2和3只有一重根, 5有两重根. 对于对角矩阵, 方法会返回两个矩阵P和D, 使得D是一个对角矩阵, 而且有 $$ M = PDP^{-1} $$ 简化表达式 方法示例 功能 expand(expr) 按照指数展开表达式 factor(expr) 因式分解 此外, Sympy还提供包括三角函数化简在内的若干方法, 由于不常用, 就不一一列举了, 详细内容可以阅读官方文档的Simplification章节 扩展阅读 Scipy:高端科学计算 用Python来学高数？解方程组？简直不敢相信！简直不可思议！ Welcome to SymPy’s documentation! 第一篇文献写于2012年, 因此其中介绍的API可能有些变化.","categories":[{"name":"Python笔记","slug":"Python笔记","permalink":"https://lizec.top/categories/Python%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://lizec.top/tags/Python/"}]},{"title":"机器学习之基础概念","slug":"机器学习之基础概念","date":"2019-01-07T13:34:57.000Z","updated":"2019-02-08T13:54:04.745Z","comments":true,"path":"2019/01/07/机器学习之基础概念/","link":"","permalink":"https://lizec.top/2019/01/07/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/","excerpt":"","text":"Deep learning is a specific kind of machine learning. In order to understand deep learning well, one must have a soild understanding of the basic principles of machine learning. 学习算法A machine learnign algorithm is an algorithm that is able to learn from data. A computer program is said to learn from expreience E with respect to some class of Tasks T and performance measure P, if its performance at tasks inT, as measured by P, improves with expreience E. 机器学习理论查准率和召回率 预测数据/实际数据 实际恶性肿瘤 实际良性肿瘤 预测恶性肿瘤 TruePositive FalsePositive 预测良性肿瘤 FalseNegative TrueNegative True/False表示预测是否正确, Positive/Negative表示预测的结果类型(即是否预测是恶心肿瘤) 查准率定义如下: $$ Precison = \\frac{TruePositive}{TruePositive+TruePositive} $$ 召回率定义如下: $$ Recall = \\frac{TruePositive}{TruePositive+FalseNegative} $$ 定义F1 Score如下: $$ F_1Score = 2\\frac{PR}{P+R} $$ 其中P表示查准率, R表示召回率. 使用F1 Score可以综合评价一个算法的效果 流行的数据库以下是一些关于机器学习的数据集, 各个数据集和说明如下: 数据库名称 说明 UC Irvine Repository 除了数据集, 还提供相关的论文链接, 比较学术 Kaggle datasets 数据集比较新, 更加多样 Registry of Open Data on AWS 提供一些关于AWS的数据集 阿里云 天池大数据竞赛 提供学习资料, 数据集, 以及基于GPU的notebook服务 如何选择算法可以参考如下的流程来选择合适的算法","categories":[{"name":"机器学习","slug":"机器学习","permalink":"https://lizec.top/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://lizec.top/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}]},{"title":"Python笔记之科学计算","slug":"Python笔记之科学计算","date":"2019-01-02T05:42:43.000Z","updated":"2021-05-24T07:00:12.000Z","comments":true,"path":"2019/01/02/Python笔记之科学计算/","link":"","permalink":"https://lizec.top/2019/01/02/Python%E7%AC%94%E8%AE%B0%E4%B9%8B%E7%A7%91%E5%AD%A6%E8%AE%A1%E7%AE%97/","excerpt":"","text":"本文介绍Python科学计算中经常使用的一些第三方库, 包括数据计算模块numpy, 科学计算模块scipy, 数据处理模块pandas, 绘图模块matplotlib等. 上述这些模块都是其他更高级模块的基础模块, 是使用Python进行科学计算的核心内容. numpy库Numpy是一个C语言实现的高性能计算库. 由于大部分代码以C语言实现, 因此在使用Python语言的前提下, 提供了很好的计算性能. 很多科学计算库甚至直接将numpy的对象作为接口的参数. 创建矩阵numpy与MATLAB类似, 以矩阵作为核心, 以下函数用于创建numpy的数组(numpy.ndarray) 方法 作用 array() 将输入的列表(或相似类型)变成一个数组 zeros((m,n)) 生成一个全0的MxN的数组 ones((m,n)) 生成一个全1的MxN的数组 full((m,n),val) 生成以val的值填充的指定维度的数组 arange() 参数与range相同，产生数组 linspace(beg,end,num) 创建一个指定范围的等分数组 concatenate() 合并多个数组, 组成一个新的数组 random.randn(m,n) 产生指定大小的符合正态分布的随机数矩阵 可以发现, Numpy提供的这些函数与MATLAB提供的基本一致, 其中的参数也基本相同. 上面的创建数组的函数, 可以在创建时使用dtype参数指定数据类型, 否则Numpy会从输入数据自动推断合适的数据类型. Numpy提供以下的一些方法来获得矩阵的基本信息 属性 作用 ndim 秩, 即维度的数量 shape 维度信息 size 元素的个数 dtype 元素的数据类型 itemsize 每个元素的大小 数据访问Numpy数组中的数据既支持常见的下标索引, 也支持切片表达式(array slice). 假设先执行如下代码 123a = np.arange(10)# a = # array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) 则对于一维数据有如下的访问方法和访问结果: 表达式 结果 说明 a[0],a[3],a[-2] (0, 3, 8) 直接访问 a[2:8:2] array([2, 4, 6]) 切片 a[3:7] array([3, 4, 5, 6]) 省略步长 a[:4] array([0, 1, 2, 3]) 省略起始 a[6:] array([6, 7, 8, 9]) 省略末尾 a[2::2] array([2, 4, 6, 8]) 省略末尾 a[::3] array([0, 3, 6, 9]) 省略起始和末尾 12345678b = np.arange(0,51,10).reshape(6,1) + np.arange(6)# b = # array([[ 0, 1, 2, 3, 4, 5],# [10, 11, 12, 13, 14, 15],# [20, 21, 22, 23, 24, 25],# [30, 31, 32, 33, 34, 35],# [40, 41, 42, 43, 44, 45],# [50, 51, 52, 53, 54, 55]]) 对于二维数据有如下的访问方法和访问结果: 表达式 结果 说明 b[0,0],b[2,-1] (0, 25) 直接访问 b[0,2:5] array([2, 3, 4]) 切片 b[2,:] array([20, 21, 22, 23, 24, 25]) 选取整行 b[:,3] array([ 3, 13, 23, 33, 43, 53]) 选取整列 从这里可以看到, 对于二维数组的表达与MATLAB基本一致, 但是Numpy总是会将列向量转化为行向量. 和MATLAB一样, Numpy也支持给一个布尔矩阵作为索引, 提取符合条件的值, 例如b[b % 2 == 0]. 最后需要注意, 大部分操作Numpy都是共享内存, 如果需要复制, 需要显式的调用copy方法 维度变换 方法 作用 reshape(shape) 不改变数组元素, 返回shape形状的数组, 原数组不变,且不拷贝数据 resize(shape) 与reshape类似, 但直接修改自己 swapaxes(ax1,ax2) 交换两个维度 flatten() 对数组降维, 返回平坦后的一维数组, 原数组不变, 且拷贝数据 astype 始终拷贝数据 tolist 转化为Python中的list类型 矩阵运算Numpy重载了必要的运算符, 因此常用的四则运算, 比较操作等都可以直接使用. 所有的基础操作都是逐元素计算的, 因此*并不是矩阵乘法, 如果需要矩阵乘法, 应该使用dot()函数. Numpy还提供了一个广播机制, 即如果两个运算对象维度不一致, 但其中一个可以扩展到相同的维度, 则自动完成维度扩展并进行计算. 例如 1b = np.arange(0,51,10).reshape(6,1) + np.arange(6) 前一项是一个6x1的矩阵, 后一项是一个1x6的矩阵, 则两者都通过复制列或者行, 变成6x6的矩阵, 然后进行加法操作. Numpy提供了一系列的数学函数, 与MATLAB相同, 这些函数都是以矩阵作为输入参数, 并返回结果的矩阵. 加载和保存数据 方法 作用 save(filename, obj) 将obj以二进制写入文件 load(filename) 读取文件中的数据 savez(filename,obj1,obj2,…) 将多个对象保存到一个文件之中 save和savez默认的文件后缀为.npy, 指定文件名时可以不指定文件后缀名. 使用load读取文件时, 必须指定文件的全名. 使用load读取savez保存的文件时, 会得到一个字典结构的对象, 其中保存了相应的对象名称和数据. Numpy还提供了loadtxt和savetxt函数来格式化的处理文件文件. 这两个函数本身操作比较复杂, 而且不一定比pandas提供的API好用, 所以具体的使用方法在需要的时候再去学习. pandas库Pandas库的主要目标是对大量数据的处理. Pandas有两个核心的数据类型, 即Series和DataFrame, 两者分别用来保存一维数据和二维数据. Pandas最初用于分析财经数据, 现在已经广泛用于数据分析. SeriesSeries是类似一维数组的字典结构, 由数据和索引组成. 构造时可以只指定数据, 此时索引自动使用从0开始的数字, 从而Series可以当做数组使用. 如果额外的指定了索引, 则可以通过索引访问数据, 就如同一个字典. 属性 作用 index 查看索引 values 查看值 当两个Series合并时, 索引相同的数据才会合并, 只有一项的索引依然存在, 但是值被设置为NaN, 这一特性称为数据对齐 DataFrameDataFrame表示二维数据, 其中每行对应同一个索引, 而每一列对应同一个属性. DataFrame也具有数据对齐的特性, 创建和使用功能方式与Series也基本相同. DataFrame支持以下的属性来获得信息 属性 作用 shape 显示维度信息 index 返回索引 columns 返回列名 values 显示值 describe 显示全部数据 DateFrame也支持以下的一些基本操作 方法 作用 head(n) 显示前n行 tail(n) 显示最后n行 loc(idx,col) idx指定索引, col指定属性列, 两者都可以指定多个项 at() 参数与loc类似，但只能选定一个值 iloc() 参数含义与loc相同，但是全部数字表示(相当访问二维数组) iat() 参数与at类似, 但是全部数字表示 drop() 删除数据 数据存储对于DataFrame, 有如下的数据存储和读取方法 方法 作用 to_csv(filename) 将数据写到csv格式的文件中 read_csv(filename) 从文件读取数据 其中 CSV(Comma-Separated Values)表示逗号分隔值, 是一种数据的表示方式. matplotlib库matplotlib是一个绘图的库, 提供了与MATLAB几乎完全相同的函数, 据说甚至可以查阅MATLAB文档来学习matplotlib中的函数. 基础设置Matplotlib库中的pyplot子包是针对Python提供的接口, 因此通常使用import matplotlib.pyplot as plt来导入这个包. 可以访问Matplotlib使用示例补充查看Matplotlib的绘图效果. 开始绘图前, 可以使用figure函数来指定图形的尺寸属性, 例如 1plt.figure(figsize=(16,10),dpi=144) 参数 默认值 推荐最大值 含义 figsize (6.4, 4.8) (16,10) 图片大小(单位为inch) dpi 100 144 每英寸点数 注意: 全部使用默认参数时, 一张图片大约10KB. 使用推荐最大值时, 一张图片大约50KB 绘制线条Matplotlib库主要通过plot函数完成绘图. plot前两个参数分别是x坐标和y坐标的列表, 第三个参数指定绘图样式, 可选值如下 颜色参数 说明 颜色参数 说明 b blue m magenta(品红) g green Y yellow r red k black w white c cyan(青色) 散点样式 英文 中文 线条参数 英文 中文 o circle 圆圈 - solid 实线 v triangle_down 下箭头 -- dashed 虚线 s square 方形 -. dashed_dot 点线 p pentagon 五角星 : dotted 点 * star 星型 None draw nothing 不绘制 h hexagon 六边形 (空格) draw nothing 不绘制 + plus 加号 (不指定) draw nothing 不绘制 D diamond 钻石 绘制时, 可以从颜色参数和样式参数之中各选择一个参数. 例如b-表示蓝色的实线线条. 注意: 程序会根据数据的范围自动调整坐标系位置和缩放比例, 因此要注意数据的范围, 使用合适的范围. 标签刻度和图例plt中有以下方法来设置图片的属性 方法 作用 方法 作用 title 设置图标题 xlable 设置x轴标题 xlim 设置/获得x轴刻度范围 set_xticks 设置x轴刻度范围 通过fig, ax = plt.subplots()获得ax对象后, 可以使用ax对象设置坐标轴的刻度和标签, 具体方法如下 方法 作用 set_xticks 设置刻度的值 set_xticklabels 设置刻度标签的值 上述方法的使用, 可以参考Matplotlib使用示例补充展示的效果. 注意: 上表中的x替换为y即为相应的y轴方法,例如ylim设置y轴刻度范围. 分块绘图与MATLAB一样, matplotlib也提供了分块绘图函数subplot. 并且与MATLAB一样, 也是使用一个3位的数字或者3个数字来指定行数,列数和索引. 例如 1234567891011x = np.linspace(-5,5,100)y1 = np.sin(x)y2 = np.cosh(x)# 设置图像大小等参数plt.figure(figsize=(10,5),dpi=144)# 指定第一个区域plt.subplot(121)plt.plot(x,y1)# 指定第二个区域plt.subplot(122)plt.plot(x,y2) subplot可以设置如下的参数 参数 说明 参数 说明 nrows subplot行数 ncols subplot列数 sharex 共享x轴刻度 sharey 共享y轴刻度 subplot_kw 创建各个subplot的关键字字典 **fig_kw 创建figure的其他参数 **fig_kw 参数使得subplot支持所有figure的参数, 例如可以在绘图时指定图形大小 1plt.subplot(2,2,figsize=(10,5)) 使用subplots_adjust函数可以控制subplot之间的间距, 如果需要使用此函数, 可以查阅官方文档的说明. 保存图表使用plt.savefig保存当前图表. 参数列表如下 参数 说明 fname 文件名, 如果指定后缀则可以自动推断保存文件的类型 dpi 图像分辨率 facecolor, edgecolor 图像背景色, 默认为w(白色) format 显式指定文件类型 bbox_inches 图片需要保留的部分, tight表示裁剪周围的全部空白 Matplotlib支持各种常见的格式, 包括png, pdf, svg, ps, eps等, 因此使用Matplotlib就可以直接创建矢量图形, 而不需要经过额外的转换. scikit-learn库scikit-learn是一个机器学习工具包, 涵盖了主流的机器学习算法, 并且提供了一致的调用接口. 不过由于不支持分布式计算, scikit-learn并不用来处理大量数据. 加载数据集scikit-learning提供了一些标准数据集, 包括用于分类训练的iris(Anderson’s Iris data set)和digits(Pen-Based Recognition of Handwritten Digits Data Set), 用于回归训练的boston house prices dataset. 这些数据集都位于sklearn的datasets包下, 例如可以使用如下的方式导入digits数据集 12from sklearn import datasetsdigits = datasets.load_digits() 由于此部分的Python代码并没有使用类型注解技术, 因此对于各个变量拥有哪些成员变量, IDE也无能为力, 无法进行补全. 但是在命令行中使用dir函数查看就可以容易的了解具体的成员变量, 通常都会包含data,feature_names, target, target_names等具有明显含义的成员. 此外每个数据集都提供了DESC变量来描述数据集的组成等信息. 训练与评估模型以下代码演示使用支持向量机对digits数据集进行分类 1234567891011121314from sklearn.model_selection import train_test_splitfrom sklearn import datasetsdigits = datasets.load_digits()# 分割数据集Xtrain, Xtest, Ytrain, Ytest = train_test_split(digits.data, digits.target, test_size=0.2, random_state=2)# 创建支持向量机并且训练clf = svm.SVC(gamma=0.001, C=100.)clf.fit(Xtrain, Ytrain)# 对训练的模型进行评分rate = clf.score(Xtest, Ytest)print(f&quot;rate = &#123;rate&#125;&quot;) 实际上对于scikit-learning中的所有模型评估对象都有如下的一些接口 方法 作用 fit 训练模型 predict 根据数据数据进行预测 score 对训练的模型进行评分 更多内容可以参考以下的连接 scikit-learn Tutorials Choosing the right estimator 模型保存与加载可以使用sklearn.externals包中的joblib对象完成模型的保存和加载, 具体代码如下所示: 12345from sklearn.externals import joblib# 保存到文件joblib.dump(clf,&#x27;digits_svm.pkl&#x27;)# 从文件加载clf2 = joblib.load(&#x27;digits_svm.pkl&#x27;)","categories":[{"name":"Python笔记","slug":"Python笔记","permalink":"https://lizec.top/categories/Python%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://lizec.top/tags/Python/"}]},{"title":"Python笔记之内置模块","slug":"Python笔记之内置模块","date":"2019-01-01T11:48:36.000Z","updated":"2021-05-31T15:19:36.000Z","comments":true,"path":"2019/01/01/Python笔记之内置模块/","link":"","permalink":"https://lizec.top/2019/01/01/Python%E7%AC%94%E8%AE%B0%E4%B9%8B%E5%86%85%E7%BD%AE%E6%A8%A1%E5%9D%97/","excerpt":"","text":"本文介绍Python常用的内置模块, 包括全部的内建函数(builtins), 以及文件操作, 系统功能,进程调度和绘图等模块的基本内容. 内置函数Python提供了一些重要的内置函数, 可以大致划分为如下的几组, 其中的大部分函数根据名称就可以了解含义, 因此在一个表中归纳, 少部分函数属于单独的模块, 因此在单独的表格中归纳. 所有的内置函数的详细信息可以使用Python的帮助系统, 或者查阅官方文档的Built-in Functions章节. 类型 方法 创建数据结构 bytearray, dict, enumerate, frozenset, list, map, set, str, tuple 数据类型转换 complex, float, int, bool, bytes, bin, hex, oct 数值计算 min, max, pow, round, sum, divmod 哈希值 hash, id 迭代器 iter, next 序列操作 range, reversed, sorted I/O操作 input, open 格式化 display, format 不常见方法 memoryview, super, slice 元操作函数 说明 compile(source,file,m) 编译一个指定的文件 eval() / exec() 将字符串视为语句或代码片段执行 dir() 返回对象包含的全部名字 type() 返回一个对象的类型 repr() 获得一个对象的可读的字符串 globals() 获得当前状态下的所有全局变量 locals() 获得当前作用域下的全部局部变量 不建议修改globals和locals返回的变量, 这些修改可能是无效的 序列操作函数 说明 range(start,end,step) 产生一个包含start,不包含end的序列, 步长为step reversed(seq) 产生一个反序的迭代器对象 sorted() 对给定的列表排序 filter(func,iter) 接受一个函数与一个可迭代对象, 产生一个过滤后的可迭代对象 map(func,iter) 接受一个函数与一个可迭代对象, 执行map操作 zip() 将多个序列的对应元素打包成一个元组, 返回这些元组构成的列表 反射操作函数 说明 hasattr 判断一个对象是否具有指定的属性 getattr getattr(x,&#39;y&#39;) 等价于 x.y setattr 对指定对象的指定属性进行赋值 delattr delattr(x, &#39;y&#39;) 等价于 del x.y isinstance 判断一个对象是否指某个类型的实例 issubclass 判断一个类是否是某个类型的子类 装饰器函数 说明 classmethod 将函数装饰为类方法 property 将函数装饰为一个只读字段(直接访问函数名获得值) staticmethod 将函数装饰为静态方法 注意: Java等语言中的类方法在Python中对应的概念是静态方法, 而不是类方法 Python虚拟环境根据实际体验, 在Linux系统使用conda, 在win系统使用PyCharm. 没有必要使用命令行处理 从Python3.6开始, 可以使用内置的模块创建虚拟环境, 例如 1python3 -m venv /path/to/new/virtual/environment 由于已经明确指定了Python的版本, 因此不会产生虚拟环境是那个Python版本的问题. 创建完成后, 进入创建的目录, 执行Script目录下的activate文件即可激活环境. 注意: 如果使用Power Shell, 应该执行Script/activate.ps1文件, 如果提示不能执行脚本, 可以先执行set-executionpolicy remotesigned Python文件处理编码与解码 函数 作用 ord() 将字符转化为对于的ASCII码 chr() 将数组转化为对于的字符 str.encode 将字符串以指定的编码转化为bytes bytes.decode 将字节数组以指定的编码转化为文字 Python 3中默认使用UTF8进行编码, 但是也可以将字符串转化为其他编码的字节数组. 例如同样的文字, 使用不同的编码方案, 可以转化为不同的字节数组: 1234&quot;中文&quot;.encode(&quot;gbk&quot;)# Out: b&#x27;\\xd6\\xd0\\xce\\xc4&#x27;&quot;中文&quot;.encode(&quot;utf8&quot;)# Out: b&#x27;\\xe4\\xb8\\xad\\xe6\\x96\\x87&#x27; 文件操作1var = open(&lt;filename&gt;,&lt;mode=&#x27;r&#x27;&gt;&lt;buffering=-1&gt;) 使用参数与C基本相同,其中buffering为0表示不缓冲，-1为使用系统指定的缓冲区大小，如果为正值，则为正值指定的缓冲区大小 方法 作用 open() 打开一个文件, 返回一个文件对象 f.read(size) 不使用参数则返回包含整个文件内容的字符串，否则返回指定字节的数据 f.readline() 返回文件下一行的内容 f.readlines() 返回整个文件内容的列表，每项是以换行符结尾的字符串 f.write() 把数据写入文件，接受的对象是字符串，可以使用str（）转换 f.writelines() 接受一个列表，将其写入文件中 f.seek() 文件指针偏移操作 f.close() 关闭文件 从提供的API来看, Python的文件操作与各种编程语言并没有太大的区别. 根据文档, open函数返回的是一个基于缓冲IO的TextIOWrapper, 因此开启文件时除了可以指定文件读取类型, 还可以指定缓冲区大小. 有关的函数都提供了文档, 可以使用help函数查阅. 文件使用完毕需要调用close()函数. 遍历文件通用代码框架123with open(&quot;somefile&quot;,&quot;r&quot;) as f: for line in f: # do something for every line. 因为TextIOWrapper中实现了迭代器相关的函数, 因此可以直接进行遍历, 相当于f.readlines(). 通过with语句, 实现文件的自动关闭. 高级APIPython的shutil提供了关于文件操作的高级API, 可以参考 shutil — High-level file operations — Python 3.8.1 documentation Python 命令行参数对于基本的参数处理, 可以使用内置的sys模块, 例如 1234import sysprint &#x27;参数个数为:&#x27;, len(sys.argv), &#x27;个参数。&#x27;print &#x27;参数列表:&#x27;, str(sys.argv) 其中sys.argv以列表的形式包含了所有给定的命令行参数, 与其他语言中的规则一样, 其中第0个参数是文件本身. getopt模块getopt模块是专门做参数解析的模块, 主要是针对需要带参数的情形, 支持短选项模式(-)和长选项模式(–), 基本用法如下 12345678910opts, args = getopt.getopt(argv,&quot;hi:o:&quot;,[&quot;ifile=&quot;,&quot;ofile=&quot;])for opt, arg in opts: if opt == &#x27;-h&#x27;: print &#x27;test.py -i &lt;inputfile&gt; -o &lt;outputfile&gt;&#x27; sys.exit() elif opt in (&quot;-i&quot;, &quot;--ifile&quot;): inputfile = arg elif opt in (&quot;-o&quot;, &quot;--ofile&quot;): outputfile = arg Python 日志处理按照如下的方式导入logging库并创建logger对象 1234import logginglogging.basicConfig(level=logging.INFO, format=&#x27;%(asctime)s - %(name)s - %(levelname)s - %(message)s&#x27;)logger = logging.getLogger(__name__) 由于全局创建的对象可全局访问, 因此如果需要在其他文件中使用, 可以直接导入这个对象. Python日志库logging总结 Python OS编程使用os库 方法 操作 getcwd() 获得当前工作目录 listdir(path) 返回指定目录下所有的文件和目录名 remove() 删除一个文件 removedirs(path) 删除多个文件 chdir(path) 更改当前目录到指定目录 mkdir(path) 新建一个目录 rmdir(name) 删除目录 rename(old,new) 更改文件名 使用os.path库os.path是os的一个字库, 主要负责与路径相关的操作 方法 作用 isfile() 检验路径是否是一个文件 isdir() 检验路径是否是一个目录 exists() 判断路径是否存在 splitext() 分离扩展名（返回一个二元组，分别包含文件名和扩展名） split() 返回一个路径的目录名和文件名 dirname() 获得路径名 basename() 获得文件名 getsize() 获得文件大小，单位是字节 join(path,name) 将路径与文件名组合获得绝对路径 遍历目录12for root, dirs, files in os.walk(&#x27;.&#x27;): # ... os库中提供了一个walk方法, 该方法可以遍历指定目录, 使用方式如上所示. 每一轮遍历, root都指向一个目录A, dirs中保存A中所有的子目录, files保存A中的全部文件. walk函数按照深度优先的方式依次遍历所有的目录. Python事件调度Python提供了sched库来实现事件调度有关的操作, sched内部维护一个事件队列, 可以安全的在多线程场景下使用. 以下是一些主要的方法 方法 作用 scheduler() 创建一个调度任务对象 enter() 加入一个事件 run() 运行调度任务中的全部调度事件 cancel() 取消某个调度事件 以下代码演示sched的基本使用, 如果需要更详细的内容, 可以查阅标准库的文档 123456789101112131415161718192021import sched, times = sched.scheduler(time.time, time.sleep)def print_time(a=&#x27;default&#x27;): print(&quot;From print_time&quot;, time.time(), a)def print_some_times(): print(time.time()) s.enter(10, 1, print_time) s.enter(5, 2, print_time, argument=(&#x27;positional&#x27;,)) s.enter(5, 1, print_time, kwargs=&#123;&#x27;a&#x27;: &#x27;keyword&#x27;&#125;) s.run() print(time.time())print_some_times()# Output:# 930343690.257# From print_time 930343695.274 positional# From print_time 930343695.275 keyword# From print_time 930343700.273 default# 930343700.276 TurtleTurtle是一个Python内置的绘图库, 通过Turtle可以绘制简单的线条. 一些主要的方法如下所示 方法 含义 Tultle() 定义一个turtle对象, 该对象可以使用turtle的相关函数 setup(high,wide,x,y) 指定窗口的高和长, 并指定窗口左上角的坐标在屏幕上的坐标 seth(angle) 指定运动的方向, 其中angle为角度制，数值与方向与数学定义相同 pensize(x) 指定运动轨迹的粗细, x为像素单位 circle(rad,angle) 圆形运动, rad正值表示圆心在左侧, 负值表示圆心在右侧, angle表示爬行的角度的角度值 turtle.fd(x) 向前爬行, x表示爬行距离 扩展阅读以下的文章给出了Python标准库中一些其他的模块的简要介绍 Brief Tour of the Standard Library – Part I Brief Tour of the Standard Library – Part II 关于各个模块的详细介绍, 可以查看Python标准库的文档.","categories":[{"name":"Python笔记","slug":"Python笔记","permalink":"https://lizec.top/categories/Python%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://lizec.top/tags/Python/"}]},{"title":"机器学习之开发工具介绍","slug":"机器学习之开发工具介绍","date":"2018-12-31T11:42:30.000Z","updated":"2019-08-02T07:45:11.474Z","comments":true,"path":"2018/12/31/机器学习之开发工具介绍/","link":"","permalink":"https://lizec.top/2018/12/31/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7%E4%BB%8B%E7%BB%8D/","excerpt":"","text":"本文介绍使用Python进行机器学习过程中经常使用的两个工具, 即 IPython 和 Jupyter. IPythonIPython实际上是一个加强的Python命令行工具, 与直接使用Python命令行相比, IPython具有代码提示, 魔术指令, 语法高亮等增强功能, 因此更适合在命令行中使用. 基本操作IPython提供了一个类EMACS的快捷键方案, 比较常用的指令如下 指令 作用 C+A 移动到本行的开头 C+E 移动到本行的末尾 C+U 删除光标所在位置之前的所有字符 C+K 删除光标所在位置以及之后的所有字符 C+L 清除屏幕 C+P 向前(Previous)移动 C+N 向后(Next)移动 魔术指令魔术指令(The magic function)是IPython提供的一系列的指令, 这些指令可以对IPython本身或者Python进行控制. 魔术指令分为面向行的指令(line-oriented)和面向块的指令(cell-oriented). 面向行的指令以%开头, 面向块的指令以%%开头. IPython默认启动%automagic, 因此输入面向行的指令时, 可以省略%, 但是面向块的指令始终需要以%%开头. 以下是一些常用的魔术指令 指令 效果 %quickref 显示IPython简要的文档 %magic 显示所有的魔术指令详细文档 %reset 删除当前环境下所有的指令 %rehashx 使大部分shell指令不需要!就直接执行 %run 运行一个脚本,并将其中的变量导入 %who/whos 显示当前的变量 %timeit 统计一条指令消耗的时间 %matplotlib inline 启用IPython对绘图的额外支持 帮助系统在任意指令的开头或者结尾加上一个?即可查询此模块/函数的文档. 使用??可以查询文档和源代码(如果有源代码). 此外, 帮助系统还支持使用*进行搜索, 例如np.*load*?将会显示numpy包中所有包含load的函数. 输入和输出变量IPython中使用_和__保存了最近的两个输出结果. 每一行的输入和输出也都保存在相应的变量之中. 例如_2保存了第二行的输入, _i2保存了第二行的输出结果. IPython的这一保存机制将导致所有的对象都始终存在引用, 而无法被垃圾回收. 如果在使用过程中会频繁的创建大对象, 注意使用%xdel来删除不必要的引用, 或者使用%reset来重置. 与OS交互在IPython中可以执行任意shell指令, 只需要在相应的指令之前加上一个!. 一些常见的指令如下表所示 指令 说明 ! &lt;cmd&gt; 执行shell执行 out = !&lt;cmd&gt; 将shell执行结果赋值给out变量 %bookmark 启用IPython目录书签系统 %pushd/%popd 使用堆栈效果的目录切换 %env 显示环境变量 使用%bookmark &lt;name&gt; &lt;path&gt;的格式, 给&lt;path&gt;创建一个名称, 之后就可以使用&lt;name&gt;代表这个路径进行切换. bookmark的操作是自动持久化的. 使用-l参数可以列出所有创建的书签. JupyterJupyter notebook是一个基于Web的图形编程界面, 可以在其中编写Markdown文本和Python代码, 并且直接运行其中的代码. 除了在网页上直接展示以外, Jupyter还支持将页面保存为Markdowm, HTML, pdf 等多种格式. 在命令行中输入jupyer notebook来启动程序. 常用命令Jupyter采用了类似VIM的键位, 因此对于VIM的常见操作(移动, 添加, 删除等)都是同样的快捷键. 下面是一些常用的指令 指令 作用 Esc 进入命令模式 Enter 进入编辑模式 A 在当前Cell之上插入一个新的Cell B 在当前Cell之下插入一个新的Cell C+Enter 执行当前Cell代码 M+Enter 执行当前Cell代码,并且移动到下一个Cell 除了以上的指令以外, 还可以在点击Help-&gt;Keyboard Shortcut查看全部的快捷键, 点击Help-&gt;User Interface Tour查看用户界面引导. 我的看法虽然只要随便搜索一下, 就可以看到很多文章推荐使用这两个工具. 但我个人的体验是这两个工具对于初学者来说, 都不太顺手. IPython的解释执行机制不太适合需要反复执行某一段代码的场景. 如果执行的代码都是单一的语句, 那么IPython用起来还是非常舒服的, 但如果涉及到更复杂的结构, 例如循环语句或者定义函数, 那么这种一行一行输入的模式显然就不太合适了. 对于这个问题, Jupyter有一定程度的弥补, 但Jupyter的代码补全不太好用, 如果不熟悉库的参数, Jupyter的体验就如同记事本写代码. 因此, 如果对使用的库非常熟悉了, 那么可以考虑使用Jupyter, 但如果是新学习一个库, 那么还是建议先使用一个有更友好的代码补全和文档的IDE.","categories":[{"name":"机器学习","slug":"机器学习","permalink":"https://lizec.top/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://lizec.top/tags/Python/"},{"name":"机器学习","slug":"机器学习","permalink":"https://lizec.top/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}]},{"title":"Python笔记之基础知识","slug":"Python笔记之基础知识","date":"2018-12-30T04:09:42.000Z","updated":"2021-05-31T14:40:55.000Z","comments":true,"path":"2018/12/30/Python笔记之基础知识/","link":"","permalink":"https://lizec.top/2018/12/30/Python%E7%AC%94%E8%AE%B0%E4%B9%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/","excerpt":"","text":"本文对Python语言进行一个简单的回顾, 对Python中各种语法进行了简单的介绍, 并且对帮助系统进行了测试, 从而保证在阅读Python代码时不至于遇到无法理解的语法. 在本文的最后, 介绍了Python中模块的有关内容, 以便于后续安装和使用第三方的模块. Python基本概念 Python有三种数值类型,即整型,浮点型以及复数类型,而且三者可以通过int(),double()和complex()函数进行转化. Python的整型可以表示任意大的数字, 浮点型表示范围与其他语言一致 Python支持幂运算, 使用 **表示 Python可以使用连续的比较符号, 例如3 &lt; x &lt; 5等于3 &lt; x and x &lt; 5 在函数外部的变量是全局变量, 在函数内部的变量是局部变量 使用global语句, 可以将一个变量强制认为是全局变量 for循环采取for &lt;var&gt; in &lt;sequence&gt;格式, python全部都是传递引用, 因此for循环中的变量也是引用变量. while语句支持接一个else语句, 当while第一次就不满足条件时跳到else语句 if语句与其他语言相同,else if简写为elif 使用help函数来获得一个Object的帮助文档 help既可以获取某个类的文档, 也可以获取某个函数的文档. 例如 12345&gt;&gt;&gt;help（abs）Help on built-in function abs in module builtins:abs(x, /) Return the absolute value of the argument. 内置方法和标准库方法都可以通过帮助系统直接查阅说明, 比查阅在线文档更有效率 异常处理try语句完整格式如下所示: 123456789101112try: Normal execution blockexcept A as e: Exception A handleexcept B: Exception B handleexcept: Other exception handleelse: if no exception,get herefinally: print(&quot;finally&quot;) Python的异常继承结构如下所示, 其中有两点需要注意 所有异常的父类是BaseException 常见的业务相关异常的父类是Exception 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950BaseException +-- SystemExit +-- KeyboardInterrupt +-- GeneratorExit +-- Exception +-- StopIteration +-- StandardError | +-- BufferError | +-- ArithmeticError | | +-- FloatingPointError | | +-- OverflowError | | +-- ZeroDivisionError | +-- AssertionError | +-- AttributeError | +-- EnvironmentError | | +-- IOError | | +-- OSError | | +-- WindowsError (Windows) | | +-- VMSError (VMS) | +-- EOFError | +-- ImportError | +-- LookupError | | +-- IndexError | | +-- KeyError | +-- MemoryError | +-- NameError | | +-- UnboundLocalError | +-- ReferenceError | +-- RuntimeError | | +-- NotImplementedError | +-- SyntaxError | | +-- IndentationError | | +-- TabError | +-- SystemError | +-- TypeError | +-- ValueError | +-- UnicodeError | +-- UnicodeDecodeError | +-- UnicodeEncodeError | +-- UnicodeTranslateError +-- Warning +-- DeprecationWarning +-- PendingDeprecationWarning +-- RuntimeWarning +-- SyntaxWarning +-- UserWarning +-- FutureWarning +-- ImportWarning +-- UnicodeWarning +-- BytesWarning Python异常类的继承关系 with语句就如同Java中管理资源的try语句, with语句有如下的等价关系 123456789101112with open(&quot;a.txt&quot;) as f: r = f.read()&lt;==&gt;f=open(&#x27;file_name&#x27;,&#x27;r&#x27;)try: r=f.read()except: passfinally: f.close() 本节可以阅读以下补充内容 python with关键字学习 浅谈 Python 的 with 语句 Python字符串操作 使用string[i]来访问字符串中的第i个字符 可以通过string[&lt;start&gt;,&lt;end&gt;]来返回一个字符串子串 可以使用负数来从右侧索引(最右侧的字符是-1,倒数第二个字符是-2) 使用+将两个字符串链接,不支持连接其他对象 从Python3.6开始, python提供一种新的字符串格式化方法, 称为f-String. 通过f-String可以直接引用变量, 例如 123name = &quot;LiZeC&quot;print(f&quot;my name is &#123;name&#125;&quot;)#output: my name is LiZeC 关于f-String有如下的一些要点 内部的引号可以根据需要灵活使用, 只要不发生冲突即可 如果需要输出大括号, 使用&#123;&#123;`和`&#125;&#125;表示 f-String格式化的采取&#123;content:format&#125;格式, 例如&#123;x:2.6f&#125;表示将x以浮点数格式输出, 且整数部分至少保留2位, 小数部分至少保留6位. 各种操作符的含义与C语言的表示方法基本相同. 关于f-string的格式化内容, 可以参考以下的文章 Python格式化字符串f-string概览 Python数据结构Python提供了一系列的内置数据结构, 每个数据结构都通过重载运算符等方式获得了一些简便操作, 使用help(&lt;name&gt;)可以容易的获得这些数据结构的文档. 数据结构 补充说明 元组(tuple) 可以使用元组同时给多个变量赋值 列表(list) 可以使用in表达式判断一个元素是否位于列表之中 字典(dict) 通过可变参数实现了几种特殊的构造方式 集合(set) 重载了各种符号, 从而可以简单的进行集合操作 集合支持可变集合与不可变集合, 分别使用set()和frozenset()创建. 上述所有的数据结构都可以使用for语句进行迭代访问, 字典结构默认访问key, 可以调用items()函数来同时迭代key和value. Python数据结构的操作可以划分为两个类别. 第一类是函数类型的API, 第二类是重载运算符构成的API. 对于大部分集合类型, 都实现了对+,*, +=等操作的重载, 对于集合类型, 还重载了逻辑运算符&amp;, |等. 可以通过dir(list)的方法查看集合类型的所有属性, 对于其中感兴趣的属性, 可以进一步使用help函数查看. 例如查询list的属性, 可以看到一个平常基本没有使用过的count属性, 使用help函数, 可以得到相应的说明 12345In [19]: help(list.count)Help on method_descriptor:count(...) L.count(value) -&gt; integer -- return number of occurrences of value 对于基础类型和标准库中的方法, 使用python内置的帮助系统往往比查询在线文档能更快的获得需要的信息. Python函数Python函数的结构如下 123def functionName(arg,*args,**kwargs): &#x27;&#x27;&#x27;Doc String&#x27;&#x27;&#x27; &lt;body&gt; 其中涉及的一些概念如下表: 名称 含义 Doc String 函数开始的第一行可以使用一个字符串对函数功能进行解释, 可以使用func.__doc__查看 默认参数 Python支持默认参数, 默认参数必须在所有的非默认参数列表后面 关键字参数 使用参数名 = 参数值来以任意的顺序对函数参数赋值 返回值 不需要定义函数返回值类型, 可以返回任何类型的数据, 可以返回多个变量(等于返回一个元组) 除了普通的参数传递以外, Python还支持两种特殊的参数传递方式 *args声明了可变长位置参数, 多余的参数会构成一个元组, 放入args之中 **kwargs声明了可变长关键字参数, 多余的关键字参数构成一个字典, 放入kwargs之中 12345678910def test_args(name, age, *args, **kwargs): print(f&quot;name = &#123;name&#125;,age=&#123;age&#125;,args=&#123;args&#125;,kwargs=&#123;kwargs&#125;&quot;)test_args(name=&quot;LiZeC&quot;, age=5, id=123321, message=&quot;mess&quot;)test_args(&quot;LiZeC&quot;, 5, 233, &quot;Apple&quot;)# output:# name = LiZeC,age=5,args=(),kwargs=&#123;&#x27;id&#x27;: 123321, &#x27;message&#x27;: &#x27;mess&#x27;&#125;# name = LiZeC,age=5,args=(233, &#x27;Apple&#x27;),kwargs=&#123;&#125; 强制位置参数与强制命名参数对于一个如下定义的函数 12def f(a, b, /, c, *, d, e): pass 其中的/表示再此之前的参数强制使用位置参数的方式进行调用, *表示再此之后的参数强制使用命名参数调用. 这种表达方式在文档中非常常见, 例如 1234567Help on built-in function sorted in module builtins:sorted(iterable, /, *, key=None, reverse=False) Return a new list containing all items from the iterable in ascending order. A custom key function can be supplied to customize the sort order, and the reverse flag can be set to request the result in descending order. 这表明了sorted需要的可迭代对象只能以位置参数的方式传入, 而后面两个参数只能以命名参数的形式传入. Python面向对象Python中的一个类通常具有如下的结构 12345678class Me(SuperName): &#x27;Doc String&#x27; def __init__(self): self.name = &quot;LiZeC&quot; self.age = 5 def hello(self, to_name): print(f&quot;Hello &#123;to_name&#125;, I am &#123;self.name&#125;&quot;) 其中涉及的一些概念如下表 名称 含义 self参数 self代表类的实例,每个实例方法都需要将self作为第一个参数 __init__ 构造函数, 由于Python不能直接声明变量, 因此可以在构造函数中添加属性 SuperName 继承的父类, Python可以多继承 在调用实例方法时, 例如me.hello(“Alice”)，解释器会自动替换为Me.hello(me,”Alice”). 如果一个方法不包含self, 则只能作为静态方法调用. 此外self并不是关键字, 仅仅是一种约定习惯. 成员函数命名规则 命名格式 说明 _xx protected变量, 使用from XX import时不会导入 __xx private变量, 仅类内部可访问,调用时名字被改变 __xx__ 特列方法, 用于重载运算符或者控制特殊函数的行为 例如在Foo类中的__boo方法的方法名变成Foo_boo, 因此虽然无法直接访问__boo方法,但是还是可以通过Foo_boo方法访问. 重载运算符以下方法可以重载类的基本操作: 函数 作用 函数 作用 __init__ 构造函数，在生成对象时调用 __del__ 析构函数，释放对象时使用 __setitem__ 重载使用中括号赋值的方法 __getitem__ 重载使用中括号取值的方法 __delitem__ 控制使用del删除时的操作 __contains__ 重载in操作符 以下方法可以重载基本函数的返回结果: 方法 重载的函数 作用 __repr__ repr() 输出此类的介绍 __len__ len() 返回此类的长度(通常指集合类元素个数) __iter__ iter() 返回此类的迭代器 __next__ next() 根据迭代器, 返回下一个元素的值 __str__ str() 返回此类转换的字符串 此外, 还有以下的一系列函数:__add__,__sub__,__mul__,__truediv__,__mod__,__pow__等函数,分别重载+,-,*,/等符号.__eq__, __gt__, __ge__, __lt__, __le__, 分别重载==,&gt;,&gt;=等符号. 另外, 如果想要实现迭代效果, 还可以使用yield关键字, 使用此方法相当于自动实现__iter__和__next__, 并且在两次调用之间还会自动保存局部变量, 例如: 123def reverse(data): for index in range(len(data)-1, -1, -1): yield data[index] 继承规则12345678910111213class Base: def __init__(self): self.base = 0class A(Base): def __init__(self): Base.__init__(self) self.a = 1class B(Base): def __init(self): super().__init(self) self.b = 2 需要调用父类方法时, 以父类名称加相应的函数调用父类方法并将子类的self变量传入即可, 这一调用相当于借助父类的函数在自己的self上完成相关的操作. 由于成员变量默认都是公共变量, 子类可以访问和覆盖任何父类的变量, 因此子类定义的变量不要与父类变量相同 由于Python支持多继承, 因此可能出现菱形继承的情况, 为了防止祖父类被多次调用, 可以使用super关键字进行调用, 此时Python通过搜索机制使租父类只被调用一次. super语法在Python 2和Python 3中不同, Python 3中使用 super().xxx替代了Python 2中的super(Class, self).xxx Python模块 使用import &lt;lib&gt;后, 可以使用库中方法的全限定名来调用 使用import &lt;lib&gt; as &lt;name&gt;后, 可以使用创建的别名来使用导入的库 使用from &lt;lib&gt; import &lt;func&gt;后, 可以直接使用导入的函数 使用import时,仅仅导入了模块的名称, 这个模块(也就是这个文件)中的任何类或者函数都需要加上模块的名称才能使用, 而使用from时, 对应的函数或者类将被直接导入. 如果一个包的内部还有子包, 则有如下的两种导入方式 : 使用import sound.effects.echo, 则需要使用完整的名称才能调用echo中的函数 使用from sound.effects import echo, 则可以直接使用echo作为前缀调用echo的函数 因此, from语句既可以导入函数, 也可以导入模块, 甚至也可以导入一个子包, 最终效果就是导入的项目可以忽略其前缀而直接使用. 而import语句永远都只导入一个名称, 而不做任何其他的工作. 相对导入上一节介绍的导入方法称为绝对导入, 即所有需要导入的函数和类都从包的顶级目录指定路径. 通常情况下, 这是导入方法和类的首选方案. 但如果在构建一个复杂的包, 就可能在包内输入一个非常长的引用路径, 例如from package1.subpackage2.subpackage3.subpackage4.module5 import function6. 在这种情况下可以考虑使用相对导入来简化导入名称. 123from .some_module import some_functionfrom ..some_package import some_classfrom . import some_class 相对导入的语法与相对路径的语法类似, .表示当前路径, ..表示当前路径的父目录, ...表示当前路径的祖父目录. 由于相对导入和相对位置有关, 因此一旦当前文件改变了位置, 相对路径都需要改变. Python中的绝对导入和相对导入 创建模块模块实际上就是一个.py文件, 此文件的文件名就是模块的名称. 由模块和有层次的子包组成的模块称为包. 当定义一个包时, 此文件夹下必须有__init__.py文件, 此文件用于标识当前文件夹是一个包, 可以为空. 关于模块的更多内容, 可以阅读以下内容 Python _init_.py 作用详解 Python包中_init_.py作用 模块搜索路径当导入一个包时, Python首先搜索内置的包中是否含有指定的名称. 如果没有则搜索sys.path中指定的路径中是否包含指定的名称. sys.path的值由以下的位置组成 执行文件时文件所在的目录, 或者直接执行时的当前目录 PYTHONPATH的值 一个模块的子模块之间可以使用绝对路径进行引用, 例如sound的两个子包之间都可以使用import sound.XXX来导入sound的子包. 安装第三方库Python提供了大量的第三方库, 一般情况下可以选择自定义安装, pip安装和文件安装, 各种安装方式的对比如下 安装方式 说明 pip安装 使用python提供的pip程序 自定义安装 在库所在的网站，根据指示下载安装 文件安装 通过.whl文件直接安装 通常情况下, 应该优先考虑使用pip安装, 如果无法安装, 再考虑使用自定义安装, 最后考虑使用文件安装. pip 常用命令 指令 作用 install &lt;package&gt; 安装库 uninstall &lt;package&gt; 卸载库 list 列出已安装的库信息 show &lt;package&gt; 列出已安装的库的详细信息 search &lt;keyword&gt; 通过PyPI搜索库 help &lt;cmdName&gt; 帮助命令 install时可以使用-U参数来更新一个库 list时可以使用--outdated显示可更新的库 库文件安装如果需要使用库文件安装, 首选需要一个可以下载库文件的网站, 这里提供一个非官方的网站Unofficial Windows Binaries for Python Extension Packages 下载对应的库文件后，使用pip install &lt;filename&gt;安装 配置镜像升级 pip 到最新的版本, 然后配置清华镜像为默认镜像源： 12pip install -i https://pypi.tuna.tsinghua.edu.cn/simple pip -Upip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple","categories":[{"name":"Python笔记","slug":"Python笔记","permalink":"https://lizec.top/categories/Python%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://lizec.top/tags/Python/"}]},{"title":"Spring笔记之Spring Web","slug":"Spring笔记之SpringWeb","date":"2018-12-23T08:18:01.000Z","updated":"2019-01-15T12:48:16.830Z","comments":true,"path":"2018/12/23/Spring笔记之SpringWeb/","link":"","permalink":"https://lizec.top/2018/12/23/Spring%E7%AC%94%E8%AE%B0%E4%B9%8BSpringWeb/","excerpt":"","text":"在Spring中, 最常使用的技术就是MVC框架, 使用Sping中的MVC框架, 可以实现将HTTP URL 映射到Controller某个方法上, 将HTTP 参数映射到Controller方法的参数上, 对参数进行检验, 调用视图等功能. 本文涉及的代码均来自一个Spring Web项目 fuelGasSystem, 此项目已经开源在Github上, 欢迎交流. 基础知识通常情况下, MVC项目按照如下的结构放置代码 包名 注解 内容 controller @Controller MVC的控制器 service @Service 业务逻辑有关的代码 mapper @Repository 数据映射相关的代码 entity N/A 业务实体类 conf @Configuration 配置类 控制器接受到请求后, 首先完成请求参数的处理, 然后调用service层的方法实现业务逻辑. service层通过mapper层提供的数据库方法完成需要的业务逻辑. mapper层通常由框架实现具体的操作, 因此仅仅需要提供方法声明, 然后使用配置文件配置具体的行为. 关于Spring Web的基础知识 , 还可以参考以下的内容 Spring Mybatis Maven 项目搭建（Java配置） 关于web.xml配置的那些事儿 Spring MVC配置首先导入需要的依赖 123456&lt;!-- https://mvnrepository.com/artifact/org.springframework/spring-webmvc --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;5.1.1.RELEASE&lt;/version&gt;&lt;/dependency&gt; 之后进行配置, 首先创建一个conf包, 然后创建一个SpringInitializer类, 这个类需要继承AbstractAnnotationConfigDispatcherServletInitializer类, 并且重载其中的三个方法, 代码如下所示 123456789101112131415161718package top.lizec.config;import org.springframework.web.servlet.support.AbstractAnnotationConfigDispatcherServletInitializer;public class SpringInitializer extends AbstractAnnotationConfigDispatcherServletInitializer &#123; protected Class&lt;?&gt;[] getRootConfigClasses() &#123; return new Class[]&#123;DAOConfig.class, WebSecurityConfig.class&#125;; &#125; protected Class&lt;?&gt;[] getServletConfigClasses() &#123; return new Class[]&#123;SpringWebConfig.class&#125;; &#125; protected String[] getServletMappings() &#123; return new String[]&#123;&quot;/&quot;&#125;; &#125;&#125; 可以看到, 代码中引用了另外三个类, 分别是DAOConfig, WebSecurityConfig和SpringWebConfig. 这三个类都是之后需要创建的, 从名称可以容易的指导它们分别用于配置数据访问, 访问安全和Spring web. 首先创建SpringWebConfig, 并且使其实现WebMvcConfigurer接口. 从Java 8开始, 接口可以提供默认实现, 因此WebMvcConfigurer中以及包含了很多默认的实现, 但同时我们也可以对默写感兴趣的部分进行实现,从而替换默认的实现, 代码如下所示 12345678910111213141516171819202122package top.lizec.config;// 省略import语句@Configuration@EnableWebMvc@ComponentScan(&quot;top.lizec&quot;)public class SpringWebConfig implements WebMvcConfigurer &#123; // 如果不添加此转换,则无法访问静态文件 public void addResourceHandlers(ResourceHandlerRegistry registry) &#123; registry.addResourceHandler(&quot;/**&quot;).addResourceLocations(&quot;/&quot;); //registry.addResourceHandler(&quot;/static/**&quot;).addResourceLocations(&quot;/static/&quot;); //registry.addResourceHandler(&quot;*.html&quot;).addResourceLocations(&quot;/&quot;); &#125; @Override public void addViewControllers(ViewControllerRegistry registry) &#123; // 将指定的URL请求转发到指定的视图 // 是一种简化控制器的方法 registry.addViewController(&quot;/login&quot;).setViewName(&quot;login&quot;); &#125;&#125; 其中@Configuration表示这是一个配置文件, @EnableWebMvc表示开启Web MVC的支持, @ComponentScan(“top.lizec”)指定了需要扫描的包路径. 在SpringWebConfig中主要实现了两个方法, 其中第一个方法完成对静态资源的处理, 第二个方法完成对视图控制器的一些基本处理. 关于WebMvcConfigurer的更多配置可以参考以下的内容 使用WebMvcConfigurer配置SpringMVC Controller层配置在Controller层, 首先需要使用@Controller注解将当前类声明为一个控制器, 然后使用@RequestMapping注解来实现HTTP请求与方法之间的映射. @RequestMapping既可以注解在类上, 也可以注解在方法上, 最终的路径由类上的注解和方法上的注解共同决定. 默认情况下, 被注解的方法应该返回一个字符串, 表示需要返回的视图的名称. 但如果只需要返回字符串, 则可以加上@ResponseBody注解, 从而表示系统应该讲返回值转为为字符串, 然后直接返回给客户端. 示例如下所示: 1234@RequestMapping(&quot;/index.json&quot;)public @ResponseBody String say() &#123; return &quot;Hello World&quot;;&#125; 如果整个类都是直接返回字符串, 则可以使用@RestController替换原来的@Controller, 这相当于给每个方法都加上@ResponseBody. 方法参数对于控制器中的方法, 可以定义为无参数的方法, 也可以定义为如下的一些类型, Spring会自动将这些变量注入当方法之中. 参数类型 含义 参数类型 含义 @RequestParam 将HTTP请求的参数转化为指定的类型 @RequestHeader 将HTTP头部的参数转化为指定的类型 Model 表示视图中使用的Model部分 ModelAndView 包含模型和视图的对象 @PathVariable 将URL中的值映射到指定的变量 JavaBean 将HTTP参数映射为指定的JavaBean @ModelAttribute 将注解的变量作为Model的一个属性 MultipartFile 代表上传的文件 HttpServletRequest 代表HTTP Request HttpServletResponse 代表HTTP Response 转发和重定向通常情况下, Controller返回表示视图的字符串. 但如果返回一个以redirect:为前缀的URL, 则表示重定向到指定的URL. 例如 12345@RequestMapping(&quot;/order/saveorder.html&quot;)public String saveOrder(Order order) &#123; Long orderId = service.addOrder(order); return &quot;redirect:/order/detail.html?orderId=&quot;+orderId;&#125; 同理, 返回一个以foward:为前缀的URL, 则表示转发到指定的URL. 错误处理在Spring中产生的错误, 需要在Web.xml进行配置(目前似乎还无法进行Java配置), 将以下的内容放置到&lt;web-app&gt;标签内 123&lt;error-page&gt; &lt;location&gt;/error&lt;/location&gt;&lt;/error-page&gt; 在Spring Boot中默认加入了此配置, 因此不需要有以上的操作. 完成以上配置后, Spring产生的操作, 将由/error处理. 通过实现一个处理/error的Controller, 即可完成错误处理. Spring提供了一个AbstractErrorController, 继承此类可以增强错误处理能力, 代码如下所示 1234567891011@Controllerpublic class ErrorController extends AbstractErrorController &#123; public ErrorController() &#123; super(new DefaultErrorAttributes()); &#125; @RequestMapping(&quot;/error&quot;) public ModelAndView getErrorPath(HttpServletRequest request, HttpServletResponse response) &#123; // 处理异常 &#125;&#125; Service层配置在Spring中业务逻辑应该集中在Service层进行处理, 与Controller层类似, Service层有两个主要的注解, @Service和@Transaction. @Service用于声明这是一个Bean, 从而可以注入到Controller层中. @Transaction表示相关的操作放到一个事务之中, 如果方法正常结束则提交事务, 如果方法抛出RuntimeException, 则进行回滚. @Transaction可以标记在一个类上, 表示所有的方法都需要进行事务管理, 也可以只标记在一个方法上, 这样就只对标记的方法进行事务管理. 其他杂项配置JSON转换器配置首先导入需要的依赖 123456&lt;!-- https://mvnrepository.com/artifact/com.fasterxml.jackson.core/jackson-databind --&gt;&lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt; &lt;version&gt;2.9.8&lt;/version&gt;&lt;/dependency&gt; 之后在SpringWebConfig中配置如下的Bean 12345678910111213@Beanpublic HandlerAdapter initRequestMappingHandlerAdapter() &#123; RequestMappingHandlerAdapter rmhd = new RequestMappingHandlerAdapter(); // HTTP JSON转换器 MappingJackson2HttpMessageConverter jsonConverter = new MappingJackson2HttpMessageConverter(); //MappingJackson2HttpMessageConverter接收JSON类型消息的转换 MediaType mediaType = MediaType.APPLICATION_JSON_UTF8; List&lt;MediaType&gt; mediaTypes = new ArrayList&lt;&gt;(); mediaTypes.add(mediaType); jsonConverter.setSupportedMediaTypes(mediaTypes); rmhd.getMessageConverters().add(jsonConverter); return rmhd;&#125; 加入以上的代码以后, 在控制器中如果返回一个非String的对象, 则Spring会使用此处定义的转化器将对象转化为JSON字符串. 如果希望将JSON字符串转化为Java对象, 则可以使用jackson提供的ObjectMapper类, 具体过程如下 12345678final ObjectMapper mapper = new ObjectMapper();try &#123; GasMeter meter = mapper.readValue(jsonString,GasMeter.class); // 解析成功 ...&#125; catch (Exception e) &#123; // 解析失败 ... e.printStackTrace();&#125; 注意, 如果希望解析过程中忽略一些Java对象中不存在的属性, 可以在相应的Java对象上加入@JsonIgnoreProperties(ignoreUnknown = true)注解 Log4j日志配置在Spring中, 默认使用了SLF4J(Simple logging facade for Java)日志接口. 因此只要提供了相应的实现, 就可以获得更过关于Spring的日志输出. 而且在自己的代码中也可以使用同样的日志模块. 想要实现日志模块, 可以加入以下依赖 123456&lt;!-- https://mvnrepository.com/artifact/org.apache.logging.log4j/log4j-slf4j-impl --&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j-slf4j-impl&lt;/artifactId&gt; &lt;version&gt;2.11.1&lt;/version&gt;&lt;/dependency&gt; 然后在resources目录下创建log4j2.xml, 内容如下 1234567891011121314&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;!--指定log4j内部日志级别--&gt;&lt;Configuration status=&quot;WARN&quot;&gt; &lt;Appenders&gt; &lt;Console name=&quot;Console&quot; target=&quot;SYSTEM_OUT&quot;&gt; &lt;PatternLayout pattern=&quot;%d&#123;HH:mm:ss.SSS&#125; [%t] %-5level %logger&#123;36&#125; - %msg%n&quot;/&gt; &lt;/Console&gt; &lt;/Appenders&gt; &lt;Loggers&gt; &lt;Root level=&quot;info&quot;&gt; &lt;AppenderRef ref=&quot;Console&quot;/&gt; &lt;/Root&gt; &lt;/Loggers&gt;&lt;/Configuration&gt; 由于log4j的配置文件配置法不太符合直觉, 因此此模块还是使用XML进行配置更加简单, 关于可配置的内容, 可以参考以下的内容 Configuration Log4j 2.x 配置详解及详细配置例子 为什么要使用SLF4J而不是Log4J 在代码中, 可以使用如下的方式使用日志 1234567891011import org.apache.logging.log4j.LogManager;import org.apache.logging.log4j.Logger;public class AOPConfig &#123; private final Logger receiveLogger = LogManager.getLogger(&quot;ReceiveInfo&quot;); public Object printReceiveLog(final ProceedingJoinPoint joinPoint) throws Throwable &#123; // ... receiveLogger.info(()-&gt;&quot;Receive request in &quot;+joinPoint.getSignature().toShortString()); &#125;&#125; Thymeleaf模板引擎配置首先加入必要的依赖 123456&lt;!-- https://mvnrepository.com/artifact/org.thymeleaf/thymeleaf-spring5 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.thymeleaf&lt;/groupId&gt; &lt;artifactId&gt;thymeleaf-spring5&lt;/artifactId&gt; &lt;version&gt;3.0.11.RELEASE&lt;/version&gt; &lt;/dependency&gt; 然后在SpringWebConfig中配置如下的Bean 1234567891011121314151617181920212223242526272829@Beanpublic ITemplateResolver templateResolver() &#123; SpringResourceTemplateResolver templateResolver = new SpringResourceTemplateResolver(); templateResolver.setTemplateMode(TemplateMode.HTML); templateResolver.setPrefix(&quot;/WEB-INF/VIEWS/&quot;); templateResolver.setSuffix(&quot;.html&quot;); templateResolver.setCharacterEncoding(&quot;utf-8&quot;); templateResolver.setOrder(1); templateResolver.setCacheable(false); return templateResolver;&#125;@Beanpublic SpringTemplateEngine templateEngine() &#123; SpringTemplateEngine templateEngine = new SpringTemplateEngine(); templateEngine.setTemplateResolver(templateResolver()); return templateEngine;&#125;@Beanpublic ThymeleafViewResolver viewResolver() &#123; ThymeleafViewResolver viewResolver = new ThymeleafViewResolver(); viewResolver.setTemplateEngine(templateEngine()); viewResolver.setCharacterEncoding(&quot;utf-8&quot;); return viewResolver;&#125; 虽然有三个Bean, 但是实际最终被其他模块引用的只有ThymeleafViewResolver. 以上的配置过程中, 通过templateResolver指定模板类型, 前缀, 后缀, 编码等信息, 在控制器中返回的模型名称会自动加上这里指定的前缀, 后缀信息, 组合成实际需要渲染的文件名. 在Controller中, 可以使用类似如下的代码, 使用Model给页面传递参数 12345@RequestMapping(&quot;/menu&quot;)public String getMenu(Model model) &#123; model.addAttribute(&quot;isAdmin&quot;, isAdmin()); return &quot;menu&quot;;&#125; 页面中使用功能Thymeleaf的语法接受变量, 并且根据相关的值决定页面的渲染. 关于Thymeleaf在页面中的语法, 可以参考如下的内容 Thymeleaf 之 内置对象、定义变量、URL参数及标签自定义属性 thymeleaf 基本语法 Spring Security首先导入需要的依赖 12345678910111213&lt;!-- https://mvnrepository.com/artifact/org.springframework.security/spring-security-web --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.security&lt;/groupId&gt; &lt;artifactId&gt;spring-security-web&lt;/artifactId&gt; &lt;version&gt;5.1.1.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;!-- https://mvnrepository.com/artifact/org.springframework.security/spring-security-config --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.security&lt;/groupId&gt; &lt;artifactId&gt;spring-security-config&lt;/artifactId&gt; &lt;version&gt;5.1.1.RELEASE&lt;/version&gt;&lt;/dependency&gt; spring-security-config提供基于Java配置的有关注解, 所以如果不需要Java配置, 可以不包含此模块. 之后创建一个初始化的类, 并使其继承AbstractSecurityWebApplicationInitializer, 代码如下所示 123public class SecurityWebApplicationInitializer extends AbstractSecurityWebApplicationInitializer &#123;&#125; 不需要有任何其他的代码, 这样就完成了springSecurityFilterChain的注册. 之后创建WebSecurityConfig配置类, 代码如下 1234567891011121314151617181920212223242526272829303132333435363738394041424344@Configuration@EnableWebSecurity// WebSecurityConfig也需要加入到SpringInitializer, 配置才能生效public class WebSecurityConfig extends WebSecurityConfigurerAdapter &#123; private DataSource dataSource; @Autowired public WebSecurityConfig(DataSource dataSource) &#123; this.dataSource = dataSource; &#125; @Bean public UserDetailsService userDetailsService() &#123; // password =&gt; &#123;bcrypt&#125;$2a$10$dXJ3SW6G7P50lGmMkkmwe.20cQQubK3.HZWzG3YB1tlRy.fqvM/BG // admin =&gt; &#123;bcrypt&#125;$2a$10$lkz8wzmNz2CcnrWCob4RhOi6qPMtrypxjTt12k.bOrzdkiOYvcYCW JdbcDaoImpl manager = new JdbcDaoImpl(); manager.setDataSource(dataSource); return manager; &#125; protected void configure(HttpSecurity http) throws Exception &#123; http .authorizeRequests() .antMatchers(&quot;/index.html&quot;,&quot;/favicon.ico&quot;,&quot;/css/**&quot;,&quot;/js/**&quot;).permitAll() .antMatchers(&quot;/user/**&quot;).hasRole(&quot;ADMIN&quot;) .anyRequest().authenticated() .and() .formLogin() .loginPage(&quot;/login&quot;) .permitAll() .and() .logout() .permitAll() .logoutSuccessUrl(&quot;/index.html&quot;) .and() .csrf() .disable() .rememberMe() .tokenValiditySeconds(86400); &#125;&#125; 首先看UserDetailsService, 这是一个用户登录信息相关的类, 其中创建了一个默认的JDBC实现, 并且将一个数据源DataSource注入其中, 从而完成数据库的配置. 关于如何创建数据源, 可以阅读本系列中关于数据库的文章. 注意, 数据库的密码字段不应该直接保存密码的明文, 此处使用了bcrypt加密算法. 由于Spring Security不提供直接的注册模块, 因此关于注册以及密码加密等内容, 需要自己组合Spring的模块来实现. 再看configure方法, 此方法通过链式调用的方式实现了授权的声明, 要求一部分页面(index.html等)允许任何权限访问, 一部分页面(/user/)要求ADMIN权限, 其他所有的页面需要登录. 注意, 此处的ADMIN权限对应数据库中的ROLE_ADMIN字符串, ADMIN并不是特殊设置, 可以指定为任何值, 只要和数据库里面的权限名称匹配即可. 最后,关于Spring Security的详细内容, 可以参考以下内容 SpringSecurity学习笔记之四：拦截请求 Security with Spring tutorials Spring Security 官方文档 curl指令curl指令是Linux中经常使用的一个文件传输指令, 可以用来简单的模拟GET, POST等请求. 对于大部分Linux系统, 都内置了此指令. 在Windows系统中, 如果安装了git bash, 则git bash也内置了此指令. curl指令具有如下的一些用法 用法示例 作用 curl www.baidu.com 直接发送请求并输出结果 curl -i www.baidu.com 直接发送请求并且只返回头部的内容 curl URL -H “Content-Type:application/json” 设置请求头后发送请求 curl URL -d “param1=value1&amp;param2=value2” 发送POST请求 curl URL -F “file=XXX” -F “name=YYY” 上传文件 注意: 如果URL或者参数中包含特殊字符, 则需要使用引号将内容包裹起来,否则shell会错误的解析指令的内容. Chrome的postman插件也可以完成curl的功能, 如果能够安装此插件, 则可以完全图形化地完成上述的操作.","categories":[{"name":"Spring","slug":"Spring","permalink":"https://lizec.top/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://lizec.top/tags/Spring/"}]},{"title":"Spring笔记之基础知识","slug":"Spring笔记之基础知识","date":"2018-12-15T06:23:38.000Z","updated":"2021-01-09T11:00:15.463Z","comments":true,"path":"2018/12/15/Spring笔记之基础知识/","link":"","permalink":"https://lizec.top/2018/12/15/Spring%E7%AC%94%E8%AE%B0%E4%B9%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/","excerpt":"","text":"本文介绍Spring体系中Spring framework的主要内容, 包括Spring的两个核心概念, 即控制反转(Inversion of Control, IoC)和面向切面编程(Aspect Oriented Programming, AOP). 这些内容是Spring的基础知识, 被广泛的应用在其他的模块之中. IoC创建BeanSpring中有两种基于注解的方式创建Bean, 具体使用功能的注解效果如下所示 注解 注解对象 效果 @Component 类 表示此类需要装配到IoC容器之中 @ComponentScan 类 自动扫描包含@Component的类并且将其装配到IoC容器之中 @Configuration 类 表示此类是一个配置类, 配合@Bean来创建Bean @Bean 方法 配置类中使用, 表示此方法的返回值需要装配到IoC容器之中 @ComponentScan不带参数时扫描当前包和其子包, 可以额外指定其扫描的表的位置. 通过includeFilters和excludeFilters可以指定需要扫描的类的条件或者需要排除的类的条件. 被@Configuration注解的类本身也会声明为一个Bean. 以下代码演示使用上述两种方式创建Bean. 12345678910111213141516171819202122@Configuration@ComponentScanpublic class DAOConfig &#123; @Bean(destroyMethod=&quot;close&quot;) public BasicDataSource dataSource() &#123; BasicDataSource dataSource = new BasicDataSource(); dataSource.setUsername(username); dataSource.setPassword(password); dataSource.setUrl(url); dataSource.setDriverClassName(driverClassName); dataSource.setMaxIdle(maxIdle); return dataSource; &#125;&#125;@Componentpublic class User &#123; private Long id; private String userName; private String note;&#125; 使用@Component生成的Bean的名称是首字母小写的类名, 使用@Bean生成的类的名称是对应的方法的名称. 因此上述代码中分别创建了名为basicDataSource和user的Bean. 此外也可以给上述两个注解提供一个字符串来指定为需要的名称. 注入BeanSpring中可以使用@Autowired进行注入, 此注解按照类型寻找合适的Bean, 因此当前的系统中有且只能有一个类与需要注入的类符合. 例如以下的代码通过此标签注入了之前声明的DataSource. 1234567891011public class WebSecurityConfig extends WebSecurityConfigurerAdapter &#123; private DataSource dataSource; @Autowired public WebSecurityConfig(DataSource dataSource) &#123; this.dataSource = dataSource; &#125; // ...&#125; @Autowired可以注解在属性, 构造方法和setter方法上, 但是推荐注解在构造方法或setter方法上. 消除歧义由于@Autowired按照类型注入, 因此如果需要注入的类型在系统中存在多个实现, 则注入时有多个选择, 从而无法自动注入. 因此Spring提供了@Primary和@Quelifier两个注解, 用于消除歧义 注解 效果 @Primary 如果多个可选类中只有一个类有此注解, 则使用此注解对应的类 @Quelifier 与@Autowired一同使用, 通过类型和名称共同确定一个Bean 如果有多个可选的了类都标记了@Primary, 则依然无法自动注入. 注入常量Spring中可以使用@Value注入一个常量, 常量值通常来自配置文件, 但也可以通过Spring EL表达式获得计算结果或者系统属性. 12345678910// 如果出现编码问题, PropertySource可以指定编码方式@PropertySource(&quot;classpath:database.properties&quot;)public class DAOConfig &#123; @Value(&quot;$&#123;dbcp.username&#125;&quot;) private String username; @Value(&quot;$&#123;dbcp.password&#125;&quot;) private String password; // ...&#125; 其中$&#123;...&#125; 对应一个配置文件中的属性. @PropertySource将指定的配置文件加入到Spring的环境之中. Spring EL表达式大致有如下的集中用法 示例 效果 #&#123;&#39;Some String&#39;&#125; 获得一个字符串 #&#123;3.1415&#125; 注入一个数字 #&#123;T(System).currentTimeMillis()&#125; 调用函数获得返回值 #&#123;user.name&#125; 引用bean的属性 #&#123;23+321&#125; 数值计算 #&#123;user.name eq &#39;admin&#39;&#125; 字符串比较 如果调用java.lang.*中的方法, 可以直接写类名, 调用其他方法需要写全限定名. 更多关于Spring EL表达式的内容, 可以阅读官方文档的Language Reference Bean作用域Spring中的Bean有如下几种作用域 类型 使用范围 说明 singleton 所有Spring应用 默认值, 单例模式 prototype 所有Spring应用 每次都会创建新的Bean session Spring Web应用 一次HTTP会话保存唯一 application Spring Web应用 整个Web工程的生命周期保持唯一 通常, application与singleton效果相同, 因此使用singleton来代替. 如果希望改变Bean的作用域, 可以使用@Scope注解. 以下代码演示将一个Bean设置为prototype作用域. 1234567@Component@Scope(ConfigurableBeanFactory.SCOPE_PROTOTYPE)// @Scope(WebApplicationContext.SCOPE_SESSION) public class ScopeBean &#123; // ....&#125; 如果使用Spring MVC, 则可以使用 WebApplicationContext 的有关属性. AOPAOP的作用是在指定的一个切面前后加入一部分代码, 从而在不干扰原有业务逻辑的基础上, 提供额外的功能. 例如在于数据库的操作过程中, 业务逻辑可以只负责数据的查询, 如何开启数据库连接以及如何关闭连接由框架通过AOP技术完成. 使用AOP功能需要引入aspectjrt(提供基本功能)和aspectjweaver(提供Advice相关功能) AOP基本概念AOP涉及如下的一些基础概念, 具体如下 名称 英文名称 含义 连接点 join point 被拦截的对象, Spring只支持方法 切点 point cut 通过规则定义的一组连接点 通知 advice 在拦截对象之前,之后等条件下执行的方法 创建切面使用@Aspect来表明一个类是切面的配置类. 由于切面的配置类需要成为一个Bean才能使用, 因此通常还会加上@Configuration来将其声明为一个配置类. 此外还可以使用@EnableAspectJAutoProxy使得多个切面时, 能使用自动代理使得这些切面都能执行. 在切面配置类中可以使用@Before, @After, @AfterReturning, @AfterThrowing等注解来添加功能, 各注解功能如下 注解 功能 @Before 此注解修饰的方法在注解指定的方法调用之前执行 @After 此注解修饰的方法在注解指定的方法调用之后执行 @AfterReturning 此注解修饰的方法在注解指定的方法正常返回后执行 @AfterThrowing 此注解修饰的方法在注解指定的方法抛出异常后执行 以下代码演示如何使用上述注解创建切面 1234567891011@Configuration@EnableAspectJAutoProxy@Aspectpublic class AOPConfig &#123; @Before(&quot;execution(* top.lizec.web.UserWeb.listUser(..))&quot;) public void before()&#123; System.out.println(&quot;Do Something Before ...&quot;); &#125;&#125; 其中的execution表示在方法执行的时候拦截, *表示任意返回值, top.lizec.web.UserWeb是拦截对象的全限定名, listUser是拦截方法的名称, (..)表示任意参数. 创建切点直接使用@Before等注解创建切面时, 可能有很多注解都需要拦截同一个连接点, 从而导致同一的条件写多次. 此时可以使用切点绑定一个条件, 之后的注解都引用这个切点. 切点通过@Pointcut注解创建, 注解在方法上. 注解的方法不需要有实际内容, 仅仅起到提供名称的作用, 其他的注解直接引用这个方法的名称来表示引用此切点. 以下代码演示如何通过切点进行拦截 123456789101112@Configuration@EnableAspectJAutoProxy@Aspectpublic class AOPConfig &#123; @Pointcut(&quot;execution(* top.lizec.web.UserWeb.listUser(..))&quot;) public void cutListUser() &#123; &#125; @After(&quot;cutListUser()&quot;) public void doAfter() &#123; System.out.println(&quot;Do Something After ...&quot;); &#125;&#125; 环绕执行除了上述提到的在拦截方法前后执行的注解以外, Spring还提供了一种环绕执行模式. 在该模式下使用新的方法替代原有的方法, 并且提供了一个调用原来方法的机制. 以下代码演示环绕执行 123456@Around(&quot;@within(org.springframework.web.bind.annotation.RestController)&quot;)public Object printReceiveLog(final ProceedingJoinPoint joinPoint) throws Throwable &#123; joinPoint.getSignature().toShortString(); receiveLogger.info(()-&gt;&quot;Receive request in &quot;+joinPoint.getSignature().toShortString()); return joinPoint.proceed();&#125; 切面执行顺序当有多个切面时, 其执行顺序是随机的, 可以使用@Order来指定切面的执行顺序. @Order需要一个数字参数, 数字越小, 优先级越高. 各个切面嵌套执行, 即执行before时, 数字越小越先执行, 执行after时, 数字越大越先执行 AOP 表达式以下是一些常见的AOP 表达式 表达式 含义 excution(...) 表示一个方法执行是拦截, 可以使用*匹配任意字符, 使用(..)表示任意参数 target(...) 指定一个接口, 拦截所有实现此接口的类的全部方法 @target(...) 指定一个注解, 拦截所有被指定注解修饰的方法 @within(...) 指定一个注解, 拦截被指定注解修饰的类的全部方法 关于AOP 表达式的详细规则可以查阅Spring文档中的Aspect Oriented Programming with Spring章节","categories":[{"name":"Spring笔记","slug":"Spring笔记","permalink":"https://lizec.top/categories/Spring%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://lizec.top/tags/Spring/"}]},{"title":"JavaWeb之Servlet","slug":"JavaWeb之Servlet","date":"2018-11-21T12:52:04.000Z","updated":"2019-01-31T14:11:56.164Z","comments":true,"path":"2018/11/21/JavaWeb之Servlet/","link":"","permalink":"https://lizec.top/2018/11/21/JavaWeb%E4%B9%8BServlet/","excerpt":"","text":"Java Web连接池配置以连接本地数据库中的api库为例, 配置如下所示: 123456789101112&lt;Context&gt; &lt;Resource name=&quot;jdbc/mysql&quot; type=&quot;javax.sql.DataSource&quot; auth=&quot;Container&quot; driverClassName=&quot;com.mysql.jdbc.Driver&quot; url=&quot;jdbc:mysql://localhost:3306/api?serverTimezone=UTC&quot; username=&quot;root&quot; password=&quot;123456&quot; maxActive=&quot;4&quot; maxIdle=&quot;2&quot; maxWait=&quot;6000&quot;/&gt;&lt;/Context&gt; 连接数据库时, 可能会提示com.mysql.jdbc.Driver 已经过时, 按照提示换成新的驱动类即可. 连接数据库时注意指定serverTimezone=UTC 否则可能无法连接数据库. 更多关于时区的问题可以参考如何规避mysql的url时区的陷阱","categories":[{"name":"JavaWeb","slug":"JavaWeb","permalink":"https://lizec.top/categories/JavaWeb/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://lizec.top/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"Java","slug":"Java","permalink":"https://lizec.top/tags/Java/"}]},{"title":"Git笔记之Git工作流","slug":"Git笔记之Git工作流","date":"2018-11-21T11:20:40.000Z","updated":"2020-06-26T14:40:21.466Z","comments":true,"path":"2018/11/21/Git笔记之Git工作流/","link":"","permalink":"https://lizec.top/2018/11/21/Git%E7%AC%94%E8%AE%B0%E4%B9%8BGit%E5%B7%A5%E4%BD%9C%E6%B5%81/","excerpt":"","text":"参考资料和扩展阅读 Git工作流","categories":[{"name":"Git笔记","slug":"Git笔记","permalink":"https://lizec.top/categories/Git%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Git","slug":"Git","permalink":"https://lizec.top/tags/Git/"}]},{"title":"Java单元测试之有效测试","slug":"Java单元测试之有效测试","date":"2018-11-21T08:54:04.000Z","updated":"2018-11-21T08:56:39.682Z","comments":true,"path":"2018/11/21/Java单元测试之有效测试/","link":"","permalink":"https://lizec.top/2018/11/21/Java%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95%E4%B9%8B%E6%9C%89%E6%95%88%E6%B5%8B%E8%AF%95/","excerpt":"","text":"什么是优秀的测试测试的价值 测试帮助捕获错误,因此一个永远正确的测试是一个无效的测试,而一个永远错误的测试也不能提供有效的信息. 在另一个层面,测试提供一个实际使用的环境,从而明确实际的需求并给出辅助设计 编写测试的最大价值不在于结果,而在于编写过程的学习 评价测试的标准 可读性, 较少阅读代码的难度, 从而提供生产力 测试结果的准确性, 不要让错误抵消了测试带来的好处 可信赖性和可靠性 测试的潜力 将测试作为一种设计工具,指导代码对实际用途的设计,从而开发过程变为 测试-&gt;代码-&gt;重构 的循环 首先给出测试,之后以测试为依据写出能通过测试的代码, 最后重构代码. 测试替身测试替身的作用是将被测代码与周围隔开,使测试不依赖随机数等外部因素, 从而将执行变得确定. 此外使用测试替身还可以模拟特殊的场景, 或者暴露特定的信息. 替身的类型 类型 使用情景 测试桩(Stub) 不关心替身的实现时, 使用测试桩 伪造对象(Fake) 在需要某些情况下能特异性的返回不同结果时, 使用伪造对象. 测试间谍(Spy) 当需要获得一些内部信息时, 使用测试间谍 模拟对象(Mock) 需要对替身进行精细的控制时, 使用模拟对象 具体使用哪一种替身取决于具体的需求: 如果关心交互情况, 考虑使用Mock 如果使用Mock的结果不如预期, 可以考虑使用一个Spy 如果只关心替身向被测对象发送的相应, 可以使用Stub, 或者使用简单的Mock 如果运行于一个复杂的场景, 而且不能简单的使用Stub, 可以考虑使用Fake 测试桩(Stub)桩都是简单的, 通常只是硬编码的返回一个结果或者完全就是空的方法. 在这种情况下, 我们通常不关心替身如何实现, 也不希望因为替身的实现逻辑消耗太多时间和资源 123456789public class LoggerStub implements Logger &#123; public void log(LogLevel level, String message) &#123; // 空方法 &#125; public LogLevel getLogLevel() &#123; return LogLevel.WARN; // 硬编码返回值 &#125;&#125; 伪造对象(Fake)伪造对象像一个真实事物的简单版本, 优化的伪造真实事物的行文, 比测试桩更加真实. 持久化对象是使用Fake的典型场景, 由于数据访问会消耗很多时间, 而且操作有副作用, 因此不应该使用真实的数据库. 在访问文件或者数据库时, 使用一个Fake就相当于自己实现了一个自定义内存数据库. 例如, 对于下面这个接口定义的数据库发方法 1234public interface BookRepository &#123; void save(Book book); Book findById(long id);&#125; 可以通过以下这个Fake简单的实现数据库的有关操作. 123456789101112131415161718public class FakeBookRepository implements BookRepository &#123; private Collection&lt;Book&gt; books = new ArrayList&lt;Book&gt;(); public void save(Book book) &#123; if(findById(book.getId()) == null) &#123; books.add(book); &#125; &#125; public Book findById(long id) &#123; for(Book book: books)&#123; if(book.getId() == id)&#123; return book; &#125; &#125; return null; &#125;&#125; 测试间谍(Spy)测试间谍继承需要替换的类,从而可以将一些内部数据通过额外的方法暴露给外部 123456789101112131415161718192021222324252627public class DLogTest &#123; @Test public void writesEachMessageToAllTarget() throws Exception &#123; SpyTarget spy1 = new SpyTarget(); SpyTarget spy2 = new SpyTarget(); DLog log = new DLog(spy1,spy2); log.write(Level.INFO,&quot;message&quot;); assertTrue(spy1.received(Level.INFO,&quot;message&quot;)); assertTrue(spy2.received(Level.INFO,&quot;message&quot;)); &#125;&#125;private class SpyTarget implements DLogTarget &#123; // 记录收到的记录 private List&lt;String&gt; log = new ArrayList&lt;String&gt;(); @Override public void write(Level level, String message) &#123; log.add(concatenated(level, message)); &#125; boolean received(Level level, String name) &#123; return log.contains(concatenated(level,name)); &#125; // 省略concatenated 方法的实现&#125; 模拟对象(Mock)模拟对象除了保证方法可以被特异性的调用以外, 还可以对调用次数做出规定, 从而任何条件不满足时都能抛出异常. 对于模拟对象, 可以使用JMock, Mockito等模拟对象库. 关于模拟对象的使用可以阅读Java单元测试库简介 的JMock章节. Given, When, Then给定-当-那么 是一种组织测试方法的约定, 一个测试方法可以分成三个部分, 使用这种表达是希望我们在编写测试的过程中能够关注于行为, 而不是程序实现的细节. 下面是一个示例 12345678910111213141516@Testpublic void usesInternetForTranslation() throws Exception &#123; // Given final Internet internet = context.mock(Internet.class); context.checking(new Expectations()&#123;&#123; one(internet).get(with(containsString(&quot;langpair=en%7Cfi&quot;))); will(returnValue(&quot;&#123;\\&quot;translatedText\\&quot;:\\&quot;kukka\\&quot;&#125;&quot;)); &#125;&#125;); Translator t = new Translator(internet); // When String translation = t.translate(&quot;folwer&quot;,ENGLISH,FINNISH); // Then assertEquals(&quot;kukka&quot;,translation);&#125; 注意, 一定要避免对Mock对象设置过于详细的期望, 如果太详细, 会导致程序的灵活性降低, 细小的变更也会导致测试的错误. 测试用例应该检测程序的行为, 而不是程序的实现. 参考文献 安卓单元测试(八)：Junit Rule的使用 深入JUnit源码之Rule","categories":[{"name":"Java单元测试","slug":"Java单元测试","permalink":"https://lizec.top/categories/Java%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://lizec.top/tags/Java/"},{"name":"单元测试","slug":"单元测试","permalink":"https://lizec.top/tags/%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95/"}]},{"title":"Java单元测试之基础类库","slug":"Java单元测试之基础类库","date":"2018-11-21T08:53:41.000Z","updated":"2019-07-09T07:11:52.506Z","comments":true,"path":"2018/11/21/Java单元测试之基础类库/","link":"","permalink":"https://lizec.top/2018/11/21/Java%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95%E4%B9%8B%E5%9F%BA%E7%A1%80%E7%B1%BB%E5%BA%93/","excerpt":"","text":"本文介绍Java的单元测试中经常使用的Junit和JMock库的主要API和使用方法. 阅读本文前需要对Maven有基本的了解, 如果对其不了解, 可以阅读 Maven笔记之基本概念 . Junit使用依赖导入根据官网上的指示, 编译和运行JUnit的代码, 需要依赖junit-4.XX.jar以及hamcrest-core-1.3.jar. 由于hamcrest库从2012年以来就没有更新, 因此1.3版是当前的最新版. 在Maven中,仅仅需要导入JUnit即可, 此依赖会自动依赖hamcrest-core, 具体的版本号可以在MvnRepository搜索. 待测试方法限制Junit中的测试方法需要满足以下的条件 使用@Test注解声明 必须声明为 public void 且不接受参数 可以抛出任意异常 生命周期Junit中提供如下的一些注解,被各注解标记的方法的含义如下 Annotation Description Annotation Description @BeforeClass 在测试类所有方法开始前调用 @AfterClass 在测试类所有方法结束后调用 @Before 在测试类每个测试方法前调用 @After 在测试类每个测试方法后调用 一个类中可以有任意数量的@BeforeClass, @Before, @After, @AfterClass标记, Junit不保证同类型标记的方法的调用顺序(调用顺序取决于反射的API实现). JUnit断言在Junit的org.junit.Assert类中提供了大量的静态方法, 这些方法都是assertXXX的形式, 通常以静态导入的方式导入这些方法. 比较常见的方法如下表所示 方法 含义 方法 含义 assertEquals 两个参数是否相等 assertArraysEquals 两个数组是否包含同样的元素 assertTrue 语句是否为真 assertFalse 语句是否为假 assertNull 对象引用是否为空 assertNotNull 对象引用是否非空 assertSame 两个对象是否引用同样对象 assertNotSame 两个对象是否应用不同的对象 Hamcrest匹配器除了常见的assertXXX API以外, JUnit还提供了一个assertThat方法. 此方法接受两个参数, 一个是Object, 另一个是org.hamcrest.Matcher. 而且Matcher是一个接口, 文档中指出, 如果需要自定义实现Matcher, 不应该直接实现这个接口, 而应该继承抽象类org.hamcrest.BaseMatcher, 从而可以保证在后续的更新过程中, 可以改变Matcher接口而不影响其他Matcher的实现. 使用过程中, org.hamcrest.CoreMatchers类提供了大量的静态方法, 这些方法都是一些谓词, 通常以静态导入的方式导入这些方法, 这些方法可以分为两类 产生Matcher以下的方法接受参数, 产生一个Matcher 方法 含义 方法 含义 equalTo 判断是否相等 not 判断是否不相等 nullValue 产生一个检查是否为Null的Matcher notNullValue 产生一个检查是否为非Null的Matcher sameInstance 判断是否为同一个引用 theInstance 判断是否为同一个引用 startsWith 判断字符串是否以指定的子串开头 endsWith 判断字符串是否以指定的子串结尾 containsString 判断字符串是否包含指定的子字符串 一些方法的使用示例如下所示: 12345assertThat(&quot;foo&quot;, equalTo(&quot;foo&quot;))assertThat(new String[] &#123;&quot;foo&quot;, &quot;bar&quot;&#125;, equalTo(new String[] &#123;&quot;foo&quot;, &quot;bar&quot;&#125;))assertThat(cheese, is(not(smelly)))assertThat(cheese, is(nullValue())assertThat(&quot;myStringOfNote&quot;, containsString(&quot;ring&quot;)) 复合Matcher以下的方法接受一个Matcher, 产生一个复合的Matcher 方法 含义 方法 含义 allOf 判断是否所有Matcher都满足条件 anyOf 判断是否有任何Matcher满足条件 both 是否添加的Matcher都满足条件 either 是否存在Matcher满足条件 is 本身无操作,用于增强语义 isA 代替instanceof anything 创建一个永远匹配的Matcher not 对Matcher取反 everyItem 判断数组是否所有元素都满足条件 hasItem 判断数组是否有元素满足指定的一个条件 describeAs 包裹已有的Matcher, 重写其描述 注意: not方法比较特殊化, 也可以接受普通的参数, 与is一起表示不等于的语义. 一些方法的使用示例如下所示: 123456assertThat(&quot;myValue&quot;, allOf(startsWith(&quot;my&quot;), containsString(&quot;Val&quot;)))assertThat(&quot;myValue&quot;, anyOf(startsWith(&quot;foo&quot;), containsString(&quot;Val&quot;)))assertThat(&quot;fab&quot;, both(containsString(&quot;a&quot;)).and(containsString(&quot;b&quot;)))assertThat(&quot;fan&quot;, either(containsString(&quot;a&quot;)).and(containsString(&quot;b&quot;)))describedAs(&quot;a big decimal equal to %0&quot;, equalTo(myBigDecimal), myBigDecimal.toPlainString())assertThat(Arrays.asList(&quot;bar&quot;, &quot;baz&quot;), everyItem(startsWith(&quot;ba&quot;))) 自定义Matcher以下演示如何使用自定义Matcher 123456789101112131415161718192021222324@Testpublic void testPhone() &#123; String phone = &quot;3232332&quot;; assertThat(phone,is(internationalNumber()));&#125;public Matcher&lt;String&gt; internationalNumber() &#123; return new BaseMatcher&lt;String&gt;() &#123; @Override // 重写此方法, 判断是否满足条件 public boolean matches(Object item) &#123; if(!(item instanceof String)) &#123; return false; &#125; return ((String) item).matches(&quot;^\\\\+(?:[0-9] ?)&#123;6,14&#125;[0-9]$&quot;); &#125; @Override // 重写此方法, 在不匹配时输出适当的提示信息 public void describeTo(Description description) &#123; description.appendText(&quot;a correct type phone number&quot;); &#125; &#125;;&#125; 检测异常当被测试方法期待抛出异常时, 可以使用@Test的参数来实现此功能, 例如 12345@Test(expected = IllegalArgumentException.class)public void ensureThatInvalidPhoneNumberYieldsProperException() &#123; FaxMachine fax = new FaxMachine(); fax.connect(&quot;+dsd-ds-0090&quot;);&#125; 如果此方法没有抛出IllegalArgumentException,则此方法运行失败. 但是使用这种方案只能检测异常, 而不能获得具体的异常以及进一步的分析异常的原因. 在这种复杂逻辑的情况下, 还是应该使用try-catch模式 @Rule注解通过该注解可以在每个测试方法的开始和结束后执行指定的操作, 通过此注解来替代原有的@Before和@After注解,从而避免同样的初始化代码在多个测试用例类种反复编写 原理使用@Rule标记的类必须实现TestRule接口,此接口定义如下 123456import org.junit.runner.Description;import org.junit.runners.model.Statement;public interface TestRule &#123; Statement apply(Statement base, Description description);&#125; 其中base表示即将执行的测试方法, description表示此方法的描述信息. 一个Rule的实现如下所示: 123456789101112131415161718public class MethodNameExample implements TestRule &#123; @Override public Statement apply(final Statement base, final Description description) &#123; return new Statement() &#123; @Override public void evaluate() throws Throwable &#123; //想要在测试方法运行之前做一些事情，就在base.evaluate()之前做 String className = description.getClassName(); String methodName = description.getMethodName(); base.evaluate(); //这其实就是运行测试方法 //想要在测试方法运行之后做一些事情，就在base.evaluate()之后做 System.out.println(&quot;Class name: &quot;+className +&quot;, method name: &quot;+methodName); &#125; &#125;; &#125;&#125; 根据文档要求, 使用@Rule标记的字段必须public and not static. 内置规则JUnit提供了一些内置的实现TestRule的类, 使用这些类可以完成全局超时控制,临时文件等功能. 这些规则全部位于org.junit.rules包下, 下面介绍两个最常见的规则 1234567891011121314public class PublisherTest &#123; @Rule public TemporaryFolder folder = new TemporaryFolder(); @Rule public MethodRule globalTimeout = new Timeout(20); @Test public void thisTempFileIsSquashedAfterTheTest() throws Exception &#123; File tempFile = folder.newFile(); // 创建一个临时文件 assertTrue(tempFile.exists()); &#125;&#125; 上述代码中, TemporaryFolder在每个Test方法被调用以前都会创建一个新的根目录, Test方法中可以使用folder方法创建文件和目录, Test方法执行完毕后, floder会自动删除有关的文件和文件夹. globalTimeout则会对每个Test方法进行计时, 如果运行时间超过指定的最大时间, 则会将测试方法终止. 其他的规则可以查看org.junit.rules的文档, 其中的每个规则都在文档中提供了使用示例. JMock使用依赖导入根据官网的指示, 编译和运行JMock需要jmock-2.6.1.jar, hamcrest-core-1.3.jar, hamcrest-library-1.3.jar和jmock-junit4-2.6.1.jar 在Maven中仅需要导入jmock-junit4即可, 此依赖会自动导入其他的三个依赖jar. 因为hamcrest库很久没有更新, 所以JUnit和JMock都是依赖同样版本的hamcrest库, 并不会产生冲突. 注意: 如果希望使用Rule注解, jmock-junit4 至少为2.6.0版本. JMock使用根据官网上的示例, 结合JUnit4的一个测试应该具有如下的结构 1234567891011121314151617181920212223242526272829import org.jmock.Expectations;import org.jmock.integration.junit4.JUnitRuleMockery;import org.junit.Rule;import org.junit.Test;public class PublisherTest &#123; @Rule public JUnitRuleMockery context = new JUnitRuleMockery(); public void oneSubscriberReceivesAMessage() &#123; // 使用JMock产生了一个Subscriber类的实例 // 使用final修饰, 从而可以在Expectations块中引用 final Subscriber subscriber = context.mock(Subscriber.class); Publisher publisher = new Publisher(); // 将mock对象注入待测试类 publisher.add(subscriber); final String message = &quot;message&quot;; // 需要检测的内容,有subscriber收到了指定的消息 context.checking(new Expectations() &#123;&#123; oneOf (subscriber).receive(message); &#125;&#125;); // 实际调用需要测试的方法 publisher.publish(message); &#125;&#125; 注意: 先调用context的checking方法, 然后再调用实际待测试的方法, 否则会抛出异常 Expectations与hamcrest库类似, JMock也提供了大量的谓词, 用来检测方法是否调用了指定次数, 接受的参数是否为指定的类型, 设置返回值等操作. 具体可以分成如下的几类 调用次数 方法 含义 方法 含义 oneOf 希望方法被调用有且只有一次 exactly(n).of 希望方法正好被调用n次 atLeast(n).of 希望方法被调用至少n次 atMost(n).of 希望方法被调用至多n次 between(min, max).of 运行调用min到max之间的次数 never 希望方法不被调用 allowing 允许方法调用任意次数 ignoring 允许方法调用任意次数 注意: allowing和ignoring效果相同, 具体使用哪一个谓词应该由实际的语义确定. 参数匹配以下的谓词用于限定被mock方法接受的参数的类型 方法 含义 方法 含义 equal(n) 参数等于n same(o) 参数与o是同一个对象 a(type) 参数是type类型的实例 an(type) 参数是type类型的实例 aNull(type) 参数是type类型且为Null aNonNull(type) 参数是type类型且非Null any(type) 参数是type的任意值 not(m) 将给定的Matcher取反 anyOf(…) 参数匹配任意的Matcher allOf(…) 参数匹配全部的Matcher 上述所有的方法,最后都需要通过with方法转化为实际的类型,从而可以作为被测试方法的参数 例如对于被测试方法add, 通过如下的代码 1allowing (calculator).add(with(any(int.class)), with(any(int.class))); 说明此方法可以调用任意次数,add的两个参数都是任意的int类型的值 动作以下谓词用于指定被mock对象的动作(Action) 方法 含义 will(returnValue(v)) 返回v给调用者 will(returnIterator(c)) 每次调用返回集合c中的一个值 will(returnIterator(v1, v2, …, vn)) 每次调用返回v1到vn的一个值 will(throwException(e)) 抛出异常e给调用者 will(doAll(a1, a2, …, an)) 在每次调用时执行a1到an的Action","categories":[{"name":"Java单元测试","slug":"Java单元测试","permalink":"https://lizec.top/categories/Java%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://lizec.top/tags/Java/"},{"name":"单元测试","slug":"单元测试","permalink":"https://lizec.top/tags/%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95/"}]},{"title":"Java多线程之核心类库","slug":"Java多线程之核心类库","date":"2018-11-21T08:39:29.000Z","updated":"2020-10-29T07:00:32.138Z","comments":true,"path":"2018/11/21/Java多线程之核心类库/","link":"","permalink":"https://lizec.top/2018/11/21/Java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B9%8B%E6%A0%B8%E5%BF%83%E7%B1%BB%E5%BA%93/","excerpt":"","text":"本文介绍Java中关于多线程的类库, 包括各种类的实现原理和使用方法, 关于多线程的基础知识, 可以阅读Java多线程之基础知识. 无锁可变量从Java 5开始, java.util.concurrent.atomic中就提供了支持无锁可变变量的类, 例如AtomicLong等. 可以使用这些类提供的方法对其进行加减法, 并且不需要任何的同步操作. 在上述的类中,使用了一种CAS技术, 即Compare And Set. 一个线程在更新变量值之前, 会检测变量的当前值是否和预期的值相同, 如果是,则说明变量尚未被其他线程修改, 于是可以直接修改这个变量. 如果发现变量已经改变, 那么这次操作失败. 用于CAS技术存在硬件支持,因此性能比加锁操作有很大的提升. 在Java 8中, 不需要写循环来反复进行CAS操作, 可以直接传入lambda或者方法引用来完成操作 1234long observed = 2333;AtomicLong largest = new AtomicLong();largest.updateAndGet(x -&gt; Math.max(x,observed));largest.accumulateAndGet(observed,Math::max); 如果线程间的竞争压力很大, 可以使用LongAdder来代替AtomicLong. LongAdder内部有多个变量, 这些变量累计起来表示总和, 从而多个线程进行操作时, 可以将它们分布到不同的变量上进行操作. 并行哈希表ConcurrentHashMap是一个保证线程安全的哈希表, 多个线程可以同时对其进行添加和删除元素, 且各个线程之间不会被阻塞. 更新值由于ConcurrentHashMap不保证内部存储的元素的原子性, 因此当需要更新元素的值时, 需要使用一些操作, 例如CAS技术, 使用CAS有两种方式, 分别如下 12345678// 手动进行循环检测do&#123; oldValue = map.get(word); newValue = oldValue == null ? 1 : oldVaue + 1;&#125; while(!map.replace(word,oldValue,newValue));// 直接使用lambda函数map.compute(word, (k,v)-&gt; v==null?1:v+1); 与compute方法参数类似的方法还有两个, computeIfPresent和computerIfAbsent分别来处理值已经存在和值不存在的情况, 此外对于上述这种第一次加入与后续操作存在差异的操作, 可以使用merge方法, 此方法提供一个额外的参数用于表示初始值. 123456map.computeIfAbsent(word, k -&gt; new LongAddr()).increment();// 如果word不存在, 初始为1L, 否则将原有值和1L进行相加map.merge(word, 1L, (existingValue, newValue) -&gt; existingValue + newValue);// 可以使用 Long::sum 进一步简化代码map.merge(word, 1L, Long::sum); 批量操作ConcurrentHashMap 提供三种批量操作的方式, 即 search, reduce 和 forEach, 这三种方式都可以分别对键, 值, 建和值, Map.Entry进行操作. 这些操作都是并行的, 需要提供一个阈值来指定一个线程中大约包含多少数据. 如果需要单线程操作, 可以将阈值指定为Long.MAX_VALUE, 如果需要尽可能多的线程, 可以将阈值指定为1, 但是无论如何设置, 最后的线程数量都不会超过ForkJoinPool指定的一个最大线程数量的4倍. Set视图可以在ConcurrentHashMap 的基础上获得一个Set视图, 根据需要, 可以使用以下两种方式 123456// 在ConcurrentHashMap上封装一个SetConcurrentHashMap.newKeySet()// 在一个已有的ConcurrentHashMap产生一个SetSet&lt;String&gt; set = map.keySet(1L);set.add(&quot;123&quot;) 其中keySet方法的参数表示使用Set视图添加元素时, 向ConcurrentHashMap添加的默认值. 如果map中不存在&quot;123&quot;, 那么执行后map中就存在此元素,且值为1. 重入锁重入锁可以代替synchronized关键字, 且JDK早期版本中性能优于synchronized关键字. 在后续版本中JDK对synchronized关键字进行了优化, 从而使两种差距不大. 重入锁通过ReentrantLock类实现, 使用lock()方法获得锁, 使用unlock()方法释放锁. 对于有异常的场景, 可以在finally语句块中释放锁. 一种典型的使用方式如下所示： 12345678try &#123; lock.lock(); // ...&#125; catch(Exception e) &#123; // ...&#125; finally &#123; lock.unlock();&#125; 而使用ReentrantLock时可以使用tryLock()来尝试获得锁, 根据能否获得锁来执行不同的操作 ReentrantLock可以多次调用lock方法进行锁定（重入）, 因而被称为重入锁. 关于ReentrantLock还有如下的一些重要方法 方法 作用 备注 lockInterruptibly() 除非被中断不断尝试获得锁 如果线程被设置为中断, 立刻抛出InterruptedException tryLock() 尝试获得锁并且立刻返回是否获得锁 可以根据是否获得锁执行不同的操作 isFair() 是否是公平锁 isHeldByCurrentThread() 此锁是否被当前线程持有 注意: tryLock()方法可以指定一个最大等待时间, 如果到达时间后还是无法获得锁, 则放弃等待并返回false. 使用tryLock()或lockInterruptibly()获取锁时, 操作更加灵活, 从而有助于解决一部分死锁问题. synchronized和默认的ReentrantLock都是非公平锁, 但是如果需要, 也可以在构造函数中将ReentrantLock指定为公平锁. 多路通知通过synchronized, wait()/notify()可以实现等待和唤醒. 其中synchronized关键字的作用可以通过ReentrantLock替代, 同样wait()/notify()机制可以被Condition对象替代. Condition对象与Lock接口配合使用(ReentrantLock实现了此接口), Lock接口的newCondition()方法可以产生一个Condition对象, 此对象具有以下的一些方法 方法 作用 备注 await() 使当前线程等待,并且释放锁 等待过程中可以响应中断 awaitUninterruptibly() 使当前线程等待,并且释放锁 等待过程中不会响应中断 signal() 唤醒一个等待中的线程 注意: 等待和唤醒都和一个Condition绑定在一起, 从而实现了更加精细的线程控制 newCondition()方法每次调用都会返回一个完全不同的实例 信号量Java也提供信号量机制, 关于信号量可以参考操作系统笔记中信号量和PV原语章节. 表示信号量的类是Semphore, 提供acquire方法实现P操作, 提供release方法实现V操作 读写锁Java提供读写锁机制, 关于读写锁的有关内容可以参考数据库系统原理中封锁技术章节. 表示读写锁的类是ReentrantReadWriteLock, 此类提供radLock()方法获得一个读锁, 提供writeLock()获得一个写锁. 在读取操作远多于写入操作时, 读写锁可以获得极高的性能. 倒计时器CountDownLatch是一个用于控制线程等待的多线程控制类. 通常由构造函数指定需要管理的子线程数量, 每个子线程执行完毕后调用countDown()通知CountDownLatch该子线程完成任务. 主线程调用await()方法等待子线程执行相关的任务, 当所有子线程都完成任务后, 主线程被唤醒, 从而继续执行后续的操作. 方法 说明 countDown() 子线程中调用, 通知此子线程完成任务 await() 主线程调用, 等待所有子线程完成任务","categories":[{"name":"Java多线程","slug":"Java多线程","permalink":"https://lizec.top/categories/Java%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://lizec.top/tags/Java/"},{"name":"多线程","slug":"多线程","permalink":"https://lizec.top/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}]},{"title":"Java多线程之基础知识","slug":"Java多线程之基础知识","date":"2018-11-21T08:39:06.000Z","updated":"2021-03-02T06:34:33.000Z","comments":true,"path":"2018/11/21/Java多线程之基础知识/","link":"","permalink":"https://lizec.top/2018/11/21/Java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B9%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/","excerpt":"","text":"用Java开发了一些大大小小的项目了, 虽然在这些项目的开发过程中都使用了一些Java多线程技术, 但对于Java多线程的原理, 细节等诸多方面的认识都是空白. 因此有必要系统的学习一次Java的多线程. 本文主要介绍Java多线程的基础知识, 包括Thread的使用, wait/notify机制等. 关于Java多线程类库的使用, 可以阅读Java多线程之核心类库. 线程基础知识线程状态 线程在调用start方法后进入RUNNABLE状态, 而RUNNABLE状态根据是否正在运行, 又可以分为READY状态和RUNNING状态. WAITING是程序主动要求等待某一个信号, 而BLOCKED是JVM控制的等待行为. 因此BLOCKED状态由JVM负责唤醒, 而WAITING由程序控制唤醒. Java线程进入WAITING状态后, 会放弃持有的锁, 因此被notify唤醒后, 需要先进入BLOCKED状态, 获得锁后才能恢复RUNNING状态. 更多关于线程切换的细节, 可以参考以下资料 Java线程的6种状态及切换(透彻讲解) 创建线程在Java中有以下几种方法可以使一段代码以多线程的方式运行, 即 继承Thread类并重写run方法 实现Runnable接口, 并构造Thread实例 实现Callable接口, 并构造Thread实例 通过线程池创建并执行线程 Runnable与Callable的主要区别在于Callable有返回值, 而Runnable没有返回值 注意: 一个Thread实例只能调用一次start()函数, 否则会抛出异常 如果使用一个Runnable对象初始化多个Thread, 则这些线程共享Runnable中的变量 线程安全如果一个类在单线程环境下能正常工作, 并且在多线程环境下, 其使用方能够不必为其做任何改变的使用, 则称此类是线程安全的. 原子性对于涉及访问共享变量的操作, 若该操作从其执行线程以外的任何线程来看都是不可分割的, 则称该操作是 原子操作, 相应的称此操作具有 原子性 例如ATM机的取款操作是具有原子性的, 要么取款成功, 要么取款失败, 不存在中间的状态. Java中实现原子性的主要方法是使用锁, 此外Java保证除了long/double以外的所有变量的写操作都是原子的(要么完成数据更新, 要么没有更新, 不会因为更新操作产生第三种结果). 注意:除了long/double类型以外的任意的Java赋值操作都是原子的, 可以充分利用这一特点来保证线程安全, 例如 1234public void updateHostInfo(String IP, int port)&#123; HostInfo info = new HostInfo(IP, port); this.hostinfo = info;&#125; 由于赋值操作是原子的, 因此上述更新操作要么没有进行, 要么完成更新, 从而不加锁也能保证线程安全. 公平调度与非公平调度公平调度指各线程按照先来先得的规则获得资源, 而非公平调度指 允许 后来的线程先获得资源. 非公平性调度往往指允许不公平的资源调度而不是刻意造成不公平的调度. 对于公平调度, 对于某个需要申请的资源, 资源调度器会维护一个等待队列, 需要申请相关资源的线程先被暂停并存放到队列之中, 待资源可用后队列最前端的线程被唤醒, 获得相应的资源后继续执行. 而非公平模式下, 允许新到来的还出于RUNNABLE状态的线程C跳过整个等待队列直接获得资源, 由于唤醒线程需要一段时间, 因此如果位于等待队列中的线程B在唤醒之前C就完成操作并释放锁, 则系统在B无影响的状态下实现了吞吐量的提升. 因此非公平调度往往比公平调度有更高的吞吐率, 但由于分配时机不确定, 因此容易导致线程饥饿问题. Thread方法介绍API简介 方法 功能 说明 currentThread 获得执行当前代码的进程对应的Thread对象 静态方法/native方法 getName 获得当前线程的名字 可有构造函数指定或者默认为Thread-XXX类型的名字 join 等待相应的线程结束 A调用B.join(), 则B结束后A才继续执行 yield 向进程调度器表明希望放弃对处理器的占用 静态方法/此请求并非强制执行 isAlive 判断当前进程是否处于活动状态 活动状态指线程处于开始执行且尚未结束的状态 sleep 让正在执行该语句的线程休眠指定毫秒 如果被中断会抛出异常并清除中断状态 setDaemon 设置当前线程是否为守护线程 如果当前运行的所有线程都是守护线程, 则JVM自动退出 interrupt 将调用此方法的线程设置为中断状态 通过中断状态控制线程的状态 isInterrupted 判断调用此方法的线程是否处于中断状态 检测到中断状态后可以自行控制优雅的退出 线程名称Thread的构造函数如下: 1234567891011public Thread() &#123; init(null, null, &quot;Thread-&quot; + nextThreadNum(), 0);&#125;public Thread(Runnable target) &#123; init(null, target, &quot;Thread-&quot; + nextThreadNum(), 0);&#125;public Thread(Runnable target, String name) &#123; init(null, target, name, 0);&#125; 如果直接继承Thread类, 那么默认的产生一个类似Thread-0, Thread-1的名字. 如果使用Runable构造且指定了线程名, 那么使用设定的名字, 否则和直接继承Thread一样使用 对于main方法对应的线程, 则名称始终都是main. 结合currentThread()方法可以发现, 一个Thread实例中, 只有run()方法内处于另外一个线程, 而其他方法都属于调用者线程. 在创建线程时, 最好能指定一个合适的名字, 例如HttpService, 从而可以减少调试的难度. 线程中断调用interrupt()并不会导致线程中断, 而实际上是标记当前线程处于中断状态. 在线程的run方法中可以检测是否处于中断状态, 进而执行相应的操作, 使自己优雅的退出. 123456789101112131415161718192021222324public class Run extends Thread &#123; public void run() &#123; super.run(); try &#123; for(int i=0;i&lt;500000;i++) &#123; System.out.println(&quot;Print i = &quot;+i); if(Thread.currentThread().isInterrupted()) &#123; throw new InterruptedException(); &#125; &#125; System.out.println(&quot;非中断情况下才输出的内容&quot;); &#125; catch (InterruptedException e) &#123; return; &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; Run mythread = new Run(); mythread.start(); Thread.sleep(10); mythread.interrupt(); &#125;&#125; 函数 作用 中断标记 函数类型 interrupted() 测试 当前线程 是否中断 调用后清除 静态方法 isInterrupted() 测试调用此方法的线程对象是否中断 不清除 成员方法 例如在main函数中有一个Thread对象t, 则在main函数中使用Thread.interrupted()判断main线程是否被中断, 使用t.isInterrupted()才判断t对应的线程是否中断. 显然从更加符合逻辑的角度来看, 如果需要判断当前线程是否中断, 应该使用成员方法isInterrupted(). 与手动设置中断标记相比, 使用interrupt()方法的优势在于线程内部执行sleep()等方法时, 可以触发这些方法抛出InterruptedException, 从而能够离开sleep()方法. 一旦触发了异常, 则中断标记被清除, 在线程内部可以在此设置中断标记, 使得程序在完成收尾工作后退出. 线程优先级setPriority()方法设置线程的执行优先级, 高优先级的线程由更多机会被执行, 但具体执行顺序仍然是随机的. 高优先级的线程由于有更多机会获得CPU时间, 因此通常在同样的任务量下有更短的执行时间. 并发访问变量访问局部变量的访问是安全的. 一个变量是否安全的依据是该变量是否可能被共享, 由于每个函数的局部变量都是独占的, 因此局部变量永远是安全的. 对于实例变量, 由于变量可能被多个线程访问, 因此有可能造成变量的读写错误. volatile关键字在JVM中不同的线程有拥有一个私有的堆栈, 在以Server模式启动的JVM中, 线程的所有变量都会从私有堆栈读取, 这会导致一个线程更新了变量以后(更新到公共堆栈), 无法影响到其他线程的变量(私有堆栈的值没有变). 使用volatile关键字声明的变量会强制JVM每次都从公共堆栈读取该变量的值. 注意: volatile关键字并不保证原子性, 多个线程同时读写时, 还是需要加锁. 而且如果变量读取加锁了, 则也没有必要使用volatile关键字, 因为synchronized关键字具有volatile关键字等价的效果. synchronized关键字synchronized关键字修饰一个方法, 表示对该方法锁定, 所有访问该方法的线程都需要排队, 依次的访问. synchronized关键字有五类用法 用法 含义 synchronized(obj) { … } 执行括号内代码前需要获得对象实例obj的锁 直接修饰实例方法 执行该方法前需要获得此对象的锁 synchronized(this){ … } 与直接修饰实例方法效果等价 直接修饰静态方法 执行该方法前需要获得此类的锁 synchronized(X.class){ … } 与直接修饰静态方法效果等价 synchronized关键字根据需要的锁决定是否需要排队, 如果两个线程需要同一个锁, 则依次排队访问, 但如果需要的锁不同, 则互不影响. 所以synchronized修饰的实例方法和synchronized修饰的静态方法由于锁不同, 两类方法调用不需要竞争锁. 12345678910public void serciveMenthod() &#123; try&#123; synchronized(this) &#123; // 具体需要同步的操作 &#125; &#125; catch(InterruptedException e)&#123; e.printStackTrace(); &#125;&#125; synchronized(this)获得此对象的锁与直接修饰实例方法的锁相同, 因此此部分代码和直接修饰的实例方法不能同时执行. 使用synchronized(this)方法的代码区域可以控制, 因此粒度更低, 对其他线程的影响更小. 类似地, 使用synchronized(XXX.class)可以获得XXX类的锁并将范围控制在更细粒度. 注意： synchronized锁定的是对象实例. 即如果有多个线程访问同一个对象的synchronized修饰的方法, 则这些线程需要排队, 但如果是多个线程访问多个对象的synchronized修饰的方法, 则相互没有影响. synchronized特性 特性 解释 可重入 当一个线程获得锁后, 如果再次请求获得锁, 则可以再次立即获得锁 异常释放 当一个线程执行的代码出现异常时, 其持有的所有锁都释放 非继承 锁定不具有继承性 非公平调度 JVM默认使用非公平调度, 需要其他调度模式时需要使用Lock的有关类 进程间通信等待/通知机制Java在Object中提供了wait()和notify()方法来实现进程间的通信. 其中wait()方法用于将当前进程进入等待状态, notify()方法随机唤醒一个调用了wait()方法的线程并使其进入就绪队列, 等待被调度器选中后继续执行. 由于这两个方法是Object方法, 因此可以在任意对象上调用这些方法. 但在调用之前, 必须获得调用对象的锁, 即通过synchronized锁定相应的对象, 例如 12345public static void fun(Object obj) &#123; synchronized(obj) &#123; obj.wait(); &#125;&#125; 如果不获得锁就直接调用, 则会抛出java.lang.IllegalMonitorStateException, 这个异常的字面意思上时说对象监视器状态异常, 实际上就是指没有获得对象级别的锁. 注意: 由于Thread的其他API使用了wait机制, 因此不要将Thread实例作为wait调用的对象. 调用wait()方法的线程会立即释放对象锁, 而执行notify()方法的线程会等到正在执行的方法结束后才会释放锁. 同样被唤醒的线程也不会立即执行, 而是等再次获得对象锁以后才执行. 以下代码演示了基本的等待/通知机制 12345678910111213141516171819202122232425262728293031323334353637383940public static void main(String[] args) throws InterruptedException &#123; final Object lock = new Object(); final ExecutorService executorService = Executors.newFixedThreadPool(2); executorService.submit(() -&gt; &#123; synchronized (lock) &#123; try &#123; System.out.println(&quot;Thread 1 Wait&quot;); lock.wait(); System.out.println(&quot;Thread 1 Finish&quot;); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;); executorService.submit(() -&gt; &#123; synchronized (lock) &#123; try &#123; System.out.println(&quot;Thread 2 Wait&quot;); lock.wait(); System.out.println(&quot;Thread 2 Finish&quot;); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;); Thread.sleep(300); synchronized (lock) &#123; System.out.println(&quot;Main Thread notifyAll&quot;); lock.notifyAll(); &#125; Thread.sleep(300); executorService.shutdown();&#125; 如果有多个线程在一个监视器上使用wait()方法, 则当其他线程调用此监视器的notify()方法时, 会随机唤醒一个线程, 使用notifyAll()则会唤醒使用此监视器上的所有线程. notify()方法不保证一定会唤醒一个线程, 可以多次调用notify()方法, 如果调用时没有等待状态的线程, 则此方法不产生任何效果. 可以使用wait(long)方法来限定一个时间, 到达时间后如果没有被唤醒, 则自动被唤醒 wait()方法与interrupt()方法一个线程如果执行了wait()方法进入等待状态后调用interrupt方法, 则会产生java.lang.InterruptedException异常. 以下代码显示此过程 123456789101112131415161718192021222324252627282930313233343536373839public class Run extends Thread &#123; public static void main(String[] args) throws InterruptedException &#123; Object lock = new Object(); ThreadA a = new ThreadA(lock); a.start(); Thread.sleep(1000); a.interrupt(); &#125;&#125;class Service &#123; public void testMethod(Object lock) &#123; try &#123; synchronized (lock) &#123; System.out.println(&quot;Begin Wait&quot;); lock.wait(); System.out.println(&quot;End Wait&quot;); &#125; &#125; catch (InterruptedException e) &#123; System.out.println(&quot;出现了异常, 锁已经被释放了&quot;); e.printStackTrace(); &#125; &#125;&#125;class ThreadA extends Thread&#123; private Object lock; public ThreadA(Object lock) &#123; super(); this.lock = lock; &#125; public void run() &#123; Service service = new Service(); service.testMethod(lock); &#125;&#125; join方法调用join()方法的线程等待被调用join()方法的线程执行结束. 例如有一个线程对象t, 若在主线程上调用t.join(), 则在t执行完毕后main才能继续执行. join()方法适合在主线程需要等待子线程执行完毕后才执行的场合. 使用join(long)方法可以指定一个最大时间, 到达最大时间后即使子线程还未执行完毕主线程也会继续执行. join()方法本质上是将线程对象t作为目标调用wait()方法, 因此调用join()后会释放锁, 从而其他线程可以执行其他的锁定方法, 并且如果当前线程被中断, 也会产生中断异常. join方法的源代码如下所示: 1234567891011121314151617181920212223public final synchronized void join(long millis) throws InterruptedException &#123; long base = System.currentTimeMillis(); long now = 0; if (millis &lt; 0) &#123; throw new IllegalArgumentException(&quot;timeout value is negative&quot;); &#125; if (millis == 0) &#123; while (isAlive()) &#123; wait(0); &#125; &#125; else &#123; while (isAlive()) &#123; long delay = millis - now; if (delay &lt;= 0) &#123; break; &#125; wait(delay); now = System.currentTimeMillis() - base; &#125; &#125;&#125; 由于join的这种设计, 因此使用wait()/notify()机制时, 不应该把Thread的实例作为调用对象, 否则可能干扰系统API的使用, 或者被系统API干扰.","categories":[{"name":"Java多线程","slug":"Java多线程","permalink":"https://lizec.top/categories/Java%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://lizec.top/tags/Java/"},{"name":"多线程","slug":"多线程","permalink":"https://lizec.top/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}]},{"title":"Java特性之文件与时间API","slug":"Java特性之文件与时间API","date":"2018-11-21T08:23:00.000Z","updated":"2018-12-02T07:13:37.381Z","comments":true,"path":"2018/11/21/Java特性之文件与时间API/","link":"","permalink":"https://lizec.top/2018/11/21/Java%E7%89%B9%E6%80%A7%E4%B9%8B%E6%96%87%E4%BB%B6%E4%B8%8E%E6%97%B6%E9%97%B4API/","excerpt":"","text":"从Java 1.4之后, Java引入了新的Java I/O 库来替代原有的File类, 到了Java 8, Java又引入了新的Base64编码和解码库, 使用新的API可以避免原来Java文件的复杂操作, 简化代码逻辑. 此外, 在Java 8中, 还引入了另外的一组时间API来替代原有的设计, 使用新的时间API能更简单的处理时间的相关问题. 文件操作Java1.4之后,Java引入了一个新的java.nio库,即New I/O. 因此现在的编程应该更多的使用新的类,而File类只应该在和旧系统交互时使用. 此外, Paths和Files两个类中还封装了一些与文件相关的常用操作, 从而可以减少重复代码. Path类Path是一个接口, 用于表示一个目录或者文件. 可以通过Paths.get方法获得一个Path实例. get方法接受若干字符串,并通过系统指定的分割符来连接字符串. 例如 1Path originPath = Paths.get(&quot;.&quot;, &quot;a.txt&quot;); 在Windows上就等于.\\a.txt而在Linux上等于./a.txt 遍历目录Files类提供了两个关于遍历指定目录下所有文件的方法, 两个方法都产生指定目录下所有文件构成的流, 但区别具体如下 方法 区别 list() 此操作不递归包含子目录中的项目 walk() 使用深度优先, 递归的包含全部的项目 此外, walk()方法还可以指定最大递归深度. 文件读取和写入Files类提供了很多以Path为参数的文件读写操作. 包括读取所有字节,所用行等操作. 1234Path path = Paths.get(&quot;a.txt&quot;);byte[] bytes = Files.readAllBytes(path);String content = new String(bytes);List&lt;String&gt; lines = Files.readAllLines(path); 在只是读取文件而后续操作与文件无关的场景下,使用Files的有关函数能更加简洁的完成任务. Fils类还提供newInputStream,newBufferedReader等方法来快速的创建一个流,相比于以往的嵌套模式,使用新的方法显然有助于增加代码可读性. Files类提供了copy方法来将一个流写入Path对应的文件或者将Path对应的文件写入流. 使用这个函数就基本可以不用再使用数据在流和文件之间交换数据了. 具体的使用示例可以参看下一节的Base64的代码. 创建文件Files类提供了createDirectory方法来创建一个目录,除了路径的最后一个目录以外,其他目录都必须存在. 如果想一次创建多个目录,可以使用createDirectories方法. 此外Files还提供了createTempFile方法来在系统或用户指定的位置创建临时文件或目录. 例如调用下面的方法 1Path tempPath = Files.createTempFile(null, &quot;.txt&quot;); 就可能返回一个类似9136812192980078079.txt的文件. 复制,移动函数Files类提供了copy和move方法来复制和移动文件或者目录,同时提供以下参数来指定复制或移动的方式. 参数 |—————–|———————————————————–REPLACE_EXISTING | 强制覆盖COPY_ATTRIBUTES | 复制文件属性ATOMIC_MOVE | 原子操作(要么完成移动,源文件删除,要么移动失败,源文件不变) 可以使用delete方法来删除一个文件,但如果指定的文件不存在,则抛出异常.使用deleteIfExists方法来检查并删除一个文件. Base64编码Java 8中提供了新的Base4编码和解码库. 可以通过Base64类的静态方法 getEnoder,getUriEncoder等方法来获得一个Base64.Encoder对象. 此外还可以包装一个输出流,使得所有发送给流数据都被自动的转换. 以下代码演示Base64的编码和解码过程 1234Base64.Encoder encoder = Base64.getEncoder();String original = &quot;LiZeC&quot; + &quot;:&quot; + &quot;, 你好&quot;;String encoded = encoder.encodeToString(original.getBytes());System.out.println(encoded); 以下代码演示对流进行包装 123456789101112131415Path originPath = Paths.get(&quot;.&quot;, &quot;a.txt&quot;);Path encodePath = Paths.get(&quot;.&quot;,&quot;a.encode&quot;);Path thridPaht = Paths.get(&quot;.&quot;,&quot;a.decode.txt&quot;);// encodeBase64.Encoder encoder = Base64.getMimeEncoder();try(OutputStream outputStream = Files.newOutputStream(encodePath))&#123; Files.copy(originPath, encoder.wrap(outputStream));&#125; // decodeBase64.Decoder decode = Base64.getMimeDecoder();try(InputStream input = Files.newInputStream(encodePath))&#123; Files.copy(decode.wrap(input), thridPaht);&#125; 时间API时刻Java 8中引入一个新的类Instant来表示时间线上的某一个时刻, 此类提供静态方法now()来获得当前时刻, 因此如果计算一段程序的执行时间, 可以使用如下的代码 12345Instant start = Instant.now();runAlgorithm();Instant end = Instant.now();Duration timeElapsed = Duration.between(start,end);long millis = timeElapsed.toMillis(); Duration表示一段时间, 内部使用long型变量保存秒数部分, 使用int型变量表示纳秒部分, 因此在表示大约300年的时间间隔时,Duration才会因为超过long范围而溢出. Instant和Duration都支持对当前时间进行四则运算, 并且提供判是否为0, 或者是否为负数的方法. 本地时间Java 8中引入LocalDate,LocalTime和LocalDateTime来表示本地的日期和时间. 这些变量都可以使用相应类的静态方法now或者of来构造, 并且支持计算在当前时间上加入几天,几个月, 几年等时间段时候的日期, 并且提供相互比较的方法. 格式化时间对于本地时间有关的类, 可以使用DateTimeFormatter进行格式化, 使用的方式如下 123final DateTimeFormatter fDay = DateTimeFormatter.ofPattern(&quot;yyMMdd&quot;);LocalDateTime time = LocalDateTime.now();System.out.println(time.format(fDay));","categories":[{"name":"Java特性","slug":"Java特性","permalink":"https://lizec.top/categories/Java%E7%89%B9%E6%80%A7/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://lizec.top/tags/Java/"}]},{"title":"Java特性之StreamAPI","slug":"Java特性之StreamAPI","date":"2018-11-21T08:07:30.000Z","updated":"2020-09-21T07:33:22.946Z","comments":true,"path":"2018/11/21/Java特性之StreamAPI/","link":"","permalink":"https://lizec.top/2018/11/21/Java%E7%89%B9%E6%80%A7%E4%B9%8BStreamAPI/","excerpt":"","text":"Stream是Java8中处理集合的关键抽象概念. 使用StreamAPI,编译器可以针对性的使用并行操作来对运算进行加速, 同时使用这些API也能让我们从处理低层次循环中脱离出来,从更高层次思考问题. StreamAPI以下代码演示了使用StreamAPI统计一段文本中所有长度大于7的单词数量 1234String contents = new String(Files.readAllBytes(Paths.get(&quot;alice.txt&quot;)),StandardCharsets.UTF_8);List&lt;String&gt; words = Arrays.asList(contents.split(&quot;[\\\\P&#123;L&#125;]+&quot;));long count = words.stream().filter(w-&gt;w.length() &gt; 7).count();System.out.println(count); 上述代码中,实际只有第三行是真正执行操作,而使用Stream可以概括成以下三步 创建一个Stream 在一个或多个步骤将一个stream转化为另一个stream 使用一个终止操作来获得结果 注意: Stream的操作很多都是延迟执行的,只有到需要的时候,有关的操作才会进行 Stream的执行顺序和实际调用的顺序可能并不一致 Stream不保存元素,有关元素保存在底层的集合中 创建Stream创建一个Stream有如下的几种方法 来源类 方法名 说明 Collection stream() 任意的集合类均可使用此实例方法 Stream of() 用于将若干个零散的元素组成一个流 Arrays stream() 用于将一个数组转化为流,这个流可能是特殊化的,例如IntStreamm Files lines() 创建文件中每一行字符串组成的字符串流 1234567891011List&lt;Apple&gt; inventory = Arrays.asList( new Apple(80,&quot;green&quot;), new Apple(155,&quot;green&quot;), new Apple(120,&quot;red&quot;));Stream&lt;Apple&gt; s1 = inventory.stream();Stream&lt;String&gt; s2 = Stream.of(&quot;123&quot;,&quot;234&quot;);int[] A = new int[10]Stream&lt;int[]&gt; s3 = Stream.of(A); // 返回Stream&lt;int[]&gt;IntStream s4 = Arrays.stream(A); // 返回IntStream, 即针对int类型的stream 对于of()方法,由于使用了可变参数,因此需要注意 可以接受数组,但是无法转换基础元素组成的数组,可以转化对象组成的数组并返回相应的类型 由于自动装箱机制,可以接受任意的基础元素,并返回包裹类的流 始终可以使用Arrays的stream()方法处理数组 特殊的流可以使用empty()函数获得一个空的流,例如 1Stream&lt;String&gt; stream = Stream.empty(); 可以使用generate()函数获得一个无穷流,每当需要一个元素的时候,就会调用给generate()提供的函数创建一个新的元素,例如 12Stream&lt;String&gt; echo = Stream.generate(()-&gt;&quot;Echo&quot;);Stream&lt;String&gt; randoms = Stream.generate(Math::random); 如果需要创建一个0,1,2,3,…的无穷序列,可以使用iterate()函数, 该函数需要一个种子和一个函数,通过反复将函数运用到上一个结果上得到一个无穷序列 1Stream&lt;BigInteger&gt; integers = Stream.iterate(BigInteger.ZERO,n -&gt; n.add(BigInteger.ONE)); 流转换以下三种方法都是用于转换流的方法,即将一个流转换为另外一个流. 方法名 效果 filter 接受一个Predicate对象,从而对流进行过滤 map 接受一个转换函数,此函数将一个元素转换为另一个元素;从而map方法将一个流转化为另一个类型的类 flatMap 接受一个转换函数,此函数将一个元素转化为一个流, 然后将所有返回的流合并成一个流 123456789101112131415String[] words = &#123;&quot;a&quot;,&quot;bcfs&quot;,&quot;ew&quot;,&quot;eqe&quot;&#125;;Stream&lt;String&gt; stream = Stream.of(words);// 通过过滤获得长度大于3的单词Stream&lt;String&gt; longWords = stream.filter(w-&gt;w.length() &gt; 3);// 通过map转换为首字母组成的流Stream&lt;Character&gt; firstChars = stream.map(s-&gt;s.charAt(0));// 通过flatMap将多个流合并成一个流(将单词流拆分为字符流)Stream&lt;Character&gt; letters = stream.flatMap(w -&gt; &#123; List&lt;Character&gt; result = new ArrayList&lt;&gt;(); for(char c:w.toCharArray()) &#123; result.add(c); &#125; return result.stream();&#125;); 注意: Objects类新增isNull和nonNull两个静态方法来进行NULL检查,在流中可能用到这些方法来进行匹配或过滤 提取或组合流 方法 效果 limit(n) 获得一个流的前n个元素(不足n则返回所有元素) skip(n) 跳过一个流的前n个元素 concat(s1,s2) 将两个流连接成一个流(第一个流不能为无限流,否则第二个流就没有被使用的机会了) peek() 可以添加一个函数,在每次取出一个元素时,调用添加的函数,从而便于调试 123456Object[] powers = Stream .iterate(1.0,p-&gt;p*2) .peek(e-&gt; System.out.println(&quot;Fetching &quot;+ e)) .skip(3).limit(5).toArray();Stream.of(powers).forEach(System.out::println); 注意: 默认情况下,给定的流都是有序的. 当不需要有序时,可以调用unorder()方法. 在无序条件下,dintinct()和limit()等方法可以获得更快的执行效率. 状态转换 方法 效果 distinct 获得一个无相同元素的流 sorted 对元素进行排序 如果仅仅是最终的结果需要无相同元素, 也可以考虑不使用distinct方法,而是将结果输出为一个Set. sorted的排序依赖Comparable接口, String,Integer等类已经实现了此接口,以此为元素的流可以无参数的调用sorted方法. 对于没有实现此接口的类, 可以为sorted提供一个Comparator来实现比较. Comparator类提供静态方法comparing,传入抽出key的函数即可完成构造指定类型的Comparator 注意: 这些方法由于涉及状态,基本上需要遍历整个流才能得到结果,因此性能开销较大 简单聚合方法查找和匹配 方法 效果 方法 效果 min 获得流中最小值 max 获得流中最大值 findFirst 返回第一个符合条件的元素 findAny 返回任意一个符合条件的元素(对多线程操作更友好) allMatch 返回是否所有元素均匹配给定的条件 noneMatch 返回是否所有元素均不匹配给定的条件 findFirst和findAny需要在调用之前调用filter函数进行筛选,而allMatch和noneMatch本身接受一个函数,因此可以直接使用 findFirst和findAny方法返回元素,而allMatch和noneMatch方法返回Boolean值 Optional类型findAny和findFirst方法并不直接返回元素,而是返回一个包装元素的Optional类型. 该对象中要么包含实际的元素,要么为空.正确的使用方法是调用其ifPresent函数. 该函数接受一个函数,如果元素存在,则执行传入的函数,否则直接跳过. 12345String[] words = &#123;&quot;Question&quot;,&quot;Stream&quot;,&quot;What&quot;,&quot;How&quot;,&quot;That&quot;,&quot;This&quot;&#125;;Optional&lt;String&gt; T = Stream.of(words).filter(s-&gt;s.startsWith(&quot;T&quot;)).findAny();T.ifPresent(System.out::println); 除此以外,还可以使用orElse函数时Optional对象为空时赋予另外的值,例如 1String result = T.orElse(&quot;none&quot;); 除了orElse以外,还可以用orElseGet填入一段代码来计算默认值或者orElseThrow来抛出一个异常 使用举例对于一个链式调用的过程,若其中的函数返回的不是基本类型而是Optional类型,可以使用flatMap函数来避免对空值的处理. 以下代码演示如何创建Optional对象以及如何组合链式调用 1234567891011121314151617public class RunStream &#123; public static void main(String[] args) &#123; Optional&lt;Double&gt; result = Optional .of(-4.0) .flatMap(RunStream::inverse) .flatMap(RunStream::sqrt); &#125; public static Optional&lt;Double&gt; inverse(Double x) &#123; return x == 0 ? Optional.empty() : Optional.of(1 / x); &#125; public static Optional&lt;Double&gt; sqrt(Double x) &#123; return x &lt; 0 ? Optional.empty() : Optional.of(Math.sqrt(x)); &#125;&#125; Optional类有一个flatMap函数,此函数接受一个条件,对Optional进行过滤,并且返回一个新的Optional. 当过程中所有的返回值都不为空时,程序正常的调用. 否则任何空值都会导致最后结果为空值 聚合操作 方法 效果 reduce 接受一个二元函数,并依次将二元函数运用到累计值和下一个元素上 123Integer[] values = &#123;1,2,3,4,5,6&#125;;Optional&lt;Integer&gt; sum = Stream.of(values).reduce((x,y)-&gt; x + y); // &lt;==&gt; 1+2+3+4+5+6sum.ifPresent(System.out::println); 注意: 上面求和过程中的lambda函数可以使用Integer::sum代替. 如果使用Integer::max则可以用来求最大值. 如果一个元素e满足e op x = x,即e为单位元时,可以作为reduce的起点,从而保证即使流为空也不用返回Optional对象 123Integer[] values = &#123;1,2,3,4,5,6&#125;;Integer sum = Stream.of(values).reduce(0,(x,y)-&gt; x + y);System.out.println(sum); 转化为集合 方法 效果 iterator 获得一个传统的迭代器 toArray 获得数组 注意:由于不能创建运行时的泛型数组,因此toArray()返回Object[]类型的数组. 或者向toArray函数传递一个构造器来获得类型. 12345678910111213Integer[] values = &#123;1,2,3,4,5,6&#125;;System.out.println(&quot;From Iterator&quot;);Iterator&lt;Integer&gt; it = Stream.of(values).iterator();while (it.hasNext())&#123; System.out.println(it.next());&#125;System.out.println(&quot;From Array&quot;);Integer[] re = Stream.of(values).toArray(Integer[]::new);for (Integer i: re) &#123; System.out.println(i);&#125; Collect操作Stream的collect操作是一个通用的操作,接受一个收集器,返回各种类型的收集结果. 以下介绍收集成各种不同类型时应该使用的收集器 收集为表使用Collectors的以下方法来产生指定的收集器 方法名 说明 toList 产生收集为List的收集器 toSet 产生收集为Set的收集器 toColection 指定一个构造器,产生指定类型的Set 123List&lt;String&gt; rlist = stream.of(words).collect(Collectors.toList());Set&lt;String&gt; rset = stream.of(words).collect(Collectors.toSet());HashSet&lt;String&gt; set = Stream.of(words).collect(Collectors.toCollection(HashSet::new)); 注意: 实际的代码中, 直接静态导入Collectors类的方法能进一步简化代码 收集为Map使用Collectors的以下方法来产生指定的收集器 方法名 说明 toMap 接受两个参数,分别提取键和值,产生收集为Map的收集器 注意: 虽然可以使用Function.identity()函数来获得实际的元素本身, 但使用e -&gt; e可能更简短 12Map&lt;Integer,String&gt; idToName = people.collect(Collectors.toMap(Person::getID,Person::getName));Map&lt;Integer,Person&gt; idToPerson = people.collect(Collectors.toMap(Person::getID, e -&gt; e); 如果有多个元素具有同样的key, 此方法会抛出IllegalStateException. 针对这种冲突, Collectors提供了groupingby方法来处理这种情况. 1 转化为字符串使用Collectors提供的以下方法产生的收集器可以将一个流转化为一个字符串 方法名 说明 joining() 返回一个可以将字符串连接起来的收集器 joining(String) 接受一个字符串作为各个元素之间的分隔符 1String result = Stream.of(words).collect(Collectors.joining(&quot;?&quot;)); //用?隔开各个元素的字符串 注意: 使用此方法连接的字符串,内部使用了StringBuilder, 因此比使用reduce方法连接效率更高 转化为数字统计如果对之后的结果需要进行最大值,最小值,平均值等数据的统计操作,可以将流转化为一个TYPESummaryStatistic类型. 其中TYPE为Int,Double或者Long. 可以分别使用Collector的如下方法 方法名 说明 summarizingTYPE 产生一个生成TYPESummaryStatistic的收集器,其中TYPE是Int,Double或者Long 123IntSummaryStatistics summary = Stream.of(words).collect(Collectors.summarizingInt(String::length));double averWordLength = summary.getAverage();double maxWordLength = summary.getMax(); 原始类型流由于Stream中使用原始类型需要进行装箱,效率很低,因此对于基础类型,Stream提供了特殊的一类Stream,包括IntStream,LongStream和DoubleStream. 可以使用如下的方法获得原始类型流, 以下均以Int为例,其他类型方法名类似. 来源类 方法名 说明 IntStream of 可变参数函数,接受零散的值或者同类型数组 Arrays stream 将对应类型的数组转化为Stream IntStream range 产生一个指定返回的Stream,类似Python中的range Stream maptoInt 将一个流转化为IntStream Random ints 一个包含随机数字的IntStream 如果想把原始类型流转化为对象流, 可以使用boxed方法 原始类型流除了不用进行装箱操作以外, 还提供了一组额外的操作, 以便于进行数值上的计算, 例如sum方法可以直接进行求和. 分组Collectors提供函数以下的方法,根据指定的条件将流进行分组 方法名 说明 groupingBy 根据指定的条件分组,类似SQL的GROUP BY partitioningBy 接受一个Prediction,将流分成两类 12345Stream&lt;Locale&gt; locales = Stream.of(Locale.getAvailableLocales());// 按照国家名称分类,以国家名称为键,语言代码的集合为值Map&lt;String, List&lt;Locale&gt;&gt; countryToLocales = locales.collect(Collectors.groupingBy(Locale::getCountry));List&lt;Locale&gt; cn = countryToLocales.get(&quot;CN&quot;);cn.forEach(System.out::println); 并行流 来源类 方法名 说明 Collection parallelStream() 任意集合类都可以直接创建并行流 Stream parallel() 任意流都可以转化为并行流 Stream sequential() 任意流都可以转化为串行流 调用parallel() 方法后, 流的内部进行了一个标记, 表示之后的操作都希望并行执行, 同样, 调用sequential()表示后续所有操作都希望按照串行执行. 并行流的内部使用了ForkJoinPool, 默认使用的线程数量与和处理数量一致. 并行流对于线程安全问题不做任何保证, 因此其中执行的方法要求保证是线程安全的. 高效实用并行流 并非任何时候采用并行流都会获得更高的性能, 当任务不容易切分时, 可能因为线程的开销导致性能反而低于串行流. 注意自动装箱机制, 尽量使用原始类型流 依赖顺序的方法,例如limit或findFirst的性能在并行流上更差, 此时可以考虑使用不依赖顺序的方法或者使用unorder方法 数据量较小或者处理每个元素的时间占比低的情况下不适合使用并行流 如果数据结构不易分解, 不适合使用并行流 各种数据源可分解程度如下表所示: 源 可分解性 源 可分解性 ArrayList 极佳 IntStream.range 极佳 HashSet 好 TreeSet 好 LinkedList 差 Stream.iteratr 差","categories":[{"name":"Java特性","slug":"Java特性","permalink":"https://lizec.top/categories/Java%E7%89%B9%E6%80%A7/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://lizec.top/tags/Java/"},{"name":"StreamAPI","slug":"StreamAPI","permalink":"https://lizec.top/tags/StreamAPI/"}]},{"title":"Java特性之Lambda表达式","slug":"Java特性之Lambda表达式","date":"2018-11-21T08:05:34.000Z","updated":"2020-07-16T10:32:51.407Z","comments":true,"path":"2018/11/21/Java特性之Lambda表达式/","link":"","permalink":"https://lizec.top/2018/11/21/Java%E7%89%B9%E6%80%A7%E4%B9%8BLambda%E8%A1%A8%E8%BE%BE%E5%BC%8F/","excerpt":"","text":"在很多函数式编程的语言中,都具有lambda表达式. lambda表达式可以视为一段可以被引用的代码, Java中经常使用的匿名类就可以视为一种lambda表达式的替代品. 在Java 8中, 正式的引入了lambda表达式的概念, 本文介绍如何在Java中使用lambda表达式. 基础知识在Java中一直有需要lambda表达式的场景,一个典型的例子就是需要注入一个匿名类的接口. 例如 12345Thread thread = new Thread(new Runnable&#123; public void run()&#123; System.out.println(&quot;Hello&quot;); &#125;&#125;); 在上述例子中,实际上只是需要一个run方法而已,但是由于java是面向对象的语言,方法不能脱离对象存在,因此必须将方法依附与某个具体的类或者接口. 而使用lambda表达式后,上述代码可以简化为 1Thread thread = new Thread(()-&gt;System.out.println(&quot;Hello&quot;)); 这样代码的简洁性就有了巨大的提升. 实际上,在Java 8中,任何需要一个接口函数的地方,都可以使用lambda函数进行替换. 一个完整的lambda表达式一般具有以下的形式 12345678(String a,String b) -&gt; &#123; if(a.length() &lt; b.length())&#123; return a; &#125; else&#123; return b; &#125;&#125; 一个lambda表达式可以分成以下几个部分 参数列表,在上例中是(String a,String b) 箭头-&gt; 函数体 注意 在任何情况下,都不需要写返回类型,返回类型由编译器根据上下文进行推导 如果参数类型也可以被推导,则参数列表中也不用写变量类型 如果只有一个参数,可以省略括号,例如v -&gt; Sysmtem.out.println(v) 如果不需要参数,则提供一对空括号,即() 引用方法在某些接口中,可能需要的方法已经在其他类中提供了,因此java也提供了直接引用已经存在方法的语言,即 使用::来引用一个方法.对于::操作符,有三种使用场景 对象::实例方法 类::静态方法 类::实例方法 对于前两种方法,方法引用等于提供方法的的lambda表达式.例如 12System.out::println &lt;==&gt; x -&gt; Sysmtem.out.println(x)Math::pow &lt;==&gt; (x,y) -&gt; Math.pow(x,y) 对于第三种情况,第一个参数将成为执行方法的对象,例如 12String::length() &lt;==&gt; x -&gt; x.length()String::compareToIgnoreCase &lt;==&gt; (x,y) -&gt; x.compareToIgnoreCase(y) 在引用方法时,也可以使用this和super,两者指向的对象取决于定义lambda函数时的位置,例如 12345678910public class Main &#123; public void greet() &#123; System.out.println(&quot;Hello!&quot;); &#125; public void hello() &#123; Thread thread = new Thread(this::greet); thread.start(); &#125;&#125; 在上述hello()函数中,this指的就是所在的Main类,而this::greet就是该类中的greet函数. 实际上这与匿名类中使用外部类.this来访问外部的变量是类似的效果.注意: 内部类中使用的this指的是内部类本身,而不是外部的类,这是lambda与内部类的一个区别 除了引用普通的方法以外,还可以引用构造函数,例如 123List&lt;String&gt; labels = new ArrayList&lt;&gt;();Stream&lt;Button&gt; stream = labels.stream().map(Button::new);List&lt;Button&gt; buttons = stream.collect(Collectors.toList()); 先不用在意这些函数到底都是些什么,这些函数具体的效果在后续章节中会进行介绍,现在只用注意到第二行的代码中,map函数接受了Button类的new构造函数. map函数会在labels的每个元素上调用Button的构造函数,从而构造了一组Button. 闭包作用域在很多实现了闭包的语言中,在函数内部定义的函数,可以自由的引用该函数外部的变量, 在java中也实现了类似的机制,例如 1234567891011121314public static Runnable repeat(String text,int count) &#123; Runnable runnable = () -&gt; &#123; for(int i=0;i &lt; count;i++) &#123; System.out.println(text); Thread.yield(); &#125; &#125;; return runnable;&#125;public static void main(String[] args) &#123; Runnable runnable = repeat(&quot;Hello&quot;, 10); new Thread(runnable).start();&#125; 在上述代码中,runnable中引用了其外部的text和count对象. 含有自由变量的代码段成为闭包. 实现闭包有一个问题,那就是在runnable被调用的时候,repeat函数已经结束了,text变量和count变量已经离开作用域了. 所以在runnable中必须保存这两个变量. 而实际上java也对自由变量做了限制, 即在lambda中不可对自由变量进行修改. 这一点有两方面原因 lambda调用时,引用的自由变量可能已经不存在了,此时修改是没有意义的 多个线程运行时,这样的修改不是线程安全的 JDK中新增Lambda相关代码生成比较器Java的Comparator提供了一种生成比较器的方法, 仅需要像此方法提供一个类的属性提取方法, 即可生成比较该类的比较器 12Comparator&lt;Person&gt; comp = Comparator.comparing(Person::getName);comp.compare(p1,p2); Map操作Map的一个常见操作是检查是否存在某个key, 如果不存在则放入新的值, Java新增computer, computerIfAbsent等方法处理这种情况, 例如 123public Artist getArtist(String name) &#123; return artistCache.computeIfAbsent(name, this::readArtistFromDB);&#125; 此外, 针对Map遍历语法比较困难的问题, Java也新增了ForEach方法, 例如 1234Map&lt;Artist, Integer&gt; countOfAlbums = new HashMap&lt;&gt;();albumsByArtist.forEach((artist, albums) -&gt; &#123; countOfAlbums.put(artist, albums.size());&#125;);","categories":[{"name":"Java特性","slug":"Java特性","permalink":"https://lizec.top/categories/Java%E7%89%B9%E6%80%A7/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://lizec.top/tags/Java/"},{"name":"函数式编程","slug":"函数式编程","permalink":"https://lizec.top/tags/%E5%87%BD%E6%95%B0%E5%BC%8F%E7%BC%96%E7%A8%8B/"}]},{"title":"JDK辅助工具介绍","slug":"JDK辅助工具介绍","date":"2018-11-21T08:05:22.000Z","updated":"2020-06-26T14:41:56.621Z","comments":true,"path":"2018/11/21/JDK辅助工具介绍/","link":"","permalink":"https://lizec.top/2018/11/21/JDK%E8%BE%85%E5%8A%A9%E5%B7%A5%E5%85%B7%E4%BB%8B%E7%BB%8D/","excerpt":"","text":"本文介绍JDK中提供了一系列辅助工具的使用方法, 包括打包程序jar, 监控程序Visual VM等. Jar指令使用jar指令对Java的的代码和资源文件进行压缩或解压 压缩包：jar cvf filename.jar a.class b.class: 压缩指定文件；jar cvf weibosdkcore.jar *: 全部压缩； 解压包：jar xvf test.jar 选项: c 创建新档案 t 列出档案目录 x 从档案中提取指定的 (或所有) 文件 u 更新现有档案 v 在标准输出中生成详细输出 f 指定档案文件名 Javascript引擎Java提供了一个新的Javascript引擎,名为Nashorn(德语的犀牛,发音类似nas-horn). 在JDK的bin目录中,可以找到一个叫做jss的工具, 通过命令行打开该程序即可获得一个JavaScript的交互命令行. 从Java运行Nashorn从Java6开始,Java提供了脚本引擎机制,通过该机制可以运行一个Nashorn脚本. 当然通过配置以后,也可以运行Groovy,JRuby,Jython等语言. 也有一些其他的引擎可以使JVM支持PHP或者Scheme. 以下代码演示如何从Java中初始化一个nashorn脚本引擎,并运行JavaScript代码 12345ScriptEngineManager manager = new ScriptEngineManager();ScriptEngine engine = manager.getEngineByName(&quot;nashorn&quot;);// 直接执行代码Object result = engine.eval(&quot;&#x27;Hello World&#x27;.length&quot;);System.out.println(result);","categories":[{"name":"JDK笔记","slug":"JDK笔记","permalink":"https://lizec.top/categories/JDK%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://lizec.top/tags/Java/"}]},{"title":"Java特性之基础特性","slug":"Java特性之基础特性","date":"2018-11-21T08:05:22.000Z","updated":"2020-08-03T03:22:01.688Z","comments":true,"path":"2018/11/21/Java特性之基础特性/","link":"","permalink":"https://lizec.top/2018/11/21/Java%E7%89%B9%E6%80%A7%E4%B9%8B%E5%9F%BA%E7%A1%80%E7%89%B9%E6%80%A7/","excerpt":"","text":"本文介绍一些零散的Java特性, 虽然这些知识都比较零散, 但是合理使用可以有效的简化程序的逻辑, 降低开发难度. Java泛型简介定义泛型函数任何一个泛型函数都需要在函数的返回类型前声明使用到的类型,例如 123public &lt;T&gt; void print(T num) &#123; System.out.println(num);&#125; 上述代码中首先声明了一个泛型名T,然后此函数接受一个类型为T的变量作为参数. 有界的参数类型有时候并不希望任何类型都被传递给函数,而希望只接受某个类的子类,此时可以使用extern关键字,例如 1public &lt;T extends Person&gt; f(T p) &#123; ... &#125; 上述函数表示只接受Person及其子类作为参数 类型通配符使用类型通配符?来代替任意一种类型,例如List&lt;?&gt;表示任意List实例化的类型,例如List&lt;Integer&gt;或者List&lt;String&gt;. 通配符既可直接作为模板类型也可以用于构成更复杂的模板类型,例如 12public void print(List&lt;?&gt; list) &#123; ... &#125;public &lt;T extends List&lt;?&gt;&gt; print(T list) &#123; ... &#125; 类型通配符也可以进行限制,例如在Compartor接口中定义的comparing函数声明如下 12public static &lt;T, U extends Comparable&lt;? super U&gt;&gt; Comparator&lt;T&gt; comparing( Function&lt;? super T, ? extends U&gt; keyExtractor) 首先&lt;T, U extends Comparable&lt;? super U&gt;&gt;表面这个函数使用了两个类型名T和U,其中T为任意类型,U是某个Comparable的子类,而该Comparable实例化的类型必须是U的父类. 再看返回类型 Comparator&lt;T&gt;,该函数返回一个T类型的Comparator对象 最后看参数声明Function&lt;? super T, ? extends U&gt; keyExtractor,首先这是一个函数对象,根据文档,Function&lt;T,R&gt;表示接受参数T,返回类型为R的函数,所以这里的keyExtractor是一个接受T和其父类的类型为参数的,返回类型为U或其子类的函数. 注意声明Function&lt;? super T, ? extends U&gt;中, 其中? super T是逆变性的一种体现, 即如果要求传入的函数是一个处理String的函数, 那么传入的函数可以是接受Object的函数, 因为String满足Object的所有特点, 可以被传入. 其中? extends U, 是协变性的体现, 即如果要求函数是一个返回Object的函数, 那么可以接受返回String的函数. 这种接口的声明方式, 在各种函数有关的接口中非常常见. Java注解简介注解的定义注解使用@interface定义, 定义的方式和接口类似, 例如 123public @interface LiZeC &#123;&#125; 如上就定义了一个名为LiZeC的注解, 之后就可以和其他注解一样使用,例如 1234@LiZeCclass Me &#123;&#125; 注意: 注解本身只提供一个标记, 具体的作用需要通过Java的反射机制, 使用额外的代码来实现 元注解元注解就是注解的注解, 元注解为我们自定的注解提供了基本的语义信息. Java的元注解包括 Annotation Description @Retention 指定注解的保留期,是仅保留至源代码还是保留到运行时 @Documented 指示注解与文档相关 @Target 指定注解运用的对象,例如是类还是方法或者字段 @Inherited 指定注解可以被继承 @Repeatable 指定注解可以被重复 其中@Retention具有如下三种类型 Type Description SOURCE 编译时被编译器丢弃(discard) CLASS 被编译到字节码文件但不加载到VM, 是默认值 RUNTIME 被编译到字节码文件并且加载到VM,从而可以被反射获得 其中@Target具有如下的类型 Type Description Type Description TYPE 类,接口(包括注解),枚举 LOCAL_VARIABLE 局部变量 FIELD 字段 ANNOTATION_TYPE 注解 METHOD 方法 PACKAGE 包 PARAMETER 参数 TYPE_PARAMETER 类型参数 CONSTRUCTOR 构造函数 TYPE_USE 任意类型 注解的值通常情况下, 注解的内部会定义一些值, 从而为处理注解时提供更多额外的信息. 例如 123public @interface LiZeC &#123; String name() default &quot;&quot;;&#125; 在上述注解中, 定义了名为name的元素, 其类型为String, 默认值为空字符串. 之后就可以如下的使用注解 1234@LiZeC(name=&quot;Me&quot;)class Me &#123;&#125; 注解的元素类型可以是 基本类型, String, Class, enum, Annotation 以及这些类型的数组. 此外, 如果定义的元素名称为value, 且此元素是唯一需要赋值的元素, 则可以省略元素名, 直接赋值. 参考文献和扩展阅读 秒懂，Java 注解 （Annotation）你可以这样学 深入理解Java注解类型(@Annotation) Java枚举类型Java从JDK1.5开始, 加入了枚举类型. 和各种语言中定义的枚举类型一样, Java枚举中的字段可以表示一个选项, 从而用于判断或者switch语句. 枚举的定义语法与类定义语法相似, 只是关键词不同, 例如: 123public enum Color &#123; RED, GREEN, BLANK, YELLOW &#125; 枚举方法实际上, Java中的枚举相当于一个继承了java.lang.Enum的类, 可以向枚举中添加任意的方法和构造函数, 例如 12345678910111213141516171819202122232425262728293031323334public enum Color &#123; RED(&quot;红色&quot;, 1), GREEN(&quot;绿色&quot;, 2), BLANK(&quot;白色&quot;, 3), YELLO(&quot;黄色&quot;, 4); // 注意最后的分号 // 成员变量 private String name; private int index; // 构造方法 private Color(String name, int index) &#123; this.name = name; this.index = index; &#125; // 普通方法 public static String getName(int index) &#123; for (Color c : Color.values()) &#123; if (c.getIndex() == index) &#123; return c.name; &#125; &#125; return null; &#125; // get set 方法 public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getIndex() &#123; return index; &#125; public void setIndex(int index) &#123; this.index = index; &#125; &#125; Java枚举的七种常见用法 Java可变参数简介Java的可变参数本质就是数组, 函数被编译成字节码后,可变参数就是一个数组. 可变参数与数组的转换 声明一个可变参数以后,既可以传入多个单独的参数,也可以传入一个数组 在函数内部,总是视为一个数组 匹配规则 可变参数至少传入一个参数 可变参数函数与固定参数函数同时匹配时,调用固定参数函数 多种可变参数同时匹配时,编译失败 Java函数式接口函数式接口标记对于自定义的函数式接口,可以使用@FunctionalInterface注解, 这样有两个效果 编译器会检测此接口是否只包含一个抽象接口 在javadoc中提供一项声明,指出这是一个函数式接口 Java常见函数式接口 函数式接口 参数类型 返回类型 抽象方法名 说明 Runnable Node void run 执行一个没有参数和返回值的操作 Supplier None T get 提供一个T类型的值 Consumer T void accept 处理一个T类型的值 BiConsumer&lt;T,U&gt; T, U void accept 处理T类型和U类型的值 Predicate T bollean test 计算出一个逻辑结果 toIntFunction T int applyasInt 转化为int,也存在转化为long和double的同类函数 IntFunction int R apply 从int转化为其他类型,也存在从long和double转化的同类函数 Function&lt;T,R&gt; T R apply 一个参数类型为T返回类型为R的函数 BiFunction&lt;T,U,R&gt; T, U R apply 一个参数类型为T和U,返回类型为R的函数 UnaryOperator T T apply 对类型T的一元操作 BinaryOperator T, T T apply 对类型T的二元操作 try-with-resources语句从Java 7开始,可以在try后跟上一个括号, 从而打开一个资源并由编译器保证无论发生何种情况, 都正确的调用close语句关闭资源. 该特性与C#的using语句类似. 编译器只保证在离开作用域后能调用close,但不主动catch任何异常,因此在try中的异常还是需要进行处理. 所有实现了AutoCloseable接口的资源类都可以使用此机制. 对null的处理Java提供了如下的一组方法来处理各种常见的null值问题, 使用下面的方法可以减少代码中的判断逻辑. 方法 解释 Objects.equals(a,b) 可以正确的处理a,b为null的情况,而不抛出异常 Objects.hash(a,b, …) 可以组合多个对象,产生一个hash值 String.valueof(obj) 可以保证null也被转化为字符串”null”,而不抛出异常 Objects.toString(o,””) 可以在o为null时,返回第二个参数指定的值 Integer.compare(a,b) 比较两个数的值,并且保证没有溢出风险 全局日志从Java 7开始, 提供了一种简便获得日志对象的方法, 即Logger.getClobel(), 使用此函数可以简便的替换System.out.println()进行日志输出. 123Logger.getGlobal().setLevel(Level.WARNING);Logger.getGlobal().info(()-&gt;&quot;Hello&quot;);Logger.getGlobal().warning(()-&gt;&quot;Warning&quot;); 默认方法在Java 8中,可以对接口添加默认的方法,使用default关键字声明,例如 1234public interface Person &#123; long getAge(); default void plusOne(int old, int you) &#123; old += 1; you -= 1;&#125; &#125; 通过默认方法, Java在行为上实现了多继承, 对于继承过程中可能的冲突问题, 按照如下的规则判断 类中的方法优先级最高, 类或父类中声明的方法的优先级高于任何声明为默认方法的优先级 子接口优先级更高, 函数签名相同时, 优先选择最具体的实现的默认方法 若以上两条规则均无法判定, 则类中需要显式的指定调用哪一个方法","categories":[{"name":"Java特性","slug":"Java特性","permalink":"https://lizec.top/categories/Java%E7%89%B9%E6%80%A7/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://lizec.top/tags/Java/"}]},{"title":"Git笔记之分支操作","slug":"Git笔记之分支操作","date":"2018-09-07T11:20:22.000Z","updated":"2020-06-26T14:40:12.279Z","comments":true,"path":"2018/09/07/Git笔记之分支操作/","link":"","permalink":"https://lizec.top/2018/09/07/Git%E7%AC%94%E8%AE%B0%E4%B9%8B%E5%88%86%E6%94%AF%E6%93%8D%E4%BD%9C/","excerpt":"","text":"分支管理查看现有分支1$ git branch 创建和切换分支12345$ git branch &lt;分支名&gt; //创建新分支$ git checkout &lt;分支名&gt; //切换分支$ git checkout digs &lt;分支名&gt; //从指定的ID创建分支$ git checkout -b &lt;分支名&gt; //创建并切换分支$ git checkout -b &lt;本地分支名&gt; &lt;origin/远程分支名&gt; //创建并拉取一个分支 分支合并和撤销123$ git merge branchName //将指定分支的内容合并到当前分支$ git merge --no-gg branchName //将指定分支的内容合并到当前分支(非快进合并)$ git reset --merge //撤销本次合并 例如，想要将dev分支的内容合并到master分支，则应该按照如下步骤操作 12$ git checkout master$ git merge dev 快进合并 假设当前有两个分支master和dev，如果仅仅在dev分支上进行更改，而在master上没有操作，此时在master分支上进行合并，则默认进行快速合并，此时相当于将master的指针移动到和dev指针相关的位置 如果使用非快进合并，则相当于在master分支上进行一次commit，此commit后的内容将和dev分支相同，从而可以保留提交的相关信息，以便于之后的查找 修改和删除分支123$ git branch -m branchName newBranchName // 重命名分支$ git branch -d branchName // 删除本地分支$ git push origin --delete branchname // 删除远程分支 冲突合并如果两个分支的修改存在冲突，合并时会提示相关的冲突文件，并且在相关的文件中留有标记，因此可以手动到相关的文件中修改冲突的内容，之后再次进行提交 注意：手动解决冲突不是必要的，可以在冲突的文件中选择保留某个分支的修改，也可以选择两个分支的更改都抛弃，或者不进行任何更改 保存现场和恢复现场12345$ git stash list //列出所有的保存内容$ git stash //保存当前工作区和暂存区的内容$ git stash apply //应用栈顶的内容$ git stash drop //删除栈顶的内容$ git stash pop //应用并删除栈顶的内容 通常情况下，如果工作区或暂存区有未提交的内容时，是不允许切换分支的 使用上述命令可以先保存相关的操作，切换分支处理优先级高的问题，最后切换回来并恢复环境 高级操作变基操作 例如有两个分支master和dev,master分支在A提交后分出dev分支，之后进行了B提交，在dev分支上进行了C和D提交， 使用变基操作后，相当于将dev分支从B上分出 相当于对于C提交和D提交都进行合并1$ git rebase master 变基操作的冲突处理 如果在变基过程中产生了冲突，变基操作会终止，并提示冲突原因 此时需要手动处理相关冲突，并add到缓冲区 之后指定 git rebase –continue 移植分支12$ git chechout dev$ git rebase master --onto release 删除冗余1$ git gc 删除不可访问的提交 改善文件保存结构 使用gc命令可以节约硬盘空间 参考资料和扩展阅读 简单介绍三路合并 git merge参数详解(还链接了几篇其他文章, 也可以看看)","categories":[{"name":"Git笔记","slug":"Git笔记","permalink":"https://lizec.top/categories/Git%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Git","slug":"Git","permalink":"https://lizec.top/tags/Git/"}]},{"title":"大数据导入和分析","slug":"大数据导入和分析","date":"2018-08-15T03:22:39.000Z","updated":"2019-02-07T09:42:07.200Z","comments":true,"path":"2018/08/15/大数据导入和分析/","link":"","permalink":"https://lizec.top/2018/08/15/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%85%A5%E5%92%8C%E5%88%86%E6%9E%90/","excerpt":"","text":"本文是大数据分析案例系列文章. 本文主要介绍将前一步生成的数据导入Hadoop平台,并进一步将数据导入Hive. 数据导入以后,可以使用SQL语句进行查询和分析, 最后对比统计分析结果和之前随机数的使用结果. 数据导入Hadoop启动Hadoop在Hadoop安装目录下执行 12sbin/start-dfs.shsbin/start-yarn.sh 访问 http://localhost:9870/, 如果显示正常, 则说明hdfs启动成功. 导入数据在Hadoop安装目录下执行 1bin/hdfs dfs -mkdir -p /dataset/user 从而在HDFS的根目录下创建一个dataset文件夹, 之后可以在 HDFS提供的Web版文件浏览器中查看是否创建成功. 导入文件之后,也可以使用文件浏览器查看导入文件的情况. 假设前一步生成的数据存放在 /home/lizec/IdeaProjects/RandomDataSet/data.txt, 则在Hadoop安装目录下执行 1bin/hdfs dfs -put /home/lizec/IdeaProjects/RandomDataSet/data.txt /dataset/user/user.txt 将本地文件系统中的data.txt文件复制到Hadoop文件系统之中,并且命名为user.txt. 在文件浏览器中查看无误, 则数据以及成功导入到HDFS之中. 关于HDFS的Shell指令,可以查看HDFS Commands Guide. 实际上, 很多指令都与linux本身的shell指令相类似, 如果有shell的使用经验, 可以很容易的理解上述的指令. 数据导入Hive启动Hive在Hive安装目录下执行 1bin/hive 启动后Hive给出了输出, 提示基于MapReduce的Hive在Hive 2中已经被标记为废弃, 后续可能不再支持, 建议更换引擎(例如Spark), 或者继续使用Hive 1 因此虽然已经被废弃,但是继续使用是暂时没有问题的, 关于更换引擎的问题,后续有机会再补充. 导入数据Hive启动后, 先输入以下的HiveQL语句来创建数据库 12CREATE DATABASE bigdata;USE bigdata; 然后执行下面的语句创建表 12345678910111213CREATE EXTERNAL TABLE bigdata.userinfo( id STRING, uid INT, item_id INT, behavior_type STRING, visit_date DATE, province STRING) COMMENT &#x27;User Info&#x27; ROW FORMAT DELIMITED FIELDS TERMINATED BY &#x27;\\t&#x27; STORED AS TEXTFILE LOCATION &#x27;/dataset/user/&#x27;; 这里解释一下上面的语句, 前面的CREATE操作和SQL一样,创建了一个表dblab.user,其中有若干字段. COMMENT行是表的注释. ROW FORMAT DELIMITED表示将源文件中的每一行视为一条记录, FIELDS TERMINATED BY &#39; &#39;表示以空格作为分隔符切分字段. STORED AS TEXTFILE表示以文本形式存储. LOCATION &#39;/dataset/user/&#39;指定原始数据在HDFS中的路径,该路径下所有的文件都为视为原始数据. 此外user似乎是关键字, 不能作为表的名称. 数据分析基本信息首先可以查看表的前10条数据,来确保数据已经被正确的解析, 执行如下的语句: 1select * from userinfo limit 10; 返回结果如下 123456789101112OK 1 24531 1728 1 2018-07-09 河南省 2 14409 1785 1 2018-03-21 四川省 3 17986 1680 1 2017-09-22 河北省 4 15028 1921 2 2018-01-25 江苏省 5 21294 1937 1 2018-07-24 广西壮族自治区 6 11613 1649 1 2018-07-03 江苏省 7 18916 1031 1 2018-03-16 河北省 8 10281 1296 1 2017-09-01 山东省 9 11770 1445 1 2017-12-24 湖南省 10 24586 1323 1 2018-07-10 湖南省Time taken: 0.269 seconds, Fetched: 10 row(s) 由此可见,数据已经被正确的解析,并且可以通过sql语句进行查询. 数据分布检验省份数据检验在前一步的数据生成过程中,对省份的数据进行了特殊的处理,使得各省份出现的概率与该省份的人口数量成正比. 下面通过统计检验这一设定是否成立. 通过统计各个省份实际出现的次数,并且依据次数的多少进行排名,再与实际的人口排名进行对比, 即可简单的检验设定是否正确. 因此执行如下语句统计各个省份实际出现的次数 1SELECT province, COUNT(*) num FROM userinfo GROUP BY province ORDER BY num DESC LIMIT 10; 统计得到结果如下 12345678910广东省 182569山东省 164191河南省 156987四川省 136488江苏省 131378河北省 123386湖南省 113062安徽省 102961湖北省 97062浙江省 92326 与之前的2018年全国各省人口总数排行榜进行比较,可以看到两者的结果是完全一致的,各部分之间比例也是接近的, 从而说明之前的随机算法是正确的. 数据导入MySQL创建Hive表经过前面的各种数据分析,我们可以把最后的分析结果导入到MySQL数据库中,从而可以被其他应用程序访问和展示. 首先在Hive中创建一个省份的分布表,并向其中插入数据, 代码如下: 12345678910CREATE TABLE bigdata.prvinfo( province STRING, num INT) ROW FORMAT DELIMITED FIELDS TERMINATED BY &#x27;\\t&#x27; STORED AS TEXTFILE;INSERT OVERWRITE TABLE bigdata.prvinfoSELECT province, COUNT(*) num FROM userinfo GROUP BY province ORDER BY num DESC; 其中第一部分的代码创建了一个名为prvinfo的表,其中包含省份名和数量两个字段. 第二部分代码之前已经使用过,从原始的表中分别统计了每个省份的人数. 上述代码执行完毕后, 可以使用HDFS的文件浏览器查看/user/hive/warehouse/bigdata.db/prvinfo目录下是否有创建文件,以及文件内容是否为上述指令的查询结果. 创建MySQL表启动mysql,并且执行如下的语句: 123456789CREATE DATABASE bigdata;USE bigdata;CREATE TABLE bigdata.prvinfo ( province CHAR(20), num INT) ENGINE=InnoDB DEFAULT CHARSET=utf8; 第一部分代码创建了一个数据库bigdata,第二部分代码创建了一个表prvinfo. 由于MySQL中并没有的STRING类型,因此可以使用CHAR代替. 使用Sqoop导入数据这里使用的Sqoop是Sqoop1.4.7, 是当前的最新稳定版. 还有一个版本是Sqoop1.99.7, 根据官网介绍,这个版本与Sqoop1.4.7不兼容,不建议在生产环境中部署此版本. 在Sqoop的安装目录下执行以下指令: 1bin/sqoop export --connect jdbc:mysql://localhost:3306/bigdata --username root --password 123456 --table &#x27;prvinfo&#x27; --export-dir &#x27;/user/hive/warehouse/bigdata.db/prvinfo&#x27; --fields-terminated-by &#x27;\\t&#x27;; 各参数含义如下 参数 含义 connect 需要连接的mysql数据库 username mysql用户名 password mysql密码 table 被导入的mysql数据库表名 export-dir Hive数据的HDFS路径 fields-terminated-by 数据分割符号 注意: --table 指定表名时, 表名一定要用引号括起来,否则可能导入失败. 数据可视化在前一步, 我们已经将省份的数据导入了MySQL之中, 之后我们就可以使用Java Web的有关技术来获得数据并且在网页上展示出来. 这里使用Tomcat作为Web服务器, 使用ECharts作为数据可视化工具. ECharts是一个JavaScript编写的图像库, 可以简单地绘制各种常见图形. 环境配置环境配置可以参考如下的一些文章, Tomcat和ECharts的配置都很简单,就不赘述了. Java Web开发与运行环境配置 ECharts用户文档 数据转换把数据库中的数据绘制到网页上有三个步骤 使用Java语言将数据从数据库中取出 将JSP的数据转换为JS的数组 调用EChart的函数绘制图形 其中第一步和第三步都是常规操作, 这里简单介绍第二步的实现方案. 在JSP代码部分, 首先声明数组并且把数据填充为HTML代码: 12345678910111213141516&lt;!-- 声明存放数据的Java数组,并获得数据 --&gt;&lt;%! ArrayList&lt;ProvincePair&gt; data = ProvinceDb.getInfo();%&gt;&lt;!-- 将Java数组转化为HTML代码 --&gt; &lt;% for(int i=0;i&lt;data.size();i++) &#123; %&gt; &lt;input name=&quot;store_name&quot; type=&quot;hidden&quot; value=&quot;&lt;%=data.get(i).getName()%&gt;&quot;/&gt; &lt;input name=&quot;store_num&quot; type=&quot;hidden&quot; value=&quot;&lt;%=data.get(i).getNum()%&gt;&quot;/&gt; &lt;%&#125;%&gt; 接下来使用js的标签查找方式获得上述的标签, 然后取出各个标签的value字段 12345678910var sname = document.getElementsByName(&quot;store_name&quot;) var snum = document.getElementsByName(&quot;store_num&quot;);var name = [];var num = [];for(var i=0;i&lt;sname.length;i++)&#123; name[i] = sname[i].value; num[i] = snum[i].value;&#125; 这样就完成了JSP数组到JS数组的转化, 由于本人没系统学过JS, 因此不能保证这种转化方案是最优的, 欢迎各位在评论区补充. 结果展示对于省份数据, 可以考虑使用饼图进行展示. ECharts网站上提供了很多实例, 我们只需要稍加修改即可完成数据的展示, 例如选择Pie With Scollable Legend. 直接复制左侧的实例代码, 将其中的数据源修改为我们从数据库中提取的数据, 最终绘制结果如下所示 特别感谢在本文的编写过程中, 参考了如下的两个系列的博客, 对博客的作者表示由衷地感谢! 网站用户行为分析 淘宝双11数据分析与预测课程案例 参考资料 Why do we use ‘row format delimited’ and ‘fields terminated by’ in table creation in Hive and in Hadoop? hive sql语法解读 hive内部表与外部表区别详细介绍","categories":[{"name":"大数据分析案例","slug":"大数据分析案例","permalink":"https://lizec.top/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%A1%88%E4%BE%8B/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://lizec.top/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"}]},{"title":"大数据环境配置和数据生成","slug":"大数据环境配置和数据生成","date":"2018-08-14T14:55:48.000Z","updated":"2019-02-07T09:42:11.205Z","comments":true,"path":"2018/08/14/大数据环境配置和数据生成/","link":"","permalink":"https://lizec.top/2018/08/14/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E5%92%8C%E6%95%B0%E6%8D%AE%E7%94%9F%E6%88%90/","excerpt":"","text":"这是一个系列的文章, 介绍了一个完整的大数据分析案例, 包括有关的软件安装, 数据集的生成, 数据分析以及最终的数据可视化. 本文介绍软件安装和数据集生成. 前置知识要求 linux基本知识，尤其是shell有关的知识 Java基础知识 SQL语言 Web有关知识（Servlet，JavaScript） 如果其中有没有学过的知识, 建议先对相关知识有基本的了解以后再阅读本文. 软件安装关于Hadoop平台的软件安装, 网络上有很多教程, 这里推荐阅读厦门大学实验室的有关博客 Hadoop安装教程_单机/伪分布式配置 Ubuntu安装MySQL及常用操作 基于Hadoop的数据仓库Hive 学习指南 Ubuntu安装Sqoop 强烈建议同时阅读各个软件的官网上的安装指南. 由于各软件都在不断的更新, 可能有各种细节的变化, 先阅读官网资料有助于减少由于安装失败浪费的时间. 数据集生成由于一般比较难获得合适的数据集, 而在练习数据分析的过程中数据本身其实相对来说并不太重要. 因此可以先编写一个小程序, 按照一定的规律产生需要的数据集. 由于数据集由程序产生, 因此数据格式等方面都可以控制, 避免了数据清洗的繁琐步骤, 从而将主要精力放在数据分析上. 此外由于完全掌握数据生成规律, 也可以和后续的统计分析结果相互印证. 用户浏览数据集用户浏览数据集可以分为5个字段,即用户id,商品id,用户行为,时间,地点. 其中用户行为包括四种情况,即浏览,收藏,加入购物车以及购买. 时间是精确到天的时间,地点是精确到省份的时间. 用户id和商品id的处理比较简单,可以直接随机. 对于用户行为, 显然四种操作的发生比例不是均匀的, 因此上述操作实际出现的比例可以大约设置为96:1:2:1. 对于时间, 为了保证随机数据不至于相差太远,可以设置为在最近一年以内随机产生,具体代码如下所示 123456public String getDay()&#123; Calendar calendar = Calendar.getInstance(); int off = random.nextInt(365); calendar.add(Calendar.DAY_OF_YEAR,-off); return dateFormat.format(calendar.getTime());&#125; 其中Calendar可以根据给定的偏移计算移动之后的日期, 因此只需要在0~356之间产生一个随机数,并且用当前的日期减去这个随机数即可.对于地点, 可以直接随机产生. 但考虑到各省的人口数量相差比较大, 因此更加精细的做法是根据人口的数量按照比例产生. 有关代码由于长度原因就不贴上来了, 全部的代码都已经开源到GitHub, 点击此处查看代码. 把各个随机器产生的数据收集到一起并按照一定的格式输出为文件, 即可完成数据集的制作. 考虑到每条数据的大约占用43B的空间, 因此可以产生2333万条数据,最终的数据集大小为1GB. 产生的部分数据格式如下所示 123456781 26068 255 1 2017-09-11 辽宁省2 10054 880 1 2017-12-29 山西省3 28234 87 1 2017-12-06 广东省4 20285 565 1 2018-07-25 广西壮族自治区5 19414 337 1 2017-12-03 广东省6 16584 233 1 2018-03-01 内蒙古自治区7 14833 102 1 2018-02-16 山东省8 20282 750 1 2018-03-15 吉林省 其中第一列为记录的序号,之后依次是用户id,商品id,用户行为,时间和地点. 注意到, 上述数据中用户的行为与时间,地点基本没有关联. 由于数据的随机, 因此单独观察一个用户时,该用户会在各种时间和地点产生记录. 针对这一问题,可以先随机产生若干用户,然后以用户的属性产生数据.","categories":[{"name":"大数据分析案例","slug":"大数据分析案例","permalink":"https://lizec.top/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%A1%88%E4%BE%8B/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://lizec.top/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"}]},{"title":"The Google File System 阅读记录","slug":"论文GoogleFileSystem","date":"2018-08-12T06:44:10.000Z","updated":"2019-02-07T09:42:37.963Z","comments":true,"path":"2018/08/12/论文GoogleFileSystem/","link":"","permalink":"https://lizec.top/2018/08/12/%E8%AE%BA%E6%96%87GoogleFileSystem/","excerpt":"","text":"本文是对论文《The Google File System》的记录. 这篇论文也是谷歌关于大数据的三大论文之一, 主要讲述了一种新的可扩展的分布式文件系统的设计与实现. 大数据处理系统Hadoop中的Hadoop Distributed File System是Google File System的开源实现. 阅读提示这篇论文从语言方面来看, 单词和语句都比较容易理解, 阅读难度大概等于英语六级水平. 但其中涉及了很多新的概念, 理解有关的概念并不容易, 如果对Hadoop有一点了解阅读起来会轻松很多. 概述Google File System(GFS)是一个可扩展的分布式文件系统, 具有一定的错误容忍能力, 从而可以构建在廉价的设备之上, 并且为大量的客户提供强大的服务能力. 在GFS的开发过程中, 研究人员发现实际的需求与以往的分布式系统中的假定并不完全相同, 因此GFS使用了一些新的假设. GFS的产生源于Google对大数据的处理需求, 因此论文中也涉及了大量关于实际使用的问题. 基本前提基本假设GFS的设计过程中引入了如下的一些假设: 故障是常态而不是异常 文件大小远大于传统文件 文件通常进行追加操作而不是随机写入 故障包括软件层面的应用程序BUG和系统BUG, 硬件层面上的磁盘故障和内存故障以及操作层面上的操作失误, 对于这些问题, 系统需要有对故障的监控,处理和恢复能力. 由于单个文件的体积显著增大, 而小文件的使用需求相对减少, 因此在此假设上可以设计新的I/O方式, 从而提高系统的效率. 由于实际的使用场景, 因此很多文件通常只进行追加操作, 而不会进行随机写入, 因此可以从充分利用这一点进行优化. 设计假设在系统的设计过程中, 有如下的一些假设 假设 解释 廉价设备 系统运行在大量廉价设备组成的集群上 超大文件 单个文件体积大, 支持小文件但不进行优化 连续读取 大量连续的读取, 少量随机的读取 追加写入 文件追加写入, 一旦写入不可修改 一致性处理 系统能有效的运行在生产者-消费者模型下 提高带宽 高带宽比低延时更重要 系统架构 一个GFS集群具有一个master节点和多个chunkserver节点, 可以同时为多个客户提供服务. 文件被分割为适当大小的chunk, 存放在chunkserver之上. 对于每个chunk, 默认都会冗余的存储三份. master保存所有的元数据, 包括文件名, 访问权限, 文件与chunk的映射关系, 每个chunk在具体节点中的位置等. master与各个chunkserver通过心跳包的方式传递之类和返回状态. 客户端(应用程序)向master发送文件请求信息, master返回chunk的相关信息, 之后客户端直接与相应的chunkserver通信. Chunk SizeChunk Size的设置是一个重要的参数, 一个大的size有如下三个方面的影响 减少文件分裂的chunk数, 从而减少客户端与master的通信量 使得大量操作在同一个chunk上进行, 可以充分利用TCP保存连接的特性 减少master上元数据的数据量,从而使元数据可以保存在内存之中 但是大的size也存在问题, 如果某个文件是热点文件, 则可能导致某个chunkserver读写压力过大. 但实际运行而言, 这并不是一个严重的的问题. Metadatamaster存储的元数据主要有三个方面, 文件和chunk的名字, 两者的映射关系以及每个chunk的具体位置. 所有的元数据都保存在内存之中, 但前两种数据来通过日志的方法保存到磁盘上, 从而对数据进行修改时不会产生一致性的问题. master不持久保存chunk的位置信息, 而是在master节点启动时或有新的chunkserver加入时, 向各个chunkserver查询位置信息. 这种方法使得master的信息不必随着chunkserver文件的修改, 删除或chunkserver的加入, 重启而同步的改变. 由于具体的chunkserver决定一个文件是否存在, 因此不必保证master的信息与chunkserver的信息完全同步. OperationLog操作日志保存了master节点上所有的修改. 如果master节点出现故障, 可以通过重新执行日志中的操作来恢复原来的状态. 为了减少恢复时间, 每当日志大小达到一定体积时, master节点就创建一个checkpoint, 之后当master需要恢复时, 可以先加载最新的checkpoint中, 然后只需要重新执行该checkpoint之后少量的操作. checkpoint采用紧缩的B-tree结构, 可以直接加载到内存之中. checkpoint的创建位于独立的线程, 创建过程不影响系统的继续使用. 主节点操作主节点执行所有的名称操作(创建,重命名,删除等), 此外主节点还负责备份的管理, chunk位置的分配, 负载均衡, 垃圾回收等. 名称操作由于名称操作可能消耗很多时间, 例如snapshot操作需要访问各个涉及到的chunkserver至少一次. 因此, 在GFS中, 允许同时进行多个操作, 通过读写锁机制来实现一定的顺序. 副本位置选择选择副本位置有两个目标 最大化数据的可靠性和可用性 最大化网络资源利用率 为了实现上述目标, 仅仅将数据分布到同一个机架的不同的机器上是不够的, 这样只能保证磁盘或者机器故障时的数据可用性. 只有将数据分布到不同机架上的机器上时, 才可以保证网络设备故障等原因下导致整个机架上的设备离线时还可以提供服务. 将数据分布到不同机架后, 客户端可以从不同的位置读取数据, 能够更充分的利用带宽资源. 但此时如果需要写入数据, 也会导致需要向多个位置发送写入数据, 这也是一个权衡后的结果. 负载均衡一个chunk的创建有三个原因, 即创建新文件, 创建副本, 负载均衡. 当创建一个chunk时, 关于位置的选择有如下的三个需求 平衡各个机器的负载 避免在一个机器上频繁的创建chunk 将副本分布到不同机架上的设备 对于第二点, 由于GFS在设计时的目标是数据一次写入, 多次读取, 因此处于可靠性的的考虑, 每一台设备都并支持长时间持续的写入数据. 无论是创建新的文件, 还是创建副本或负载均衡, GFS都按照以上的需求调整chunk的位置. 垃圾回收在一个文件被删除以后, GFS并不会立刻处理相关的物理存储, 而是做了一个标记, 在之后master节点周期性的扫描过程中, 发现这些节点以后, 就删除对应的的元数据并通知各个chunkserver可以删除此文件. 通过这种方式, 可以使得系统更加简单可靠. 虽然分布式的垃圾回收是一个复杂的问题, 但在GFS中却十分简单. 因为master节点维护了文件和chunk的映射关系, 同时chunkserver也能定位每一个chunk的位置, 因此任何master节点中没有记录的chunk就是垃圾. 这种策略的一个主要问题是删除过程存在一定的延时, 当系统资源比较紧张时无法充分利用释放的资源.","categories":[{"name":"论文阅读","slug":"论文阅读","permalink":"https://lizec.top/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"}],"tags":[{"name":"论文阅读","slug":"论文阅读","permalink":"https://lizec.top/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"}]},{"title":"MapReduce：Simplified Data Proessing on Large Clusters 阅读记录","slug":"论文MapRudece","date":"2018-08-09T06:41:45.000Z","updated":"2019-02-07T09:42:45.395Z","comments":true,"path":"2018/08/09/论文MapRudece/","link":"","permalink":"https://lizec.top/2018/08/09/%E8%AE%BA%E6%96%87MapRudece/","excerpt":"","text":"本文是对论文《MapReduce：Simplified Data Proessing on Large Clusters》的记录。这篇论文是Google的关于大数据的三篇论文之一，主要介绍了一种新的编程模型，即MapReduce模型。MapReduce模型也是之后开源的大数据处理系统Hadoop的主要实现基础。 前言这是我真正意义上第一次阅读英文的论文，本以为在语言方面可能会遇到一些问题，然而实际阅读表明，这篇论文的单词和语句难度大概只有英语四级水平，因此这篇论文在阅读方面并不会有太多问题。 网络上关于这篇论文的介绍和中文翻译已经很多了，本文主要介绍我在阅读过程中的一些见解和结论。 概述MapReduce是一种编程模型，用户（使用此编程模型的程序员）指定一个map函数将一系列的原始的键值对转化为中间状态的键值对，之后用户再指定一个reduce函数，将中间结果合并，产生最终的结果。 很多操作都可以转化为MapReduce操作，而且使用MapReduce模型之后，系统就可以自动的将操作进行并行化，从而充分利用分布式系统的资源。 根据论文，MapReduce的抽象灵感源于一种古老的函数式语言Lisp。 在Lisp语言中，map函数指定的操作运用到一个或多个列表之上，从而获得一个新的列表， reduce函数将指定的操作依次作用到列表的各个元素上，从而获得运算结果。 对比MapReduce模型中的map函数和reduce函数，可见两者确实有一定的相似性。 在编程语言的发展历史之中，由于函数式的语言特性的实现对机器性能的开销大，因此很长一段时间内都没有投入实际的使用，仅仅是“实验室”的产物。然而随着并行计算的需要，函数式语言天然的并行性使得其再一次被人们重视。 词频统计举例WordCount在MapReduce中的地位就如同Hello World在编程中的地位，是很多人写的第一个MapReduce程序。 因此下面从分析WordCount来讲解MapReduce的过程。 WordCount的任务是给定一个文本，统计其中每个词出现的次数。而且对于输入的文本系统会按照行自动进行切分。例如给定如下的文本 12Hello World Hello LiZeCBye Hadoop Bye LiZeC 那么经过系统的处理以后，会得到如下的两个原始键值对 12&lt;1,Hello World Hello LiZeC&gt;&lt;2, Bye Hadoop Bye LiZeC&gt; 其中key为行号，value为每一行具体的内容。 那么对于map函数，则可以有如下的操作(伪代码) 123456map(Object key,String value)&#123; // key代表行号 // value代表每一行的值 for each word w in value: EmitIntermediate(w,&quot;1&quot;); &#125; 即对于每个词，产生一个1的标记，从而可以得到下面的一系列中间结果键值对 1&lt;Hello,1&gt;,&lt;World,1&gt;,&lt;Hello,1&gt;,&lt;LiZeC,1&gt; ... 在reduce阶段之前，系统会将所有相同的key合并到一起，形成类似&lt;key,&lt;value1,value2,value3,...&gt;&gt; 的形式，那么对于reduce函数有 12345678reduce(String key,Iterator values)&#123; // key表示一个词 // values表示所有统计值的列表 int sum = 0; for each v in values: sum += v; Emit(key,sum);&#125; 即将所有键值对中的值累加起来，从而获得最后的结果键值对 1&lt;Hello,2&gt;, &lt;World,1&gt;, &lt;LiZec,2&gt;, ... 其他应用举例在论文中给出了一些Google的实际应用，以下介绍两个比较特殊的实现方案。 Distributed Grep此操作的任务是给定一个正则表达式，返回所满足条件的行。 在map阶段，对于每一行，如果匹配表达式，则写入此行。在reduce阶段不需要额外操作，直接将中间结果写入即可。 Reverse Web-Link Graph对于一个网页，可以很容易的获得从此网页指向其他网页的关系图，而Reverse Web-Link Graph任务反转这个关系图，获得指向此网页的其他网页的关系图。 在map阶段，对于每个网页source，记录所有指向的其他页面target，从而写入若干&lt;target,source&gt;的键值对。reduce阶段合并结果，得到&lt;target, list(source)&gt; 错误处理由于MapReduce是架构在大量设备之上的，因此需要容忍部分机器出现故障。故障可以分成工作节点故障，主节点故障 工作节点故障主节点会周期性的检测各个工作节点的状态，如果工作节点在指定的时间内没有回应，则主节点将此工作节点标记为故障状态，并且自动将运行在上面的任务分配给其他机器执行。 论文中提到，有一次对网络维修的时候，导致80个节点同时从正在运行MapReduce的集群脱离，但通过这种重新分配机制使得任务并没有受到影响。 主节点故障主节点可以通过checkpoint技术，周期的保存主节点的状态，从而使得主节点故障时，备份节点能从checkpoint恢复主节点的状态。 其他问题LocalityMapReduce集群的底层文件系统是Google File System(GFS)。GFS通常会将其中的数据冗余存储3份。因此在分配map任务的时候，会尽量将map任务分配到含有需要读取的数据的节点上，从而执行任务时可以尽量从本地读取数据，减少网络的消耗。 使用这一策略必然会导致某些存储了较多重要数据的节点计算任务变多，因此后续可能还涉及到资源平衡的问题，将经常使用的资源分布到不同的机器上，从而均衡各个节点的任务强度。 Backup Tasks根据论文，Google实现的MapReduce系统在处理即将结束时，对于一些尚未完成分配的任务的机器，会将相关机器上的任务重新分配到其他机器上同时执行，根据相关的实验结果，不使用这一操作的集群执行同样的任务多消耗44%的时间。 根据Google的分析，导致这一现象的原因是部分机器的的性能降低，降低的原因可能是磁盘故障，机器被分配其他任务导致CPU可用时间减少，或者代码错误等。通过把相关的任务分配其他机器上重新执行，可以减少上述问题导致的部分任务迟迟无法结束，进而导致的总时间的延长。 实际上这一问题并不能直观的从理论上发现，只能通过实际的运行才会发现。而这种通过增加资源消耗来节省时间的策略也非常的具有工程师的特色了。 总结 严格的编程模型使得并行化和错误更加容易被处理 网络带宽资源是稀缺资源，应该尽量减少网络传输 冗余的执行可以减少因为部分执行速度慢的设备导致的时间延长","categories":[{"name":"论文阅读","slug":"论文阅读","permalink":"https://lizec.top/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"}],"tags":[{"name":"论文阅读","slug":"论文阅读","permalink":"https://lizec.top/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"}]},{"title":"Git笔记之远程仓库","slug":"Git笔记之远程仓库","date":"2018-08-07T11:19:54.000Z","updated":"2021-01-14T13:06:06.729Z","comments":true,"path":"2018/08/07/Git笔记之远程仓库/","link":"","permalink":"https://lizec.top/2018/08/07/Git%E7%AC%94%E8%AE%B0%E4%B9%8B%E8%BF%9C%E7%A8%8B%E4%BB%93%E5%BA%93/","excerpt":"","text":"远程仓库初始化SSH密钥检查当前用户目录下是否有.ssh文件夹，其中是否包含id_rsa和id_rsa.pub这两个文件，如果有则说明已经创建过SSH密钥. 如果没有则执行如下的指令来创建密钥 1$ ssh-keygen -t rsa -C &quot;youremail@example.com&quot; 指令执行过程中会询问几个问题, 全部使用默认值即可. 执行完毕后就可以在当前用户目录的.ssh文件夹下看到id_rsa和id_rsa.pub这两个文件. 添加SSH公钥 登陆GitHub, 进入个人主页, 选择设置选项后, 依次选择Account settings-&gt;SSH Keys 点击Add SSH Key, 添加任意Title, 在Key文本框里粘贴将上一节生成的id_rsa.pub文件的内容 注意: Title用来标识不同的Key的, 例如在不同的设备上有不同的Key, 则Title可以设置为设备的名称 完成上述操作后, 即可免密码的从GitHub上传和下载代码. 关联远程仓库 在GitHub上创建相关的仓库，如果为远程仓库为空，本地仓库非空，则可使用1$ git remote add origin git@github.com:XXX/YYY.git //关联本地仓库和远程仓库 若本地尚未建立仓库，远程仓库非空，则可使用1$ git clone git@github.com:XXX/YYY.git //将远程仓库内容拷贝到本地并关联 因为只在第一次使用时需要关联远程仓库, 所以不建议GitHub和本地同时存在内容时进行关联. 在这种条件下的关联操作非常繁琐, 强烈不建议尝试. Remote操作一个本地的git仓库可以关联多个远程仓库, 并且每个仓库可以分别具有不同的用户权限. 操作 指令 查看已有仓库 git remote -V 添加 git remote add &lt;name&gt; &lt;address&gt; 删除 git remote remove &lt;name&gt; 重命名 git remote rename &lt;old&gt; &lt;new&gt; 2.5 Git 基础 - 远程仓库的使用 GitHub技巧文件模板在Github中创建名为LICENSE或gitignore时, 网站会提示可以使用模板, 从而可以快速添加协议或忽略文件. 更多关于Github的小细节, 可以查看GitHub秘籍（中文版） 本地关联技术本节介绍如何将Git仓库与本地其他位置的仓库关联. 当其他仓库位于可移动设备上时, 可以使用Git进行同步. 创建公共仓库使用以下指令在需要的位置创建一个没有工作区的仓库 1$ git --bare init 管理公共仓库Git支持将远程仓库指定为本地的仓库, 因此使用和远程仓库相同的指令进行关联即可. 例如以下代码联了位于G:/files文件夹下的公共仓库 1$ git clone /g/files 一旦和本地的仓库管理以后，之后的操作与一般的远程仓库没有区别 Windows下可能的问题Windows上不能直接在分区跟目录创建公共仓库. 如果执行这一操作, Windows会提示Permission denied. 产生这一错误的原因是Git创建仓库时, Git需要先创建文件夹, 而Windows会认为Git想要创建一个驱动器, 从而拒绝Git的操作. Git的操作被拒绝后, 又会认为是权限不够, 因此返回Permission denied的提示. 解决这一问题的方法就是先在根目录创建一个文件夹, 在此文件夹内再创建Git仓库. 详细的讨论可以参考这个回答 私有Git服务器本节介绍如何在个人服务器上创建Git服务, 从而将自己的代码发布到自己私有的服务器上.","categories":[{"name":"Git笔记","slug":"Git笔记","permalink":"https://lizec.top/categories/Git%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Git","slug":"Git","permalink":"https://lizec.top/tags/Git/"}]},{"title":"SQL语法精简笔记","slug":"SQL语法精简笔记","date":"2018-07-21T02:59:04.000Z","updated":"2021-02-17T04:55:17.514Z","comments":true,"path":"2018/07/21/SQL语法精简笔记/","link":"","permalink":"https://lizec.top/2018/07/21/SQL%E8%AF%AD%E6%B3%95%E7%B2%BE%E7%AE%80%E7%AC%94%E8%AE%B0/","excerpt":"","text":"由于日常开发过程中不经常使用SQL，对于其中的一些高级语法比较容易遗忘。因此本文简要介绍了SQL的各种语法，用于快速回顾有关的知识。关于详细的数据库理论，可以阅读数据库系统原理的有关章节。 模式 操作 指令 定义 CREATE SCHEMA &quot;S-T&quot; AUTHORIZATION WANG 删除 `DROP SCHEMA &lt;模式名&gt; &lt;CASCADE 几点说明 模式是一系列表的集合，数据库是一系列模式的集合 在MySQL中并不区分模式和数据库（Schema和Database） 在SQL Server中每个数据库默认创建dbo模式，并且将其作为默认模式 实际上可以把一个模式视为一个数据库的一部分表的集合 表操作创建表1234567891011CREATE TABLE &lt;表名&gt; ( &lt;列名&gt; &lt;数据类型&gt; [列完整性约束条件] [, &lt;列名&gt; &lt;数据类型&gt; [列完整性约束条件]] ... [, &lt;表完整性约束&gt;]);列完整性约束条件 =&gt; PRIMARY KEY | NOT NULL | UNIQUE表完整性约束条件 =&gt; PRIMARY KEY(&lt;列名1&gt; [,&lt;列名2&gt;]...[,&lt;列名n&gt;])表完整性约束条件 =&gt; FOREIGN KEY(&lt;列名&gt;) REFERENCES &lt;表名&gt;(&lt;列名&gt;) 关于全部的约束条件，可以查看本文的完整性约束章节 常见的数据类型有如下的几种： 数据类型 含义 CHAR(n) 长度为n的定长字符串 INT 整数（4字节） FLOAT(n) 至少n为精度的浮点数 DATE 日期，包含年月日 TIME 时间，包含时，分，秒 完整的数据类型表请查看本文末尾的附录A 数据类型, 数据类型选择应该遵守如下的一些约束 选择不超过范围的最小数据类型 尽量使用简单类型 避免使用NULL, 尤其索引列不适合有NULL值 修改表12345ALTER TABLE &lt;TableName&gt;[ADD [COLUMN] &lt;newColName&gt; &lt;datType&gt; [ColIntegrity]][ADD &lt;TabIntegrity&gt;][DROP [COLUMN] &lt;ColName&gt; [CASCADE|RESTRICT]][DROP CONSTRAINT &lt;Integrity&gt; [RESTRICT|CASCADE]] 删除表1DROP TABLE &lt;TableName&gt; [RESTRICT|CASCADE] 完整性约束用户自定义约束可以使用Check关键字来检测一个属性是否位于某个集合之中，例如 1234567CREATE TABLE St( Sname CHAR(8) NOT NULL, Ssex CHAR(2) CHECK(Ssex IN (&#x27;男&#x27;,&#x27;女&#x27;))， Grade SMALLINT CHECK(Grade &gt;=0 AND Grade &lt;= 100), CHECK(Ssex=&#x27;女&#x27; OR Sname NOT LIKE &#x27;Ms.%&#x27;)) 创建命名约束123456789101112CREATE TABLE Student( Sno NUMBERIC(6) CONSTRAINT C1 CHECK(Sno BETWEEN 90000 AND 99999)， Sname CHAR(20) CONSTRAINT C2 NOT NULL， Sage NUMERIC(3) CONSTRAINT C3 CHECK(Sage &lt; 30)， Ssex CHAR(2) CONSTRAINT C4 CHECK(Ssex IN (&#x27;男&#x27;，&#x27;女&#x27;))， CONSTRAINT StudentKey PRIMARY KEY(Sno)) 修改约束条件1234ALTER TABLE Student DROP CONSTRAINT C1;ALTER TABLE Student ADD CONSTRAINT C1 CHECK(Sno BETWEEN 900000 AND 999999) 查询单表查询12345SELECT [ALL|DISTINCT] &lt;目标列表达式&gt; [，&lt;目标列表达式&gt;] ...FROM &lt;表名 | 视图名&gt; [, &lt;表名 | 视图名&gt;][WHERE &lt;条件表达式&gt;][GROUP BY &lt;列名&gt; [HAVING &lt;条件表达式&gt;]][ORDER BY &lt;列名&gt; [ASC|DESC]] 目标表达式除了使用属性列以外，还可以使用表达式，例如 1SELECT Sname,2018-Sage BIRTHDAY FROM Student; 上面的语句通过2018-Sage计算了实际的年龄，并且将该列命名为BIRTHDAY。 HAVING语句用于给GROUP BY的分组设置条件，例如 1SELECT Sno,AVG(Grade) FROM SC GROUP BY Sno HAVING AVG(Grade)&gt;=90; 连接查询12345SELECT *FORM &lt;TabName1&gt; &lt;JoinKeyWord&gt; &lt;TabName2&gt;ON &lt;ConditionExpr&gt;JoinKeyWord ==&gt; JOIN | LEFT OUTER JOIN | RIGHT OUTER JOIN | FULL OUTER JOIN 例如: 123SELECT Student.Sno, Sname, Ssex, Sage, Sdept, Cno, GradeFROM Student LEFT OUT JOIN SC ON (Student.Sno=SC.Sno); 说明: JOIN等价于 ENTER JOIN 表示普通连接，会去除所有的空行 LEFT OUTER JOIN 表示左外连接，左边的表中的项一定会出现 RIGHT OUTER JOIN 表示右外连接，右边的表中的项一定为出现 FULL OUTER JOIN 表示全连接，左右的表中项都会出现 嵌套查询123456SELECT Sname FROM StudentWHERE Sno IN( SELECT Sno FROM SC WHERE Cno=&#x27;2&#x27;;) 更新插入元组12INSERT INTO &lt;TableName&gt; [(&lt;ColName_1&gt; [，&lt;ColName_2&gt;]...)]VALUE (&lt;Data1&gt;，[&lt;Data2&gt;] ...); 注意: 字符串需要使用单引号括起来 非字符类型的数据也可以使用单引号包括 修改元组123UPDATE &lt;TableName&gt;SET &lt;ColName&gt; = &lt;Expr&gt; [，&lt;ColName&gt; = &lt;Expr&gt;][WHERE &lt;ConditionExpr&gt;] 可以同时更新多个表, 例如 123UPDATE message m, lib mlSET m.M_ID = ml.M_ID, m.TYPE = ml.TYPEWHERE m.LIB_ID = ml.LIB_ID; 删除元组12DELETE FROM &lt;TableName&gt;[WHERE &lt;conditionExpr&gt;] 索引建立索引1234CREATE [UNIQUE] [CLUSTER] INDEX &lt;IndexName&gt;ON &lt;TableName&gt;(&lt;ColName&gt; [Order] [，&lt;ColName&gt; [Order]])Order =&gt; ASC | DESC 注意: 上述索引中，可以选择每个索引是对应唯一值还是聚簇索引 每个列名后可跟随一个排序表示 修改索引1ALTER INDEX &lt;OldIndexName&gt; RENAME TO &lt;NewIndexName&gt; 删除索引1DROP INDEX &lt;IndexName&gt; 视图建立视图123CREATE VIEW &lt;ViewName&gt; [(&lt;ColName&gt; [，&lt;ColName&gt;] ... )]AS &lt;SubSelect&gt;[WITH CHECK OPTION] 注意: 可以全部省略列名，表示由子查询语句指定 WITH CHECK OPTION表示对视图的更新操作需要保证满足子查询的条件表达式 删除视图1DROP VIEW &lt;ViewName&gt; [CASCADE] 更新视图 更新视图与更新表没有语法差异 但是有些视图操作是不可逆的，此时不能进行更新操作(例如使用了聚集函数) 事务对于MySQL数据库, 不同的设置下有不同的效果 如果autocommit=0, 只有用户手动COMMIT以后, 数据才会写入磁盘 如果autocommit=1, 则有两种情况 如果用户执行START TRANSACTION;, 则用户手动提交才会写入磁盘, 否则自动回滚 如果用户直接执行语句, 则每个语句都视为一个独立的事务 使用以下指令进行事务相关的操作. 操作 指令 开始事务 START TRANSACTION; 提交 COMMIT; 回滚 ROLLBACK; 上面的每条执行都是单独执行的, 开始事务以后, 可以执行任意SQL语句, 更新数据库可以接着执行查询语句来检查效果. 在用户手动提交以前, 其他事务都不可见当前的更新. 注意: 只能回滚数据的修改, 不能回滚结构的修改. mysql事务的开启 权限控制授予权限1234GRANT &lt;权限&gt; [，&lt;权限&gt;] ...ON &lt;对象类型&gt; &lt;对象名&gt; [，&lt;对象类型&gt; &lt;对象名&gt;]TO &lt;用户&gt; [，&lt;用户&gt;][WITH GRANT OPTION] 例如： 123GRANT UPDATE(Sno)，SELECTON TABLE StudentTO PUBLIC 说明： WITH GRANT OPTION 表示被授权用户可以再次将权限授予其他用户 不允许循环授权 收回权限1234REVOKE &lt;权限&gt; [，&lt;权限&gt;] ...ON &lt;对象类型&gt; &lt;对象名&gt; [，&lt;对象类型&gt; &lt;对象名&gt;]FROM &lt;用户&gt; [，&lt;用户&gt;][CASCADE|RESTRICT] 角色控制创建角色1CREATE ROLE &lt;RoleName&gt; 角色授权123GRANT &lt;权限&gt; [，&lt;权限&gt;] ...ON &lt;对象类型&gt; &lt;对象名&gt; [，&lt;对象类型&gt; &lt;对象名&gt;]TO &lt;角色&gt; [，&lt;角色名&gt;] 用户角色授权123GRANT &lt;角色1&gt; [，&lt;角色2&gt;] ...TO &lt;角色3&gt; [，&lt;用户1&gt;] ...[WITH ADMIN OPTION] 说明： 角色可以授予给某个用户或者其他角色 WITH ADMIN OPTION表示被授权者可以再次授予自己的权限 角色权限的收回123REVOKE &lt;权限&gt; [，&lt;权限&gt;] ...ON &lt;对象类型&gt; &lt;对象名&gt; [，&lt;对象类型&gt; &lt;对象名&gt;]FROM &lt;角色&gt; [，&lt;角色名&gt;] 断言创建断言1CREATE ASSERTION &lt;断言名&gt; &lt;CHECK子句&gt; 例如 1234567CREATE ASSERTION ASSE_SC_DB_NUMCHECK (60 &gt;= ( SELECT COUNT(*) FROM Course,SC WHERE SC.CNO = Course.CNO AND Course.CNAME=&#x27;数据库&#x27; ) ) 执行上述语句后，每次插入选课记录后，都会执行一次CHECK子句中的条件，如果选课人数超过60人，就会拒绝执行 删除断言1DROP ASSERTION &lt;断言名&gt; 附录A 数据类型 数据类型 含义 数据类型 含义 TINYINT 小整数(1字节) SMALLINT 短整数（2字节） INT 整数（4字节） BIGINT 长整数（8字节） FLOAT(p,d) 单精度浮点数 DOUBLE(p,d) 双精度浮点数 DECIMAL(p,d) 货币类型 NUMERIC(p,d) 定点数， 两个浮点数类型支持指定数字范围, 但仅影响存储时的舍入操作, 不影响存储精度 DECIMAL可以用参数指定数据范围是p位整数数字，d位小数数字, 并且提供此范围的精确存储 其他数据类型也可以指定一个数字, 但此参数值影响命令行中的显示效果, 不影响实际的存储大小 整数数据类型支持有符号数与无符号数(使用UNSIGNED关键字), 相应的存储范围也会变化 注意: 对于有精度要求的浮点数, DECIMAL通常是首选 数据类型 含义 取值范围 DATETIME 时间日期 ‘1000-01-01 00:00:00’ to ‘9999-12-31 23:59:59’ DATE 仅含日期 ‘1000-01-01’ to ‘9999-12-31’. TIMESTAMP 时间戳 截止于北京时间 2038-1-19 11:14:07 注意: 输入时间时尽量使用标准格式表示, 以免数据库解析规则不一致导致错误 数据类型 含义 数据类型 含义 CHAR(n) 长度为n的定长字符串 VARCHAR(n) 最大长度为n的变长字符串 TEXT 字符串大对象 BLOB 二进制大对象 CHAR和VARCHAR的参数表示存储的字符数量, 每个字符具体需要几个字节取决于实际的编码. 而CHAR最多存储 256 Byte 数据, VARCHAT最多存储 65536 Byte 数据. 由于UTF-8是不定长编码, 因此CHAR类型为了保证能够存储指定数量的字符, 会将字符集中需要的最大字节长度作为一个字符的长度. UTF-8中一个汉字一般需要三个字节, 而GBK编码中, 一个汉字仅需要两个字节. TEXT和BLOB都有四种类型, 以TEXT为例, 分别是TINYTEXT, TEXT, MEDIUMTEXT和LONGTEXT. TEXT和BLOB的四种类型的存储范围是一致的, 其存储范围分别用1字节, 2字节, 3字节和4字节无符号整数表示. 两种类型的区别是TEXT用于存储文本, 存在编码的问题, 而BLOB用于存储二进制数据, 直接将数据作为二进制串进行存储. 关于MySQL中的数据类型, 可以参考下面的几篇文章. 第一篇文章对相关数据类型进行了详细的测试. 第二篇和第三篇都是偏向官方文档的表格式描述. 第四篇是官方文档, 对数据的存储细节进行了详细的介绍. 详解MySQL数据类型 MySQL 数据类型 MySQL Data Types MySQL官方文档 - String Type Storage Requirements 附录B 聚合函数 函数 含义 函数 含义 COUNT(*) 统计元组数量 COUNT(&lt;列名&gt;) 统计指定列包含元素的数量 SUM(&lt;列名&gt;) 统计列的总和 AVG(&lt;列名&gt;) 统计平均值 MAX(&lt;列名&gt;) 统计最大值 MIN(&lt;列名&gt;) 统计最小值 说明： 各种聚合函数都可以在列名前指定DISTINCT或ALL（默认值），来指定是否计算重复值 附录C 查询条件 查询条件 谓词 查询条件 谓词 比较 =, &gt;, &lt;, != 等常见数学运行符号 字符匹配 LIKE, NOT LIKE 范围 BETWEEN AND, NOT BETWEEN AND 空值 IS NULL, IS NOT NULL 集合 IN, NOT IN 逻辑 AND, OR, NOT 附录D 集合操作 操作名 含义 UNION 并 INTERSECT 交 EXCEPT 差 附录E 包含操作 原理12A Contain B = (B - A) 为空集 = NOT EXIST (B EXCEPT A) 举例应用 查询至少选修了学生2002122选修的全部课程的学生号码 即 求所有学生S: (S选修课程) Contains (学生2002122选修的所有课程) 即 NOT EXISTS (学生2002122选修的所有课程 EXCEPT S选修课程)123456789101112131415SELECT DISTINCT snoFROM sc AWHERE NOT EXISTS( ( SELECT cno FROM sc WHERE sno = &#x27;2002122&#x27; ) EXCEPT ( SELECT cno FROM SC B WHERE A.sno = B.sno ))","categories":[],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://lizec.top/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"SQL","slug":"SQL","permalink":"https://lizec.top/tags/SQL/"}]},{"title":"JavaWeb之JavaScript","slug":"JavaWeb之JavaScript","date":"2018-06-21T12:22:17.000Z","updated":"2019-03-04T13:35:12.580Z","comments":true,"path":"2018/06/21/JavaWeb之JavaScript/","link":"","permalink":"https://lizec.top/2018/06/21/JavaWeb%E4%B9%8BJavaScript/","excerpt":"","text":"很早以前就尝试学习js,不过用于当时的时机还不成熟,因此始终没有真正的学会js. 现在终于有机会可以再次系统的学习一次,因此将js学习过程中的笔记记录在此. 由于已经学习过Java和Python等编程语言,因此本文不是一个面向初学者的笔记. 在笔记中往往只会记录js特有的语言特性,而与大部分语言相同的共性内容会直接忽略. 网页中使用js的两种方法 直接嵌入html代码123&lt;script type=&quot;text/javascript&quot;&gt;alert(&quot;Hello&quot;);&lt;/script&gt; 从文件导入1&lt;scrpit src = &quot;/static/js/hello.js&quot;&gt;&lt;/scrpit&gt; js的比较 比较的类型 注意事项 类型比较 应始终使用===来进行比较,使用==时会进行隐含的类型转换 浮点数比较 浮点数不能精确表示,因此不能直接比较 NaN NaN与任何符号都不相等,使用isNaN函数来判断 对于null, undefined,NaN,空字符串&quot;&quot;与0都视为false,其他所有视为true 基本类型 类型 解释 变量 使用let声明可变变量, 使用const声明不可变变量 数组 使用[和], 与大部分语言一样,且数组中元素可以是任意类型 对象 使用大括号包括的键值对 字符串 &#39;和&quot;以及反引号都可以定义字符串 123456789101112131415161718var i = 5; // 定义变量var array = [1,2,&quot;hello&quot;]; // 定义数组var p = &#123; // 定义对象 name: &quot;Li&quot;, age: 13, tag: [&quot;apple&quot;,&quot;book&quot;], info:null&#125;;var s = `这是一个多行字符串`// 字符串模板var name = `Li`;var hello = `Hello $&#123;name&#125;`;consloe.log(hello); 基本数据结构数组 数组属性 每个数组都默认有一个length属性表示数组的长度 越界处理 越界写入返回undefined 越界写入,数组会自动扩到到指定的长度,中间的元素使用undefined填充(与matlab类似) 直接修改length也会导致数组长度变化 函数 数组的pop,push,sort,reverse与各种语言效果一样,需要的时候查一下就可以了 对象 属性访问方法 使用形如p.name访问,也是标准的访问方法 使用p[‘name’]访问,效果与上面一致 未定义访问 js这么随意的语言当然不会报错,访问未定义的属性时返回undefined 写入未定义属性时,会直接添加这个属性到对象之中 属性检查 使用in关键字可以判断一个属性是否属于对象,无论这个属性是对象原本的属性还是继承的属性 使用hasOwnProperty方法检查是否是对象原本的属性 123456789101112131415161718192021&gt; var p = &#123;... name : &#x27;Li&#x27;,... age: 18... &#125;;undefined&gt; p.name = &quot;iL&quot;;&#x27;iL&#x27;&gt; p.name&#x27;iL&#x27;&gt; p,age20&gt; p.tagundefined&gt; p.tag = [&quot;apple&quot;][ &#x27;apple&#x27; ]&gt; p&#123; name: &#x27;iL&#x27;, age: 18, tag: [ &#x27;apple&#x27; ] &#125;&gt; &#x27;toString&#x27; in ptrue&gt; p.hasOwnProperty(&#x27;toString&#x27;)false 语句 foreach循环 使用for(var i in arr)的格式进行foreach循环,既可以遍历数组也可以遍历对象 由于设计问题,不建议使用此方法 for..of循环 由于后来的类型不能使用for..in循环,因此后来的标准中,添加了统一的循环方式 使用回调函数的for循环 可以遍历的类型都继承了forEach函数,该函数接受一个回调函数,从而在循环的每个元素上可以执行具体的操作 从清晰性的角度,使用回调函数最好 1234567891011121314151617181920212223242526272829303132333435var o = &#123; name: &#x27;Jack&#x27;, age: 20, city: &#x27;Beijing&#x27;&#125;;for (var key in o) &#123; if (o.hasOwnProperty(key)) &#123; console.log(key); // &#x27;name&#x27;, &#x27;age&#x27;, &#x27;city&#x27; &#125;&#125;var a = [&#x27;A&#x27;, &#x27;B&#x27;, &#x27;C&#x27;];for (var i in a) &#123; console.log(i); // &#x27;0&#x27;, &#x27;1&#x27;, &#x27;2&#x27; console.log(a[i]); // &#x27;A&#x27;, &#x27;B&#x27;, &#x27;C&#x27;&#125;// for...of循环var a = [&#x27;A&#x27;, &#x27;B&#x27;, &#x27;C&#x27;];var s = new Set([&#x27;A&#x27;, &#x27;B&#x27;, &#x27;C&#x27;]);var m = new Map([[1, &#x27;x&#x27;], [2, &#x27;y&#x27;], [3, &#x27;z&#x27;]]);for (var x of a) &#123; // 遍历Array console.log(x);&#125;for (var x of s) &#123; // 遍历Set console.log(x);&#125;for (var x of m) &#123; // 遍历Map console.log(x[0] + &#x27;=&#x27; + x[1]);&#125;var m = new Map([[&quot;Apple&quot;,1],[&quot;Banana&quot;,2]]);m.forEach(function(value,key,map)&#123; console.log(`value = $&#123;value&#125;, key = $&#123;key&#125;`);&#125;) Map与Set类 js的对象可以视为一个Map,但是因为键只能是字符串因此有所限制,因此js提供了Map与Set两个类型. Map可以使用set,delete,get,has等函数来实现增删改查等操作. Set使用add与delete实现插入和删除操作.123456789101112var m = new Map([[&#x27;Apple&#x27;,14],[&#x27;Banana&#x27;,7]]);var s = new Set([1,2,3]);&gt; m.get(&#x27;Apple&#x27;)14&gt; m.set(&quot;Orange&quot;,3)Map &#123; &#x27;Apple&#x27; =&gt; 14, &#x27;Banana&#x27; =&gt; 7, &#x27;Orange&#x27; =&gt; 3 &#125;&gt; s.has(2)true&gt; s.has(5)false 函数 使用function关键字引导一个函数 没有return的函数返回undefined12345function add(a,b)&#123; return a+b;&#125;add(2,3) 函数也是对象,可以保存到变量之中12345// 使用匿名函数定义并保存到变量中var puls1 = function(a)&#123; return a+1;&#125;; js函数不强制调用与声明的一致,传入的变量个数也可以完全不同(简直不能更随意) 多传入的参数会被忽略 少传入的参数会被置为undefined 使用arguments可以获得所有传入参数组成的数组,从而对于实际传入参数进行判断 可以使用rest关键字实现可变参数函数1234567891011121314151617181920212223242526272829303132333435// 手动检查function narg(a,b,c)&#123; if(arguments.length == 1)&#123; return a; &#125; else if(arguments.length == 2)&#123; return a+b; &#125; else if(arguments.length == 3)&#123; return a+b+c; &#125;&#125;console.log(narg(1));console.log(narg(1,2));console.log(narg(1,2,3));// 可变参数声明function foo(a, b, ...rest) &#123; console.log(&#x27;a = &#x27; + a); console.log(&#x27;b = &#x27; + b); console.log(rest);&#125;foo(1, 2, 3, 4, 5);// 结果:// a = 1// b = 2// Array [ 3, 4, 5 ]foo(1);// 结果:// a = 1// b = undefined// Array [] js支持闭包 因此内部定义的函数可以直接访问外部的函数中的变量 可以将子函数作为参数返回,之后子函数依然可以访问定义此子函数的父函数中的变量12345678910111213141516171819202122232425262728function foo(x)&#123; function bar(y)&#123; return x+y; &#125; return bar;&#125;var g = foo(10);console.log(g(2));// 通过闭包机制,还可以实现更加复杂的机制function cons(x,y)&#123; return function(c)&#123; return c(x,y); &#125;&#125;function car(m)&#123; return m(function(x,y)&#123;return x&#125;);&#125;function cdr(m)&#123; return m(function(x,y)&#123;return y&#125;);&#125;console.log(car(cons(1,2))); 使用return的时候,单一语句一定要写在同一行,否则解释器会默认在return后直接加上分号,因此要确保return后不为空 变量作用域 全局变量 js有一个window变量,所有的全局变量实际是作为属性保存到了window变量中 直接声明的函数是全局变量,因此不同文件中的同名函数会冲突 为了避免冲突,可以手动设置名字空间123var myNameSpace = &#123;&#125;;myNameSpace.foo = function(x) &#123; ... &#125;; 变量提升 在函数中声明的变量具有函数作用域 即无论在函数中的何处声明的变量都是函数类任意位置可见的 因此在循环中的变量在循环外也是可以访问的12345function f(x)&#123; var x; console.log(&quot;y=&quot;+y); var y = 4;&#125; &lt;==&gt;123456function f(x)&#123; var x; var y; console.log(&quot;y=&quot;+y); y = 4;&#125; 真局部变量 -使用let关键字创建绝对的局部变量(其实这个作用域规则和lisp之类的语差不多了) 1234567function f(x)&#123; var sum = 0; for(let i = 0;i &lt; x;i++)&#123; sum += i; &#125; i += 3; // 报错&#125; 常量 使用const关键字声明 声明的变量是真局部变量 解构赋值 可以同时对多个变量赋值 使用中括号包括1234567891011121314151617181920212223let [x, [y, z]] = [&#x27;hello&#x27;, [&#x27;JavaScript&#x27;, &#x27;ES6&#x27;]];x; // &#x27;hello&#x27;y; // &#x27;JavaScript&#x27;z; // &#x27;ES6&#x27;var person = &#123; name: &#x27;小明&#x27;, age: 20, gender: &#x27;male&#x27;, passport: &#x27;G-12345678&#x27;, school: &#x27;No.4 middle school&#x27;, address: &#123; city: &#x27;Beijing&#x27;, street: &#x27;No.1 Road&#x27;, zipcode: &#x27;100001&#x27; &#125;&#125;;var &#123;name, address: &#123;city, zip&#125;&#125; = person;name; // &#x27;小明&#x27;city; // &#x27;Beijing&#x27;zip; // undefined, 因为属性名是zipcode而不是zip// 注意: address不是变量，而是为了让city和zip获得嵌套的address对象的属性:address; // Uncaught ReferenceError: address is not defined 高阶函数 map函数 将一个函数依次作用到每个元素上,并将结果组成一个新的列表123var arr = [1,2,3];var result = arr.map(Math.sqrt);console.log(result); //Array(3) [1, 1.4142135623730951, 1.7320508075688772] reduce函数 接受一个函数,该函数接受两个参数 将函数计算结果与下一个元素一同被函数再次计算12var arr = [1,2,3];var result = arr.reduce((x,y)=&gt; x+y); // 6","categories":[{"name":"JavaWeb","slug":"JavaWeb","permalink":"https://lizec.top/categories/JavaWeb/"}],"tags":[{"name":"Javascript","slug":"Javascript","permalink":"https://lizec.top/tags/Javascript/"}]},{"title":"JavaWeb之JavaServerPages","slug":"JavaWeb之JavaServerPages","date":"2018-06-21T12:22:03.000Z","updated":"2019-07-09T01:47:41.675Z","comments":true,"path":"2018/06/21/JavaWeb之JavaServerPages/","link":"","permalink":"https://lizec.top/2018/06/21/JavaWeb%E4%B9%8BJavaServerPages/","excerpt":"","text":"本文介绍JSP的基本知识和语法以及由JSP衍生的Web开发技术. JSP（Java Server Pages）是由Sun Microsystems公司倡导和许多公司参与共同创建的一种使软件开发者可以响应客户端请求,而动态生成HTML,XML或其他格式文档的Web网页的技术标准.JSP技术是以Java语言作为脚本语言的,JSP网页为整个服务器端的Java库单元提供了一个接口来服务于HTTP的应用程序. JSP文件结构JSP和PHP等语言一样,可以和HTML文件一同混合编写. 与PHP代码包含在&lt;?PHP和?&gt;之间一样,所有的JSP代码都包含在&lt;%和%&gt;之中. JSP文件通常以.jsp作为后缀, 在JSP文件中,JSP代码出现的位置并没有具体的限制. 以下是一段JSP代码的例子: 123456789101112131415161718192021222324&lt;%@page import=&quot;java.util.Random&quot;%&gt;&lt;%@ page language=&quot;java&quot; contentType=&quot;text/html; charset=utf8&quot; pageEncoding=&quot;utf8&quot;%&gt;&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD HTML 4.01 Transitional//EN&quot; &quot;http://www.w3.org/TR/html4/loose.dtd&quot;&gt;&lt;html&gt;&lt;head&gt;&lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html; charset=ISO-8859-1&quot;&gt;&lt;title&gt;Hello From JSP&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;%! String sayHello(String name) &#123; return &quot;Hi,&quot; + name; &#125;%&gt;&lt;%=sayHello(&quot;Lily&quot;) %&gt;&lt;% Random rand = new Random(); int num = rand.nextInt(1000); out.println(&quot;\\n您是今天的第&quot;+num+&quot;位访客&quot;);%&gt;&lt;/body&gt;&lt;/html&gt; 从以上代码,我们可以注意到以下几个特征 所有的JSP代码都是包裹在&lt;%...%&gt;之中的 页面属性有关的代码使用&lt;%@page ...&quot;%&gt;包裹 JSP代码本质还是Java代码 如果刷新页面,则每次显示的数字都不同,说明JSP代码每次请求的时候都会被重新执行 JSP元素类型 类型 标记 解释 静态内容 N/A 即HTML代码,与JSP语法无关 声明(declaration) &lt;%! ... %&gt; 用于定义方法, 变量等 表达式(expression) &lt;%= ... %&gt; 可以计算, 调用函数, 引用变量等 代码片段(scriptlet) &lt;% ... %&gt; 任意的Java代码片段, 通常会产生输出到客户端的输出流 指令 &lt;%@ ... %&gt; 使用page关键字来设置属性 动作 &lt;jsp:动作&gt;...&lt;/jsp:动作&gt; 包含文件, 请求转发等 JSP隐式对象JSP中共包含4大类,共9个隐含对象,这些对象直接存在于JSP脚本中,不需要任何操作即可使用他们. 具体分类如下所示: 输入输出对象 request request对象表示客户端的请求,包含了所有的请求信息,包括协议名,端口号,IP地址,编码方式等信息. response response对象表示服务器端的返回,JSP一般很少使用 out 表示输出流,此输出流会作为请求的响应返回给客户端 out是JspWrite的实例 作用域通讯对象 session 表示用户的会话情况 用于和客户端进行唯一标识,从而保持客户端状态信息 由于HTTP是无状态连接,因此实现此功能通常都是使用了cookie技术 application 全局的共享信息 pageContext 显式的访问隐式的对象 例如pageContext.getOut()获得out对象 此外也可以保存页面级的信息 Servlet对象 page 指向当前页面,相当与其他语言中的this指针 现在已经很少使用page变量 config 存储Servlet的一些初始信息 现在已经很少使用 错误对象 exception 需要在页面中使用page质量将isErrorPage属性置为true 表示异常,是java.lang.Throwable对象 关于session实现的讨论 JSP Session介绍 深入理解cookie与session Session原理和Tomcat实现分析 演示代码 以下代码演示了如何使用request对象和HTML代码实现网页的数据交互12345678910111213141516171819202122232425262728293031&lt;%@page import=&quot;java.util.Enumeration&quot;%&gt;&lt;%@ page language=&quot;java&quot; contentType=&quot;text/html; charset=utf8&quot; pageEncoding=&quot;utf8&quot;%&gt;&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD HTML 4.01 Transitional//EN&quot; &quot;http://www.w3.org/TR/html4/loose.dtd&quot;&gt;&lt;html&gt;&lt;head&gt;&lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html; charset=ISO-8859-1&quot;&gt;&lt;title&gt;Hello From JSP&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;%String str = &quot;&quot;;if(request.getParameter(&quot;username&quot;) != null &amp;&amp; request.getParameter(&quot;password&quot;) != null)&#123; Enumeration&lt;String&gt; enumt = request.getParameterNames(); while(enumt.hasMoreElements())&#123; str = enumt.nextElement().toString(); out.println(str + &quot;:&quot;+ request.getParameter(str) + &quot;&lt;br&gt;&quot;); &#125; &#125;%&gt;&lt;form method=&quot;post&quot; action=&quot;&quot;&gt; 用户名:&lt;input type=&quot;text&quot; name=&quot;username&quot; id=&quot;username&quot; value=&quot;&quot; /&gt; 密码: &lt;input type=&quot;password&quot; name=&quot;password&quot; id=&quot;pass&quot; value=&quot;&quot; /&gt; &lt;input type=&quot;submit&quot; value=&quot;提交&quot;/&gt; &lt;/form&gt; &lt;/body&gt;&lt;/html&gt; Servlet技术Servlet是一种独立于平台和协议的服务器端的Java应用程序,处理请求的信息并将结果返回给客户端. Servlet的客户端可以是浏览器,java应用程序等. Servlet实际上是充当客户端与服务器端数据库之间的中间层. Servlet运行原理 客户端发送请求 服务器将请求转发给Servlet容器处理 Servlet容器处理完毕后将结果返回给服务器 服务器将结果返回给客户端注意: 当一个Servlet第一次收到http请求时,服务器启动一个Servlet实例,并启动一个线程. 后续同一个Servlet再次收到请求时,只开一个新的线程,不再创建实例. Servlet方法和使用学习Servlet方法的最简单方式就是阅读源代码,但是tomcat并没有提供源代码,如果想看诸如HttpServlet类的实现需要自己下载源代码,例如这篇博客提供了源代码的下载和使用方法. 以下的内容都是基于HttpServlet的源代码. doGet方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869/** * * Called by the server (via the &lt;code&gt;service&lt;/code&gt; method) to * allow a servlet to handle a GET request. * * &lt;p&gt;Overriding this method to support a GET request also * automatically supports an HTTP HEAD request. A HEAD * request is a GET request that returns no body in the * response, only the request header fields. * * &lt;p&gt;When overriding this method, read the request data, * write the response headers, get the response&#x27;s writer or * output stream object, and finally, write the response data. * It&#x27;s best to include content type and encoding. When using * a &lt;code&gt;PrintWriter&lt;/code&gt; object to return the response, * set the content type before accessing the * &lt;code&gt;PrintWriter&lt;/code&gt; object. * * &lt;p&gt;The servlet container must write the headers before * committing the response, because in HTTP the headers must be sent * before the response body. * * &lt;p&gt;Where possible, set the Content-Length header (with the * &#123;@link javax.servlet.ServletResponse#setContentLength&#125; method), * to allow the servlet container to use a persistent connection * to return its response to the client, improving performance. * The content length is automatically set if the entire response fits * inside the response buffer. * * &lt;p&gt;When using HTTP 1.1 chunked encoding (which means that the response * has a Transfer-Encoding header), do not set the Content-Length header. * * &lt;p&gt;The GET method should be safe, that is, without * any side effects for which users are held responsible. * For example, most form queries have no side effects. * If a client request is intended to change stored data, * the request should use some other HTTP method. * * &lt;p&gt;The GET method should also be idempotent, meaning * that it can be safely repeated. Sometimes making a * method safe also makes it idempotent. For example, * repeating queries is both safe and idempotent, but * buying a product online or modifying data is neither * safe nor idempotent. * * &lt;p&gt;If the request is incorrectly formatted, &lt;code&gt;doGet&lt;/code&gt; * returns an HTTP &quot;Bad Request&quot; message. * * @param req an &#123;@link HttpServletRequest&#125; object that * contains the request the client has made * of the servlet * * @param resp an &#123;@link HttpServletResponse&#125; object that * contains the response the servlet sends * to the client * * @exception IOException if an input or output error is * detected when the servlet handles * the GET request * * @exception ServletException if the request for the GET * could not be handled * * @see javax.servlet.ServletResponse#setContentType */protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException&#123; ... &#125; 以上是源代码中提供的注释. 从注释可以看到以下几点 这是一个回调方法,会被该类的service方法在合适的时候调用 通过重写这个方法来实现对get请求的处理,如果不重写,也提供了一个默认的操作 重写这个方法时,从request中读取数据,处理后写入respond中 此方法要求安全且幂等,即没有副作用且可以重复调用,并且说明查询通常时安全且幂等的而修改数据既不是安全也不是幂等的 如果请求格式不正确,返回一个”Bad Request”的HTTP消息 此外, 源代码注释中使用了大量的篇幅说明了使用过程的可能出现错误的细节问题,这些问题将在后续统一的进行讨论. doPost方法12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061/** * * Called by the server (via the &lt;code&gt;service&lt;/code&gt; method) * to allow a servlet to handle a POST request. * * The HTTP POST method allows the client to send * data of unlimited length to the Web server a single time * and is useful when posting information such as * credit card numbers. * * &lt;p&gt;When overriding this method, read the request data, * write the response headers, get the response&#x27;s writer or output * stream object, and finally, write the response data. It&#x27;s best * to include content type and encoding. When using a * &lt;code&gt;PrintWriter&lt;/code&gt; object to return the response, set the * content type before accessing the &lt;code&gt;PrintWriter&lt;/code&gt; object. * * &lt;p&gt;The servlet container must write the headers before committing the * response, because in HTTP the headers must be sent before the * response body. * * &lt;p&gt;Where possible, set the Content-Length header (with the * &#123;@link javax.servlet.ServletResponse#setContentLength&#125; method), * to allow the servlet container to use a persistent connection * to return its response to the client, improving performance. * The content length is automatically set if the entire response fits * inside the response buffer. * * &lt;p&gt;When using HTTP 1.1 chunked encoding (which means that the response * has a Transfer-Encoding header), do not set the Content-Length header. * * &lt;p&gt;This method does not need to be either safe or idempotent. * Operations requested through POST can have side effects for * which the user can be held accountable, for example, * updating stored data or buying items online. * * &lt;p&gt;If the HTTP POST request is incorrectly formatted, * &lt;code&gt;doPost&lt;/code&gt; returns an HTTP &quot;Bad Request&quot; message. * * * @param req an &#123;@link HttpServletRequest&#125; object that * contains the request the client has made * of the servlet * * @param resp an &#123;@link HttpServletResponse&#125; object that * contains the response the servlet sends * to the client * * @exception IOException if an input or output error is * detected when the servlet handles * the request * * @exception ServletException if the request for the POST * could not be handled * * @see javax.servlet.ServletOutputStream * @see javax.servlet.ServletResponse#setContentType */protected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException&#123; ... &#125; doPost方法的注释和doGet方法的注释介绍的内容基本是相同的,但有如下的几点差别 使用post方法可以提供无限制长度的数据传输 此方法不要求安全或幂等,即可以在此方法中处理诸如数据更新的任务 init方法1234567891011121314151617181920/** * Called by the servlet container to indicate to a servlet that the * servlet is being placed into service. See &#123;@link Servlet#init&#125;. * * &lt;p&gt;This implementation stores the &#123;@link ServletConfig&#125; * object it receives from the servlet container for later use. * When overriding this form of the method, call * &lt;code&gt;super.init(config)&lt;/code&gt;. * * @param config the &lt;code&gt;ServletConfig&lt;/code&gt; object * that contains configutation * information for this servlet * * @exception ServletException if an exception occurs that * interrupts the servlet&#x27;s normal * operation * * @see UnavailableException */public void init(ServletConfig config) throws ServletException &#123; ... &#125; 由于HttpServlet方式继承自GenericServlet,所以这个方法实际上是定义在GenericServlet中的. 从注释可以看到 此方法被Servlet容器调用,来使Servlet进入服务状态 此方法提供了默认的实现,保存最近的ServletConfig,重写此方法时一定要调用super.init() service方法12345678910111213141516171819202122232425262728/** * Receives standard HTTP requests from the public * &lt;code&gt;service&lt;/code&gt; method and dispatches * them to the &lt;code&gt;do&lt;/code&gt;&lt;i&gt;XXX&lt;/i&gt; methods defined in * this class. This method is an HTTP-specific version of the * &#123;@link javax.servlet.Servlet#service&#125; method. There&#x27;s no * need to override this method. * * @param req the &#123;@link HttpServletRequest&#125; object that * contains the request the client made of * the servlet * * @param resp the &#123;@link HttpServletResponse&#125; object that * contains the response the servlet returns * to the client * * @exception IOException if an input or output error occurs * while the servlet is handling the * HTTP request * * @exception ServletException if the HTTP request * cannot be handled * * @see javax.servlet.Servlet#service */protected void service(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException&#123; ... &#125; service方法注释提到了以下几个要点 此方法接受HTTP请求并根据方法类型调用doXXX类型的方法(例如doGet和doPost) 通常没有必要重写此方法 destory方法12345/** * Called by the servlet container to indicate to a servlet that the * servlet is being taken out of service. See &#123;@link Servlet#destroy&#125;. */public void destroy() &#123; ... &#125; 此方法也定义在GenericServlet之中,注释提到如下要点 此方法被Servlet容器调用,当一个Servlet不再提供服务 Servlet生命周期 实例化 Servlet容器创建Servlet类的实例 初始化 容器调用init方法 通常在init方法中申请资源,以便于后续使用 服务 根据请求,调用doGet,doPost等方法 销毁 调用destroy方法 通常在destroy方法中释放之前申请的资源 不可用 释放容器对应的内存 JDBC技术本节介绍如何使用JDBC技术连接MySQL数据库. 本质上, JDBC和JSP技术并没有相关性, 使用到的JDBC技术也是可以直接用于其他的Java应用程序之中. MySQL和Connector下载MySQL提供了多种版本, 一般情况下选择免费的社区版下载即可. 下载完MySQL后可以在官网上下载最新版的Connector. 官网上提供了多种语言的Connector, 选择Java语言的版本即可. 下载过程中可能要求注册一个账户, 点击最下方的直接下载即可. 补充: 如果使用完整的安装, 则在安装过程中MySQL就提供了各种语言的驱动, 因此不需要再额外的下载 如果使用Maven, 也可以直接导入需要的驱动 导入Connector包下载MySQL的按照程序后, 按照向导进行安装即可. 下载的Connector解压后有两个jar包, 选择mysql-connector-java-XXX.jar(XXX为版本号)并将其复制到项目的WEB-INF\\lib文件夹下即完成包的导入工作. 连接数据库连接数据库是一个固定操作, 一般有以下的过程 1234567891011121314151617181920212223242526272829303132333435363738Connection conn=null; //声明数据库连接对象PreparedStatement pstmt=null; //声明数据库操作对象ResultSet rs=null; //声明查询结果集对象,对于更新操作，可不声明String driverName = &quot;com.mysql.jdbc.Driver&quot;;String userName = &quot;root&quot;;String userPwd = &quot;123456&quot;;String dbName = &quot;webinfo&quot;;String url1 = &quot;jdbc:mysql://localhost:3306/&quot;+dbName;String url2 = &quot;?user=&quot;+userName+&quot;&amp;password=&quot;+userPwd;String url3 = &quot;&amp;useUnicode=true&amp;characterEncoding=UTF-8&amp;serverTimezone=UTC&quot;;String url = url1+url2+url3;try &#123; Class.forName(driverName); conn=DriverManager.getConnection(url); String sql= &quot;SELECT * FROM stu_info;&quot;; //构造完成所需功能的SQL语句(可带参数) pstmt= conn.prepareStatement(sql); rs=pstmt.executeQuery(); while (rs.next()) &#123; response.getWriter().append(rs.getString(1)).append(&quot; &quot;).append(rs.getString(3)); response.getWriter().append(&quot;\\n&quot;); &#125; &#125; catch (ClassNotFoundException e) &#123; e.printStackTrace();&#125; catch (SQLException e) &#123; e.printStackTrace();&#125;finally &#123; try &#123; if(rs!=null)&#123; rs.close(); &#125; if(pstmt!=null)&#123; pstmt.close(); &#125; if(conn!=null)&#123; conn.close(); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125;&#125; 连接数据库时注意指定serverTimezone=UTC 否则可能无法连接数据库. 更多关于时区的问题可以参考如何规避mysql的url时区的陷阱 连接池技术以连接本地数据库中的api库为例, 配置如下所示: 123456789101112&lt;Context&gt; &lt;Resource name=&quot;jdbc/mysql&quot; type=&quot;javax.sql.DataSource&quot; auth=&quot;Container&quot; driverClassName=&quot;com.mysql.jdbc.Driver&quot; url=&quot;jdbc:mysql://localhost:3306/api?serverTimezone=UTC&quot; username=&quot;root&quot; password=&quot;123456&quot; maxActive=&quot;4&quot; maxIdle=&quot;2&quot; maxWait=&quot;6000&quot;/&gt;&lt;/Context&gt; 连接数据库时, 可能会提示com.mysql.jdbc.Driver 已经过时, 按照提示换成新的驱动类即可. 更多关于MySQL和JDBC的内容, 可以参考一下的一些博客 21分钟 MySQL 入门教程 JavaBeanJavaBean是一个Java编写的,符合某种规则的类. JavaBean封装了数据和业务逻辑, 可以被JSP或者Servlet直接调用. JavaBean设计规则 必须是公共类 具有公共的无参数构造方法 所有属性定义为私有 每个属性提供get和set方法(boolean类型方法特殊处理) 通常位于某个包下(而不是默认包) JSP种使用JavaBeanJSP标签一般可以使用以下三种标签来使用JavaBean &lt;jsp:useBean&gt; &lt;jsp:setProperty&gt; &lt;jsp:getProperty&gt; &lt;jsp:useBean id = &quot;对象名&quot; class = &quot;类名&quot; scope = &quot;有效范围&quot;&gt; id相当于类对象标识符,后续使用此标识符引用JavaBean对象 class是JavaBean的类名,且需要使用完整的类型 scope表示范围,可选page, request, session, application, 默认为page &lt;jsp:setPropert name = &quot;对象名&quot; property = &quot;属性名&quot; value = &quot;属性值&quot;&gt; name对应useBean种id的值 属性值按照声明的属性类型进行自动转换 &lt;jsp:setPropert name = &quot;对象名&quot; property = &quot;参数名&quot;&gt; 将一个同名的参数赋值给属性 &lt;jsp:setProperty name=&quot;beanname&quot; property=&quot;属性名e&quot; param=&quot;请求参数名&quot;/&gt; 将请求参数的值赋值给JavaBean属性值 从而协调参数名与JavaBean属性名不一致的问题 &lt;jsp:setProperty name=&quot;对象名&quot; property=&quot;*&quot;/&gt; 将所有的输入参数赋予相应的属性值 脚本代码使用脚本代码时,和使用一个Java类没有区别.","categories":[{"name":"JavaWeb","slug":"JavaWeb","permalink":"https://lizec.top/categories/JavaWeb/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://lizec.top/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"Java","slug":"Java","permalink":"https://lizec.top/tags/Java/"}]},{"title":"JavaWeb之环境配置","slug":"JavaWeb之环境配置","date":"2018-06-21T02:22:03.000Z","updated":"2018-11-21T12:45:27.697Z","comments":true,"path":"2018/06/21/JavaWeb之环境配置/","link":"","permalink":"https://lizec.top/2018/06/21/JavaWeb%E4%B9%8B%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/","excerpt":"","text":"本文介绍在Windows环境下,进行Java Web开发需要的环境配置方法, 以及将开发的项目部署到远程Ubuntu服务器的方法. Windows开发环境配置过程在windows平台主要进行的是开发环境配置,包括本地的运行环境和开发的IDE. 开发工具 JDK Apache-tomcat eclipse-jee 由于使用java进行开发,因此首先需要下载JDK. 之后是Web服务器的有关程序,即Apache-tomcat. 最后下载开发IDE,即eclipse-jee. 这三个软件都是可以免费下载的,使用搜索引擎直接搜索一下就可以获得相应的官网的网址. 注意: JDK按照后,按照惯例需要配置环境变量,如何配置可以百度有很多图文教程 tomcat有无需安装的版本,直接解压即可使用,同样也需要配置环境变量,具体步骤可百度 下载eclipse时一定要下载jee版本,该版本对Web开发提供了很多额外的支持 创建项目在eclipse中,依次选择File-&gt;New-&gt;Others. 在弹出的对话框中选择Web文件夹下的Dynamic Web Project.由于不同版本可能会有变化,所以具体路径是多少并不重要,最后能找到Dynamic Web Project即可. 注意: 在创建项目的过程中,一定要选中Generate web.xml deployment descriptor 否则由于最后的项目不自动生成web.xml而导致Servlet模块无法访问. 如果已经创建了项目,而且忘记了选中Generate web.xml deployment descriptor,还可以在最后项目开发完毕准备部署的时候执行以下操作 在项目上右键,选择Java EE Tools 在次级菜单中选择Generate deployment descriptor stub,即手动生成web.xml文件 选择目标运行时在创建项目的过程中,需要选择程序运行时(Target Runtime),如果没有可以新建一个. 注意以下两点 新建的时候注意选择和之前下载的tomcat保持相同版本 路径选择之前解压tomcat的路径. 注意: 如果没有选择运行时, 创建项目以后, 新建了JSP文件, 可能会提示he superclass &quot;javax.servlet.http.HttpServlet&quot; was not found on the Java Build Path. 这是由于项目之中没有添加tomcat的依赖, 导致有关的类无法找到. 重新创建项目并选择运行时即可. 此外以下两个文章给出了从现有项目添加运行时的方法. 解决办法：错误异常The superclass “javax.servlet.http.HttpServlet” was not found on the Java Build Path the superclass javax servlet http httpservlet was not found on the java build 创建服务器程序运行之前还需要配置运行服务器. 不过由于eclipse有引导, 点击运行按钮以后,按照引导选择正确的tomcat版本即可. 查看效果tomcat运行后会在本地的8080端口展示效果,因此使用浏览器访问http://localhost:8080/项目名 即可查看运行效果 ubuntu远程服务器配置Ubuntu平台只需要执行有关的代码而不需要进行开发,因此只需要下载运行环境而不需要下载IDE,也不需要使用图形界面. 因此以下过程都是在命令行中执行. 安装JDK和Windows环境一样,在Ubuntu下安装jdk只需要输入以下指令 1sudo apt install default-jdk 注意: 按照惯例,安装软件之前应该先更新软件源和软件列表,具体方法可以百度 据说某些情况下可能无法访问到国外的源,这个时候可以考虑换一个国内的 使用apt安装时,自动配置了有关的环境变量,因此不需要再次配置 安装tomcat依次执行以下指令下载tomcat 123456789101112131415161718192021# 下载并解压tomcatcd /usr/local/libsudo wget -c http://apache.mirrors.tds.net/tomcat/tomcat-9/v9.0.10/bin/apache-tomcat-9.0.10.tar.gzsudo tar -zxvf apache-tomcat-9.0.5.tar.gz# 修改文件名sudo mv apache-tomcat-9.0.10 apache-tomcat#修改用户sudo chown -R ubuntu:ubuntu /usr/local/lib/apache-tomcat/# 添加环境变量export TOMCAT_HOME=/usr/local/lib/apache-tomcatexport CATALINA_HOME=$TOMCAT_HOMEexport PATH=$PATH:$TOMCAT_HOME/bin# 启动服务cd apache-tomcat/bin/./startup.sh# 关闭服务 注意: 由于tomcat不断的更新,因此可能某一天这个链接就不能用了,由于wget本质就是一个下载程序,因此可以访问 http://apache.mirrors.tds.net/tomcat/ 查看最近的版本,依据情况自行调整下载连接 部署Web项目到远程服务器将项目部署到tomcat文件夹默认情况下,Eclipse会将项目放在工程目录并将最后的Web文件存放在.metadata\\.plugins\\org.eclipse.wst.server.core\\tmp0\\wtpwebapps\\ 下,通过修改部署位置可以为后续部署到远程服务器提提供便利. 按照以下步骤修改Eclipse项目部署位置 在Eclipse中创建服务并运行项目(如果已经由服务器和项目跳过此步) 移除当前服务上的项目 在Eclipse的Servers视图,选中服务器右键 选择Remove,移除所有项目 配置属性 再次在Servers视图,选中服务器右键 选中Open,打开配置 将Server Locations修改为Use Tomcat installation 在下面的Deplay path输入wabapps 配置依赖库 在项目上右键,选中Properties 在弹出菜单的侧边栏选择Deplayment Assembly 在右侧选择Add,在弹出菜单中选择Java Build Path Entries,点击Next 在弹出菜单中选择需要添加的库 Tomcat配置热部署默认情况下,将Windows上生成好的Wen项目直接复制到Ubuntu的相应目录下就可以直接访问了,但是如果对内容进行了修改,则必须要重启tomcat服务才能更新内容. 通过配置tomcat热部署可以动态的改变内容而不需要重启服务. 配置tomcat热更新仅仅修改$TOMCAT_HOME\\conf\\server.xml文件, 在其中的&lt;host&gt;&lt;/host&gt;内部添加&lt;context/&gt;标签 12345&lt;host&gt; ... &lt;Context debug=&quot;0&quot; docBase=&quot;WebHello&quot; path=&quot;/WebHello&quot; privileged=&quot;true&quot; reloadable=&quot;true&quot;/&gt; ...&lt;/host&gt; 注意: 其中的docBase指的是项目在服务器上的路径,使用相对路径时,当前目录是webapps path是最后在浏览器上的访问路径,例如本例中是http://example.com:8080/WebHello reloadable表示文件发生变动时是否自动重新加载 如果修改servlet文件没有生效，可以先删除有关的class文件，再添加新的文件 补充: Tomcat文件结构介绍 bin 该目录下存放的是二进制可执行文件 包括启动,关闭tomcat服务的各种程序 conf 这是一个非常非常重要的目录,这个目录下有四个最为重要的文件 server.xml 配置整个服务器信息 例如修改端口号, 添加虚拟主机等 tomcatusers.xml 存储tomcat用户的文件,这里保存的是tomcat的用户名及密码, 以及用户的角色信息 配置后可通过配置的用户名密码进入Tomcat Manager页面 web.xml 部署描述符文件 context.xml 对所有应用的统一配置 lib 项目依赖的二进制文件 logs 日志文件 temp 运行过程中产生的临时文件 webapps 存放web项目的目录,其中每个文件夹都是一个项目 其中ROOT是一个特殊的项目,在地址栏中没有给出项目目录时,对应的就是ROOT项目 work 运行时生成的文件,最终运行的文件都在这里 可以删除,下次运行时tomcat会再次自动生成 参考文献 Eclipse开发Web项目入门篇 Eclipse手动生成JavaWeb项目web.xml文件 Ubuntu 服务器安装 Java Web 开发环境 Eclipse中web项目部署至Tomcat步骤 Tomcat热部署方法 Tomcat的目录结构","categories":[{"name":"JavaWeb","slug":"JavaWeb","permalink":"https://lizec.top/categories/JavaWeb/"}],"tags":[{"name":"环境配置","slug":"环境配置","permalink":"https://lizec.top/tags/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"},{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://lizec.top/tags/Ubuntu/"}]},{"title":"大数据技术原理","slug":"大数据技术原理","date":"2018-04-28T06:23:42.000Z","updated":"2020-06-26T14:43:49.000Z","comments":true,"path":"2018/04/28/大数据技术原理/","link":"","permalink":"https://lizec.top/2018/04/28/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86/","excerpt":"","text":"本文的主要介绍大数据原理与技术, 对大数据的基本概念, 大数据处理架构, Hadoop平台及其生态系统进行概要性的介绍. 本文的主要内容都基于中国大学MOOC上的&lt;&lt;大数据技术原理与应用&gt;&gt;课程, 并且结合Hadoop官网上的文档进行适当补充. 概述数据产生的三个阶段 运营式系统阶段: 通过各种运营系统产生数据 用户原创内容阶段: 博客,微博等各种用户可以发布数据的平台产生数据 感知式阶段: 物联网设备的大量普及,各种传感器产生数据 大数据的特征大数据的特征可以使用5V来概括 特征 含义 大量化(Volume) 数据流跃升, 数据量大 多样化(Variety) 种类繁多, 来源各异 快速化(Velocity) 实时响应要求 价值密度低(Value) 大数据的价值往往呈现稀疏性的特点 可信性(Veracity) 数据可信性和可用性 大数据的思维方式 全样而非抽样 效率而非精度 相关而非因果 在以往的数据处理过程中, 由于使用抽样, 因此对计算过程要求有一定的精度, 否则可能随着计算过程不断的放大误差. 在大数据中, 由于对全体数据进行处理, 因此往往不再要求算法精度, 反而对算法的执行效率有更高的要求. 云计算云计算是指通过网络以服务的方式向用户提供非常廉价的IT资源. 云计算的主要内容就是解决分布式存储和分布式处理的问题. 大数据时代的海量数据只能通过集群来进行存储和处理.云计算的典型特征是虚拟化和多租户. 用户不需要自己购买机房, 而是直接购买相关的服务. 大数据处理架构介绍Hadoop是Apache基金会下的一个开源的分布式计算平台. Hadoop实际上包含了一系列的组件. Hadoop架构Hadoop大致有如下的几大部分组成: 每个部分的基本功能如下所示, 具体的细节和使用在后续各章节分别介绍. 名称 作用 名称 作用 HDFS 分布式文件存储 TeZ 分析优化工具 YARN 资源调度 Pig 类SQL的脚本语言 MapReduce 基于磁盘的分布式计算 Oozie 作业流调度系统 Spark 基于内存的分布式计算 Zookeeper 分布式协调服务 Hive 数据仓库 Flume 日志收集分析框架 HBase 非关系型的分布式数据库 Ambari 集群部署和监控工具 Sqoop 与传统数据库传递数据 Hadoop安装与配置Hadoop平台上有很多项目, 这些项目基本都是独立的, 需要到各个项目的官网上下载相关的代码. 在学习Hadoop的过程中, 由于国内的文档多数比较陈旧, 存在很多兼容性问题, 因此安装时推荐安装官网教程操作. 官方的文档比起各种转述或者翻译的文章, 更具有权威性, 内容的正确性更有保证. HDFS简介Hadoop分布式文件系统(Hadoop Distributed File System, HDFS), 是Hadoop平台下的分布式文件系统, 主要以分布式集群的方式来实现海量数据的存储. HDFS是Google文件系统(Google File System, GFS)的开源实现, 关于GFS的有关内容参考阅读笔记. 核心概念 名称 作用 块 与普通的文件系统的块含义类似,是数据存储的基本单位 名称节点 整个集群的主节点, 管理了所有文件的位置信息 数据节点 实际存放数据的节点 FsImage 保存系统文件树和文件的属性信息, 包括访问与修改时间, 访问权限等 EditLog 记录了对数据的操作记录 几点补充 与普通的文件系统相比, 一个默认的HDFS块大小为64MB 较大的块大小有助于减少索引空间., 但由于MapReduce使用块作为基本处理单位, 因此如果块过大, 又会导致并行性降低 HDFS是基于文件的系统, 数据保存在磁盘上, 但名称节点的元数据由于频繁访问, 因此保存在内存之中 EditLog的作用HDFS文件的元数据保存在内存之中, 同时有关的信息也同时存储到FsImage之中. 如果每次修改文件信息后, 都同步的将修改写到FsImage之中, 就会导致大量的磁盘读写, 限制了程序的性能. 因此因此在HDFS中, 所有的操作都是记录到EditLog之中, 而FsImage不发生改变. 第二名称节点在名称节点中, 虽然FsImage不发生改变, 但EditLog依然会不断增大. 在HDFS的设计中, 每次启动时会将EditLog与FsImage合并, 但如果长时间运行, 当EditLog增大到一定程度以后, 会同样的影响程序性能. 因此HDFS引入第二名称节点. 第二名称节点定期的与名称节点通信, 请求名称节点停止项EditLog写入. 名称节点受到请求后, 创建一个edits.new的文件, 将后续更新写入此文件之中. 第二名称节点将原来的EditLog文件和FsImage文件下载dao本地进行合并. 第二名称节点将合并的FsImage文件返回给名称节点. 名称节点将原有的FsImage文件替换并且将edits.new更名为EditLog 通过上述操作, 第二名称节点实现了FsImage和EditLog的合并, 而保存在第二名称节点上的FsImage又可以作为备份文件, 在名称节点出现故障时用来恢复状态. HDFS 1.0的局限性 命名空间限制: 名称节点保存在内存中,因而存储规模受单机内存大小限制 性能瓶颈: 整个系统的吞吐量受单个节点的性能限制 隔离性: 只有一个名称节点, 各个应用之间不能隔离 集群可用性: 名称节点出现故障整个集群失效 HDFS存储机制 冗余存储机制由于底层架构在廉价的设备上, 因此设备出现故障是常态, HDFS引入冗余机制, 将数据以块为单位进行冗余保存.此外, 由于有多个副本, 因此还可以加快传输速度. 数据存储策略 第一个副本存放在发起请求的节点上, 从而减少网络传输. 后续副本存放在不同机架和不同节点的设备上, 从而在减少网络传输和提高数据安全性之间取得一个平衡 MapReduce编程MapReduce的基本策略是分而治之, 把庞大的数据切分为多个独立的小分片, 然后为每个分片启动一个单独的map任务, 最终通过多个map任务, 并行的在多个机器上处理. MapReduce过程中有一个重要的理念, 即 计算向数据靠拢而不是数据向计算靠拢. 在需要一个计算时, 将应用程序分发到数据所在的机器, 从而绕过网络带宽对数据传输的限制, 极大的提高总体的处理效率. 更多关于MapReduce概念性的内容, 可以参考关于Google的论文《MapReduce：Simplified Data Proessing on Large Clusters》的阅读记录. 本文接下来介绍MapReduce在架构方面的内容. 体系结构 Client 提交用户编写的程序 查看作业运行状态 JobTracker 负责资源的监控和作业调度 监控底层其他的TaskTracjer以及当前Job的状态 探测到失败时进行任务转移 跟踪任务进度和资源使用量 TaskTracker 接收JobTracker发送的任务, 执行具体的任务 监控自身的资源使用情况, 使用心跳方式发送给JobTracker 把资源分成若干个slot,, 即map类型的slot和reduce类型的slot 统计slot占用使用量衡量资源占用率 Task 分为map任务和reduce任务 一台物理设备可以同时运行两种类型的任务 工作流程分片大小分片大小和HDFS的块大小并没有直接联系, 但是为了减少不必要的数据传输, 通常使分片大小和块大小相等. map任务数量确定由于每个分片都需要分配一个map任务, 因此map任务数量等于分配数量 reduce任务数量确定通常依据系统可以提供的reduce的slot数量决定reduce任务数量,且实际数量略小于最大可用数量. Shuffle过程数据流动过程 数据首先通过HDFS系统提取出来,进行map任务 map任务执行结果写入缓存 缓存慢后进行溢写操作,溢写过程执行分区,排序和合并操作 多个磁盘文件进行归并 reduce机器取走相应分区的数据 reduce函数进行处理,并最终输出到HDFS Map端的Shuffle过程 数据输入和执行任务 转换的键值对写入缓存 溢写过程 达到溢写比后启动溢写操作 分区: 按照不同的reduce任务分到不同的区 排序: 对分区的数据按照字典序排序 合并: 多个键值对合并成一个键值对(不是必须的,由用户定义) 文件归并: 将多个溢写文件归并成一个大的文件(最终文件时分区且排序的) Reduce端Shuffle过程 从Map机器领取需要的数据 归并(生成key-valuelist)后合并(合并value值) 将数据输入给Reduce任务 MapReduce程序执行过程 程序部署: 将程序分发到不同的机器 不同的机器分别执行map任务和reduce任务 读数据,生成键值对 本地写数据, 将缓存的数据写入磁盘 远程读数据, 执行reduce任务机器获取相关数据 写数据, 写入输出结果 HBase简介HBase是BigTable的开源实现. HBase是一个 高可靠, 高性能, 面向列的可伸缩的分布式数据库. HBase主要用于存储非结构化和半结构化的数据, 是对HDFS和MapReduce在实时性上的扩展, 同时弥补了传统数据库在大量数据上无法应对的问题. HBase不保存数据类型, 全部都是原始数据, 由应用程序去解释数据类型. 不同于关系数据库, Hbase是基于列的存储. HBase不存在替换操作, 定时的清理无效数据. HBase构建在HDFS之上, 使用集群保存数据, 因此很容易扩展设备. 传统数据库的问题传统的数据库在面临大量数据时, 有两个主要问题 数据库不便于分布式扩展, 难以面对海量的数据读写请求 数据库模式无法轻易改变, 无法满足数据类型快速变化的需求 实际上, HBase的产生, 也就是对上述两个问题的解决方案. HBase访问接口HBase本身使用Java开发, 因此可以通过JavaAPI进行访问. 此外HBase还提供基于shell的命令行工具, 和基于网络的API. 最后还可以通过构建在HBase之上的类SQL脚本语言Pig或者数据仓库产品Hive进行访问. HBase数据模型HBase中的数据需要通过行键, 列族, 列限定符和时间戳四个元素来唯一确定. HBase的概念视图如下所示: 一行可以有一个行键(RowKey)和若干列族, 每个列族可以包含若干列, 使用列族:列限定符来指定具体的一列,通过时间戳区分新旧版本的数据. 必须使用行键, 列族, 列限定符和时间戳才能唯一的确定一个数据. 从概念视图来看, 由于每次更新并不是更新一行的所有数据, 因此存储是稀疏的. HBase的物理视图如下所示: HBase采用以列族为单元的存储方式, 从而避免了概念视图过于稀疏的问题. 效率与规范化根据关系数据理论, 如果不准守规范化的要求, 可能会导致数据冗余, 更新异常, 插入异常, 以及删除异常. HBase中存储的数据并没有任何的规范化的要求, 主要有两个原因： 存储空间价格快速降低, 可以接受一定程度的数据冗余, 相反此时查询时间更加重要, 遵守规范化理论导致在查询时通常需要进行多表连结操作, 在面对海量数据时, 连接操作低效且耗时 HBase构建在HDFS上, 本质上只插入新数据, 处理的海量数据也往往也不会再被修改, 从而可以一定程度上容忍更新异常, 插入异常和删除异常 HBase系统结构 组件 功能 客户端 为客户提供访问接口 ZooKeeper服务器 提供协同管理, 保证任意时刻只有一个Master服务器运行 Master服务器 维护分区信息、维护Region服务器列表和状态、负载均衡 Region服务器 实际维护和管理数据, 与客户端直接通信 HBase三级访问结构 HBase最初有一个.META表, 用于存放Region ID和服务器ID的映射关系..META表本身也保存于Region中, 因此一定容量以后也会无法被一个Region保存, 这个时候使用类似二级页表的方法, 使用-ROOT-表保存.META表的位置. HBase设计时规定只能有一个-ROOOT-文件, 使用Zookeeper文件保存-ROOT-表的位置. 与页表的缓冲机制类似, 客户端也会对位置信息进行缓存, 从而减少寻址的时间. 存储过程 在HBase中每个族列对应一个Store, 保存在磁盘上的Store称为StoreFile文件. 写入数据是先写入MemStore,并且将记录写入HLog. 读取数据时先访问MemStore(因为其中可能包含更新后的数据), 如果没有找到,再去访问磁盘. 服务器周期性的将MemStore中的数据刷写到磁盘中,然后清空MemStore并且对Hlog进行标记. 每次刷写都产生新的StoreFile文件. 多个StoreFile可以合并成一个更大的StoreFile,进一步增大,达到Region上限后又会触发分裂操作. 这也是唯一的Region分裂操作. HBase的Shell指令 操作 指令 含义 创建表 create &#39;tempTable&#39;,&#39;f1&#39;, &#39;f2&#39;, &#39;f3&#39; 创建表tempTable,其中包含列族f1,f2和f3 显示表 list 显示所有的表 浏览记录 scan &#39;tempTable&#39; 浏览表中所有的数据 添加记录 put &#39;tempTable&#39;,&#39;r1&#39;,&#39;f1:c1&#39;,&#39;hello dblab&#39; 向tempTable的r1行,f1族c1列放入数据’hello dblab’ 查询记录 get &#39;tempTable&#39;,&#39;r1&#39;, &#123;COLUMN=&gt;&#39;f1:c1&#39;&#125; 获得tempTable的r1行,f1族c1列的数据 删除表 disable &#39;tempTable&#39; drop &#39;tempTable&#39; 先令表失效之后才能删除表格 注意: 不需要事先声明列的名称,可以直接添加新的列 每次只能为一个表的一行的某一列添加数据 NoSQL简介NoSQL最初是表示反对SQL, 后来发现关系数据库和非关系数据库各有优势, 因此NoSQL现在是Not Only SQL的缩写. NoSQL数据库与传统数据库NoSQL特点 具有灵活的可扩展性, 可以对多个节点扩增 灵活的数据模型, 可以动态变换,甚至没有模式 与云计算紧密结合, 可以充分利用底层硬件的伸缩性 传统数据库的缺陷 无法满足海量数据管理需求 无法满足高并发需求(用户数据必须实时生成) 无法满足高可扩展性和高可用性的需求 NoSQL兴起的原因 关系数据库无法满足Web2.0的需求 数据模型局限性 Web2.0关系型数据库许多特性没有被发挥(例如事务机制) Web2.0的特点 不需要严格的事务机制 不需要严格的实时性 不需要复杂的SQL查询(去规范化) NoSQL数据库分类NoSQL数据库现在有4大类, 各类基本特征如下所示 数据库类型 特点 常见产品 键值数据库 存储数据是一堆键值对 Redis,Memcached,SimpleDB等 列族数据库 数据按照列存储 BigTable,HBase, Cassandra等 文档数据库 存储键值对且值是文档 MongoDB, CouchDB等 图数据库 基于图结构的数据库 Neo4j 键值数据库 键是字符串对象, 值是任意类型数据 扩增性好, 读写性能高 适合简单存储, 高性能读写的场景, 如配置文件,购物车等 适合作为Web数据的缓冲层 无法存储结构化信息, 条件查询效率低 不适合按值查询或者关系查询, 可能无法回滚 列族数据库 适合分布式存储和管理 适合需要动态字段的以及可以运行短期不一致的应用 查找速度块,可扩展性强 文档数据库 本质是键值数据库,且值是一个文档 文档可以根据数据库内容自描述, 通常使用JSON格式 更好的并发性, 修改属性通常只用修改一个文件 不支持事务机制 图数据库 专门用于具有高度相关的数据,如社交网络,模式识别,推荐系统等 支持图论的各种复杂算法 使用场景有限 NoSQL三大基石CAP理论 一致性(Consistency): 任何一个读操作总能读到之前完成的写操作的结果 可用性(Availability): 可以快速的获得数据 分区容忍性(Partition tolerance): 当某一部分节点出现错误是,分离的系统依然可以正常工作 理论和实践证明CAP不可能同时满足, 三者只能取其二CA: 所有事务都放在同一机器,避免分区问题CP: 使用网络分区, 数据一致后再取数据AP: 立即获得数据, 忽略一致性 传统数据库一般采用CA, HBase采用CP Base理论Basically Avaible Soft state和Eventual consistency的简写, 缩写是BASE,即”碱” 与关系型数据库中的ACID(酸)对应 基本可用: 部分出错不影响其他分区 软状态: 状态可以有一定的滞后性 最终一致性: 数据最终能到达一致 NewSQL原有SQL无法满足各种新的业务场景的需求, 因此在不同的领域对SQL产生了一些分化. NewSQL是同时具备OldSQL和NoSQL数据库的优点. 既保证了事务一致性有保证了非常好的可扩展性. MonogoDB数据库MongoDB是文档数据库, 其中的值部分是二进制的JSON格式,称为BSON.可以针对任何属性建立索引,从而可以依据值进行查询 传统数据库术语与mongoDB数据库术语对应关系入下表所示 传统数据库 MongoDB database database table collection row document column field index index 注意:在MongoDB同一个集合的文档结构不需要相同,同名字段也不需要内容相同 数据仓库数据仓库是一个面向主题的, 集成的, 相对稳定的, 反应历史变化的数据集合, 用于支持管理决策. Hive 不提供存储 只提供编程接口 借助于HDFS和MadReduce完成数据存储和计算 使用HiveQL语言完成分析任务 应用场景 Pig 主要用于数据的源的转换操作 Hive 主要用于数据的批处理分析 与传统数据的区别 Hive只支持数据的批量导入 Hive不支持数据更新 Hive执行延迟高,扩展性较好 Hive对外接口 CLI: 命令行工具 HWI: Hive Web Interface, Hive的Web接口 JDBC/ODBC: 开放数据库接口 Thrift Server: 基于Thrift的接口 Impala 提供类似Hive的功能 性能比Hive高3~30倍 支持SQL查询 不能独立运行,依赖Hive的元数据 使用分布式查询引擎直接对HDFS或者HBase查询,而不需要进行转化 Impala系统架构 Impalad: 查询任务 Query Planner Query Coorddinator Query Exec Engine State Store 元数据管理状态信息维护 CLI 用户访问接口 Hadoop再探讨最初版本Hadoop的缺陷 抽象层次低, 需要人工编码 Map/Reduce表达能力有限 需要开发者管理作业之间的关系 无法看到整体的逻辑 迭代执行效率低 实时性差 Hadoop2.0的改进 设计HDFS HA, 提供名称节点的热备份机制 设计HDFS Federation管理多个命名空间 设计新的资源管理框架Yarn(Yet Another Resource Negotiator) 使用Pig解决抽象层次低的问题 使用Spark解决实时性差,迭代效率低的问题 使用Ooize解决不同的作业协同问题 使用Tez支持有向无环图的问题,减少重复操作 使用Kafka进行分布式发布订阅消息,实现对各种组件的数据交换 HDFS HA 同时运行两个名称节点,一个处于活跃状态,一个处于待命状态 使用Zookeeper协同两个节点的运行 使用共享存储系统保持两个名称节点的数据(Editlog)同步 底层的数据节点需要同时向两个名称节点同时汇报状态, 从而保证映射表信息的同步 HDFS Federation 支持同时运行多个名称节点,各名称节点独立工作 通过挂载方式访问不同的命名空间 解决了HDFS名称接待的扩展问题 使用多个名称节点同时服务, 提高了系统的吞吐量 多个名称节点为系统提供了良好的隔离性 注意: 各名称节点是联盟关系, 因此不能解决单点故障的问题 Yarn原有架构的缺陷 使用JobTracker进行管理, 存在单点故障 由于JobTracker管理过多, 导致任务繁忙 任务分配只考虑数量,容易内存溢出 资源划分不合理, Map任务和Reduce任务的slot不可通用 Yarn设计思路对原有JobTracker功能拆分, Yarn作为纯粹的资源调度框架 ResourceManager功能 处理客户端请求 监控NodeManager 启动/监控ApplicationMaster 资源分配与调度 ApplicationMaster 为资源申请资源,分配内部任务 任务调度,监控和容错 NodeManager 管理单个节点 处理ResourceManager指令 处理ApplicationMaster指令 参考资料 中国大学MOOC &lt;&lt;大数据技术原理与应用&gt;&gt; DouglasEadline. 写给大忙人的Hadoop 2[M]. 电子工业出版社, 2016. 本文内容主要是基于中国大学MOOC上厦门大学开设的&lt;&lt;大数据技术原理与应用&gt;&gt;课程. 该课程整合了很多资源, 因此相比于在网络查阅各种资料, 更加适合初学者学习.","categories":[{"name":"大数据","slug":"大数据","permalink":"https://lizec.top/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://lizec.top/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"}]},{"title":"Markdown中插入数学公式","slug":"Markdown中插入数学公式","date":"2018-03-30T08:46:54.000Z","updated":"2020-01-14T02:24:59.785Z","comments":true,"path":"2018/03/30/Markdown中插入数学公式/","link":"","permalink":"https://lizec.top/2018/03/30/Markdown%E4%B8%AD%E6%8F%92%E5%85%A5%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F/","excerpt":"","text":"在日常写文章的过程中,经常会遇到需要使用公式的情况, 在以前我都是尽量使用文字描述, 但这毕竟不能从本质解决问题, 因此我决定学习如何在Markdown中使用公式. 经过一番搜索, 发现要加入公式还是比较简单的. 本文介绍如何在Markdown中使用LaTeX公式, 并且基于此简单介绍LaTeX的数学公式语法. 学会了如何使用公式以后,Markdown基本上就可以完全替代Word了. 什么是LaTeX本来我以为LaTex是专门用于数学公式的, 但实际上LaTeX是一个排版工具, 编写公式只是LaTeX的应用之一. 通过导入不同的包, 还可以使用LaTex来展示棋谱,化学式,乐谱,电路图等其他复杂的图示. 由于本文仅仅讨论LaTeX的数学公式, 因此其他的内容就不再展开, 具体可以参考LaTeX的百科. Markdown中引入LaTex公式引擎如果需要在Markdown中加入LaTex公式,可以使用MathJax引擎, 在Markdown中添加MathJax引擎仅仅需要在文章的任意地方加入以下代码 1&lt;script type=&quot;text/javascript&quot; src=&quot;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=default&quot;&gt;&lt;/script&gt; 注意: 上述地址可能在某一天失效, 可以在MathJax的News页面查看最新版的有关信息. 引入公式在文本中$$公式$$表示行间公式,\\\\(公式\\\\)表示行内公式. 例如以下的一段源代码 12345We denote the conditional probability that \\\\( y = y\\_1\\\\) given \\\\( x = x\\_1\\\\) as \\\\( P(y=y\\_1|x=x\\_1) \\\\). This conditional probability can be computed with the formula:$$ P(y=y\\_1|x=x\\_1) = \\frac&#123;P(y=y\\_1, x=x\\_1)&#125;&#123;P(x=x\\_1)&#125; $$ 对应的渲染效果: We denote the conditional probability that \\( y = y_1\\) given \\( x = x_1\\) as \\( P(y=y_1|x=x_1) \\). This conditional probability can be computed with the formula: $$ P(y=y_1|x=x_1) = \\frac{P(y=y_1, x=x_1)}{P(x=x_1)} $$ LaTeX语法与Markdown的兼容问题由于_ , *, &#123;, &#125;, \\等符号在Markdown中是特殊符号, 因此如果需要使用这些符号, 需要在前面加上转义符号\\. 对于部分特殊的符号, 在LaTeX中也是特殊符号, 也需要转义, 则在Markdown中需要输入两次转义符号, 即\\\\. 角标和括号 名称 LaTeX语法 示例 上标 i^2 \\( i^2 \\) 下标 i_2 \\( i_2 \\) 上标和下标,默认将这两个符号后的一个符号作为上下标, 如果需要多个符号, 则使用&#123;和&#125;括起来. 由于最后的结果依然是HTML代码,而不是图片,因此不支持多层嵌套的上标和下标. 但对于一般公式而言,这也基本够用了. 注意: Markdown中, _是特殊符号, 通常情况下需要转义才能使用功能 在LaTeX中,(, ), [ 和 ]都不变. &#123;和&#125;需转义, 即使用\\\\&#123;和\\\\&#125;. 例如 1$$ a(2) + b[3] = c\\\\&#123;5\\\\&#125; $$ $$ a(2) + b[3] = c\\{5\\} $$ 特殊符号 名称 LaTeX语法 示例 分数线 \\frac &#123;a&#125; &#123;b&#125; \\(\\frac {a} {b}\\) 平方根 \\sqrt&#123;a*x+b&#125; \\(\\sqrt{a*x+b}\\) n次方根 \\sqrt[n]&#123;a*x+b&#125; \\(\\sqrt[n]{a*x+b}\\) 积分 \\int_a^b f(x) dx \\(\\int_a^b f(x) dx\\) 极限 \\lim_&#123;n \\rightarrow 0&#125; \\sin&#123;x&#125; / x \\(\\lim_{n \\rightarrow 0} \\sin{x} / x\\) 求和 \\sum_&#123;i=0&#125;^n \\frac&#123;1&#125;&#123;i^2&#125; \\(\\sum_{i=0}^n \\frac{1}{i^2}\\) 求积 \\prod_&#123;i=0&#125;^n \\frac&#123;1&#125;&#123;i^2&#125; \\(\\prod_{i=0}^n \\frac{1}{i^2}\\) 梯度算子 \\nabla \\(\\nabla\\) 偏导数 \\partial x \\(\\partial x \\) 希腊字母 字母名称 大写 小写 字母名称 大写 小写 alpha Α α nu Ν ν beta Β β xi Ξ ξ gamma Γ γ omicron Ο ο delta Δ δ pi Π π epsilon Ε ε rho Ρ ρ zeta Ζ ζ sigma Σ σ/ς eta Η η tau Τ τ theta Θ θ upsilon Υ υ iota Ι ι/℩ phi Φ φ kappa Κ κ chi Χ χ lambda Λ λ psi Ψ ψ mu Μ μ omega Ω ω 希腊字母基本上就是\\加上拉丁语写法,例如 \\(\\Gamma\\) 的公式是\\\\(\\Gamma\\\\), \\(\\gamma\\) 的公式是 \\\\(\\gamma\\\\) . 通常仅仅在公式中以这样的方式输入希腊字母. 如果仅仅是在文本中输入希腊字母, 由于使用Unicode编码, 所以这些符号可以直接输入. 所有的希腊字母及其拉丁语写法如上表所示. 矢量与划线 名称 LaTeX语法 示例 矢量 \\vec&#123;a&#125; \\( \\vec{a} \\) 上划线 \\overline&#123;IOW&#125; \\( \\overline{IOW} \\) 下划线 \\underline&#123;IOW&#125; \\( \\underline{IOW} \\) 所以结合前面提到的各种符号, 现在基本可以无压力的输入一个麦克斯韦方程组了,例如 1$$ \\nabla \\cdot \\vec&#123;E&#125; = \\frac &#123;\\rho&#125; &#123;\\epsilon_0&#125; $$ $$ \\nabla \\cdot \\vec{E} = \\frac {\\rho} {\\epsilon_0} $$ 集合操作 名称 LaTeX语法 示例 名称 LaTeX语法 示例 任意 \\forall \\( \\forall \\) 存在 \\exists \\( \\exists \\) 属于 \\in \\( \\in \\) 不属于 \\notin \\( \\notin \\) 子集 \\subset \\( \\subset \\) 子集 \\sqsubseteq \\( \\sqsubseteq \\) 交 \\cup \\( \\cup \\) 并 \\cap \\( \\cap \\) 可以看到, 集合操作基本就是个符号含义的英文单词, 比较容易记忆. 矩阵操作矩阵的基本形式通过使用$$\\begin&#123;matrix&#125;…\\end&#123;matrix&#125;$$来实现,例如 1234567$$ \\begin&#123;matrix&#125; 1 &amp; 2 &amp; 3 \\\\\\\\ 4 &amp; 5 &amp; 6 \\\\\\\\ 7 &amp; 8 &amp; 9 \\end&#123;matrix&#125; $$ $$ \\begin{matrix} 1 &amp; 2 &amp; 3 \\\\ 4 &amp; 5 &amp; 6 \\\\ 7 &amp; 8 &amp; 9 \\end{matrix}$$ 注意: 由于LaTex使用\\\\来表示换行, 因此在Markdown代码中,需要使用\\\\\\\\ 由于上述形式中没有括号, 因此可以使用\\left和\\right来加入一个可变长的括号. 例如使用小括号的语法如下 123456789$$ \\left( \\begin&#123;matrix&#125; 1 &amp; 2 &amp; 3 \\\\\\\\ 4 &amp; 5 &amp; 6 \\\\\\\\ 7 &amp; 8 &amp; 9 \\end&#123;matrix&#125; \\right) $$ $$ \\left( \\begin{matrix} 1 &amp; 2 &amp; 3 \\\\ 4 &amp; 5 &amp; 6 \\\\ 7 &amp; 8 &amp; 9 \\end{matrix} \\right)$$ 与点结合可以产生各种带省略号的矩阵,例如 12345678910$$\\left[\\begin&#123;matrix&#125; 1 &amp; 2 &amp; \\cdots &amp; 4 \\\\\\\\ 7 &amp; 6 &amp; \\cdots &amp; 5 \\\\\\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\\\\\ 8 &amp; 9 &amp; \\cdots &amp; 0 \\\\\\\\\\end&#123;matrix&#125;\\right]$$ $$\\left[\\begin{matrix} 1 &amp; 2 &amp; \\cdots &amp; 4 \\\\ 7 &amp; 6 &amp; \\cdots &amp; 5 \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ 8 &amp; 9 &amp; \\cdots &amp; 0 \\\\\\end{matrix}\\right]$$ 当然,矩阵中的元素可以是其他的公式, 虽然写起来比较麻烦,但最终还是可以得到类似如下的矩阵公式 123456789101112131415$$\\left( \\begin&#123;matrix&#125;4 \\\\\\\\3 \\end&#123;matrix&#125; \\right)=\\left( \\begin&#123;matrix&#125;1 &amp; 2 \\\\\\\\2 &amp; -1 \\end&#123;matrix&#125; \\right)\\left( \\begin&#123;matrix&#125;x \\\\\\\\y\\end&#123;matrix&#125; \\right)$$ $$\\left(\\begin{matrix}4 \\\\3\\end{matrix}\\right)=\\left(\\begin{matrix}1 &amp; 2 \\\\2 &amp; -1\\end{matrix}\\right)\\left(\\begin{matrix}x \\\\y\\end{matrix}\\right)$$ 等号对齐使用\\begin&#123;align&#125;和\\end&#123;align&#125;来标记需要等号对齐, 并且在公式中, 使用&amp;=在表示要对其的等号, 使用\\\\来换行, 例如 123456789$$\\begin&#123;align&#125; Vdiag(\\lambda)V^&#123;-1&#125; &amp;= diag(\\lambda)VV^&#123;-1&#125; \\\\\\\\ &amp;= [\\lambda\\_&#123;1&#125;v^&#123;(1)&#125;,\\lambda\\_&#123;2&#125;v^&#123;(2)&#125;,\\cdots,\\lambda\\_&#123;n&#125;v^&#123;(n)&#125;]V^&#123;-1&#125; \\\\\\\\ &amp;= [Av^&#123;(1)&#125;,Av^&#123;(2)&#125;,\\cdots,Av^&#123;(n)&#125;]V^&#123;-1&#125; \\\\\\\\ &amp;= AVV^&#123;-1&#125; \\\\\\\\ &amp;= A\\end&#123;align&#125;$$ 渲染效果为: $$\\begin{align} Vdiag(\\lambda)V^{-1} &amp;= diag(\\lambda)VV^{-1} \\\\ &amp;= [\\lambda_{1}v^{(1)},\\lambda_{2}v^{(2)},\\cdots,\\lambda_{n}v^{(n)}]V^{-1} \\\\ &amp;= [Av^{(1)},Av^{(2)},\\cdots,Av^{(n)}]V^{-1} \\\\ &amp;= AVV^{-1} \\\\ &amp;= A\\end{align}$$ 字体转化 字体 示例 效果 罗马体 \\\\( \\rm&#123;A&#125; \\\\) \\( \\rm{A} \\) 意大利体 \\\\( \\it&#123;A&#125; \\\\) \\( \\it{A} \\) 黑体 \\\\( \\bf&#123;A&#125; \\\\) \\( \\bf{A} \\) 花体 \\\\( \\cal&#123;A&#125; \\\\) \\( \\cal{A} \\) 等线体 \\\\( \\sf&#123;A&#125; \\\\) \\( \\sf{A} \\) 数学斜体 \\\\( \\mit&#123;A&#125; \\\\) \\( \\mit{A} \\) 打字机字体 \\\\( \\tt&#123;A&#125; \\\\) \\( \\tt{A} \\) 一般情况下, 公式默认使用意大利体. 其他符号LaTex也支持输入包括逻辑运算符,集合运算符等其他的符号, 由于这些符号的使用场景不多, 因此就不再逐一展示了,具体的名称可以阅读下面的参考文献: MathJax使用LaTeX语法编写数学公式教程 辅助输入工具在codecogs的网站上提供了一个LaTeX的公式编辑器, 通过点击相应符号的按钮就可以生成LaTeX代码, 并且提供实时预览. 针对矩阵语法比较复杂的问题, 我编写了一个小程序来完成矩阵代码的生产, 可以查看我的博客文章如何优雅的输入矩阵公式获得程序源代码和使用说明. 特殊符号转义问题在LaTex中可能要使用 _ 等符号, 而这些符号在Markdown中也是特殊符号, 并且Markdwon会先于LaTex的解析过程, 因此公式中使用了这些符号就导致公式的解析错误. 对于这一问题, 目前基本上是无解的, 综合考虑之后, 我编写了一个小程序来完成转义字符的处理, 输入原始的LaTeX代码之后, 由小程序完成转义字符的处理工作. 代码已经开源在Github上. 因为我只在Markdown上使用LaTeX输入数学公式, 而所有的Markdown渲染器都存在这一问题, 因此修改LaTeX代码应该是一种代价最小的方案. 此外, 还有一些针对Markdown渲染器进行修改的方法, 具体内容如下所示: 关于 Markdown 与 Mathjax 的冲突问题及几个解决方案 MathJax 与 Markdown 的究极融合 参考文献和补充 Markdown中插入数学公式的方法 LaTeX 各种命令，符号 MathJax使用LaTeX语法编写数学公式教程 使用LaTeX写矩阵 在线LaTeX公式编辑器","categories":[{"name":"LaTeX","slug":"LaTeX","permalink":"https://lizec.top/categories/LaTeX/"}],"tags":[{"name":"LaTeX","slug":"LaTeX","permalink":"https://lizec.top/tags/LaTeX/"}]},{"title":"英语语法笔记","slug":"英语语法笔记","date":"2018-03-22T09:00:40.000Z","updated":"2019-07-09T07:18:35.225Z","comments":true,"path":"2018/03/22/英语语法笔记/","link":"","permalink":"https://lizec.top/2018/03/22/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95%E7%AC%94%E8%AE%B0/","excerpt":"","text":"本来英语的各种常见语法在高中就已经学习的差不多了,然而大学阶段由于使用机会减少以及原来的笔记本找不到了, 所以只能再学一次了. 本文记载了我还能记得名字的语法规则,包括基础的各种时态,语态介绍,各种从句规则,非谓语动词以及伴随状语,虚拟语气,强调句等, 至于我连名字都不记得的语法规则, 大概以后也用不上了. 目录 基础知识 主语从句 宾语从句 定语从句 状语从句 非谓语动词 比较级 基础知识时态介绍英语一共有16种时态,其中可以分成两组,每组有4个元素,每组任意取一个元素可以组成一个时态. 所有的组合如下表所示 时态 一般时 进行时 完成时 完成进行时 现在 do is doing hava done hava been doing 过去 did was doing had done had been doing 将来 shall do will be doing will have done will hava been doing 过去将来 shuold do should be doing should have done would have been doing 及物动词与不及物动词在英语中按动词后可否直接跟宾语, 可以把动词分成两种: 及物动词(transitive verb,vt)与不及物动词(intransitive verb,vi). 及物动词可以直接跟上宾语,不及物动词必须加上介词后才能跟上宾语. 附带地,由于不及物动词不接宾语,因此这些词也不能用于被动语态 由于词汇本身是否为及物动词并没有规律, 因此在学习词汇的时候注意看字典上的标注. vi表示不及物动词,其中的i是否定前缀. 被动语态通常情况下,被动语态只需要将原来的动词do替换成be done. be的时态变成原来do的时态. 例如 时态 主动 被动 一般现在时 do is done 一般过去时 did was done 现在完成时 hava done hava been done 其他的时态下的主动和被动转化可以查阅上面的时态表 人称主格宾格所有格 主格 宾格 所有格 形容性物主代词 名词性物主代词 I me my mine myself you you your yours yourself he him his his himself she her her hers herself it it its its itself we us our ours ourselves you you your yours yourselves they them their theirs themselves 第三人称单数与名词复数变化规则最近复习的时候才发现原来这两种情况是不一样的. 不过规则基本一样,具体如下表所示 动词变化规则 例词 一般情况下+s stop-stops 以s, x, ch, sh结尾+es teach-teaches 以o结尾的动词+es go-goes 以辅音字母 + y结尾的, 改y为i加es study-studies 名词变化规则与动词基本相同,仅仅对于以o结尾的词有所区别,且对于f和fe结尾的词有特殊的处理. 名词变化规则 例词 一般情况词尾加s mouth-mouths 以s、 x、 ch、 sh结尾+es class-classes 以 o 结尾的词,有生命的加es，无生命的加s hero-heroes photo-photos 以辅音字母+y结尾的，改y为i加es city-cities monkey-monkeys 以f, fe结尾的改f或fe为v加es leaf-leaves knife-knives 注意: 除了元音就是辅音,所以对于需要改y为i,再加es的词实际上是容易判断的. 单复数变化也存在不规则的情况,不过这些词汇大部分我们已经非常熟悉, 例如 Chinese-Chinese sheep- sheep deer- deer fish-fish foot-feet tooth- teeth man- men woman- women mouse- mice 动词过去式过去分词规则 变化规则 例词 一般情况词尾加ed work-worked 以不发音的-e结尾动词,动词词尾加d move-moved 以辅音字母+y结尾的动词,把y改成i,加ed copy-copid study-studied 重读闭音节动词,双写词尾辅音字母,再加ed stop-stopped 当然,实际情况中,不规则的动词使用的更多, 完整的不规则动词表可见百度百科 不规则动词表词条. 由于重读闭音节的判定规则比较复杂,因此不在深入讨论. 可以将此规则中的词汇连同不规则动词表一同记忆 副词位置规则 多数副词都可以放在动词的后面,如果动词带有宾语,副词就放在宾语后面12I get up early in the morning everyday. We can go to this school freely. 副词修饰形容词,副词时,副词在前面,而被修饰的词在后面12It&#x27;s rather easy, I can do it. He did it quite well. 频度副词可放在实义动词的前面,情态动词和助动词的后面12I often help him these days. You mustn&#x27;t always help me. 疑问副词,连接副词,关系副词以及修饰整个句子的副词,通常放在句子或从句的前面12When do you study everyday?Slowly it evolved into the most grand lantern festival among the Chinese people. 时间副词和地点副词在一个句中, 地点副词在前面,时间副词在后面12We went shopping in the supermarket at 9 o&#x27;clock yesterday. What were you doing in the classroom yesterday afternoon? 否定副词在句首，句子要倒装1Never have I felt so excited! 主语从句连接词主语从句，即在复杂句中充当主语成分的句子. 常见的连接词有以下三类 从属连词：that whether 连接代词：who whoever whom whose what whatever which whichever 连接副词：when where how why 从属连词用来引导从句以形成句子的一部分或修饰句子的构成要素. 所谓从属是和并列连词对应,从属连词表示引导的句子与主句是从属关系. 使用that时通常无意义,使用whether时通常表示是否的含义. 例如 12That he finished writing the composition in such a short time surprised us all.Whether we will go for an outing tomorrow remains unknown. 连接代词依据在从句中充当的不同部分使用不同的代词,例如代替人且做主语时使用who, 代替人且做宾语时使用whom, 代替物的时使用waht. 例如 1234Who will be our monitor hasn&#x27;t been decided yet.Whom we must study for is a question of great importance.What caused the accident remains unknown.What we need is time. 连接副词也引导一个从句,而且通常保留引导词本身的疑问含义,例如 1Where the English evening will be held has not yet been announced 时态规则 主句为一般时,从句时态不受限制 主句过去时,从句使用相应的过去时态 客观真理始终使用一般时,不受任何规则约束 注意: 上述规则对其他类型的从句也是有效的. 此外主语从句通常视为第三人称单数,但在主谓一致规则下存在例外情况. 具体规则可以参考主谓一致章节 形式主句有时为了避免主语太长,使用it替代主语,将主语放在句子的末尾. 例如 12It is certain that he will win the match.It is strange that he should do that. 从句子结构来说,仅仅是将从句移动到尾部而已,有关的连词使用规则完全不变. 定语从句一个简单句跟在一名词或代词后（先行词）进行修饰限定, 就叫做定语从句. 被修饰的词称为先行词. 连接词 关系代词 who whom whose that which 关系副词 when where why 关系代词所代替的先行词是人或者物的名词或者代词, 并且在从句中充当主语,宾语或者定语. 关系代词代替人关系代词中 who whom that 可以用来代替人,例如 12Is he the man who/that wants to see you?He is the man whom/ that I saw yesterday. 关系代词代替物关系代词中 which that 可以用来代替物,例如 1The package which / that you are carrying is about to come unwrapped 关系代词做定语关系代词中whose用来代替人或者物,且从句只做定语. 当whose指物时,可以与 of which 替换,例如 12They rushed over to help the man whose car had broken down. Please pass me the book whose (of which) cover is green. 关系副词关系副词 when, where, why 的含义相当于 “介词+ which” 结构，因此常常和 “介词+ which” 结构交替使用, 例如 123There are occasions when (on which) one must yield.Beijing is the place where (in which) I was born. Is this the reason why (for which) he refused our offer? 关系代词与关系副词的区别判断先行词在从句中的成分,如果是主语,定语或者时宾语时,使用关系代词,如果是状语,则使用关系副词.如果无法判断是否为状语, 则可以判断从句是否缺少主语或者宾语或者定语,如果缺乏,则说明从句中先行词充当了缺少的成分, 应该使用关系代词,否则根据排除法,说明从句从当状语, 此时使用关系副词. 123Beijing is the place where (in which) I was born. This is the mountain village (which) I visited last year.I&#x27;ll never forget the days (which) I spent in the countryside. 第一句中,单独看从句I was born. 这是一个完整的句子, 先行词不充当主语,定语或者宾语的成分, 因此使用关系副词. 第二句中 I visited last year. 缺少宾语的, 先行词充当从句的宾语成分, 因此使用关系代词. 综合来看,判断的关键就是一个动词是及物动词还是非及物动词. 而这一点就只能靠平时学习词汇的积累了. 只能使用that的情况从上述分析可以知道,所有情况下,几乎都是可以使用that, 并且以下六种情况只能使用that. 不定代词 anything, nothing, everything,all,much,few,any,little为先行词时 先行词为 the only, the very, the just时 先行词为序数词, 数词, 形容词或最高级时 先行词既有人又有物时 当主句是以who或which开始的特殊疑问句时,为避免重复而用that 关系代词作表语时 1He is not the man that he used to be. 因此在多数情况下,对于定语从句都可以直接使用that. 但是以下三种情况不能使用that 介词前置 非限定性定语从句 先行词本身是that 此外,在代指人的时候,多用who系列的词汇,而不使用that. 非限定定语从句限定性定语从句对被修饰的先行词有限定制约作用, 使该词的含义更具体, 更明确. 限制性定语从句不能被省略, 否则句意就不完整. 非限定性定语从句起补充说明作用, 缺少也不会影响全句的理解. 在非限制性定语从句的前面往往有逗号隔开. 12The house,which I bought has a lovely garden.This novel, which I have read three times, is very touching. 单复数规则 关系代词在定语从句中作主语时, 从句谓语动词的人称和数要和先行词保持一致 非限定性定语从句将整个主句作为先行词,其进行修饰时,从句谓语动词要用第三人称单数 非限定性定语从句在从句中不能做主语(此时应该使用限定性定语从句) 状语从句英语中的状语用于说明地点, 时间, 原因, 目的, 结果, 条件, 方向, 程度, 方式和伴随状况等. 一般状语可以由副词, 介词短语, 非谓语动词和从句构成. 在本节中介绍介词短语作状语和状语从句, 在非谓语动词章节介绍非谓语动词作状语. 九种状语从句英语种的状语从句可以分为九种, 以下依次介绍这九种状语从句和相关的引导词. 由于状语的结构比较随意, 因此熟悉这些引导词有利于英语中长句的拆分和理解. 1. 表事件 常用引导词: when（在…时）, as（当…时）, while（在…期间） as soon as（一……就……）, before（在…之前）, after（在…之后） since（自从…以来） , not…until（直到…才）until/till(直到…时 特殊引导词： the minute, the moment, the second, every time, the day，the instant（ 瞬间，顷刻） immediately , directly（不久，立即）, no sooner … than（一…就…）, hardly …when（刚一…就…）, scarcely … when（刚…就…/一…就…） 当用no sooner … than，hardly …when，scarcely … when作为引导词的时候，从句要部分倒装 12345When you&#x27;re ready to start unloading some of your stuff, that list will be a good place to start.I chose the house for my home as soon as I saw it.All thing are difficult before they are easy.Every time I listen to your advice, I get into trouble.No sooner had I arrived home than it began to rain. 2. 表地点 常用引导词：where 特殊引导词：wherever, anywhere, everywhere 123Generally, air will be heavily polluted where there are factories.Cross the stream where it is shallowest(谚语, 渡溪当自浅处过)Wherever you go, you should work hard. 3. 表原因 常用引导词：because, since, as, 特殊引导词：seeing that, now that, in that, considering that, given that. 12My friends dislike me because I’m handsome and successful.The higher income tax is harmful in that it may discourage people from trying to earn more. 4. 表结果 常用引导词：so … that, such … that, 特殊引导词：such that, to the degree that, to the extent that, to such a degree that 12The wind was so strong that she could hardly move forward.It’s such a good chance that we must not miss it. 5. 表目的 常用引导词：so that, in order that 特殊引导词：lest, in case, for fear that，in the hope that, for the purpose that, to the end that 12The boss asked the secretary to hurry up with the letters so that he could sign them.I am telling you that lest you should make a mistake(我告诉你这一点, 以免你搞错) 注意: 由for引导的是一个并列句，不是原因状语从句，但有表原因的意思，是并列连词 6. 表条件 常用引导词：if, unless,whether(whether…or not) 特殊引导词：as/so long as, only if, providing/provided that, supposing that, in case（美语中表条件，英语中表目的）, on condition that 123If I were you, I&#x27;d go to night school. (表虚拟)You will fail to arrive there in time unless you start earlier.You will certainly succeed so long as you keep on trying. 7. 表方式 常用引导词：as, as if, how 特殊引导词：the way 123When in Rome, do as the Romans do.She behaved as if she were the boss. (表虚拟)Sometimes we teach our children the way our parents have taught us. 8. 表比较 常用引导词： as … as (同级比较) more … than(比较级) the (most) … (最高级) 特殊引导词： the more … the more … ; just as …， so… A is to B what/as X is to Y no … more than; not so much A as B 123456She is as bad-tempered as her mother.This book is much more interesting than that one.This street is the most busiest one in out city.The house is three times as big as ours.The more you exercise, the healthier you will be.Food is to men what oil is to machine. 9. 表让步 常用引导词：though, although, even if, even though 特殊引导词： as(用在让步状语从句中必须要倒装)，while ( 一般用在句首 ) no matter …， in spite of the fact that whatever, whoever, wherever, whenever, however, whichever 123The old man always enjoys swimming even though the weather is rough.No matter how hard he tried, she could not change her mind.He won’t listen whatever you may say. 状语从句时态规则一般情况下, 使用一般现在时表示一般将来时, 使用现在完成时表示将来完成时, 例如 12I will call you as soon as I arrive in Beijing. As soon as I have finished this work, I will have gone home. 非谓语动词非谓语动词, 又叫非限定动词. 非谓语动词是指在句子中不是谓语的动词, 主要包括不定式, 动名词和分词（现在分词和过去分词）. 非谓语动词除了不能独立作谓语外, 可以承担句子的其他成分, 例如定语或者状语. 非谓语动词做定语使用非谓语动词做定语时,需要注意两个方面 非谓语动词和先行词的时间关系 语态时主动还是被动 通常而言, 表示将来使用不定式,表示同时发生(或者一种持续的状态)使用现在分词. 主动使用现在分词, 被动使用过去分词. 各种情况使用的非谓语动词形式如下表所示 时间\\逻辑关系 主动 被动 与谓语同时发生 doing being done 在谓语之前 done 将来 to do to be done 12345Things lost never come again.The houses being built are for teachers.The car to be brougt is for my sister.He is the man to do this job. 非谓语动词做状语和状语从句可以分成九种情况一样, 非谓语动词也大概分成几种不同的情况. 由于语法上状语更加随意, 因此非谓语动词做状语的情况也需要加强记忆. 不定时作状语 表目的 He worked day and night to get the money. 表原因 I am glad to hear that you are mush better now. 表结果 The police searched the whole room only to find nothing. 分词分词做状语的时候, 主动使用现在分词, 被动使用过去分词. 例如 123The dog entered the room, following his master.The master entered the romt, followed by his dog.Hearing the bad news, they couldn&#x27;t help crying. 分词做状语,相当于一个状语从句. 123Hearing the bad news, they couldn&#x27;t help crying. = as soon as/the moment they heard the bad news, they couldn&#x27;t help crying.Being so angry,he couldn&#x27;t go to sleep. = because he was so angry,he couldn&#x27;t go to sleep.He dropped the glass, breaking it into pieces. = He dropped the glass, so it broke into pieces. 参考文献 百度文库 英语的十六种时态 百度百科 被动语态 百度文库 人称主格宾格所有格 百度文库 动词第三人称单数形式与名词复数形式变化规则区别 知乎 请教英语中副词的位置 作者:颜全伟 英语语法大全 副词在句中的位置,介绍副词修饰动词时在英语句子中不同的位置 百度百科 主语从句 百度百科 宾语从句 百度百科 定语从句 百度百科 状语 百度百科 状语从句 百度百科 非谓语动词 百度文库 高考语法复习之非谓语动词做定语及与定语从句的转换 百度文库 高考英语知识点非谓语动词做状语 简单学习网 非谓语动词做状语 百度百科 主谓一致","categories":[],"tags":[]},{"title":"微型计算机接口笔记","slug":"微型计算机接口笔记","date":"2018-03-09T12:31:52.000Z","updated":"2018-06-21T02:11:48.214Z","comments":true,"path":"2018/03/09/微型计算机接口笔记/","link":"","permalink":"https://lizec.top/2018/03/09/%E5%BE%AE%E5%9E%8B%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%8E%A5%E5%8F%A3%E7%AC%94%E8%AE%B0/","excerpt":"","text":"本文记录在学习&lt;&lt;微型计算机接口技术及应用&gt;&gt;课程过程中的笔记. 由于硬件课程与编程课程相比,往往比较缺乏实践机会,因此需要多做一点笔记. 在微机系统中,微处理器的强大功能必须通过外部设备才能实现,而外设与微处理器之间的信息交换及通信又是靠接口实现的, 所以, 微机应用系统的研究和微机系统的产品的开发,从硬件角度来讲,就是接口技术的演技和开发. 微机的应用随着外设的不断更新早已深入各个领域. 目录 概述 I/O地址译码技术 定时计数技术 并行接口 中断技术 模数数模转换接口 串行接口 DMA控制器 概述 ---------- 接口设备接口(Interface)是指I/O设备与本地总线之间的 连接电路 . 是CPU与外设进行信息交换的中转站. 是CPU与外设之间信息交换的桥梁, 接口与CPU之间通过系统总线连接起来. 为什么要设立接口 微机的总线与I/O设备不兼容,在逻辑定义,时序等方面都不一致 CPU与I/O设备速度不匹配,CPU速度快,而I/O设备速度慢 如果让全部I/O设备交由CPU处理,会占用过多的CPU时间 如果让I/O设备交由CPU处理,则会导致I/O设备依赖CPU结构,不利于I/O设备发展 接口的三个重要部分 命令口 状态口 数据口 其中状态口是一个输入端口(对于CPU而言),通过数据总线与CPU交换信息. 接口的功能 执行CPU指令 返回外设状态 数据缓存/锁定 信号转换 设备选择 数据宽度与数据格式的转换 接口电路的一般结构 从硬件角度看有三个主要的模块 基本逻辑电路(三大寄存器) 端口地址译码电路(设备选择) 供选电路(功能选择) 从软件角度看,由于各个被控对象存在差异,因此没有统一的模式,但一个完整的设备接口程序大约包括如下一些程序 初始化程序段落 传送方式处理程序段落 主控程序段 程序终止与此退出程序段 辅助程序段 CPU与接口交换数据方式 程序控制方式 无条件传送方式（又称同步传送方式） 由控制程序直接向端口写入数据 优点: 所需的硬件和软件都很少, 且硬件接口电路简单 缺点: 这种传送方式必须在已知且确信外设已准备就绪的情况下才能使用, 否则出错 条件传送方式（查询传送方式） CPU在执行一个输入/输出操作前, 必须对外设的状态进行测试, 当外设准备好才能传送, 否则CPU等待并查询外设的状态, 直至外设准备好 优点: 传送数据前, CPU先检测接口的状态, 保证数据传送的正确率高 缺点: CPU的效率很低, 且CPU与外设不能并行工作 中断方式 外设作好传送准备后, 主动向CPU请求中断, CPU响应这一请求, 暂停正在运行的程序, 转入用来进行数据传送的中断服务子程序, 在完成中断服务了程序后, 自动返回原来运行的程序 优点: 提高了CPU的利用效率 缺点: 需要保存大量环境参数 直接存储器存取(DMA)方式 在DMA控制器的控制下, 完成由外设与存储器之间的数据传送 CPU不干预传送过程, 整个传送过程由硬件来完成而不需要软件介入 优点: 具有非常高的传送速率 缺点: 硬件电路复杂 I/O地址译码技术 ------------------ I/O端口端口(port): I/O接口电路中能够被 CPU直接访问 的寄存器. CPU可以通过这些端口发送命令,读取状态和传送数据.端口地址 = 芯片地址(高位地址) + 片内地址 端口地址编制方式 统一编址(存储器映射方式) 从存储空间中划出一部分空间分配给I/O设备,把I/O接口中的端口视为存储器的一部分一样进行访问. 优点: 不需要额外的I/O指令,各种内存指令可以直接使用,简化指令系统 缺点: 降低存储器容量,指令执行效率不如专门的I/O指令 独立编制 内存地址空间和I/O地址空间相互独立,使用专门的I/O指令 优点: 不占据存储空间,执行速度快,程序可读性好 缺点: 指令功能弱,仅仅能进行数据传输,不能进行逻辑运算 PC系列微机端口分配 拥有1024个端口 地址空间为000 ~ 3FFH 有效的译码地址为 A0 ~ A9,这10跟地址线 在有效范围内,使用 单字节端口地址 的是 芯片 中的端口,使用 双字节端口地址 的是 接口卡 中的端口 端口指令 格式 IN AL, 60H / IN AL, DX / OUT DX, AL / OUT 61H, AL 对于端口号在0-255之间的端口, 可以直接访问 对于端口号在236-65535之间的端口, 端口地址需要放在dx寄存器中 访问8bit端口时, 数据只能存入AL, 访问16bit端口时, 只能使用AX 更多关于端口的汇编指令可以阅读&lt;&lt;汇编语言笔记&gt;&gt;的端口和外中断章节 串I/O指令 串指令有INSB,INSW和INSD 即分别从8bit,16bit,32bit的端口取出相应大小的数据到存储器 dx指定I/O端口,DI指定存储器偏移地址(默认段寄存器为ES),CX指定传输字节数 以下代码演示使用串指令将数据从301端口取出15个字节到从ES:1001H开始的内存位置12345MOV DX, 301HMOV DI, 1001HMOV CX, 0FHCLDREP INSB C语言中端口读写 使用 unsigned char inportb(int addr) 读取数据 使用 void outportb(int addr,unsigned char data) 写入数据 这些函数本质是调用IN和OUT指令 I/O译码电路 高位地址信号与控制信号组合,通过译码电路产生片选信号 地位地址不参加译码,直接连接到I/O芯片 参与译码的控制信号有AEN, \\( \\overline{IOR} \\), \\( \\overline{IOW} \\) AEN为1时表示DMA方式, 为0时表示CPU控制方式 芯片控制电路规则 是否可读写 如果可读可写,则两个读写控制信号都不参加译码 片内地址 片内地址决定每个接口的端口数目,例如需要32个端口,则片内地址有5位 片间寻址 根据地址范围确定不参加译码的高位数量,再减去低位的片内地址即可 定时计数技术可编程的计数器/定时电路 其计数与计时功能由程序决定,且不占用CPU时间,常见的芯片有8254 采用减一计数方式,更便于终止条件判定(判定条件始终为检查是否为零) 可编程的计数器/定时电路工作原理 通过控制命令,将初值写入初值寄存器 从初值开始,在GATE信号的控制下,每出现一次CLK信号,计数值减一 计数达到零,从OUT端输出信号 注意:GATE无效时,即使出现CLK信号,也不会减一 82C54主要特点 具有三个独立的16bit计数器(#0~#2通道) 每个通道有6种工作模式 可以按照二进制或十进制计数 如果初值设为0,则可以实现从可显示最大值+1的计数范围 指令字格式 指令长度为1字节 第一个字段2bit,表示计数器,0010分别表示计数器03,11无效 第二个字段2bit,表示读写方式 00表示锁存 01 表示只读写低字节 10 表示只读写高字节 11 表示先读写低字节,在读写高字节 第三个字段3bit,表示工作方式,二进制000101表示工作方式05 最后一个字段1bit,表示数制,0表示二进制,1表示十进制(BCD) 例如00110001b表示0号计数器先读写低字节,在读写高字节,在方式0以十进制方式工作 指令中的选择信号和片内寻址在82C54的指令字中也提供了选择哪一个计数器的方法,同时在芯片中也有用于寻址的A0和A1. 实际上由于指令都是发送到控制芯片的, 因此在控制字中才需要指定哪一个芯片,而取出数据的时候,就可以根据A0和A1直接获得数据. 即在发出命令的时候A0和A1始终等于11b,而读取和写入数据的时候,A0和A1取值为00b~`10b` 12345678# 端口地址为60H~63H, 选择1#, 工作方式2, 计数初值为5533H, BCD码制其初始化程序段为: MOV AL,01110101B ;写入控制命令字OUT 63H,ALMOV AL,33H ;写入计数初值低字节OUT 61H,AL MOV AL,55H ;写入计数初值高字节OUT 61H,AL 计数方式方式0(计数结束中断方式) 写入工作方式后OUT会设置为低电平 写入初值后就立即启动一次新的计数 从设置初值的下一个时钟下降沿 开始 计数,即初始值也会维持一个周期 达到计数以后,OUT从低电平跳变到高电平,可用于中断控制 GATE为低电平时计数暂停 方式1(可重复编程单脉冲) 写入工作方式后OUT设为高电平 写入初值后,GATE产生一次由低到高的跳变(正跳变)后开始计数 从跳变后的下一个时钟下降沿开始计数 开始计数时OUT变为低电平,计数结束后OUT变为高电平 由于OUT开始工作和结束工作后都是高电平,而计数时为低电平,因此可以视为输出了一个长度为n的负脉冲 GATE信号可以重复触发,触发后从初值开始计数 在计数过程中写入新的初值,在GATE信号再次触发后才生效 方式2(周期性负脉冲输出,分频器) 写入工作方式后OUT设为高电压 写入计数方式后,下一个时钟下降沿开始计数 计数到1变为低电平,计数到0时恢复高电平,即产生一个时钟周期的负脉冲 计数到0时,也等于变为设置初值,开始下一轮计数, 从而每个设定事件周期内产生一次负脉冲 写入计数初值后,GATE信号为高电平时,为软起动,立即开始计数. GATE信号为低电平时,为硬启动,GATE正跳变后开始计数 计数过程中写入初值,则从下一轮开始以新的初值计数 方式3(方波发生器) 方式3与方式2基本一致 一个计数周期中,高低电平之间基本一致 可以视为频率降低的的方波信号 当计数周期为奇数时,前(N+1)/2周期为高电平, 后(N-1)/2个计数周期为低电平 各种方式的区别 各模式波形对比 计数初始值计算方法已知 \\( f_{CLK} \\) 和 \\( f_{OUT} \\) ,则计数初值 \\( n = \\frac{f_{CLK}}{f_{OUT}} \\)已知 \\( T_{CLK} \\) , 定时时间为t, 则 \\( n = \\frac{t}{T_{CLK}} \\) 并行接口并行接口特点 通过多根信号线同时传送多位数据 传送时一般不需要特定的数据传送格式 并行接口多用于传送距离短, 数据量大, 速度高的实时传输场合;(例如: 微机与并行接口打印机、磁盘驱动器) 但并行接口布线成本高, 线路间互相干扰, 时钟同步问题, 因此并行传输技术发展受限 8255概述 有三个输入输出端口: 端口A, 端口B, 端口C 每个端口可编程设定为输入端口或输出端口, 并且有不同的工作模式 端口C可以作为独立的端口使用,但常常是配合A和B,为这两个端口提供联络信号 8255A结构图如下所示: 8255A工作方式 8255A有3种工作方式: 方式0, 方式1和方式2 A端口: 3种方式中的任一种; B端口: 方式0和方式1; C瑞口: 通常作为控制信号使用, 配合A端口和B端口的工作 指令字格式指令字格式 端口C控制字格式 8255A工作方式方式0 无条件传送 2个8bit端口和2个4bit端口,都可以进行输入输出 输出可以被锁存,输入无法锁存 常用于连接简单外设,适用无条件传送和查询方式 单向I/O, 一次初始化只能指定端口为输入或者输出 系统没有指定C口的格式, 用户可以自定义 端口信号线之间无固定的时序关系, 由用户根据数据传送的要求决定输入输出的操作过程, 不需要任何选通信号 以下代码演示从A端口读入数据并输出到B端口过程 123456789MOV DX,203H ;初始化MOV AL,98HOUT DX,ALMOV DX,200H ;inIN AL,DXMOV DX,201H ;outOUT DX,AL 方式1 应答发式传送（查询、中断） 分成A,B两组,每组包括一个8位的数据端口和1个4位的控制／数据端口 8位的数据端口既可以作为输入也可以作输出 4位的控制／数据端口用于传送8位数据端口的控制和状态信息 输入和输出都可以被锁存 PC3～PC5分配给A口, PC0～PC2给B口, PC6，PC7可作为简单的输入／输出线使用 方式1时, 按照以下的步骤进行数据输入 输入过程用到的结构如图所示 其中各信号含义如下: \\( \\overline{STB} \\) : 选通信号, 表示外设已经准备好数据 IBF : 输入缓冲器满信号, 表示A口已经接收数据 INTQ: 中断请求信号, 通过此信号向CPU发出中断请求 INTE: 中断允许信号, 该信号是内部信号, 通过C口按位置位字进行设置 C端口状态字定义如下所示: 在代码中, 首先需要向INTE(Interrupt Enable)写入1表示允许中断, 写入方式参考端口C的置为复位指令字格式. 后续通过INTR(Interrupt Request)判断是否产生了中断, 示例代码如下: 123456789101112131415161718192021ccd segmentassume cs:ccd ; 送方式命令字BG: MOV DX,203H MOV AL,0B0H ;10110000B OUT DX,AL MOV AL,9H ;00001001B ; C口 使INTEA=1 OUT DX,AL ; 输入C口数据AG: MOV DX,202H IN AL,DX ; 循环查询，直到INTRA=1 TEST AL,8 JZ AG ; 从A口输入 MOV DX,200H IN AL,DX ... ccd endEND 方式1的输出结构如下所示: 方式1的输出过程与输入过程基本类似,但C端口指令字有所不同. 中断技术中断响应的一般过程中断响应一般执行以下的过程 中断请求 中断识别和判优 中断响应 中断处理 中断返回 其中从中断响应到中断返回涉及的具体过程可以参看汇编笔记 中断处理程序设计章节的相关内容. 在外设方面, 中断请求信号分为可屏蔽中断请求INTR和不可屏蔽中断NMI. 中断识别 在更古老的CPU中, 使用软件查询法来获得中断信息. 在软件查询法中, 通过编写程序轮流查询各种外部设别是否存在中断请求. 现代的CPU使用中断矢量法, 由中断源提供的中断类型号来确定中断源 中断判优原则 优先级法则: 异常 &gt; 软件中断 &gt; 非屏蔽中断 &gt; 外部可屏蔽中断 先来先响应 8259A结构 中断请求寄存器IRR: 反应那些中断请求发生了 中断屏蔽寄存器IMR: 决定那些中断请求被屏蔽 正在响应寄存器ISR: 显示那些中断正在被服务 上述三个寄存器都是按位使用,每一位都对应芯片上的一个引脚. 中断过程 IRQ0~IRQ7有中断请求, 8259A的IRR相应位置1 IRR与IMR相应位进行比较, 封锁或发送中断请求给PR PR分析后, 把当前最高优先级的中断请求信号通过INT发送给CPU 若IF=1, CPU执行完当前指令后,连续发出两个 \\( \\overline{INTA} \\) 信号 收到第一个 \\( \\overline{INTA} \\) 信号后, 8259A的ISR和IRR对应位分别置1清0 收到第二个 \\( \\overline{INTA} \\) 信号后, 8259A把中断类型号送上数据总线 CPU将收到的中断类型号乘以4，到中断向量表中获取中断向量，转入相应中断服务子程序进行中断处理 8259A的工作方式中断触发方式 电平触发方式: IRi端出现高电平作为中断请求 边沿触发方式: IRi端出现上升沿作为中断请求 中断查询方式: 不使用INT信号, 直接由软件查询中断状态 电平触发方式如果保持时间较长, 则可能被CPU触发两次, 但使用边沿触发方式则不存在这一问题. 中断屏蔽方式 普通屏蔽方式: 即设置IMR的相关位 特殊屏蔽方式: 中断服务程序中设置IMR的位,使ISR相应位复位 在特殊屏蔽模式下, 对IMR的某一位置位会导致ISR相应位被重置, 因此这样既屏蔽了本级中断又开放了低级中断 优先级排队方式 普通全嵌套方式: IR0优先级最高, IR7优先级最低 特殊全嵌套方式: 本级中断请求可以中断同一级的中断 循环优先级方式 优先权普通循环方式: IR0最高,IR7最低, IR0相应后变为最低, 其他的都升高一级 优先权特殊循环方式: 用户指定最低级(例如IR5),则后一位是最高级(如IR6),之后按顺序优先级递减 在普通全嵌套模式下, 在从片发出的不同优先级的中断信号, 在主片看来都是相同等级的请求. 因此主片必须使用特殊全嵌套方式, 使得同一级的中断请求能够中断同一级的中断. 中断处理方式 自动结束方式: ISR中的位在相应的时机(第二个INTA信号结束)由硬件自动复位 常规结束命令字: 通过指令使ISR中最高级复位 指定结束命令: 指定某一个ISR位复位 注意: 自动结束方式时, 中断还未完全处理结束, 若此时又发送中断,则会产生错误, 因此此方式仅支持没有中断嵌套, 且使用单片的情况. 常规结束命令只适合全嵌套方式下(固定优先级) 控制命令字一共有4个控制命令字, 分别用ICW1~ICW4表示, 其中ICW1和ICW2是必须设定的, ICW3和ICW4根据情况可选的设置. ICW1写入A0为0的偶数地址,其余命令字写入A0为1的奇数地址. 各控制字主要含义如下: ICW1: 设置触发方式, 是否有级联片,以及是否有ICW4 ICW2: 设置中断高5位的值, 例如设置为08H,则中断号为08H~0FH ICW3: 说明主片的哪一个引脚接了从片, 或从片对应主片的哪一个引脚 ICW4: 设置嵌套方式,缓存方式, 是主片还是从片,中断结束方式和处理器类型 操作命令字一共有3个命令字, 分别使用OCW1~OCW2表示, 在工作期间可以任意时刻以任意顺序写入操作命令字. OCW1: 屏蔽命令字, 相应的设置IMR OCW2: 设置优先级方式和初始最低优先级等 OCW3: 中断屏蔽方式和后续读取的状态字含义 模数数模转换接口模拟接口A/D : Analog to DigitalD/A : Digital to Analog 数模转换器主要技术指标 分辨率: 使用数字量比特位数衡量 精度: 实际输出值与理论值的差距 建立时间 数模转换器DAC0932特点 数字输入端双重缓存, 可使用双缓冲, 单缓冲和直通数字输入 分辨率为8bit 满足TTL电平规范的逻辑输输入 控制逻辑 内部有两个数据缓冲器, 分别由两组控制信号控制 输出量的值由DAC寄存器控制, 输入寄存器可以接收不同的值,从而便于多路复用 ILE,CS与WR1有效时LE1端才有效, 此使该寄存器输出随输入变化 当XFER与WR2有效时,LE2端有效,此时寄存器输出随输入变换 使用Iout1进行输出, 且Iout1与Iout2之和为一个定值(可用于校验) DAC0932工作方式双缓冲方式输入数据先存放在输入寄存器中，而输出的模拟值由存放在DAC寄存器内的数据决定. 当把数据由输入寄存器转存到DAC寄存器以后,输入寄存器就可以接受新数据而不影响模拟输出值. 可以在转换的时候采集下一个数据, 可实现多通道同步转换输出 单缓冲方式DAC寄存器始终处于有效状态,只需要向数据寄存器进行一次写入操作就开始转换,适合不需要多片D/A同时输出的场景 12MOV DX，200H ；设DAC0832的地址为200HOUT DX，AL ；AL内数据送DAC转换 直通方式输入数据寄存器和DAC寄存器始终有效, 输出随输出的变化随时转换 ADC0809工作方式 IN0IN7: 8路模拟量输入(互不相关,任意时刻接入其中的一个)ADDAADDC: 3-8选择器输入,决定选中的模拟量输入ALE:地址锁存允许, 正跳变时锁定地址选择器输入START信号: 启动信号, 上升沿使片内所有的寄存器清零,下降沿启动A/D转换EOC: 转换结束, 转换开始时输出低电平,转换结束后输出高电平OE: 输出允许,高电平时,锁存缓冲器打开,数据被发送给CPU 输出方法 延时等待法: 软件延时足够长的时间, 不使用EOC信号,效率低 中断法: 把EOC信号作为中断请求信号,在中断服务程序中读入转换结果 查询法: 软件查询EOC信号状态 应用举例12345MOV AL, 03H ；送输入通道号3OUT 84H, AL ；同时发出启动信号STARTCALL DELAY150 ；等待转换结束，延时150μSIN AL, 84H ；转换结束，读入数据HLT 串行接口调制解调器(MODEM) 调制器(Modulator): 把数字信号转化为模拟信号发送到通信链路上 解调器(Demodulator): 把通信链路上收到的模拟信号转化为数字信号 MODEM是数据通信设备(DCE), 计算机等是数据终端设备(DTC) 串行通信的数据传输方向可以分为单工, 半双工和全双工 串行数据传输速率收发时钟频率 = 波特率因子 X 波特率 异步通信与同步通信 异步通信: 以字符为单位发送数据, 各字符之间随机出现(异步),适合数据量小,数据不连续发送的场景 同步通信:以数据块为单位发送数据, 各字符之间同步,字符内也同步, 适合数据量大,批量传输数据的场景 外同步与自同步 外同步: 发送端发送数据前先发送同步时钟信号, 接收端用这一同步信号锁定自己的时钟频率 自同步: 发送的数据中包含同步信息(例如曼切斯特码) 8251结构 8251可以分为5个部分 (1) 面向CPU的信号线大部分信号线和其他芯片的含义一样C/D 信号线, 为1时访问命令或状态寄存器,为0时访问数据寄存器 （2）状态信号（供CPU查询或向CPU申请中断）TxRDY(Transmitter Ready）：发送器准备好，高电平有效。通知CPU可以向8251A发送数据。RxRDY（Receiver Ready）：接收器准备好，高电平有效。通知CPU读取数据。TxE(Tmnsmitter Empty）：发送器空，高电平有效。指示发送器中的数据已发送出去，已经变空。SYNDET（Synchronous Detection)/BD(Break Detection）：双功能引脚。这个引脚在同步方式时，作同步字符检出信号，为双向线。 （3）时钟信号（包括发送器时钟、接收器时钟以及内部的工作时钟信号CLK) TXC*（Transmitter Clock）：发送器时钟，由外部（波特率时钟发生器）提供。由它控制8251A发送数据的速率。在异步方式下TXC*的频率可以等于波特率，也可以是波特率的16倍或64倍。在同步方式下TXC*的频率与数据速率相同。 RXC*（Receiver Clock）：接收器时钟，由外部（波特率时钟发生器）提供。其频率的选择和TXC*相同。实际应用中，把RXC*和TXC*连接在一起，使用同一个时钟源—波特率时钟发生器。 (4)面向调制器的接口信号 8251A提供了4个与MODEM相连的控制信号和数据发送以及数据接收信号线。DTR*：数据终端准备好，是输出信号，低电平有效。它由工作命令字的D1置“1”变为有效，用以表示8251A准备就绪。DSR*：数据装置准备好，是输入信号，低电平有效。用以表示调制器已准备好。CPU通过读状态寄存器的D7位检侧这个信号。RTS*：请求发送，是输出信号，低电平有效。用于通知MODEM,8251A要求发送。它由工作命令字的D5置“1”来使其有效。CTS*：清除传送（即允许传送），是输入信号，低电平有效。是MODEM对8251A的信号的响应，当其有效时8251A方可发送数据。 DMA控制器DMA的功能（1）能接受CPU的编程，以便进行功能设定（2）能接收I/O接口的DMA请求，并向CPU发出总线请求信号，请求总线控制权（3）CPU响应总线请求之后，DMAC能接管总线的控制，进入DMA传送过程（4）能实现有效的寻址，即能输出地址信息并在数据传送过程中自动修改地址指针（5）能向存储器和I/O接口发出相应的读/写控制信号（6）能控制传送数据的字节数，判定DMA传送是否结束（7）DMA结束时，能发出DMA结束信号，释放总线，恢复CPU对总线的控制 人机接口键盘接口的分类 编码键盘: 这种键盘内部能自动检测被按下的键, 并提供与被按键对应的键码 非编码键盘: 这种键盘只简单地提供键盘的行列矩阵,而按键的识别和键值的确定、输入等工作通过软件完成 线性键盘: 每一个按键均有一条输入线送到计算机的接口 矩阵键盘: 按键按行和列排列 按键扫描方法 （1）扫描法依次查询键盘矩阵的每一行线，然后读取列数据确定按键是否在本行，具体方法如下：首先使PA0=0，然后读取PB端口。若PB=0FFH则表示行0没有按键按下，再使PA1=0再读取PB判断行2有无按键按下，依次扫描全部的行线。当PB读取的数据不为0FFH，则表示该扫描行有按键按下，则再确定相应的按键序号。 （2）行列交换法（行列行反转法）使CPU通过A口向各行线上全部送低电平，然后从B口读入列线的值。如果某按键按下，则必定会使某一列线值为0。然后，交换A口B口的输入输出方向，并将刚才读到的列线值从列线所接的并口输出。再读取行线上的输入值，在闭合键所在的行线上的值必定为0。这样，当一个按键被按下时，必定可以读取一对唯一的行值和列值。","categories":[{"name":"计算机核心课程","slug":"计算机核心课程","permalink":"https://lizec.top/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%A0%B8%E5%BF%83%E8%AF%BE%E7%A8%8B/"}],"tags":[]},{"title":"MATLAB笔记","slug":"MATLAB笔记","date":"2018-03-07T06:01:31.000Z","updated":"2018-07-04T07:08:05.515Z","comments":true,"path":"2018/03/07/MATLAB笔记/","link":"","permalink":"https://lizec.top/2018/03/07/MATLAB%E7%AC%94%E8%AE%B0/","excerpt":"","text":"本文记录MATLAB的基础知识, 包括MATLAB的基础知识介绍, MATLAB的基础运算以及通过MATLAB语言进行编程. 目录 MATLAB基础 MATLAB计算基础 MATLAB运算符 MATLAB矩阵操作 其他数据类型 MATLAB程序设计 Matlab基础主界面窗体启动MATLAB程序后, 程序界面如下所示: 可以分成以下的几个界面 命令窗口: 在此窗口可以直接输入MATLAB指令 工作空间窗口: 此窗口显示了当前状态下保存的各种变量, 可通过工作空间窗口对这些变量进行操作 当前目录窗口: 显示了当前的目录,只有位于当前目录和搜索路径下的文件才能被直接使用 历史命令窗口: 自动保留自安装起所有用过的命令的历史记录, 从而方便用户查询 MATLAB搜索过程在MATLAB的命令窗口中输入一个名称以后, MATLAB按照以下顺序进行检测 是否为变量 是否为内部函数 是否为当前目录下的M文件 是否为其他搜索路径下的文件 目录操作修改启动目录 matlab默认的启动位置位于其安装路径, 通常该位置不适合作为工作目录 通过修改快捷方式中的启动位置, 即可修改matlab启动位置 可在命令窗口中使用cd指令切换当前目录 可以通过path(path,&#39;C:/WorkSpace&#39;)指令将指定目录C:/WorkSpace临时加入搜索路径(添加到末尾) 系统目录和用户目录 系统目录 系统目录指的是matlab本身提供的各种包所在的路径 可以通过输入matlabroot查看 通常是matlab的安装路径,例如C:\\Program Files\\MATLAB\\MATLAB Production Server\\R2015a 用户目录 用户自定义的代码可以存放的路径 可以通过输入userpath查看 通常位于用户的文档文件夹下,例如C:\\Users\\lizec\\Documents\\MATLAB 点击HOME界面上ENVIROMENT区域的Set Path,可以设置搜索路径 位于搜索路径中的文件可以直接被调用 如果同时存在多个同名文件,Matlab采用最先出现的 默认情况下用户目录是第一个路径,所以用户定义的任何同名函数都会覆盖系统提供的函数 帮助系统help命令 无参数,显示当前帮助系统的所有项目,及搜索路径的所有目录名称 +函数名,显示该函数的帮助说明 +目录名,显示某一类函数 lookfor命令 help指令是完全匹配,而lookfor进行关键字匹配 无参数,在M文件的第一行进行搜索 -all参数,搜索全文 模糊查询 输入开头几个字母,使用tab建进行补全 演示系统 在命令行中输入demos 实际上是项目文档合集,包括文档,示例,以及联网资料 资源站 公司主页 matlabsky ilovematlab 清空 使用clear指令清除工作区变量 使用clc清除命令行 MATLAB计算基础变量定义 变量以字母开始,以字母数字下划线构成的,长度不超过63个字符 变量名区分大小写 标准库函数始终由全部小写字母构成 语句 直接输入表达式,命令行会显示运行结果 每条命令后加上分号,则命令执行后不输出结果 注释和节 matlab中注释以%开始,仅支持单行注释 如果需要注释多行,直接选择需要注释的内容后点击界面上的commet按钮 使用%% 开始的注释称为节,可以将一段代码分成若干节,使用界面上的按钮来以节为单位执行代码 预定义变量 表示圆周率的pi 表示虚数的i和j 预定义可以被用户自定义变量覆盖 内存控制 clear 无参数,清除工作空间全部变量 指定变量名,则清除指定的变量 who/whos who显示当前工作空间全部变量名称 whos显示当前工作空间全部变量详细信息 save save filename 将工作空间保存到指定的文件中 -append 追加模式,即将新的变量和修改的变量追加保存到文件中 -ascii 以文本模式保存,不过实在是没啥优势,不建议使用 可以在filename后指定变量名,则只保存指定的变量 load load filename 将指定的文件中保存的变量加入工作空间 MATBLAB常用函数abs函数 获得实数的绝对值 获得复数的模 获得字符串的ASCII码 取整函数 函数名称 含义 示例1 示例2 fix 向零取整 fix(3.5) = 3 fix(-3.5) = -3 floor 不大于指定数据的最大整数 floor(3.5) = 3 floor(-3.5) = -4 ceil 不小于指定数据的最小整数 ceil(3.5) = 4 ceil(-3.5) = -3 round 四舍五入 round(3.5) =4 round(-3.5) = -4 求余数 函数名称 含义 示例1 rem 余数与被除数符号相同 rem(-3,-4) = -3 mod 余数与除数符号相同 mod(7,-4) = -1 格式化输出使用format格式进行输出格式化,format函数用法为format 格式 变量. 其中格式有如下若干选项: 名称 含义 SHORT Scaled fixed point format with 5 digits. LONG Scaled fixed point format with 15 digits for double and 7 digits for single. SHORTE Floating point format with 5 digits. LONGE Floating point format with 15 digits for double and 7 digits for single. SHORTG Best of fixed or floating point format with 5 digits. LONGG Best of fixed or floating point format with 15 digits for double and 7 digits for single. SHORTENG Engineering format that has at least 5 digits and a power that is a multiple of three LONGENG Engineering format that has exactly 16 significant digits and a power that is a multiple of three. MATLAB模式使用SHORT模式, 其他细节可以使用help指令查阅format文档 矩阵输入方式 直接在交互窗口编辑矩阵 使用M文件 即在M文件中先定义矩阵,之后使用文件名导入矩阵 从而可以一次输入,反复使用 使用冒号表达式 e1:e2:e3 从e1开始以e2为步长,到e3结束的行向量 可以省略e2,此时e2默认等于1, 由于步长原因,最后可能不包含元素e3 与使用linspace(a,b,n)效果类似,从a到b,产生n个元素(且必定包含边界值b) 使用小矩阵构建大矩阵 空矩阵 创建空矩阵后使用IDE提供的编辑器进行编辑 矩阵引用的转换矩阵的引用 可以使用形如A(m,n)的方式引用矩阵A的第m行,第n列的元素 如果引用越界,程序不会报错,而是自动扩展到相应的大小 可以使用形如A(n)的方式引用矩阵第n个元素, MATLAB按列存储且从1开始计数 序号和下标的转换使用sub2ind和ind2sub可以将序号(Index)和下标(Subscript)相互转换,例如 123456789101112131415161718&gt;&gt; a = [10,20,30;40,50,60;70,80,90]a = 10 20 30 40 50 60 70 80 90&gt;&gt; sub2ind(size(a),1,2) %第1行2列对应的序号ans = 4&gt;&gt; [i,j] = ind2sub(size(a),5) %序号为5的元素对应的下标i = 2j = 2 矩阵拆分reshape(A,m,n)函数 在元素不变的情况下,将矩阵A变成m*n的矩阵 仅仅改变逻辑结构,不改变物理结构 冒号表达式 使用冒号表达式获得一段数据 使用单独的冒号表示获得一整行或者一整列 冒号表达式配合end表示获取直到末尾 使用空矩阵删除部分元素 将矩阵的一部分置为空矩阵[], 即可将部分元素删除 矩阵拆分举例12345678910111213141516171819202122232425262728&gt;&gt; A = magic(5)A = 17 24 1 8 15 23 5 7 14 16 4 6 13 20 22 10 12 19 21 3 11 18 25 2 9&gt;&gt; A(1:3,2:4)ans = 24 1 8 5 7 14 6 13 20&gt;&gt; A(3,:)ans = 4 6 13 20 22&gt;&gt; A(2,2:end)ans = 5 7 14 16&gt;&gt; A(1,:) = []A = 23 5 7 14 16 4 6 13 20 22 10 12 19 21 3 11 18 25 2 9 特殊矩阵通用特殊矩阵 函数名 效果 zeros 全零矩阵 ones 全1矩阵 eye 单位矩阵 rand 0-1之间的随机数矩阵 randn 均值为0,方差为1的标准正态分布随机矩阵 上述函数具有以下的调用方法,其中f表示上表的任意一个函数 调用方法 效果 f(m) 产生一个m*m的矩阵 f(m,n) 产生一个m*n的矩阵 f(size(A)) 产生一个同A一样大小的矩阵 学科特殊矩阵 函数名 效果 magic(n) 每行,每列和两条对角线上元素之相等 vander(V) 最后一列全为1,倒数第二列为一个指定的向量(基础向量), 其他各列是其后列与倒数第二列的点乘积 hilb(n) H(i,j) = 1/(i+j-1) ,高度病态的矩阵 invhilb(n) 希尔伯特矩阵对应的逆矩阵 toeplitz(x,y) 托普利兹矩阵,除第一行和第一列外，其他每个元素都与左上角的元素相同 compan(p) 伴随矩阵,其中p是一个多项式的系数向量，高次幂系数排在前，低次幂排在后 pascal(n) 生成一个n阶帕斯卡矩阵 注意: 多项式对应的伴随矩阵的特征值是多项式的根 求5次方系数时, 应该使用pascal(6) 特殊矩阵使用举例12345678910111213141516171819202122232425262728293031323334&gt;&gt; Vand = vander([1;2;3;5])Vand = 1 1 1 1 8 4 2 1 27 9 3 1 125 25 5 1&gt;&gt; H=hilb(4)H = 1 1/2 1/3 1/4 1/2 1/3 1/4 1/5 1/3 1/4 1/5 1/6 1/4 1/5 1/6 1/7 &gt;&gt; T=toeplitz(1:2,1:4) % 两个参数都是向量,且第一个值应该相等T = 1 2 3 4 2 1 2 3 &gt;&gt; p=[1,0,-7,6];&gt;&gt; compan(p)ans = 0 7 -6 1 0 0 0 1 0&gt;&gt; pascal(5)ans = 1 1 1 1 1 1 2 3 4 5 1 3 6 10 15 1 4 10 20 35 1 5 15 35 70 MATLAB运算符算数运算基础规则Matlab的矩阵加,减,乘法都和数学定义一致,且不可运算时报错. 对于除法运算, 提供了两种除法 A/B(右除) 等价于 A*INV(B). A\\B(左除) 等价于 INV(A)*B 注意: 矩阵乘法不可交换,所以注意矩阵位置,这也决定了A和B行,列数的关系 逆矩阵和原矩阵的行列数交换,例如3x2矩阵的逆矩阵是2x3矩阵 当除数可逆时(非奇异方阵),被除数要能和除数的逆进行运算即可,而不必是方阵 当除数不可逆时(奇异或者非方阵或者两者均有), 使用求广义逆(即pinv)代替. 深入探讨除法除法A\\B实际上可以认为是线性方程组Ax=B的解,即x = inv(A)*B. 当A是方阵时,运算结果就是其解向量.当A是MxN矩阵时, 有两种情况 M &gt; N , 即方程数大于未知量数, 此时方程无解, A\\B给出最小二乘法下的近似解 M &lt; N , 即未知量数大于方程数, 此数方程无穷多解, A\\B给出一个特解 关系运算 同维矩阵之间可以进行关系运算, MATLAB将两个矩阵中的同一位置元素逐一比较,并返回一个同维的矩阵 当标量和矩阵比较时, 标量与矩阵逐一比较并且返回一个同纬度的矩阵. 关系运算符基本与各个语言使用的格式一致,但不等于使用~=表示. 充分利用矩阵和矩阵的比较, 矩阵和标量的比较可以简化代码,提高运行速度. 逻辑运算 逻辑运算的符号分别为&amp;,|,~ 和关系运算一样,可以在同维矩阵直接进行或者矩阵与标量之间进行. 和C语言的位运算一样, 这些符号的运算结果只能为0或者1. 运算优先级算数运算 &gt; 关系运算 &gt; 逻辑运算 MATLAB运算示例建立矩阵A，找出大于4的元素的位置，并输出这些元素的序号 12A=[4,-65,-54,0,6;56,0,67,-45,0];k = find(A&gt;4) MATLAB矩阵操作本节介绍MATLAB中关于矩阵的各种操作, 大部分操作都涉及线性代数的有关内容, 有关线性代数的定义可以查阅相关课本, 本节直接使用而不进行解释. 对角阵 diag函数可以提取一个矩阵的对角线,组成一个向量,或者将一个向量变成一个对角阵 当输入的矩阵不是一个方阵时, 尽可能的获得对角线的元素 可以指定一个数字k来提取第k条对角线的元素(与主对角线平行，往上为第1，2，…，n条对角线，往下为第-1，-2，…，-n条对角线，主对角线为第0条对角线). 当输入是向量时, 将向量还原成一个矩阵, 同时也可以指定一个数字k来指定是还原成那一条对角线. 123456789101112131415161718192021222324252627&gt;&gt; A=[4,-65,-54,0,6;56,0,67,-45,0]A = 4 -65 -54 0 6 56 0 67 -45 0&gt;&gt; diag(A)ans = 4 0&gt;&gt; diag(A,1)ans = -65 67&gt;&gt; diag(A,-1)ans = 56&gt;&gt; V = [1,2,3,4];&gt;&gt; diag(V,1)ans = 0 1 0 0 0 0 0 2 0 0 0 0 0 3 0 0 0 0 0 4 0 0 0 0 0 上三角矩阵和下三角矩阵 triu函数将给定的矩阵提取称为上三角矩阵 tril函数将给定的矩阵提取为下三角矩阵 与diag函数一样,两个函数都可以指定一个数字k来决定从哪一条对角线开始提取. 123456789101112&gt;&gt; A = [1,2,3;4,5,6;7,8,9]&gt;&gt; triu(A)ans = 1 2 3 0 5 6 0 0 9&gt;&gt; triu(A,1)ans = 0 2 3 0 0 6 0 0 0 矩阵的转置和旋转 使用’表示转置 使用rot90函数以90为单位旋转矩阵 使用fliplr和flipud进行左右反转或者上下翻转. 123456789101112131415&gt;&gt; A = [1,2;3,4]&gt;&gt; A&#x27;ans = 1 3 2 4&gt;&gt; rot90(A,1)ans = 2 4 1 3&gt;&gt; fliplr(A)ans = 2 1 4 3 矩阵的逆和伪逆 使用inv函数求非奇异矩阵的逆矩阵 使用pinv求解矩阵的伪逆 123456&gt;&gt; A = [1,2;3,4]&gt;&gt; inv(A)ans = -2.0000 1.0000 1.5000 -0.5000 行列式使用det函数求解矩阵的行列式 1234&gt;&gt; A = [1,2;3,4]&gt;&gt; det(A)ans = -2 矩阵的秩和迹 使用rank函数求解矩阵的秩 矩阵的秩可以分为行秩和列秩, 两种总是相等的, 统称为秩. 矩阵的秩也称为奇异值数. 使用trace函数求解矩阵的迹, 矩阵的迹等于矩阵对角线元素之和,或特征值之和. 向量和矩阵的范数度量矩阵或者向量在某种意义下的长度. 使用norm(V,1)计算1范数 使用norm(V,2)或者norm(V)计算2范数 使用norm(V,Inf)计算无穷范数 矩阵的条件数 如果在表达式AX=B中解向量X随矩阵A的微小扰动而发生很大变化, 则称矩阵A是病态矩阵, 否则称A为良性矩阵 条件数是用来描述矩阵良性或者病态性能的参数. 矩阵A的条件数 = A的范数* A的逆矩阵的范数 任何矩阵的条件数都大于1, 条件数越接近1, 则矩阵越接近良性. 使用cond计算条件数, cond函数的参数与norm类似,从而可以使用3种范数方法计算条件数. 特征值和特征向量使用如下的函数获得特征值或特征向量 函数 效果 E = eig(A) 获得特征值组成的向量 [V,D] = eig(A) 全部特征值构成的对角阵D,特征向量组成V的列向量 [V,D] = eig(A,’nobalance’) 不做相似变换,直接求特征值和特征向量 矩阵的超越函数对矩阵整体进行运算,而不是对各个元素进行运算. 各种运算都要求矩阵必须是方阵.例如 sqrtm(A) 求解矩阵X,使得X*X=A funm(A,’fun’) 用指定的函数计算相应的矩阵版本,例如 funm(A,’sqrt’)等价于sqrtm(A) 其他数据类型字符串定义 MATLAB种使用单引号括起来的字符序列表示字符串 MATLAB将字符串视为一个行向量 可以使用字符串构成矩阵,每行字符数必须相同 字符串中的&#39;使用&#39;&#39;表示1234&gt;&gt; ch = [&#x27;abcdef&#x27;;&#x27;123456&#x27;]ch =abcdef123456 转换 使用abs和double函数获得字符串矩阵对应的ASCII码数值矩阵 使用char获得ASCII码数值矩阵对应的字符串 代码示例在使用MATLAB对字符串进行操作时, 也应该充分的使用MATLAB提供的矩阵操作, 从而更加高效的完成任务 以下代码演示将字符串逆序排列 1revch = ch(end:-1:1) 以下代码演示将小写字符转化为大写字母,其他字符不变 123ch = &#x27;Good Good&#x27;;k = find(ch&gt;=&#x27;a&#x27; &amp; ch &lt;=&#x27;z&#x27;);ch(k) = ch(k) - (&#x27;a&#x27;-&#x27;A&#x27;); 输出函数使用disp函数, 此函数接受一个向量, 输出向量元素依次连接构成的字符串 12f = 12.33disp([&#x27;Room temperature is&#x27;,num2str(f)]) 结构矩阵使用结构可以存储不同元素,并且将不同类型的元素使用同一个变量名进行管理 结构矩阵的建立12345678&gt;&gt; a.x1 = 12; a.x2 = &#x27;LiZeC&#x27;; a.x3 = [12;32];&gt;&gt; a(2).x1 = 233;a(2).x2=&#x27;Hello,&#x27;;a(2).x3=[];&gt;&gt; aa = 1x2 struct array with fields: x1 x2 x3 从定义方式来看, MATLAB的结构与Python的类很相似, 可以动态的添加属性. 定义的时候,可以将a(1)写成a, 后续引用的时候,a就表示整个结构数组了 结构矩阵的引用 引用结构变量(矩阵本身): 显示矩阵大小,成员名 引用结构矩阵元素: 成员是矩阵时,显示矩阵大小 成员不是矩阵时,显示成员的值 引用元素的成员: 显示值 123456789&gt;&gt; a(1)ans = x1: 12 x2: &#x27;LiZeC&#x27; x3: [2x1 double]&gt;&gt; a(1).x3ans = 12 32 结构矩阵的修改 矩阵大小,成员都可以动态的添加, 如果赋值的属性不存在,则自动扩展 使用rmfield函数删除成员 12345&gt;&gt; a = rmfield(a,&#x27;x2&#x27;)a = 1x2 struct array with fields: x1 x3 单元数据(Cell)单元数据的每个元素都可以是不同的类型, 通过下标或者序号直接访问各个元素 1234567891011121314151617181920212223242526272829&gt;&gt; b = &#123;10,&#x27;Hello&#x27;,[1,2,3];12,&#x27;LiZeC&#x27;,[4,5,6];&#x27;GGBoy&#x27;,[23,33,3],23&#125;b = [ 10] &#x27;Hello&#x27; [1x3 double] [ 12] &#x27;LiZeC&#x27; [1x3 double] &#x27;GGBoy&#x27; [1x3 double] [ 23]&gt;&gt; b&#123;1,3&#125;ans = 1 2 3&gt;&gt; b&#123;3&#125;ans =GGBoy% 将元素置为空&gt;&gt; b&#123;3&#125; = []b = [10] &#x27;Hello&#x27; [1x3 double] [12] &#x27;LiZeC&#x27; [1x3 double] [] [1x3 double] [ 23]% 将元素删除,注意矩阵变成一维了(无法通过b&#123;2,1&#125;访问元素)&gt;&gt; b(3) = [] b = [10] [12] &#x27;Hello&#x27; &#x27;LiZeC&#x27; [1x3 double] [1x3 double] [1x3 double] [23]% 输出每个元素的具体值(此处省略输出)&gt;&gt; celldisp(b) 稀疏矩阵稀疏存储矩阵的创建 稀疏存储矩阵仅存储矩阵所有的非零元素的值及其位置, 从而节省存储空间 使用sparse函数创建一个稀疏矩阵 12345678910&gt;&gt; A = sparse(4,5)A = All zero sparse: 4-by-5&gt;&gt; A = sparse(2:5,3:6,3)A = (2,3) 3 (3,4) 3 (4,5) 3 (5,6) 3 转化和产生 使用sparse函数将一个完全存储的矩阵转化为稀疏存储的矩阵 使用full函数将一个稀疏存储的矩阵转化为完全存储矩阵 使用spconvert产生一个指定格式的稀疏矩阵 1234567891011121314151617181920212223242526272829&gt;&gt; I = eye(5)I = 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1&gt;&gt; s = sparse(I)s = (1,1) 1 (2,2) 1 (3,3) 1 (4,4) 1 (5,5) 1% 寻找所有不为0的元素,返回值可以作为sparse的参数&gt;&gt; [u,v,S]=find(A);% 对于A的每一行,其元素分别表示行号,列号,元素值实部,元素值虚部% 如果全部是实数,第四列可以省略&gt;&gt; A=[2,2,1;3,1,-1;4,3,3;5,3,8;6,6,12];&gt;&gt; B=spconvert(A)B = (3,1) -1 (2,2) 1 (4,3) 3 (5,3) 8 (6,6) 12 带状稀疏矩阵带状稀疏矩阵指非零元素主要分布在对角线或其平行线上的矩阵. 例如下面的矩阵A就是一个带状稀疏矩阵 123456A = 11 0 0 12 0 0 0 21 0 0 22 0 0 0 31 0 0 32 41 0 0 42 0 0 0 51 0 0 52 0 对于上述矩阵,可以按照以下方式创建 123456789101112m = 5; % 最终矩阵的行数n = 6; % 最终矩阵的列数d = [-3,0,3]; % 矩阵中包含元素的对角线序号, 与矩阵B对应B = [ 0 11 12; 0 21 22; 0 31 32; 41 42 0; 51 52 0;]; % B对应了对角线的元素数量A = spdiags(B,d,m,n); 注意: 对于B矩阵, 如果m &lt; n , 则对于每条对角线,从第一行开始补零, 如果m &gt;= n , 则对于每条对角线,从第一列开始补零 例如上述矩阵A的-3对角线上,第一个元素是第4行,因此前面补3个零 分析可知, 补零无论是从行数还是从列数, 总是试图加入少的零, 相等时数列 其他格式介绍 调用方法 效果 [B,d] = spdiags(A) 根据矩阵A提取前述的矩阵B和d B = spdiags(A,d) 根据d提取矩阵A指定的对角线(符合B的格式) E = spdiags(B,d,A) 使用B替换矩阵A中由d指定的对角线 speye(m,n) 产生稀疏单位矩阵 MATLAB程序设计M文件分类 M文件可以分为命令文件(Script)和函数文件(Function) 使用命令文件时可以直接操作工作空间中的变量, 和直接在命令行上执行其中的命令一样 使用函数文件时, 函数的变量会作为函数的局部变量在执行完毕后清除 数据的输入与输出 输入使用 A = input(‘提示信息’,选择), 选项为’s’时表示作为字符串处理,否则始终视为数字 输出使用 disp([输出项1,输出项2,…]) MATLAB其他特殊语法结构switch语句123456789switch 表达式 case 表达式1 语句组1 case 表达式2 语句组2 ...... otherwise 语句组nend 注意: 不需要break, 执行一个语句组以后直接退出 switch表达式可以时标量或者字符串, case语句可以时标量,字符串以及单元矩阵 try语句12345try 语句组1catch 语句组2end 注意: 抛出异常后,保存在lasterr中,通过该变量获得异常信息 各种错误(包括指令拼写错误等)都可以被catch, 因此可以保证程序执行不出现错误 函数文件function 输出形参表 = 函数名(输入形参表) 注释说明部分 函数体语句 函数是按照文件名调用的, 因此一定要保证文件名和函数名一致 函数参数可调性 nargin 调用函数时, 输入变量的个数 nargout 调用函数时,输出变量的个数 全局变量 使用global声明全局变量 在工作空间使用global定义全局变量后, 函数内部使用global再次声明 大量数据的传递可以使用全局变量 MATLAB符号计算产生符号1syms x y a b 求导 function description diff(S,’v’) 对符号对象S 中指定的符号变量v，求其1阶导数 diff(S) 对符号对象S 中的默认的独立变量求其1阶导数 diff(S,n) 对符号对象S中的默认的独立变量求其n阶导数 diff(S,’v’,n) 对符号对象S 中指定的符号变量v求其n阶导数 符号表达式求值12subs(f,x,1) % 将x替换为1double(r) % 将符号表示的数值转化为浮点表示,例如double(1/5) = 0.2 符号求解1sol = solve(eq1, eq2, …, eqn, var1, var2, …, varn) 其中eq1到eqn为表达式,var1到varn为未知变量, 例如 12345678910syms x y[Sx,Sy] = solve(x^2 + x*y + y == 3,x^2 - 4*x + 3 == 0) returns Sx = 1 3 Sy = 1 -3/2 补充阅读 Matlab符号计算与方程组求解","categories":[],"tags":[{"name":"Matlab","slug":"Matlab","permalink":"https://lizec.top/tags/Matlab/"}]},{"title":"计算机网络笔记","slug":"计算机网络笔记","date":"2018-03-01T02:00:29.000Z","updated":"2018-06-09T07:38:02.000Z","comments":true,"path":"2018/03/01/计算机网络笔记/","link":"","permalink":"https://lizec.top/2018/03/01/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%94%E8%AE%B0/","excerpt":"","text":"本文记录了计算机网络的有关知识. 包括计算机网络的各层次主要内容,TCP/IP协议的主要内容等. 目录 概述 物理层 数据链路层 网络层 运输层 应用层 概述计算机网络计算机网络是把分布在不同地点，并具有独立功能的多个计算机系统通过通信设备和线路连接起来，在功能完善的网络软件和协议的管理下，以实现网络中资源共享为目标的系统。 注意: 计算机网络是由若干节点和连接这些节点的链路组成的网络 其中节点可以是计算机,集线器,交换机或路由器 互联网 不同的网络通过 路由器 组成更大的网络 计算机网络将许多计算机连接起来,而互联网将许多网络通过路由器连接起来 与网络相连的计算机称为主机(host) 互联网三个发展阶段 单个网络ARPANET向互联网发展 三级网络互联网 分为主干网,地区网和校园网(或企业网) 多层次ISP结构的互联网 internet与Internet internet泛指由计算机网络连接而成的计算机网络 Internet特指当前的因特网 互联网交换节点(Internet eXchange Point, IXP) 为了减少主干网流量,更快的转发分组而建立 使两个网络(例如地区ISP)直接相连而不需要经过第三个网络(例如主干ISP)来转发 互联网的组成 边缘部分 所有连接在互联网上的主机构成 是用户直接使用的部分 用来进行通信和资源共享 核心部分 由大量网络和连接这些网络的路由器组成 为边缘部分提供服务 端系统端系统(end system)是处在互联网边缘的所有主机, 端系统在功能上可能有很大的差别 端系统通讯方式 客户-服务器方式 描述进程间服务和被服务的关系 客户是服务请求方,服务器是服务提供方 对等连接方式(P2P) 两台主机在通讯时处于对等地位,不区分哪一个是服务请求方,哪一个是服务提供方 “主机 A 和主机 B 进行通信” 实际上是指:”运行在主机 A 上的某个程序和运行在主机 B 上的另一个程序进行通信” 数据交换方式 电路交换 在两个通讯端之间建立一条专用的物理通路 必须经过建立连接-&gt;通话-&gt;释放资源的过程 在通话的全部时间内,通话的两个用户始终占用端到端的通讯资源 分组交换 采用存储转发技术 一个报文(message)被划分为几个分组以后再进行传送 每个数据段加上一些必要的首部(header)后,构成一个分组(packet) 报文交换 起源于电报时代,操作员按照报文为单位进行数据发送 整个报文完整的发送到下一个节点 三种方式的比较 若要连续传送大量的数据，且其传送时间远大于连接建立时间，则电路交换的传输速率较快。 报文交换和分组交换不需要预先分配传输带宽，在传送突发数据时可提高整个网络的信道利用率。 由于一个分组的长度往往远小于整个报文的长度，因此分组交换比报文交换的时延小，同时也具有更好的灵活性。 计算机网络性能指标 速率 单位是比特每秒(bit per second,bps) 带宽 原本指信号具有的频率带宽,单位制赫兹 在计算机网络中指某通道传送数据的能力,单位与速率相同,为bps 吞吐量 单位时间通过某个网络的实际数据量 吞吐量受带宽或额定速率的限制 时延 数据从网络的一端传送到另一端所需的时间 发送时延: 主机或路由器发送数据帧所需要的时间,即从发送第一个bit到最后一个bit用的时间 传播时延: 电磁波在信道中传播一定距离的时间 (信道长度/电磁波在信道上传播的速率) 处理时延: 主机或路由器收到分组进行数据提取,差错检验或查找路由的时间 排队延时: 分组在进入路由器后在输入队列等待的时间 总延时 = 发送延时 + 传播延时 + 处理延时 + 排队延时 时延带宽积 时延带宽积 = 传播时延 X 带宽 表示信号的容量,相当于在第一个bit到达目的地时,发送端发送的在链路上的数据量 也称以比特为单位的链路长度 往返时间(Round-Trip Time,RTT) 一次双向交互需要的时间 A发送完毕后开始计时,B收到后立即发送确认信息,到A收到返回信息后截至计时 利用率 信道被利用时间与总时间的比例 根据排队了,利用率提高会导致时延增加 利用率U,空闲网络时延D0,当前网络时延D满足 \\(D=\\frac{D_0}{1-U}\\) 奈氏准则与香农定理 每赫带宽的理想低通信道的最高码元传输速率是每秒2个码元 在任何信道中，码元传输的速率是有上限的，否则就会出现码间串扰的问题，使接收端对码元的判决（即识别）成为不可能 信道的带宽或信道中的信噪比越大，则信息的极限传输速率就越高 只要信息传输速率低于信道的极限信息传输速率，就一定可以找到某种办法来实现无差错的传输 网络协议(network protocol)网络协议也成协议,一般包含以下三个要素 语法, 即数据与控制信息的结构或格式 语义, 即需要发出何种控制信息,完成何种动作以及做出何种相应 同步, 即时间实现顺序的详细说明 协议的分层 层次 每个层次解决不同问题 下层为上层提供服务 上层屏蔽下层的服务实现细节 协议 下面的协议对上面的服务用户是透明的。 接口 层间的信息传送的规约 增加灵活性 三种体系结构比较 7 应用层应用层5 应用层 6 表示层 5 会话层 4 运输层运输层4 运输层 3 网络层网络层3 网络层 2 数据链路层网络接口层2 数据链路层 1 物理层1 物理层 ISO体系结构TCP/IP体系结构五层体系结构 物理层物理层特性 机械特性: 接线器形状与尺寸等 电气特性: 各线路电压范围 功能特性: 各线路电压含义 过程特性: 不同功能涉及的顺序 通信交互的三种方法 单向通信 : 通信双方只有一方向另一个方法发送信息 只使用一个信道 例如 广播 双向交替通信 通信双方都能发送信息,但不能同时发或者同时收 占用两个信道 例如 对讲机 双向同时通信 通信双方都能同时发送或者接受信息 占用两个信道 例如 电话 信号与传输 基带信号 由计算机或终端产生的数字信号. 由于计算机输出的信号中通常包含较多的低频信号, 因此往往不适合信道的传输 基带传输 把数字信号转换为另外一种数字信号的过程,也成为编码. 基带传输适合近距离,有线传输 带通信号 基带信号经过载波调制后的模拟信号 带通传输 把基带信号载波调制成为模拟信号,再送到信道传输. 适合远距离,无线传输 数据传输率 比特率 单位时间传输的比特数 波特率 单位时间传输的码元数 关系 比特率=波特率×码元信息量 奈奎斯特准则在假定的理想条件下, 为了避免码间串扰, 码元的传输速率的上限值 = 2W Baud. 即最大传输速率等于传输带宽的两倍. 香农公式信道的极限信息传输速率\\( C=W \\log_{2}( 1 + \\frac{S}{N} ) \\) b/s. 其中W为信号带宽, S/N为信噪比. 信道复用技术 频分复用(Frequency Division Multiplexing, FDM) 用户在分配到一定的频带后, 在通信过程中自始至终都占用这个频带 频分复用的所有用户在同样的时间占用不同的带宽资源 时分复用(Time Division Multiplexing, TDM) 时分复用则是将时间划分为一段段等长的时分复用帧（TDM 帧） 每一个时分复用的用户在每一个 TDM 帧中占用固定序号的时隙 每一个用户所占用的时隙是周期性地出现（其周期就是 TDM 帧的长度） 统计时分复用(Statistic TDM, STDM) 通过统计各个数据的实际到来情况,从而更紧凑的发出数据 波分复用(Wavelength Division Multiplexing, WDM) 实际就是光的频分复用 码分复用(Code Division Multiple Access, CDMA) 通过正交向量点乘为零实现多用户同时数据通信 数据链路层数据链路层的两种信道类型 点对点协议: 使用一对一的点对点通信方式 广播协议: 使用一对多的广播通信方式 点对点信道的数据链路层数据链路层的三个基本问题在数据链路层协议中有三个基本问题, 后续的各种协议都是围绕以下这三个问题展开 封装成帧 如何将从上层收到的数据进行封装,组成基本的传输结构 透明传输 在传输过程中可能用到了特殊的符号, 如何进行控制使得用户的数据不需要对特殊符号进行处理 差错检测 传输过程中可能存在错误, 如何进行检测 数据链路和帧 链路(link)是指一个节点到另外一个节点的物理线路,在两者之间没有其他交换节点. 通常一次通信需要经过多个这样的链路 数据链路(data link)是指因为通信的需要而使用的一系列硬件和软件的整体. 数据链路传输的基本数据单元称为 帧 透明传输 使用控制字符SOH(Start Of Head)和EOT(End of Tail)作为开始和结束的表示 传输的内容中出现相同编码的字节时,插入一个ESC字符 循环冗余校验(Cyclic Redundancy Check, CRC)给定一个k bit的数据, 可提供一个n bit的冗余码, 组成k+n位数据进行发送,从而接收端能对数据进行检验. 例如设数据M = 101001, 则k=6, 此时可取n=3. 按照以下步骤进行计算和校验 计算过程 在M后添加n个零,即变成M’ = 101001000 产生一个双方事先约定的数据P = 1101. (P要求是一个n+1 bit数据) 使用模2运算计算 M’ / P , 得余数为001 将获得的余数加添到M的末尾,组成k+n bit数据,即M’’ = 10100001 检验过程 接收端将收到的数据N使用模2运算计算 N / P 如果余数为0,说明数据正确 说明模2运算实际上就是异或, 在进行除法运算时,只要最高位与P相同,商就可以上1. 对于除数P, 有几种常见的选择,例如CRC-16, CRC-CCITT,CRC-32等, 具体形式可以查阅其他相关资料. 数学上可以证明, 如果数据传输过程中发生改变, 进行校验后除数仍为零是一个非常小的小概率事件. 通过使用CRC等技术, 可以对数据进行校验,从而实现了数据链路过程中的差错检验, 不过数据链路层通常不负责数据错误数据重传, 如果发现错误, 通常仅仅直接将数据丢弃. 点对点协议(Point-to Point Protocol, PPP)PPP协议满足特点 简单 数据链路层上不需要提供比IP协议更多的功能, 因此不进行纠错, 不负责流量控制等 封装成帧 透明性 多种网络协议 PPP能够在同一物理链路上支持多种网络层协议(例如IP和IPX) 多种链路类型 除了要支持多种网络协议外, PPP协议必须能够在多个类型的链路上运行(例如并行链路和串行链路) 错误检测 检测连接状态 具有能够及时的(几分钟内)检测链路是否正常的机制 最大传输单元 规定了数据部分的默认最大长度MTU(默认为1500字节) 接受过程中超过了最大长度的帧会被丢弃 网络层地址协商 能够使网络层协议知道彼此的网络层地址 数据压缩协商 提供协商压缩算法的方法 PPP帧格式 PPP使用0x7E作为开始和结束的标记,每个帧的第一字节和最后一个字节都是0x7E 帧的头部第二,第三个字段是字段A和字段C,均为1字节,没有定义,通常设置为0xFF和0x03 帧头部第四个字段协议字段,长度为2字节,为0x0021时为IP数据报,为0xC021为LCP协议 后续为信息部分,可变长,不超过1500字节 尾部第一个字段为FCS,是使用CRC的帧检验序列 尾部以0x7E结尾 字节填充(异步传输) 使用0x7D作为转移符号 出现0x7E时,转换为0x7D 0x5E 出现0x7D时,转换为0x7D 0x5D 出现ASCII控制字符时, 也使用类似的方法加入转移字符 零比特填充(同步传输) 发送过程中,一旦出现5个1,就立即插入一个0 接受过程中,一旦读取到5个1,下一个比特如果是0,就删除这个0并继续解码 广播信道的数据链路层以太网以太网是美国施乐公式的研究中心与1975年研制成功的. 当时以太网是一种基带总线局域网, 以无源电缆作为总线来传输数据帧, 并以历史上表示传播电磁波的以太(Ether)命名. 以太网的两个标准 DIX Ethernet V2 是世界上第一个局域网产品（以太网）的规约。 IEEE 802.3 是第一个 IEEE 的以太网标准。 DIX Ethernet V2 标准与 IEEE 的 802.3 标准只有很小的差别，因此可以将 802.3 局域网简称为“以太网”。 严格说来，”以太网” 应当是指符合 DIX Ethernet V2 标准的局域网 局域网数据链路分层 可以分为逻辑链路控制(Logical Link Control,LLC)和媒体接入控制(Medium Access Control,MAC) 由于DIX Ethernet V2的胜利,现在的很多配置器只有MAC协议 适配器与MAC地址 配适器处理计算机与网络之间交换的数据 对数据进行串并转换,速率适配等操作 CSMA/CD协议载波监听多点介入/碰撞检测(Carrier Sense Multiple Access with Collision Detection,CSMA/CD)协议是总线结构的以太网常用的协调方法. 多点接入是指这是总线型网络, 有许多计算机接入. 载波监听是指利用电子技术,在数据发送前和发送中对数据信道进行监听. 发送数据前如果发现其他节点正在发送,就暂时等待. 发送数据过程中, 检测到其他节点也在发送,即发送碰撞,就进行相应的处理. 传播时延假定在线路上有A,B两个节点且相距1km, 由于电磁波传输1km大约需要5μs, 因此如果某时段信道为空,A检测到后发送信息,则信息需要5μs后才到达B节点, 若B在此时间段内发送信息,则会导致碰撞. 而从B发送信息开始的5μs后,A才能检测到发送碰撞, 因此在线路上,至多只需要10μs,任意一个节点都能检测到碰撞. 通常,将A到B的传播时延记为τ. 将2τ称为争用期 截断二进制指数退避算法协议规定,基本退避时间为争用期2τ, 具体值为51.2μs. 对于10Mbps的网络,相当于发送512个bit的时间, 因此也说争用期是512比特时间. 从离散的整数集合[0,1,2,3,4,…,(2^k-1)]中随机取出一个数r,重传推迟时间为r倍的争用期. 并且k按照以下规律获得 $$k = Min[重传次数,10]$$ 即当重传次数小于10次时,k等于重传次数,重传次数大于10时,k始终为10. 且当重传次数为16时仍然不能成功,则丢弃该帧并向高层反馈. 一些限制 发送数据最小长度必须大于64字节,即512bit,否则数据发送完毕后发生的冲突无法被发现 从开始发送数据的一个争用期内没有发送冲突,则后续也不会发生冲突 由于发送过程需要监听信道,因此只能以半双工方式工作 由于争用期为51.2μs,因此以太网理论上最大长度约为5km 发送节点检测到碰撞以后,立即停止发送数据并发送32bit或48bit的人为干扰信息以强化碰撞 帧与帧之间最小间隔96bit时间,即任何时刻必须监听到96bit以上空闲时间才能发送数据 发送过程 收到数据后封装成帧 等待信道空闲96bit时间 发送数据,一边发送一边等待,有两种情况 如果开始发送后的一个争用期内没有检测到冲突,则此帧必定可以发送成功 如果在争用期内检测到冲突,则执行指数退避算法 MAC协议MAC地址 MAC地址是一种全球唯一的48bit的固化在适配器ROM中的地址 前3字节需要购买,后3字节厂家自行分配 MAC帧格式 前8字节为同步码和帧开始符,后面紧跟MAC帧 MAC帧第一个字段为目的地址,占6字节 MAC帧第二字地段为源地址, 占6字节 MAC帧第三字段为类型,占2字节 后面为46~1500字节的IP数据报 最后为4字节FCS 帧中不包含尾部,信道为空则说明到达尾部 同步模式时不需要同步码 扩展以太网在物理层扩展由于铜线衰减速度很快, 因此可以使用光纤代替铜线,将主机距离扩展. 使用集线器可以将多台主机连接,组成一个看似星型实际为总线型的网络, 且集线器还可以连接集线器, 从而将多个网络连接到一起. 但由于所有设备竞争一个总线, 因此网络传输效率有所下降. 在数据链路层扩展在数据链路层,可以使用以太网交换机对以太网进行扩展,以太网交换机具有以下特点 相互通信的主机都是独占传输媒体,无碰撞的传输数据 内部使用交换表,通过自学习算法建立 使用交换机的以太网就不再是总线结构, 因此也不存在共享总线的问题, 也不使用CSMA/CD算法, 但由于此网络依旧使用以太网帧,因此还是称为以太网 虚拟局域网通过以太网交换机有条件的转发分组, 虚拟局域网技术可以将不同位置的主机模拟成处于同一局域网的状态. 使用该技术可以减少广播风暴的影响. 网络层网络层与电信网络提供的虚电路不同, 网络层向上只提供简单灵活的, 无连接的, 尽量努力交付的 数据报服务. 网络层 不提供服务质量的承诺. 网络层协议网络层最重要的协议时IP协议, 除此以外, 还有三个协议与IP协议配套使用 地址解析协议ARP(Address Resolution Protocol) 网际控制报文协议ICMP(Internet Control Message Protocol) 网际组管理协议IGMP(Internet Group Management Protocol) 由于历史的进程, 实际上网络最初并没有统一的通信标准, 因此各种网络之间是无法直接通信的, IP协议的出现使得不同的网络之间可以使用同样的协议进行通信, 从而将不同的网络连接起来,组成更大网络, 即虚拟IP网络或互联网. 常见中间网络设备和工作的网络层次 网络层次 中间设备 物理层 转发器(repeater) 数据链路层 网桥/桥接器(bridge) 网络层 路由器(router) 网络层以上 网关(gateway) 当中间设备是转发器或者网桥时, 则仅仅是把一个网络扩大, 网络的角度看, 这仍然是一个网络. 而网关用于连接两个不兼容的系统并在高层进行协议转换, 现在已经很少使用. 因此对网络进行互连时, 主要时通过路由器进行连接. IP地址及其表示方法IP地址是一个32位的标识符,通常可以按照字节写成4个使用.划分的十进制数,例如127.0.0.1. 一个IP地址可以分成 网络号 和 主机号, 不同类型的IP地址具有不同长度的网络号和主机号, IP地址可以划分为5大类 A类, 网络号占1字节且以0开始, 主机号占3字节 B类, 网络号占2字节且以10开始,主机号占2字节 C类, 网络号占3字节且以110开始,主机号占1字节 D类, 多播地址, 以1110开始 E类, 保留地址, 以1111开始 各类型网络对比 网络类型 最大网络数 第一个可指派网络号 最后一个可指派网络号 每个网络最大主机数 A 126(\\(2^{7}-2\\)) 1 126 16777214 B 16383(\\(2^{14}-1\\)) 128.1 191.255 65534 C 2097151(\\(2^{21}-1\\)) 192.0.1 223.255.255 254 注意 A类网络中,0表示本网络,127表示回环测试,从而不能使用 B类中128.0被保留 C类中192.0.0被保留 主机号全0表示本主机连接的网络地址,全1表示本网络所有主机,从而不能使用 特殊地址规则 网络号 主机号 源地址使用 目标地址使用 含义 0 0 Y N 本网络上的本主机 0 host-id Y N 本网络的某台主机host-id 全 1 全1 N Y 对本网络广播 net-id 全1 N Y 对net-id上的所有主机广播 127 非全0或全1 Y Y 回环测试 IP网络的特点 每一个IP由网络号和主机号组成, 从而便于分配和管理 路由器只需要根据 网络号进行转发而不需要考虑主机号,从而极大减少路由表的大小和查找时间 IP地址本质上是表示一个接口,一个主机(或路由器)可以连接多个网络从而获得不同的IP地址, 这种主机称为多归属主机 IP地址和MAC地址的一些特点 IP地址与MAC地址的关系如上图所示, IP层抽象的互联网只能看到IP数据报 中间过程的路由器IP地址不体现在IP数据报中 路由器仅仅根据目标IP地址的网络号进行路由选择 在局域网的数据链路层,只能看到MAC帧,每一步都更换MAC地址 由于IP层屏蔽了不同网络的下层细节,因此不同网络能使用统一的方式通信 地址解析协议ARP在网络中传输数据时,网络层使用IP地址,而数据链路层需要使用MAC地址,因此需要有协议能将IP地址转换为MAC地址, ARP协议完成这个工作.每台主机设有一个ARP高速缓存, 保存了本局域网中各主机和路由器的IP地址与MAC地址映射关系.主机A与主机B通信,如果可以直接由IP地址查询到B的MAC地址,则直接发送信息,否则广播ARP分组请求. ARP分组请求 ARP分组的请求的格式类似”我的IP是209.0.0.5 MAC地址是00-00-C0-15-AD-18, 我想知道IP地址位209.0.0.6的主机的MAC地址” 局域网中只有B的IP地址与分组请求的地址一致,因此B则收下该分组并向A发送ARP分组相应 ARP响应的格式类似”我的IP地址是209.0.0.6 MAC地址是08-00-2B-00-EE-0A” ARP分组请求时广播的,而响应是单播的 考虑到A与B发送消息后,B可能还要与A发送消息,因此ARP分组中包含A的MAC地址,B可以保存下来以便于后续使用 ARP高速缓存中的条码都存在生存时间, 时间到达后会被自动删除 跨网络通信ARP请求是为了解决 同一局域网上 主机 或 路由器IP地址和MAC地址映射关系的问题. 当请求的IP地址不再同一网络时, 通过ARP协议是无法获得MAC地址的(实际也不需要获得). 此时数据直接转发给路由器, 由路由器决定后续的转发路径 IP数据报格式 版本 表示IP协议版本, 当前使用的版本号为4或者6 首部长度 以4字节为一个单位,表示首部长度的的单位数 通常首部占20个字节, 因此首部长度值一般为5 区分服务 该字段通常不使用 总长度 包括首部和数据在内的整个数据报的长度 该字段占16bit,单位为字节, 因此IP数据包最大为65535字节 由于底层的数据链路层协议都规定了最大传输长度, 因此IP协议虽然支持65535字节,但往往不能传输如此大的数据报 如果数据报长度超过限制, 一般进行分片处理 标识 IP软件内部维持一个计数器, 同一批的数据具有同样的标识值 从而一个分片的数据报能够依据标识值进行恢复 标志 占3bit,但目前只有低2bit有意义 最低位是MF(More Fragment), MF=1表示后续还有分片, MF=0表示这是最后一个数据报片 中间位是DF(Don’t Fragment), DF=0时才允许分片 注意分片时,最后一个分片的值是 MF=0, DF=0 片偏移 占13bit, 以8字节位一个单位,表示此分片的数据在原始数据中的偏移单位数 以8字节为单位,相当于左移3位,从而扩展到16bit, 能够表示接近65535的偏移 分片时, 数据偏移需要按照8的倍数分割,从而起始位置能被正确的表示 生存时间 每经过一个节点, 生存时间减一 生存时间为零时, 数据报被丢弃 协议 表述此数据报携带的数据使用的协议,从而上层能使用正确的方式进行处理 常见协议字段值如下所示 协议名 ICMP IGMP IP TCP EGP IGP UDP IPv6 ESP OSPF 字段值 1 2 4 6 8 9 17 41 50 89 首部检验和 使用二进制反码求和对数据报首部进行计算 计算时将校验和字段设置为0,计算所有字段的反码二进制和, 取反后写入校验和字段 校验时将所有字段再次计算反码二进制和后求反码, 结果为0则数据正常,否则丢弃该数据包 IP数据报首部可变部分 该部分没有规定,可以自行扩展 由于当前的很多路由器并不考虑可变部分, 因此在后续的协议(例如IPv6)中取消了可变部分 IP层转发过程路由器的路由表中只包含了目的网络地址(网络号)和下一跳地址(主机或者其他路由器IP地址). 有以下三种情况 目标主机在当前网络,则路由器直接交付 目的主机在其他网络,且所在网络号在路由表中有记录, 则路由器转发给相应的下一跳地址 目的主机所在网络没有记录,则路由器转发给默认路由, 如果没有默认路由,则报告转发分组错误 虽然任意一个路由器都不包含完整的路径信息, 但是通过一步步的查询最终也能找到目标主机 划分子网 从主机号借用若干位构成子网号,从而使IP地址变成由 网络号, 子网号, 主机号 构成 划分子网后, 内部分成若干网络, 对外仍然表现为一个网络 路由器收到数据后,如果在当前网络,则直接交付,否则根据子网号交付给相应的子网 子网掩码 由于子网长度可以任意设置, 因此需要设置一个子网掩码来表明网络号+子网号的长度 将数据包中的网络号和掩码进行&amp;运算即可得到目标主机的网络号+子网号 注意: 按照规定, 对于n位的子网号, 全0和全1不能使用, 因此划分后只有 \\( 2^{n} - 2\\) 个子网, 总可用IP数进一步减少了. 子网转发过程 从收到的数据提取目的IP地址D 判断是否位于同一网络(使用掩码运算),是则直接交付,否则执行下一步 判断是否又特定路由,是则发送给特定路由,否则执行下一步 对比路由表中每一行, 通过掩码计算后比较是否是同一网络, 发现匹配项目后发送给对应的端口 没有匹配条目则发送给默认路由或报错 构造超网CIDR(Classless Inter-Domain Routing), 即无分类域间路由选择, 该技术消除了传统的A,B,C类地址以及划分子网的概念, 从而能更有效的利用IPv4地址. CIDR将IP地址划分为网络前缀和主机号两个部分,并且使用斜线记法来表示网络前缀的长度,例如 128.14.35.7/20 =&gt; 10000000 00001110 00110011 00000111 即使用20位表示网络前缀,剩余的12为表示主机号. CIDR使用与子网掩码同样的技术来指示网络前缀. 注意: 在使用此模式表示IP地址时, 一定要写斜线后面的数字, 否则是没有意义的 不使用主机号为全0或者全1的IP地址 最长前缀匹配由于CIDR的分配方式, 在一个大的网络中, 可以进一步的分配成多个子网, 因此在路由表中可能或有多个条目与指定的IP匹配. 此时按照最长前缀原则匹配, 即尽可能到更具体的网络位置. 查询过程可以使用二叉树等技术. 网际控制报文协议ICMP网络层使用网际控制报文协议(Internet Control Message Protocol, ICMP)来保证更加有效的转发IP数据报. ICMP允许主机或路由器报告差错情况和提供有关异常的报告. ICMP作为数据部分封装在IP数据报中. 类型ICMP分成两大类, 一类是差错报告报文, 另一类是询问报文. 其中差错报告报文包括 终点不可达 时间超时 参数问题 改变路由 询问报文包括 回送请求或回答 时间戳请求或回答 ICMP的格式 ICMP的前4字节结构是相同的,分别表示类型,代码和校验和 之后的4个字节内容取决于不同的协议 ICMP的数据部分都是相同的, 将收到需要进行差错报告的IP数据报的首部以及数据部分的前8个字节作为ICMP的数据部分 由于IP数据报的数据部分前8字节包含运输层协议的端口内容, 因此加上此内容有助于通知高层协议. ICMP应用ICMP协议最常见的应用是分组网间探测(Packet InterNet Groper, PING). 在Windows上和Linux上都是使用ping指令来执行此应用. 此外还可以使用traceroute(UNIX)或tracert(Windows)指令来执行路由追踪, 了解一个数据包从本地主机到目标主机的路由路径. 例如以下是从本地到知乎服务器的路由路径, 可以看到数据包在本地局域网中经过若干步跳转后进入本地ISP网络, 最后达到位于北京的腾讯云服务器. 互联网路由选择协议互联网规模非常大, 让每一个路由器知道所有的网络如何到达时不现实的,而且很多企业不愿意暴露自己网络的布局和细节. 因此可以把互联网划分成许多较小的自治系统(Autonomous System,AS). 自治系统内部使用单一的技术一致的路由选择策略, 然后将不同的自治系统连接起来组成互联网. 这样, 互联网就涉及两种协议,即 内部网关协议(Interior Gateway Protocol,IGP)和外部网关协议(External Gateway Protocol, EGP). 由于历史的进程原因, 这里的网关实际上是指路由器, 但由于名称由来已久,因此依旧使用此名称. 内部网关协议IGP协议有两个主要的协议, 即基于距离向量的路由选择协议(Routing Information Protocol)和开放最短路径优先(Open Shortest Path First, OSPF) RIP协议的特点 仅和相邻的路由器交换数据, 交换当前的全部路由表数据,按固定的时间间隔交换数据 定义直接相连距离为1, 每通过一个路由器距离+1, 定义16为不可达 坏消息传的慢(不可到信息可能被其他路由中未更新的错误信息覆盖) RIP协议交换过程 收到X的路由表后,对其中的所有条目进行修改,将所有的下一条地址都修改为X,对距离字段都+1 对比修改后的路由表A和当前的路由表B的每一条记录I 如果B中不包含I的网络,则将I加入B 如果A和B都包含I的网络,且B中下一跳地址正好是X,则使用I更新B的条目 如果A和B都包含I的网络,且下一跳地址不同,则I的路径更短时更新B的条目 OSPF协议特点 和所有的路由器交换信息, 使用泛洪法 交换本路由器和其他路由器的链接信息 只有网络改变时才交换信息 通过将一个自治域划分未为若干个区域,可以扩展OSPF网络规模 运输层从通信和信息处理的角度看, 运输层向它上面的应用层提供通信服务, 它属于面向通信部分的最高层, 同时也是用户功能中的最底层. 网络层是为主机之间提供逻辑通信, 而运输层为应用程序之间提供端到端的通信. 运输层的一个重要功能是复用和分用. 根据应用程序的需求不同, 运输层有两种不同的运输协议, 即面向连接的TCP协议和无连接的UDP协议. 端口建立端口是为了在不同的主机之间能够确定需要通信的进程,而不受到相关进程动态变化的影响. 01023 为熟知端口102449151为登记端口,49152~65535为短暂端口 UDP协议 提供无连接服务 在传输数据前不需要建立连接 对方在收到UDP报文后不需要给出任何确认 虽然UDP不提供可靠交付, 但在某些情况下是一种最有效的方式 UDP支持一对一,一对多,多对一和多对多通信 UDP格式 长度: 整个数据报的程度, 字节为单位, 至少为8 校验和: 使用 二进制反码加法 计算包括伪首部在内的全部数据,计算结果最后取反写入校验和字段 计算时,每16bit作为一个数字 数据部分必须为偶数, 如果不足可以使用0补充 检验时,直接对所有内容使用二进制反码求和,结果全1,则校验正确 TCP协议 面向连接的服务, 提供可靠交付 提供全双工通信 面向字节流, TCP协议会根据各种因素自行决定数据块大小 只提供点对点通信 停止等待协议 每发送一个数据,都等待接收方的确认 等待一段时间后没有收到确认,则自动重发数据 这种协议通常称为自动重传协议(Automatic Repeat reQuest,ARQ) TCP格式 源端口和目的端口 序号: 本报文发送的第一个字节在待发送的字节流中的序号 确认号: 期望收到对方的下一个报文的第一个字节的序号 数据偏移: TCP报文中数据部分在此报文中的起始位置,以4字节为单位,此字段最大值为15 保留: 此段应该置为零 控制位: 紧急URG, 为1时, 表示紧急指针有效,从而可发送紧急数据 确认ACK, 为1时, 确认号字段才有效,建立连接后的所有报文ACK都必须为1 推送PSH, 为1时, 表示不等缓冲区满就发送信息 复位RST, 为1时, 表示出现严重错误, 必须释放连接 同步SYN, 当SYN=1,ACK=0时,表示一个请求报文,SYN=1,ACK=1表示接收请求 终止FIN, 为1时, 表示传输结束, 要求释放连接 窗口: 发送此报文方的接收窗口大小, 作为另一方决定发送窗口大小的依据 检验和: 校验包括伪首部在内的全部内容,校验方法与UDP一致 紧急指针: 指示紧急数据的大小,从而能提取紧急数据和其他正常数据 选项: 长度可变,最多40字节 TCP的滑动窗口 根据B的确认号和窗口值, 可以构建A的发送窗口 发送窗口表示在没有收到B的确认信号前,A可以将窗口内的数据连续的发送出去 B根据接收缓冲区大小以及已经收到的数据决定窗口值大小 通常不建议前沿收缩 超时重传的选择对于超时重传时间的选择, TCP采取了一种自适应算法, 通过采集传输过程的往返时间动态的调整重传时间 加权平均往返时间第一次测量到 RTT 样本时，\\(RTT_S\\) 值就取为所测量到的 RTT 样本值。以后每测量到一个新的 RTT 样本，就按下式重新计算一次\\(RTT_S\\) $$新的 RTT_S 值 = (1 - α) \\times (旧的 RTT_S 值) + α \\times (新的RTT样本)$$ 其中α建议取值为0.125, 可以看到, 上述公式对应了时间序列中的指数平滑公式,相当于使用现有样本来预测以后的RTT值的变化. 加权平均往返值偏差除了对往返时间进行估计以外, 还同时的对往返时间的偏差进行估计, 第一次测量时 \\(RTT_D\\) 取值为 \\(RTT_S\\) 值的一般,以后按照如下的公式计算 $$ 新的RTT_D 值 = (1- β) \\times (旧的RTT_D值) + β \\times |RTT_S - 新的RTT样本| $$ 其中β建议取值为0.25. 超时重传时间超时重传时间(Retransmission Time-Out, RTO)按照如下公式计算: $$ RTO = RTT_S + 4 \\times RTT_D $$ 样本的选择由于发生重传以后,无法知道对方发送的确认是对于以前的包的确认还是对重传包的确认, 因此使用Karn算法时, 不将重传的确认作为样本. 但如果线路发送变化, 导致延时突然增加, 产生了大量的重传, 则由于不采用这些数据, 导致算法无法调整. 修正的Karn算法在每次发生重传时, 将超时重传时间翻倍, 当不再发送超时重传以后, 再采用之前的公式计算重传时间. 实践证明, 此策略较为合理. TCP流量控制流量控制就是让发送发的发送速率不要太快, 使接受发来得及接收. 零窗口探测报文 在一定的情况下,接受方可能将窗口值置为零, 使发送发停止发送 若后续增加窗口值的报文丢失, 则会导致双方互相等待 因此对于发送方, 窗口值被置为零后启动一个计数器, 到达设定时间后向接收方发送零窗口探测报文 接受方即使窗口为零, 也必须接收和处理此报文, 从而双方能保证消息被相互传达, 解除死锁 拥塞控制算法TCP的拥塞控制算法有四种, 即慢开始(slow-start), 拥塞避免(congestion avoidance), 快重传(fast retransmit)和快恢复(fast recovery) 1. 慢开始发送方维持一个拥塞窗口cwin(congestion window)的变量, 此变量大小取决与网络的拥塞层度, 并且可以动态变化. 慢开始算法要求主机先使cwin取一个较小的值, 例如cwin等于1个发送发最大报文段长度(Sender Maximum Segment Size,SMSS). 以后每次收到一个报文段确认,则有 $$ d(cwin) = min(N,SMSS) $$ 其中N为之前未被确认, 而现在被确认的字节数. 因此cwin每次最多可以增加一个SMSS大小. 通常以SMSS为单位讨论数据发送, 因此每轮收到全部的确认以后,cwin大小翻倍. 但实际上收到确认报文后, 会立即更新, 而不会按照轮次进行翻倍. 但最终表现都是cwin随时间指数增加. 2. 慢开始门限为了防止cwin无限增大,导致网络最终拥塞,设置了一个门限值ssthresh, cwin到达门限值后采用拥塞避免算法 3. 拥塞避免算法每轮使cwin增加一个SMSS大小, 由于实际的确认报文是逐一到达的, 因此每次到达后,可以设置 $$ d(cwin) = MSS \\times (MSS / cwin) $$ 例如当前cwin等于10个MSS, 则现在收到一个确认以后增加0.1个MSS, 从而一轮以后正好增加一个MSS. 当拥塞避免算法运行到产生超时重传时, 将门限值ssthresh置为当前cwin的一半. 并开始执行慢开始算法 4. 快重传在通信过程中, 快重传算法要求接受发每次收到一个报文后,立即发送确认. 例如有某个报文段M2缺失, 后续收到M3,M4,M5时, 接受发都要发送确认收到M1. 当接受发收到3个重复的确认时, 就可以肯定M2确实没有被收到, 此时立即重传M2, 以免由于超时进入慢开始过程. 5. 快恢复发生快重传以后,启动快恢复过程, 将门限值ssthresh置为当前cwin的一半, 并从ssthresh值开始执行拥塞避免算法 6. 控制过程图 7. 发送窗口大小实际的发送窗口大小等于接受发给出的窗口值和实际拥塞窗口值中的最小值 TCP的连接建立TCP建立连接的过程叫握手, 握手需要在客户端和服务器之间交换三个TCP报文段. 使用三次报文主要是为了保证已经失效的请求不会被服务器端处理. 三报文握手的过程如下所示: 注意: SYN报文始终消耗序号, 单纯的ACK报文如果不携带数据,则可以不消耗序号,即第三次报文后,A的下一个报文还可以使用x+1作为序号 TCP的链接释放释放过程如下所示: A主动结束程序, 发送FIN报文 B对A的报文确认, 后续根据实际情况传输一些数据 B数据传输完毕, 发送FIN+ACK报文 A对B的报文进行确认, 并等待2MSL的时间 在等待过程中,若B没有收到A的确认报文, 超时后B会重传FIN+ACK报文, 从而A在2MSL的等待时间内可以重传ACK报文. 如果A在等待的时间内没有收到B的重传报文, 则可以认为B已经收到了确认报文, 从而可以关闭连接. 应用层DNS服务 一个服务器所负责管辖的（或有权限的）范围叫做区(zone) 各单位根据具体情况来划分自己管辖范围的区。但在一个区中的所有节点必须是能够连通的 每一个区设置相应的权限域名服务器，用来保存该区中的所有主机的域名到IP地址的映射 DNS 服务器的管辖范围不是以“域”为单位，而是以“区”为单位 主机向本地域名服务器的查询一般都是采用递归查询, 本地域名服务器向根域名服务器的查询通常是采用迭代查询 FTP协议 文件传送协议 FTP 只提供文件传送的一些基本的服务, 它使用 TCP 可靠的运输服务 FTP 的主要功能是减少或消除在不同操作系统下处理文件的不兼容性 FTP 使用客户服务器方式. 一个 FTP 服务器进程可同时为多个客户进程提供服务 FTP 的服务器进程由两大部分组成 一个主进程，负责接受新的请求 另外有若干个从属进程，负责处理单个请求 控制连接在整个会话期间一直保持打开，FTP 客户发出的传送请求通过控制连接发送给服务器端的控制进程，但控制连接不用来传送文件 实际用于传输文件的是“数据连接”. 服务器端的控制进程在接收到 FTP 客户发送来的文件传输请求后就创建“数据传送进程”和“数据连接”，用来连接客户端和服务器端的数据传送进程。 数据传送进程实际完成文件的传送，在传送完毕后关闭“数据传送连接”并结束运行。 电子邮件协议 发送邮件的协议: SMTP 读取邮件的协议: POP3(Post Office Protocol), 网际报文存取协议(Internet Message Access Protocol, IMAP) 基于万维网的电子邮件 两端的用户使用HTTP协议与服务器通信,服务器之间使用SMTP协议. 从而只要能够找到上网的计算机, 打开任何一种浏览器就可以非常方便的收发邮件. 网络安全计算机网络的安全威胁 被动攻击: 主要是截获, 即从网络上窃听他人的通信内容, 又称为流量攻击 主动攻击: 篡改: 故意篡改网络上传送的报文 恶意程序:包括计算机病毒, 计算机蠕虫,特洛伊木马和逻辑炸弹, 后门入侵等 拒绝服务: 包括分布式拒绝服务攻击, 攻击者向互联网的某个服务器不停发送大量分组而导致该服务器无法提供正常服务 数字签名数字签名必须保证以下三点： 报文鉴别: 接收者能够核实发送者对报文的签名； 报文的完整性: 发送者事后不能抵赖对报文的签名； 不可否认: 接收者不能伪造对报文的签名 鉴别分类 报文鉴别：即鉴别所收到的报文的确是报文的发送者所发送的，而不是其他人伪造的或篡改的。这就包含了端点鉴别和报文完整性的鉴别。 实体鉴别：仅仅鉴别发送报文的实体。实体可以是一个人，也可以是一个进程（客户或服务器）。这就是端点鉴别。","categories":[{"name":"计算机核心课程","slug":"计算机核心课程","permalink":"https://lizec.top/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%A0%B8%E5%BF%83%E8%AF%BE%E7%A8%8B/"}],"tags":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://lizec.top/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}]},{"title":"编译原理笔记","slug":"编译原理笔记","date":"2018-01-13T03:09:01.000Z","updated":"2018-06-05T07:44:33.441Z","comments":true,"path":"2018/01/13/编译原理笔记/","link":"","permalink":"https://lizec.top/2018/01/13/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%94%E8%AE%B0/","excerpt":"","text":"目录 引论 文法 词法分析 自顶向下分析 自底向上分析 LR分析 语法制导翻译 目标程序运行时组织 代码优化 引论 ------------------- 全文结构 编译程序(Compiler) 编译程序是一种翻译程序,它将不能被计算机识别的某种高级语言翻译成计算机能够识别的低级语言 一般编译程序分成五个逻辑模块:词法分析、语法分析、语义分析和中间代码生成、中间代码优化、目标代码生成 解释程序（Intepretter） 解释程序是一种翻译程序,它将不能被计算机识别的某种高级语言翻译成计算机能够识别的低级语言 它是逐个语句翻译的,边翻译边执行,不生成目标代码 文法 ------------------- 句子,句型和语言 设G[S]是一文法,若 S =*=&gt; x 则x是文法G[S]的句型 若上述x仅有终结符构成,则称x为文法G[S]的句子 文法G[S]的所有句子组成G[S]定义的语言 文法的类型 0型文法 递归可枚举 与图灵机等价 1型文法(上下文有关文法) 若α-&gt;β,则有|β|&gt;=|α|,仅S-&gt;ε除外 或αAβ-&gt;αcβ(即A的左右是α和β时才能使用产生式) 2型文法(上下文无关文法) 文法中每个产生式α-&gt;β都有α∈VN,β∈(VN∪VT)* 3型文法(正则文法) 文法中的每个产生式满足 A-&gt;aB 或A-&gt;a,其中A,B∈VN,a∈VT* 最左推导与最右推导 每次使用最左侧的非终结符进行替换称为最左推导 每次使用最右侧的非终结符进行替换称为最右推导,也称规范推导 短语 若S =*=&gt;αAδ且A =+= &gt; β(任意步推出),则称β是句型αβδ是对于A的短语 特别的,如果有A =&gt; β(一步推出),则称β是句型αβδ相对于规则A-&gt;β的直接短语(简单短语) 一个句型的最左直接短语称为该句型的句柄 短语的推导树含义 实际上短语就是推导树中A的叶子节点构成的符号串 如果A只有一层叶子节点(简单子树),那么这些叶子节点构成的串是A的直接短语 最左的简单子树构成的符号串称为句柄 词法分析 ------------------- ε-closure ε-closure(I)定义为从I开始,经过任意步ε可以到达的状态 **注意:**由于任何状态可以经过ε到达自己,所以I∈ε-closure(I) I是可能状态的集合,所有I包含一个或多个状态 move(I,a) move(I,a)定义为状态I经过步骤a后可以到达的所有状态的集合 在不确定有限自动机中,move(I,a)可以包含多个状态 NFA转DFA 求初始状态I的ε-closure(I) 对ε-closure(I)中的状态,对字母表中每个符号求move(I,ai) 对2中产生的状态求ε-closure,如果得到的集合没有出现过,加入结果集合中 对产生的新状态不断重复上述求ε-closure,以及move操作,直到不产生新状态 DFA最小化 无法到达的状态直接去掉 无效状态射出的弧直接去掉 DFA最小化算法 去除不可达状态和相关的弧 将所有节点按照接受状态与非接受状态分成两类 对每个集合中的状态,分析接受某一元素后的状态改变 如果新的状态均指向当前状态下的某一集合,则这些状态暂时等价 如果新的状态指向当前状态下的不同的集合,则将这些状态分成不同的集合,分裂后的每个集合指向同一目标集合 重复步骤3,直到不能分裂 正规式与有穷自动机的转换 有穷自动机转正则式 添加一个x节点,使用ε弧连接所有初始状态 添加一个y节点,使用ε弧连接所有接受状态 正则式转有穷自动机 状态x到第一个状态或最后状态到y之间可以添加一些ε弧 自顶向下分析 ------------------- FISRT集 FIRST集中的元素都是终结符 FIRST(A)等于A所有可能的推导中右端的第一个终结符 FISRT集算法 若X-&gt;ε,则ε∈FIRST(X) 若X为终结符,则X∈FIRST(X) 若X可推出多个符号且前面若干个符号可以推出空,则前面若干为空的符号的(FISRT(Ai)- {ε})∈FIRST(X) 若X可推出多个符号且所有符号都可以推出空,则FISRT(Ai)∈FIRST(X)且ε∈FIRST(X)注意: 分析一条产生式的FIRST集,如果需要其他符号的FIRST集,则递归的获取 递归结束后,将元素加入当前FIRST集,并判断当前递归元素是否为空,为空则递归的获取下一个元素的FIRST集 因为按照条件3,可以在一个产生式中产生多次递归,所以保存递归状态 FOLLOW集 FOLLOW集中所有元素都是终结符 FOLLOW(A)等于从S开始任意推导过程中,所有出现在A之后的终结符 也可以表述为从S开始任意推导过程中,所有出现在A之后的符号的FISRT集 FOLLOW集算法 对于文法开始符号S,有#∈FOLLOW(S) 若有(B-&gt;aA)则FOLLOW(B)是FOLLOW(A)的子集 若有(B-&gt;aAp) 则(FISRT(p)- {ε})∈FOLLOW(A) 若ε∈FIRST(p),则FOLLOW(B)是FOLLOW(A)的子集说明: 一定主要要先将#加入S的FOLLOE集 对于类似A-&gt;BC的产生式,相当于B-&gt;aA与B-&gt;εAp 有FOLLOW(A)∈FOLLOW(C) 有(FISRT(C)- {ε}) ∈ FOLLOW(B) 且 若ε∈FIRST(C)有FOLLOW(A)∈FOLLOW(B) 产生式右部如果只有一个元素,则无任何信息 SELECT集 FOLLOW集中所有元素都是终结符 当A-&gt;a有a不能推导空,则SELECT(A-&gt;a) = FIRST(a) 当A-&gt;a可以为空时,SELECT(A-&gt;a) = (FIRST(a) - {ε})∪FOLLOW(A) LL(1)文法 第一个L表示从左向右扫描,第二个L表示最左推导,1表示向前查看一个符号 当一个文法中的任意符号A的任意产生式的SELECT集不相交,则该文法是LL(1)文法 文法的等价变换 提取左公因子 消除左递归 对于产生式 A-&gt;Ab|r 可直接改写为 A-&gt;rA’ A’-&gt;bA’|ε 对于间接的递归,先使用带入变成直接递归,再消去直接递归 注意: 对于间接递归,不要忘记加入之前的非带入的部分 消除递归后一定要有一个推出ε的结束条件 自底向上分析 ---------------- 优先关系分析 HEAD(A)是A可以推导的所有的字符串的第一个字符组成的集合 LAST(A)是A可以推导的所有的字符串的最后一个字符组成的集合 注意: HEAD和LAST集中包含终结符和非终结符,不需要消去左递归,可以包含本身 一定要先加入产生式中的非终结符,每一步推导都要及时加入非终结符 #小于任何相邻的符号 优先级实际上就是可以规约符号的比两边的符号大 所以只用分析一个终结符a与一个非终结符X相邻的情况 如果有aX,则a小于所有X的HEAD集元素 如果有Xa,则X的所有LAST集元素大于a 直接相邻的两个符号相等(#除外),其他没有出现的关系都是未定义的 简单优先文法 简单优先文法满足以下条件 任意两个符号之间只有一种优先关系 任意两个产生式有不同的右部 规约过程 向右加入符号,直到有S[j] &gt; S[j+1] 再向左寻找,直到有S[i - 1] &lt; S[i] 将S[i]到S[j]之间的符号取出,查询产生式右部,进行替换 重复上述操作,直到规约为开始符号 可以看到规约的本质就是可以规约的串大于两端的串,从而进行识别和规约 算符优先分析 FIRSTVT集合LASTVT集定义与之前类似,大于小于的情况也类似 但是限定必须是终结符,而且在任意字符串中,可以忽略开始或者结束的非终结符 如果两个符号相邻或者中间间隔一个非终结符,则相等 注意: 无论是简单优先还是算符优先,都不要忘记先加上S’-&gt;#S#,否则后面都白做了 对于算符优先,一定要注意可以忽略非终结符的特点,对于等号的判断有较大影响 素短语与最短素短语 素短语是这样的一个短语，它至少含有一个终结符，并且除它之外不再含更小的素短语 最左素短语是指处于句型最左边的素短语 简单优先与算符有限比较 两种方法都是自下而上分析法，但简单优先法是找句柄归约成某个非终结符，而算符优先法是找最左素短语归约成统一的一个非终结符 LR分析 ------------- 最右推导与最左规约 最右推导指每次使用最右侧非终结符进行推导 最左规约指每次都将最左侧的符号规约成非终结符 两个正好是互逆的过程 最右推导也称为规范推导 活前缀从S开始,由规范推导产生的任意一个句型中,不超过句柄的部分称为活前缀 LR分析过程 一般RL分析程序由总控程序,分析栈(状态栈和符号栈),分析表构成 开始分析时,先将初始状态和左界符#入栈 分析到某一步时,首先根据栈顶状态S[i]与带读入符号a,查询ACTION[S[i],a] 如果ACTION[S[i],a] = S[j], 则表示要进行移入操作,将a与S[j]入栈 如果ACTION[S[i],a] = R[j], 则表示要进行规约操作 首先根据第j条产生式的要求,将栈顶的k个元素出栈 然后将规约后的符号入栈(设该符号为A) 最后根据GOTO[S[i-k],A]查询相应的状态,并将状态入栈 如果ACTION[S[i],a] = acc, 则表示分析完毕,接受输入的句子 如果ACTION[S[i],a] = ERROR或空白, 则表示分析的句子有错 LR(0)规范族的构造1. 求闭包 I的项目均在CLOSEURE(I)中 若A-&gt; a.Bp 属于CLOSEURE(I), 则每一个形如 B-&gt; .r 的项也属于CLOSEURE(I) 重复2的过程直到CLOSEURE(I)不增加注意: 此处B是非终结符 一定要重复添加操作,直到小圆点后只有终结符 2. 状态转移 对于形如A-&gt; a.Bp的项目,产生一条标记为B的弧连接A-&gt; aB.p 新产生的状态称为核,此节点的值等于核的闭包 对于形如A-&gt;E.的项目,进入了规约状态,不转移到其他状态 不断的转移获得核和求核的闭包,直到不产生新的状态 3. GO(I,X)的定义 GO(I,X) = CLOSEURE(J),其中J = {任何形如A-&gt;aX.p的项目|A-&gt;a.Xp属于I} 对应到DFA,即为当前节点上通过X弧到达的节点 4. 构造LR(0)分析表 若项目A-&gt;C.aB属于I[k]且GO(I[k],a) = I[j] 若a为终结符,则ACTION[k,a] = S[j] 若a为非终结符,则仅仅置GOTO[k,A] = j 补充: ACTION表中只有终结符的列,GOTO表中只有非终结符的列 若项目A-&gt;c.属于I[k] 则对任意终结符a[i]和#,有ACTION[k,a[i]] = r[j] 和ACTION[k,#] = r[j] 其中r[j]表示第j条产生式 若项目S’-&gt;S. 属于I[k], 则ACTION[k,#] = acc LR(0)的冲突 移入-规约冲突 即在一个节点上同时包含形如A-&gt;E.和A-&gt;a.bp这样需要规约或者移入的项目 由于LR(0)不向后查看符号,因此难以确定上述两种产生式如何选择 规约-规约冲突 即在一个节点上包含形如A-&gt;E.和B-&gt;F.这样同时多种不同需要规约的项目 SLR(1)分析表构造 表的基本构造方法与LR(0)相同 添加额外的冲突解决方法 冲突解决方法 设有一个规范族中有如下一个状态 I = {X-&gt;a.bp, A-&gt;r., B-&gt;d.} 如果移入符号与各规约符号的FOLLOW集两两不相交,则可以解决冲突 即 FOLLOW(A)交FOLLOW(B)为空,FOLLOW(A)交{b}为空,FOLLOW(B)交{b}为空在此状态的分析报表中,任意一个符号a 如果a=b 则ACTION[k,a] = I[j] 如果a属于FOLLOW(A),则ACTION[k,a] = r[j] 如果a属于FOLLOW(B),则ACTION[k,a] = r[j] 其他情况,报错 改进的SLR(1)分析表 基本构造与SLR(1)分析表相同 对于形如 A-&gt;r.的产生式,只有a属于FOLLOW(A)的元素,在表中填入转移状态,其他可以直接报错 说明: 比较来看,唯一的改进就是对于所有的符号,都按照冲突解决办法,求解了FOLLOW集 并且对于不在FOLLOW集中的元素,都直接进行了报错处理,从而提前发现错误 LR(1)构造方法 初始S&#39;-&gt;.S,#属于项目I I的项目均在CLOSEURE(I)中 若A-&gt; α.Bβ,a 属于CLOSEURE(I), B-&gt;r是文法的产生式,若β∈V*, b∈FIRST(βa),则B-&gt;.r,b也属于CLOSEURE(I) 重复2的过程直到CLOSEURE(I)不增加 注意: 通常β是终结符,因此没有求FIRST集的过程 如果β为空,则实际上就是由a决定 后续的步骤与LR(0)基本相同,但在规约的是时候,只有相应的前向搜索符时才规约 语法制导翻译 ------------- 继承属性与综合属性 设有产生式A-&gt;α且b = f(c1,c2,..,ck) 若b是A的属性,则b是综合属性 若b是产生式右部的某个符号的属性,则b是继承属性 说明: 综合属性是从语法树下面的属性计算出来的 继承属性是从语法树上面继承下来的 终结符只有综合属性,该属性由此法分析程序提供 语法制导翻译与翻译模式 在语法分析过程中，随着分析的步步进展，每当进行推导或归约时，同步的去执行每个产生式所附带的语义规则描述的语义动作或语义子程序，这样进行翻译的办法称作语法制导翻译 如果在构造属性文法时把语义规则用花括号括起来，插入到产生式右部的合适位置上，用以指明语义规则的计算次序，这样的属性文法称为翻译模式（或称为翻译方案） 四元式 (OP,ARG1,ARG2,RESULT) 四元式直接通过临时变量相互联系 单目运算使用ARG1域,转移语句目标位置放在RESULT域 三元式 编号 (OP,ARG1,ARG2) 其中ARG1与ARG2是指向符号表或其他三元式的指针 间接三元式 结构与三元式相同 间接码表包含一个指示三元式编号的域,其中的出现顺序指示执行顺序 目标程序运行时组织 ------------- 运行时存储区结构 目标代码区 静态数据区 栈区 堆区 几个术语 name 变量名 environment 将名字映射到存储位置 storage 存储位置 state 将存储位置映射到值 value 值 内存分配方式 静态分配 在编译时确定空间,如C中的静态变量,全局变量 动态分配 栈式动态分配 堆式动态分配 代码优化 ------------- 代码优化技术 删除多余运算(删除公共子表达式) 如果统一表达式在多处出现,可以只计算一次,其他地方直接引用 循环不变代码外提 强度削弱 将乘法转化为加法 变换循环控制条件 通过改变循环变量,尝试去除一些变量 合并已知量和复写传播 编译时初始值已知的运算可以在编译过程中直接计算出来,从而减少运行时运算(合并已知量) 变量T被变量S赋值,后续引用变量T时若T未改变,可改为直接引用变量S(复写传播) 删除无用赋值 经过变换循环控制条件和复写传播,可能有一些变量被赋值后却没有引用,可以直接删除这些变量 基本块 指程序中一个单入口、单出口的线性程序块（顺序执行的语句序列） 所谓基本块，是指程序中一个单入口、单出口的线性程序块（顺序执行的语句序列） 入口语句 程序的第一个语句 条件转移语句或无条件转移语句的转移目标语句 紧跟在条件转移语句后面的语句 基本块划分算法 找到所有的入口语句 基本块时从入口语句开始到下一个入口语句之前的所有语句 没有被划分到任何基本块的语句是不可到达的,可以直接删除 基本块内优化方法 删除公共子表达式 删除无用代码 重新命名临时变量 交换语句次序","categories":[{"name":"计算机核心课程","slug":"计算机核心课程","permalink":"https://lizec.top/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%A0%B8%E5%BF%83%E8%AF%BE%E7%A8%8B/"}],"tags":[{"name":"编译原理","slug":"编译原理","permalink":"https://lizec.top/tags/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/"}]},{"title":"人工智能概论","slug":"人工智能概论","date":"2017-12-31T01:04:05.000Z","updated":"2020-06-26T14:46:28.831Z","comments":true,"path":"2017/12/31/人工智能概论/","link":"","permalink":"https://lizec.top/2017/12/31/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%A6%82%E8%AE%BA/","excerpt":"","text":"目录 第一章 绪论 第二章 知识表示 第三章 搜索方法 第四章 经典逻辑推理 第五章 专家系统 第六章 不确定推理 ## 第一章 绪论 人工智能(Artificial Intelligence, AI) 是一门综合性学科,它旨在研究如何利用计算机等现代工具设计模拟人类智能行为的系统 图灵测试(Turing Test) 在2000年之前,计算机有30%的概率蒙骗一个普通人达到5分钟 图灵测试仅反映了结果的比较,没有涉及视为过程,没有指出什么是人 三个主要学派 符号主义学派(逻辑主义, 心理学派) 主要观点: AI起源于数理逻辑,人类认知的基元是符号,认知过程是符号的表示上的一种运算 代表性成果: 厄尔和西蒙等人研制的称为逻辑理论机的数学定理证明程序LT 连接主义学派(仿生学派或心理学配) 主要观点: AI起源与仿生学,特别是人脑模型,人类认知的基元是神经元,认知过程是神经元的连接活动过程 代表性成果: 由麦克洛奇和皮兹创立的脑模型，即MP模型 行为主义学派(进化主义,控制论学派) 主要观点: AI起源与控制论,只能取决于感知和行为,取决于对外界复杂环境的适应,而不是推理 代表性成果: Brooks教授研制的机器虫 人工智能研究和应用领域 定理证明 专家系统 机器学习 自然语言理解 智能检索 机器人学 自动程序设计 组合调度问题 模式识别 机器视觉 ## 第二章 知识表示 一阶谓词的逻辑表示 是一种基于数理逻辑的表示方法 其基础是命题 命题 一个陈述句称为断言 具有真假意义的断言称为命题 谓词 是命题的谓语,表示个体的性质,状态或个体之间的关系 个体: 是命题的主语,表示独立存在的事物或概念 谓词与函数的区别 谓词是个体域D到{T,F}的映射 函数是个体域到个体域的映射 谓词可独立存在,函数只能作为谓词的个体 项 单独的一个个体词是项 若t1,t2,…,tn是项,f是n元函数,则f(t1,t2,…,tn)是项 有(1),(2)生成的表达式是项 项是个体常量,个体变量和函数的统一 原子谓词公式 若t1,t2,…,tn是项, P是谓词,则称P(t1,t2,…,tn)为原子谓词公式 一阶谓词等价式 吸收律 量词分配律 全体对且分配 存在对或分配 推理规则 P规则 在任何的步骤上都可以引入前提 T规则 在推理时,如果前面的步骤中有一个或多个公式永真蕴含S,则可把S引入推理过程 CP规则 如果能从R和前提集合中推出S,则可从前提集合推出R-&gt;S 反证法规则 若P=&gt;Q,当前仅当P且非Q不可满足 推广到有n个变元的情况,(P1,P2,…,Pn) =&gt; Q,当且仅当(P1,非P2,…,非Pn)且非Q不可满足 谓词逻辑表示方法 根据要表示的知识定义谓词 使用连词,量词把这些谓词连接起来 产生式表示法 确定性知识,事实可用三元组表示 (对象,属性,值) 例如: (雪,颜色,白), (热爱,王峰,祖国) 非确定性知识,事实可用如下四元组表示 (对象,属性,值,可行度因子) 规则的作用 描述事物之间的因果关系 基本形式 P -&gt; Q 或 IF P THEN Q 即,如果前提P满足,则可推出结论Q或执行Q所规定的操作 产生式与蕴含是的主要区别 蕴含式表示的知识只能是精确的,产生式表示的知识可以是不确定的 蕴含式的匹配一定要求是精确的,而产生式的匹配可以是不确定的 产生式系统 一个产生式系统由以下3个基本部分1[规则库] &lt;--&gt; [控制机构] &lt;--&gt; [综合数据库] 规则库(Rule Base, RB) 也称知识库(Knowledge Base,KB),用于存放求解问题有关的所有规则的集合 作用: 是产生式系统问题求解的基础 要求: 知识的完整性,一致性,准确性,灵活性和知识组织的合理性 控制机构 也称推理机,用于控制整个产生式系统的运行,确定问题求解的推理线路 主要任务包括: 选择匹配,冲突消解,执行操作,不确定推理,路径解释,终止推理 框架表示法 有若干接点和关系(统称为槽)构成的网络 是语义网络的一般化形式 没有固定的推理机理,遵循匹配和继承的原理 善于表示结构性的知识 ## 第三章 搜索方法 表示方法 状态空间 用状态和算符来表示问题 状态 描述问题求解过程不同时刻的状态的数据结构,可用一组变量的有序集表示 当给每个分量一个确定值时,即得到了一个具体的状态 算符 引起状态中某些分量发生变化,从而使问题由一个状态变为另一个状态的操作 在产生式系统中,每条产生式规则就是一个算符 算符每次使用使状态发生改变,达到目标状态时,由初始状态到目标状态使用的算符序列就是问题的一个解 由问题的全部状态以及一些可用的算符构成的集合称为问题的状态空间 一般用一个三元组表示:(S,F,G) 其中S是问题的所有初始状态构成的集合,F是算符的集合,G是目标状态的集合 与或树 把复杂的问题转化为若干需要同时处理的较为简单的子问题后,分别求解 如果问题P可以归约为一组子问题P1,P2,…,Pn,并且当任意子问题Pi无解时,原问题无解 则称此归约为问题的分解 分解的子问题的与 同原问题等价,使用与树表示 如果问题P可以归约为一组子问题P1,P2,…,Pn,并且子问题Pi中所有的子问题都无解时,原问题才无解 则称此种归约为问题的等价变化 变换得到的子问题的或 同原问题等价,使用或树表示 本原问题 不能再分解或变换,而且可以直接可解的子问题 端结点与终止节点 没有子节点的节点称为端结点 本原问题对应的节点称为终止节点 终止节点一定是端结点,端结点不一定是终止节点 可解节点 满足以下条件之一的节点称为可解节点 是终止节点 是一个或节点,且子节点至少有一个可解 是一个与节点,且全部子节点都可解 状态空间的搜索方法 盲目搜索 数据结构 OPEN表: 存放待考察的节点 CLOSED表: 存放已考察的节点 搜索方法(盲目搜索) 宽度优先 非改进方法中,从OPEN表取出元素,判断是否是目标节点 改进方法中,在放入OPEN表前,判断是否是目标节点 深度优先 有界深度优先 设计搜索深度dm,当达到深度后就选择其他兄弟节点扩展 改进算法 先设置一个较小的dm,如果全部遍历后不能满足,且CLOSED表中还存在可扩展节点,那么将这些节点送回OPEN表,并扩大dm 重复上述操作直到问题求解 此方案不一定获得最优解 可以设置表R,记录搜索过程中得到的目标节点的路径长度,然后继续搜索 保证搜索的解的路径长度最短,则可以保证获得最优解 代价树的宽度优先搜索 边上标有代价的树称为代价树,使用g(x)表示从初始节点到节点x的代价 若c(x1,x2)表示从父节点x1到子节点x2的代价,则有g(x2) = g(x1) + c(x1,x2) OPEN表中的节点在任意时刻都是按照代价的大小排序的,每次都选择代价最小的进行扩展 是完备搜索,如果有解,定必可以求出最优解 代价树的深度优先搜索 每次从刚扩展的子节点中,选择代价最小的进行考察 是不完备的,可能陷入无穷分支或局部最优 搜索方法(启发式搜索) 启发式搜索一般属性 估计函数 f(x) = g(x) + h(x) 其中g(x)是从初始节点到目标节点已经实际付出的代价 h(x)是当前节点到目标节点估计的代价,h(x)称为启发函数,体现了问题的启发性信息 局部择优搜索 每次一个节点扩展以后,按f(x)最小节点进行扩展,由于每次只在子节点范围内选择,因此称为局部择优 全局择优搜索 每次从OPEN表的全体节点中,选择一个估计值最小的节点进行扩展 有序搜索 前面的搜索都是针对树状结构,每个节点只有一个父节点,如果搜索的是有向图,就会有多个父节点,从而导致大量的搜索冗余 每次产生一个新节点i时,与所有已经生产的节点进行比较,若节点i是一个已经产生的节点,则表示找到一个通过节点i的新路径,如果节点i的值更小,则更新节点i的父节点指针 与或树的搜索方法 可解与不可解的确定 “与”节点只有全部节点可解时,才可解 “或”节点只要有一个节点可解,就可解 搜索方法 宽度优先算法 与状态空间基本一致 主要区别在于,在搜索过程中需要多次调用可解标识过程或不可解标识过程 从OPEN表读取一个节点,判断是否是可扩展 如果可扩展,对其进行扩展,并存入OPEN表 对每个扩展节点分析是否为终止节点 如果是,则标识这些节点是都可解,并递归的标识其父节点 如果可以标识到初始节点,则问题可解,否则删除标识过程的可解先辈节点 如果不可扩展,标记为不可解节点 递归的标识其父辈节点 如果可以标识到初始节点,则问题不可解,否则删除标识过程中的不可解前辈节点 深度优先搜索 每次将刚生产的节点置于OPEN表的首部 有序搜索 解树的代价 设c(x,y)表示节点x到节点y的代价 如果x是终结节点,则定义x的代价h(x) = 0 如果x是”或”节点,则x的代价为 h(x) = min&#123;c(x,yi) + h(yi)&#125; 如果x是”与”节点,则x的代价有两种方法 和代价法:h(x) = ∑(c(x,yi) + h(yi)) 最大代价法:h(x) = max&#123;c(x,yi) + h(yi)&#125; 如果x不可扩展,又不是终止节点,则h(x)为无穷大 按照上述方法逐步推导,就可以求出初始节点的代价,也就是解树的代价 希望树 希望树是搜索过程中,最有可能称为最优解树的那棵树 与或树的启发式搜索过程就是不断的选择,修正希望树的过程 ## 第四章 经典逻辑推理 推理类型 演绎推理 从已知的一般性知识出发,去推出蕴含在其中的个别情况的的结论,核心是三段论 不能增加新知识 归纳推理 由个别到一般的推理方法,从足够多的事例中归纳一般性的结论 是增加新知识的过程 默认推理 又称缺省推理,是知识不完全的情况下的推理 谓词公式化为字句集 消去蕴含和等价 将否定移动到紧靠谓词的位置 确保每个否定只作用于一个谓词 对变元标准化 不同子句中的变量名通过替换使得互不相同 从而避免后续的合并中产生冲突 化为前束范式 所有量词移动到公式最左边 移动时不能改变相对顺序 消去存在量词 如果存在量词不再全称量词的辖域中,直接用个体变元替换 否则使用全称量词的函数替换 化为标准形 即子句之间变换成合取式(and) 其中的析取部分(or)可以使用析取对和合取分配律展开 消去全称量词 消去合取式 更换变量名 任意两个子句中不能出现同样的变量名 因为所有子句都是在全称量词的辖域内,且任意两个子句之间没有任何关系 Skelem函数特性 在谓词公式化子句集的过程中,如果Skelem函数不同,则最后结果也不唯一 如果原谓词公式为不可满足式,则转化后的子句集也不可满足 如果原谓词公式非永假,则子句集并不一定等价 设有谓词公式F,其标准子句集为S,则F为不可满足的充要条件是S为不可满足 归结式的定义及性质 若P是原子谓词公式,则称P与非P为互补文字 设C1与C2是子句集中任意两句,若C1中文字L1与C2中文字L2互补,那么可以从C1与C2中分别消去L1与L2,并将C1与C2中余下的部分按析取关系构成一个新的子句C12,这样过程称为归结 C12是C1与C2的归结式,C1和C2是C12的亲本子句 基于归结反演的问题求解 将已知前提使用谓词公式表示,并转化为子句集 把带求解的问题也用谓词公式表示,然后将其否定式与谓词ANSWER构成一个析取式. ANSWER是为了求解问题而专设的谓词,其变元数量和变元名必须与问题公式的变元完全一致 把此析取式化为子句集,并且把该子句集并入到子句集S中,得到S’ 对S’使用归结原理进行归结 若在归结树的根节点中仅仅得到归结式ANSWER,则答案就在ANSWER中 123456789101112131415161718已知: 张和李是同班同学,如果x和y是同班同学,则x的教室也是y的教室,现在张在325上课问: 现在李在哪个教室上课解：首先定义谓词： C(x, y) x和y是同班同学； At(x, u) x在u教室上课。把已知前提用谓词公式表示如下： C(zhang, li) (∀x) (∀y) (∀u) (C(x, y)∧At(x, u) -&gt; At(y,u)) At(zhang, 325) 把目标的否定用谓词公式表示如下： ﹁(∃v)At(li, v) // 不存在v,使得李在v教室上课把上述公式化为子句集： C(zhang, li) ﹁C(x, y)∨﹁At(x, u)∨At(y, u) At(zhang, 325)把目标的否定化成子句式， ﹁At(li,v) ∨ANSWER(v) 代替之。 ## 第五章 专家系统 专家系统结构 知识库(Knowledge Base) 以某种存储结构存储的专家知识 全局数据库(Global Database) 也称黑板 存储求解问题的初始数据和推理得到的中间数据,以及最后的推理结论 推理机(Reasoning Machine) 根据全局数据库的当前内容,从知识库中选择匹配成功的规则,并通过执行可用规则来修改数据库中的内容 解释机构(Expositor) 用于向用户解释专家系统的行为 包括解释”系统怎样得到这一结论”,”系统微信么要提出这样的问题来询问用户”等 用户接口(Interface) 系统与用户进行对话的界面 用户通过接口输入必要的数据,提出问题和输出推理结果,以及向用户做出解释等 知识获取 把知识工程师提供的知识转化为知识的内部标识模式并存入知识库中 在存储过程中,对知识的一致性,完整性检查 ## 第六章 不确定推理 知识的不确定性 证据的不确定性 证据的歧义性: 证据可以由多种理解 证据的不完全性 证据尚未收集完全 证据的特征值不完全 证据的不精确性 证据的模糊性 证据的可信性 证据的随机性 规则的不确定性 规则前件的不确定性(信息的可信度) 规则前件的证据组合的不确定性(组合方式) 规则本身的不确定性(规则强度) 规则结论的不确定性(推论最后的可信度) 推理的不确定性 证据组合的不确定测度计算模式 合取计算方式 CF(e1∧e2) = min(CF(e1),CF(e2)) 析取计算方式 CF(e1∨e2) = max(CF(e1),CF(e2)) 否定计算方式 CF(﹁e) = - CF(e) 并行规则的不确定测度计算模式 即如果有多个规则可以获得同一结论,求结论的h的不确定度 CF(h,e1e2) = CF(h,e1) + CF(h,e2) - CF(h,e1)CF(he2) (同正) CF(h,e1e2) = (CF(h,e1) + CF(h,e2)) / (1 - min( |CF(h,e1)| , |CF(h,e2| )) (异号) CF(h,e1e2) = CF(h,e1) + CF(h,e2) + CF(h,e1)CF(he2) (同负) 顺序(串行)规则的不确定测度计算模式 如果有if e1 then e2 和 if e2 then h 求 if e then h 的不确定度 CF(h,e1) = CF(h,e2) X max(0,CF(e2,e1)) 一个系统只要给定上述三个情况的计算方法,即可获得各种证据组合的不确定度 信任度 信任度MB(h,e)表示证据e出现时,对h成立的信任程度的增加量 不信任度MD(h,e)表示证据e出现时,对h成立的不信任程度的增加量 两者的取值范围都是[0,1] 其中一个大于零,则另一个必定为零 可信度 CF(h,e) = MB(h,e) - MD(h,e) 取值范围是[-1,1] 大于零表示证据e可以增加h的可信度 小于零表示证据e可以减少h的可信度 等于零表示证据e与h无关","categories":[{"name":"计算机核心课程","slug":"计算机核心课程","permalink":"https://lizec.top/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%A0%B8%E5%BF%83%E8%AF%BE%E7%A8%8B/"}],"tags":[{"name":"人工智能","slug":"人工智能","permalink":"https://lizec.top/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"}]},{"title":"CSharp学习笔记","slug":"CSharp学习笔记","date":"2017-12-23T02:29:33.000Z","updated":"2018-06-18T01:50:47.887Z","comments":true,"path":"2017/12/23/CSharp学习笔记/","link":"","permalink":"https://lizec.top/2017/12/23/CSharp%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","excerpt":"","text":"这是关于C#的学习笔记,假定读者已经具有C与Java的基础,本文只涉及与这两种语言有差异的C#特性 目录 基本语句 基本类型属性与方法 类与函数 垃圾回收与资源管理 属性与索引器 泛型 委托与事件 LINQ 窗体和控件 基本语句 ----------------------- 格式码 一般格式为&#123;N [,M]: D&#125; N为一个数字,表示对应第n个参数 M为一个数字,表示总长度,为负数时表示左对齐 D表示格式码,具有如下选项 格式码 含义 C 金额 D 十进制整数 F 浮点数 0 指定具体的长度,不足用0填充 # 同0,但省略无效的0 12345678910111213示例 | 结果--------------------------------------------|--------------------Console.WriteLine(&quot;&#123;0:F4&#125;&quot;,10.5); | 10.5000Console.WriteLine(&quot;&#123;0:D5&#125;&quot;,12); | 00012Console.WriteLine(&quot;&#123;0:00000&#125;&quot;, 123); | 00123Console.WriteLine(&quot;&#123;0:000&#125;&quot;, 12345); | 12345Console.WriteLine(&quot;&#123;0:0000&#125;&quot;, 123.64); | 0124Console.WriteLine(&quot;&#123;0:00.00&#125;&quot;, 123.6484); | 123.65Console.WriteLine(&quot;&#123;0:####&#125;&quot;, 123); | 123Console.WriteLine(&quot;&#123;0:####&#125;&quot;, 123.64); | 124Console.WriteLine(&quot;&#123;0:####.###&#125;&quot;, 123.64); | 123.64Console.WriteLine(&quot;&#123;0:####.##&#125;&quot;, 0); | 0Console.WriteLine(&quot;&#123;0:####.##&#125;&quot;, 123.648); | 123.65 注意: 上述格式码还可以在String.Format和ToString函数中使用 在DateTime的ToString函数中还可以通过y,M,d,h,m,s来格式化时间 checked与unchecked关键字 使用checked关键字可以对其后的语句中的算术运算进行溢出检查 只适用于整数,如int和long 如果计算结果溢出,会抛出OverflowException 使用unchecked关键字可以强制不进行溢出检查 无论是否溢出,都必定不会抛出OverflowException1234int m = int.MaxValueint n = checked(m + 1); // 抛出异常int o = unchecked(m + 1); // 不抛出异常 使用params object[] 实现可变参数, 使用此方式声明的函数可以对应任意数量的任意类型的参数123456789void Hole(params object[] args);Hole(); // =&gt; Hole(new Object[0])Hole(null); Hole(array); Hole(&quot;string&quot;,3); // =&gt; Hole(new Object[]&#123;&quot;string&quot;,3&#125;)// Console.WriteLine方法的声明public static void WriteLine(string format, params object[] args) 可空类型 对于值类型的变量,不能设置为null,但可以通过可空类型实现这一点 在基础类型后加上一个?构成相应的可空类型 正常的值类型变量可以赋值给相应的可空类型,但反之不行 任意可空类型具有两个属性,HasValue用来判断是否为空,Value用来读取变量值 其中Value是只读属性,如果需要修改变量,还是需要使用普通的赋值语句 1234567891011121314int ? i = null;int j = 19;i = 19; // 正常类型向可空类型赋值,允许j = i; // 可空类型向正常类型赋值,不允许if(!i.HasValue)&#123; i = 99;&#125;else&#123; Console.WriteLine(i.value);&#125; ref与out关键字 ref和out都用于函数形参声明 ref表示引用这个参数,无论这个参数是一个类还是一个基本类型 out与ref效果相同,但是ref要求传入的参数必须已经初始化,而out没有这一要求 out主要用于在函数内向外部的参数赋值 ref与out都带有一定的语义信息,有时虽然没有效果,但是可以起到提示其他程序员的效果 函数调用时,对应的实际参数也需要加上ref或out关键字12345678910111213141516int addOne(ref int n)&#123; n = n + 1;&#125;int initToThree(out int n)&#123; n = 3;&#125;int m()&#123; int n; initToThree(out n); // n = 3 addOne(ref n) // n = 4&#125; is与as关键字 is用于判断一个实例是不是属于一个类,可以用于辅助类型转换 as尝试将一个实例转化为一个指定的类 如果成功,则返回指定的类 如果失败,则返回null12345678910111213WarppedInt wi = new WarppedInt();...object o = wi;if(o is WarppedInt)&#123; // do&#125;WarppedInt temp = o as WarppedIntif(temp != null)&#123; // do&#125; foreach循环 使用foreach in 的格式进行foreach循环, 语义和个语言一致 迭代变量是只读的,不可修改 基本类型属性与方法 ----------------------- String常用属性和方法 函数 作用 String.Empty 空字符串 string.Compare(string s1,string s2) 逐一比较字符, s1大时返回1,否则返回0或者-1 Contains( string value ) 返回是否包含指定的字符串 IndexOf(string s, int startIndex) 返回给定字串第一次出现位置的索引, 第二个参数可以省略 LastIndexOf() 参数与IndexOf类似,但返回最后一次出现的位置 IndexOfAny(char[] anyOf) 返回给定数组中任意字符第一次出现的索引 Substring(int startIndex，int count) 从指定位置截取指定长度的字符串 Remove(int startIndex,int count) 删除指定内容,返回新字符串 Replace (string oldStr,string newStr) 替换指定内容,返回新字符串 Insert(int startIndex,string value) 插入指定的内容,返回新字符串 Join(string separator, string[] value) 将给定的字符串数组使用指定的分隔符连接组成一个新的字符串 Split(params char[] separator) 使用指定的分隔符切分当前的字符串 ToUpper() 转化为大写 toLower() 转化为小写 多维数组和交错数组123456789101112131415161718192021// 多维数组时真的多维数组int[,] arr = new int[3,5];int[,] n2 = new int[,] &#123; &#123;1, 2&#125;, &#123;3, 4&#125;, &#123;5, 6&#125; &#125;;// 交错数组就是数组的数组,每行长度可以不一致int[][] n1 = new int[2][ ] &#123; new int[ ] &#123;2,4,6&#125;, new int[ ] &#123;1,3,5,7,9&#125;&#125;;arr[2, 3] = 4;n1[1][2] = 2;// 使用Resize函数可以调整数组大小// 如果新数组小于原数组,则忽略之后的元素// 如果新数组大于原数组, 补充0// 如果一样大,则不进行任何操作, 注意使用ref关键字int[] arr = new int[] &#123; 1, 2, 3, 4, 5 &#125;;Array.Resize(ref arr, 3); 此外数组还提供Average,Sum,Max,Min,Sort,Reverse进行简单的数据操作 类与函数 -------------------- 枚举 与C一样,枚举对应的是一个整数 每个枚举类型变量都可以使用ToString函数输出对应的名称 使用强制类型转换可以得到枚举变量对应的数字 可以手动指定某一个枚举值的具体数值,也可以将两个枚举值设为同样的数值123456789101112enum Season &#123; Spring = 1, // 手动指定值 Summer, Fall, Autumn = Fall, // 设为同样的值,进行某种意义上的兼容 Winter&#125;;Season ? colorful = null;colorful = Season.Fall;Console.WriteLine(colorful.ToString()); 使用Enum.GetNames和Enum.GetValues获得枚举的名称和值 两个函数都接受一个Type类型变量,可以使用typeof(枚举集合名)获得相应的Type类型对象 1var list = Enum.GetNames(typeof(Season)); // 获得Season的枚举名,即 Spring,Summer,... 结构 与C一样,C#的结构也是一个值类型,并且存放于栈上 与类相比,结构有一些差异 结构不能定义无参数构造函数 结构不能在声明中初始化 结构可以使用new创建,也可以直接声明,两种方式都是创建在栈上 函数覆盖与重载 C#中,所有函数默认是非虚的,因此如果希望此函数可以多态,则必须使用virtual关键字声明 如果没有任何设置,在子类中覆盖了一个父类的函数,编译器会提出警告 可以使用new关键字引导一个函数,表示自己就是要覆盖一个非虚的函数,让编译器安心 在子类中,使用base调用父类的函数 注意,使用override关键字时,才是重写,此时会检查是否重写的是虚函数等操作 如果不使用override关键字,直接定义函数,是覆盖操作12345678910111213141516171819202122232425262728293031323334class Mammal&#123; public void Talk() &#123; // do something &#125;&#125;class Horse:Mammal&#123; new public void Talk() &#123; // do something others &#125;&#125;// Object中ToString的示例class Object&#123; public virtual string ToString() &#123; ... &#125;&#125;class MyClass&#123; public override string ToString() &#123; base.ToString() ... &#125;&#125; 扩展方法 对于一个类,有时可能只是想扩展一个方法,但直接继承会编写大量重复的代码 可以使用扩展方法对当前的类或结构进行扩展 需要定义一个静态类,在这个类中,为需要扩展的类或结构提供静态方法 使用this关键字引导,后面是需要扩展的类型12345678910111213static class Util&#123; // 为int类型扩展一个取反的方法 public static int Negate(this int i) &#123; return -1; &#125;&#125;// 在其他地方可以直接调用扩展的方法int x = 42;Console.WriteLine(&quot;x.Negate &#123;0&#125;&quot;, x.Negate()); 密封类 使用sealed修饰一个类表示此类不可作为基类 使用sealed修饰方法可以使一个虚方法不可再次被重写 接口,抽象类,抽象方法 与Java一致,使用interface定义接口,使用abstract定义抽象类和抽象方法 垃圾回收和资源管理 托管资源与非托管资源 与Java一样,C#会自动管理所有的托管资源,例如分配的内存 对于非托管资源,C#有析构机制,从而可以类似C++的释放资源 非托管资源常见有文件流,网络连接,数据库连接等 析构器 析构函数声明方法与C++一致 C#对析构函数的实现机制保证了即使在析构函数中发生异常也可以保证调用父类的析构函数 实现了析构器的类在内存回收的时候会先进入一个队列 回收机制在保证这些类的析构方法被调用以后才会进行内存释放 不定义析构器则可以避免这一过程,从而提高运行效率 析构函数的调用时机是不确定且无法控制的 因此虽然析构函数有着和C++析构函数一样的名称,但实际上更加接近Java的finalize()方法` 资源清理 除了定义析构函数以外,还可以定义资源清理函数来手动释放资源,从而明确资源的释放时间 以下演示了如何同时使用析构函数和资源清理函数 123456789101112131415161718192021222324252627282930313233343536373839404142434445class Example : IDisposable&#123; private Reasource scarce; private bool disposed = false; ~Example() &#123; this.Dispose(false); &#125; public virtual void Dispose() &#123; // 被用户手动调用了 this.Dispose(true); GC.SupressFinalize(this); // 告诉GC不要调用此方法的析构函数 &#125; public virtual void Dispose(bool disposing) &#123; if(!this.disposed) &#123; if(disposing) &#123; // 此处释放托管资源,例如将大型数组置为null &#125; // 此处释放非托管资源,例如文件流 this.disposed = true; &#125; &#125; public void someBahavior() &#123; checkIfDisposed(); // 每个常规方法都需要检查资源是否被释放 ... &#125; private void checkIfDisposed() &#123; if(this.disposed) &#123; throw new ObjectDisposedException(&quot;对象已经被清理&quot;); &#125; &#125;&#125; 注意: 由于析构函数与资源清理函数都实现了同样的功能,而又没有强制资源清理函数一定被调用,因此存在多种可能的情况 接受bool值的Dispose函数通过对this.dispoesd的检查,保证此方法可以被多次调用,从而无论析构函数与Dispose函数如何调用,都能保证最后资源被正确的释放 用户手动调用时,释放非托管资源并将托管资源置null(便于垃圾回收器标记和清除),并且通知GC不要调用析构函数 用户没有手动调用时,则在析构函数中释放非托管资源,由于此时已经进入垃圾回收过程,因此不需要将托管资源置为null 由于用户可以手动释放资源,因此在每个方法中都需要检查非托管资源是否被释放 对this.dispoesd的检查不是线程安全的, 因此多线程下可以考虑加锁(使用lock(this)语句块) using语句与IDisposeable接口 通过此组合实现对某些资源的自动管理,使资源可以得到立即的释放 using后的类型必须实现了IDisposable接口 注意: 内存始终是由垃圾回收机制管理的,这里的资源释放指的是对象内部持有的非托管资源的释放(例如文件流)12345678910111213141516171819202122232425262728293031using(TextReader reader = new StreamReader(filename))&#123; string line; while((line = reader.ReadLine()) != null) &#123; Console.WriteLine(line); &#125;&#125;&lt;==&gt;&#123; TextReader reader = new StreamReader(filename); try &#123; string line; while((line = reader.ReadLine()) != null) &#123; Console.WriteLine(line); &#125; &#125; finally &#123; if(reader != null) &#123; ((IDisposable)reader).Dispose(); &#125; &#125;&#125; 扩展 ----------------------- 属性 是字段和方法的集合,看起来像字段,用起来像方法12345678910struct ScreenPoint&#123; private int _x, _y; public int X &#123; get &#123;return this._x;&#125; set &#123;this._x = rangeChecked(value);&#125; &#125;&#125; 通过控制是否创建get与set,可以决定属性是否只读,只写或者执行某些检查等 注意:C#不推荐使用下划线开头的命名方法,但此处是例外 自动生成属性 C#编译器可以自动生成属性的get与set方法 后续如果添加逻辑,也可以直接更改此方法,不用修改其他地方 1234class Circle&#123; public int Radius&#123;get; set;&#125;&#125; 索引器 通过定义索引器,使一个实例可以像数组一样使用12345678910111213141516171819struct IntBits&#123; public bool this[int index] &#123; get &#123; return (bits &amp; (1 &lt;&lt; index)) != 0; &#125; set &#123; if(value) bits |= (1 &lt;&lt; index); else bits &amp;= ~(1 &lt;&lt; index); &#125; &#125;&#125; 泛型 -------------------------- 泛型 泛型的方法与Java基本一致 范型约束 如果定义的某种范型要求其实例必须实现某种方法可以按照如下格式定义 例如以下声明要求实际的T类型必须实现IPrintable接口,否则会报告编译错误1public calss PrintableCollection&lt;T&gt; where T : IPrintable &#123; ... &#125; 泛型库 集合 说明 List&lt;T&gt; 列表 Queue&lt;T&gt; 队列 Stack&lt;T&gt; 堆栈 LinkedList&lt;T&gt; 双向链表,对两端的插入与删除做了优化 HashSet&lt;T&gt; 集合 Dictionary&lt;TKey,TValue&gt; 哈希表 SortedList&lt;TKey,TValue&gt; 有序列表,必须实现IComparable接口 协变接口和逆变接口 协变性:如果泛型接口中的方法能返回字符串,那么也能返回对象(所有字符串都是对象) 逆变性: 如果泛型接口中的方法能获得对象参数,那么也能获得字符串参数(所有对象能做的事情,字符串都能做) 协变性在泛型名前加上out关键字,逆变性在泛型名前加上in关键字 枚举集合 实现了System.Collections.IEnumerable接口的集合 枚举集合可以被foreach遍历 委托与事件 --------------------------- 委托 之所以称为委托,是因为一旦被调用,就”委托”所引用的方法进行处理 看起来像一个函数指针,但委托是类型安全的,且一个委托可以同时引用多个方法 定义方法1234567891011121314151617class Controller&#123; delegate void stopMachineryDelegate(); // 定义委托 private stopMachineryDelegate stopMachinery // 创建委托实例 ... public Controller() &#123; this.stopMachinery += folder.StopFolding; // 添加引用 this.stopMachinery += welder.FinishWelding; &#125; public Shutdown() &#123; this.stopMachinery(); //调用 &#125;&#125; 调用委托与调用一个函数方法没有区别 通过委托可以实现执行过程与方法名,方法数量无关,从而将代码逻辑分离 Lambda表达式 声明形式与各语言差不多,使用=&gt;表示箭头12345x =&gt; x*x;() =&gt; folder.StopFolding(0);(x,y) =&gt; &#123;x++;return x/y;&#125;;(ref int x, int y) &#123;&#125; 可以作为函数直接添加到委托中 也可以作为配适器来配饰接口和实际函数 事件 格式1event delegateTypeName eventName 一个事件的定义依赖于一个委托,委托实际上是提供了函数的结构 事件也可以添加方法且和委托的添加方法一致 引发事件时,会自动的调用所有在事件上登记的方法 事件的引发方法和函数调用一致,且C#限制一个时间只能在被定义的类中被调用 12345678910111213141516class TemperatureMonitor&#123; public delegate void StopMachineryDelegate(); public event StopMachineryDelegate MachineOverheating; private void Notify() &#123; // 事件默认为空,因此有必要检查是否为null if(this.MachineOverheating == null) &#123; // 引发事件 this.MachineOverheating(); &#125; &#125;&#125; LINQ 什么是LINQLINQ意为语言集成查询(Language Integrated Query,LINQ). LINQ语言设计时借鉴了很多数据库管理系统的经验. 因此LINQ使用起来与SQL有很多相似之处. 以下语句分别演示了使用LINQ语句进行Select,Where,OrderBy以及Join操作,这些操作的含义与SQL语句中的含义完全一致. 注意: 由于Select语句执行以后,就变成选定元素组成的集合了,因此大多数的限制性操作(例如Where或From)都必须在Select语句之前执行 12345678910111213141516171819202122232425262728293031var furitList = new[]&#123; new &#123;ID = 1,Name = &quot;Apple&quot;,Price = 4.5&#125;, new &#123;ID = 2,Name = &quot;Banana&quot;,Price = 4.0&#125;, new &#123;ID = 3,Name = &quot;Orange&quot;,Price = 3.0&#125;, new &#123;ID = 4,Name = &quot;Others&quot;,Price = 99.9&#125;&#125;;var addresses = new[]&#123; new &#123;Name = &quot;Apple&quot;,City = &quot;Ax&quot;&#125;, new &#123;Name = &quot;Banana&quot;,City = &quot;Bh&quot;&#125;, new &#123;Name = &quot;Orange&quot;,City = &quot;Cy&quot;&#125;, new &#123;Name = &quot;None&quot;,City = &quot;None&quot;&#125;&#125;;var Names = furitList.Where(fruit =&gt; fruit.Name.Length &gt; 5) .Select(furit =&gt; furit.Name);foreach (var name in Names)&#123; Console.WriteLine(name);&#125;var OrderNames = addresses.OrderBy(addr =&gt; addr.Name).Select(addr =&gt; addr.Name);var list = furitList .Select(furit =&gt; new &#123; furit.Name, furit.Price &#125;) .Join(addresses, fruit =&gt; fruit.Name, addr =&gt; addr.Name, (fruit, addr) =&gt; new &#123; fruit.Name, fruit.Price, addr.City &#125;); 使用查询操作符除了上述提到的使用各种函数调用来实现查询以外,LINQ也提供了一组操作符来使LINQ查询更加像SQL语句,例如上例中的查询语句可以进行如下的替换 12var Names = furitList.Where(fruit =&gt; fruit.Name.Length &gt; 5) .Select(furit =&gt; furit.Name); 等价与 123var Names = from furit in furitList where furit.Name.Length &gt; 5 select furit.Name; 此外LINQ还提供了集合操作等其他SQL语句中的方法,具体内容可以查阅文档.","categories":[],"tags":[{"name":"CSharp","slug":"CSharp","permalink":"https://lizec.top/tags/CSharp/"}]},{"title":"数据库系统原理","slug":"数据库系统原理","date":"2017-12-20T01:19:45.000Z","updated":"2019-08-17T07:11:18.359Z","comments":true,"path":"2017/12/20/数据库系统原理/","link":"","permalink":"https://lizec.top/2017/12/20/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F%E5%8E%9F%E7%90%86/","excerpt":"","text":"本文依据《数据库系统概率》（第五版），记录了数据库理论基础，关系数据库设计，以及数据库有关技术。关于SQL语句的有关知识，可以阅读SQL语法精简笔记。 关于大数据的有关内容，可以阅读大数据技术原理。 第一章 绪论数据库系统概述数据库数据库是 长期存储 在计算机内，有组织的 ，可共享 的 大量 数据的集合。数据库中的数据按照一定的 数据模型 组织，描述和存储，具有 较小的冗余度（redundancy）、较高的数据独立性（data independence）和 易扩展性（scalability），并可为各种用户共享。 常见数据库 Database Description Oracle RDBMS 成熟的商业数据库，支持各种主流平台 Microsoft SQL Server 微软的数据库，可在windows上运行 MySQL 开源的免费数据库，支持多种平台，适合web环境使用 信息和知识 信息（Information）： Data + Context 知识（Knowledge）： Data + Context + Casual relation（因果关系） 数据库系统构成 数据库(DataBase, DB) 数据库管理系统（DataBase Management System, DBMS) 应用程序 数据库管理员(DataBase Administrator, DBA) 数据库系统特点 数据结构化 数据的共享性高，冗余性低，易于扩充 数据独立性高 数据由DBMS统一管理和控制 DBMS主要功能 数据定义 数据定义语言(DDL)，定义数据库表等数据对象 数据操纵 数据操纵语言(DML)，实现对数据库的基本操作 数据库运行管理 对数据库实现统一的管理，统一的控制 数据库建立、维护 实用程序，实现数据加载，转储恢复，重组重构，性能检测分析等 数据模型 是对现实世界数据特征的抽象 是描述数据库的语言 两类数据模型 概念模型 也称信息模型，是按照用户的观点来对数据和信息建模 逻辑模型和物理模型 逻辑模型主要包括网状模型，层次模型，关系模型，面向对象模型等 是按照计算机系统的观点进行数据建模 物理模型是最底层的数据抽象，描述数据在系统内部的表示方式与存取方法 数据库系统结构数据库的模式和实例 模式是对数据库的逻辑结构和特征的描述 是型的表示，不涉及具体值 实例是一个模式具体的值 反应数据库某一时刻的状态 同一模式可以有很多实例 数据库系统的三级模式 模式(Schema) 也称为逻辑模式 数据库中全体数据的逻辑结构和特征的描述 所有用户的公共数据视图 是数据库系统模式结构的中间层 外模式(External Schema) 也称子模式或用户模式 数据库用户使用的局部数据的逻辑结构和特征描述 用户的数据视图是与某一应用有关的数据的逻辑表示 介于模式与应用之间 保证数据库安全性的一个有力措施 内模式(Internal Schema) 是数据物理结构和存储方式的描述 是数据在数据库内部的表示方式 一个数据库只有一个内模式 数据库的二级映像 外模式/ 模式映像 当模式改变时，由DBA对各个外模式/模式映像做相应改变，使外模式保持不变，从而应用程序不必修改，保证了数据的 逻辑独立性 模式 / 内模式映像 数据库存储结构改变时，由DBA对模式/内模式映像做相应改变，使模式保持不变，从而保证了数据的 物理独立性 模式与模型 数据模型(Data Model) 是(抽象的)规约或语言，用于说明”数据库模式” 有不同抽象基本的数据模型 概念模型: E-R模型 逻辑模型:层次模型，网状模型，关系模型，OR模型 数据库模式(Database Schema) 对数据库结构，约束等对象的说明与规定 针对某一特定的应用领域 也称为”数据库模型” 有不同的抽象几倍 教学数据库概念模式:教学数据库E-R图 教学数据库逻辑模式:教学数据库关系模式 数据模型的组合要素 数据结构 数据操作 数据约束条件 主要的逻辑数据模型 第一代(70~80年代) 层次模型 网状模型 第二代(80年代后) 关系模型 新型数据模型(90年代后) 面向对象模型(Object-Oriented Model) 对象-关系模型(Object-Relational Model) 第二章 关系数据库关系和码 名称 英文名称 含义 候选码 Candidate Key 若关系中的某一属性(组)能唯一的标识一个元组，则称该属性(组)为候选码 全码 All-key 最极端的情况，关系模式中所有属性组是这个关系模式的候选码 主码 Primary Key 若一个关系中有多个候选码，可选择一个作为主码 主属性 Prime Attribute 候选码的属性称为主属性 非主属性 Non-Prime Attribute 不包含在任何候选码中的属性称为非主属性 关系模式 关系是值，关系模式(Relation Schema)是型 关系模式是对关系的描述，包括元组的结构描述和完整性约束条件描述 关系的完整性 实体完整性(Entity Integrity) 如果属性A是关系R的主属性，则属性A不可为空 参照完整性(Referential Integrity) 若属性F是关系R的外码，对于与关系S的主码K 则对于每个元组在F上的取值，或者为空，或者为S的某个元组的主码值 用户定义完整性(User-defined Integrity) 属性是否唯一 非主属性是否可为空 属性的取值范围 第四章 数据库安全性数据库的安全性是指保护数据库以防止不合法的使用导致的数据泄露，更改或破坏。 用户身份鉴别 名称 含义 标识(Identification) 标识用户身份 鉴别(Authentication) 核实用户身份 安全等级划分 安全级别 定义 解释 A1 验证设计 在B3的基础上，给出形式化设计说明和验证 B3 安全域 满足访问监控器要求，审计能力更强 B2 结构化保护 提供形式化的安全策略模型 B1 标记安全保护 对数据进行标记，对标记的主体和客体实施强制存取控制，是真正意义上的安全产品 C2 受控存取保护 安全产品的最低档，支持审计和资源隔离 C1 自主安全保护 非常初级的保护，实现用户和数据分离，提供自主存取控制 D 最小保护 所有不安全的系统归为此类 存取控制 自主存取控制(DAC，Discretionary Access Control) 用户对不同的数据对象有不同的存取权限 不同用户对同一对象也有不同权限 用户可以授权给其他用户 强制存取控制(MAC，Mandatory Access Control) 每一个数据对象被标以一定的密级 每一个用户被授予某一个级别的许可证 对与任意对象，只有合法许可证的用户可以存取 权限控制有关权限控制的内容，查看SQL语法精简笔记的权限控制和角色控制章节。 强制存取方式 敏感度标记 绝密(Top Secret，TS) 机密(Secret，S) 可信(Confidential，C) 公开(Public，P) 主体敏感度标记称为许可证级别(Clearance Level) 客体敏感度级别称为密级(Classification Level) 仅当主体的许可证级别大于或等于客体的密级时，该主体才能读相应的客体 仅当主体的许可级别小于或等于客体的密级时，该主体才能写相应的客体(保证高级别的数据不能被当前主体重写成低等级的数据) 审计 启用一个专用的审计日志(Audit Log)，将用户对数据库的所有操作记录在上面 审计员利用审计日志监控数据库中的各种行为，找出非法存取数据的人、时间和内容 C2以上的DBMS必须具有审计功能 由于审计消耗时间和空间，因此DBA可以根据安全性要求，灵活的决定是否开启审计 数据加密 根据一定的算法将原始数据，从明文(Plain text)变为不可直接识别的密文(Cipher text) 可分为存储加密和传输加密 第五章 数据库完整性数据库完整性(Integrity)是指数据的正确性(Correctness)和相容性(Consistency)。 正确性是数据符合现实世界语义，反应了当前的实际状况。 相容性是数据库同一对象在不同关系表中的数据是符合逻辑的。 数据库完整性的要求 提供定义完整性约束条件的机制 提供完整性检查方法 违约处理 违约处理 操作 含义 拒绝执行(NO ACTION) 不允许该操作执行，通常是默认操作 级联操作(CASCADE) 当删除或修改被参照表的一个元组导致与参照表不一致时，删除参照表中的数据 设置为空值 当删除或修改被参照表的一个元组导致与参照表不一致时，将参照表中的数据置为空 用户定义完整性 操作 SQL关键字语句 不许取空值 NOT NULL 列值唯一 UNIQUE 自定义检查 CHECK 关于具体的完整性定义，参考SQL语法精简笔记的完整性约束章节 第六章 关系数据理论数据依赖 是一个关系内部，属性与属性之间的一种约束关系 是现实世界属性间相互联系的抽象 是语义(Semantics)的一种体现 数据依赖(Dependency)是表内部属性的关系 联系(Relationship)是不同表之间的关系 两种依赖 函数依赖(Functional Dependency，FD) 多值依赖(Multi-Valued Dependency，MVD) 不合理数据库的问题 问题 解释 数据冗余 某些数据多次重复的出现 更新异常 更新某一数据后，需要同时更新大量其他地方的数据 插入异常 某些条件不具备时，无法插入数据(例如，某个系没有学生无法加入系主任) 删除异常 删除某一数据时，其他数据一同被删除(例如，某个系全部毕业，系主任信息一同消失) 一个好的数据库不应该存在插入异常，删除异常，更新异常，数据冗余要尽可能少 函数依赖 如果X可以唯一的确定Y，则记为 X-&gt;Y 若X-&gt;Y 且Y不是X的子集，则称此为非平凡的函数依赖，否则称为平凡的函数依赖 如果X-&gt;Y，且对于任何X的子集X’，都没有X’-&gt;Y，则称Y对X完全函数依赖，否则称Y对X部分函数依赖 如果X–&gt;Y，Y-/-&gt;X，Y–&gt;Z，且Z不是Y的子集，则Z对X传递函数依赖(Transitive Functional Dependency) 注意若有Y–&gt;X，则X&lt;–&gt;Y，此时Z直接依赖X，而不是传递依赖X 范式理论 范式 要求 第一范式 关系的每个分量必须是不可分开的数据项 第二范式 如果R是第一范式，且每个非主属性都完全函数依赖于任何的候选码，则R是第二范式 第三范式 如果R是第一范式，若R中不存在非主属性对码的部分依赖和传递依赖，则R是第三范式 BC范式 如果R是第一范式，若R中每个决定属性集都包含候选码，则R是BC范式 注意： 如果不满足第二范式，说明有些属性并不需要候选码中的所有属性就能确定，但是整个元组却需要这些属性，因此需要将元组拆分 如果不满足第三范式，此时任意的断开一个函数依赖即可解决传递依赖的问题 范式的证明对于第三范式，如果有Y部分函数依赖X，则存在X的一个子集X’，有 X’–&gt; Y， 从而有 X –&gt; X’, X’–&gt; Y， 即X与Y传递依赖，因此不满足第二范式时必然不满足第三范式。 对于BC范式，相当于所有的X都是候选码，从而所有的依赖都是完全依赖。由于所有的候选码之间没有依赖，因此不可能产生传递依赖。综上BC方式满足三范式。 由于BC范式的判定反而更简单，因此更容易直接得到BC范式。 范式理论小结 并不是规范化程度越高就越好，实际的范式选择需要结合实际情况 通过范式分析不一定比通过ER图分解更容易处理 第七章 数据库设计数据库设计 广义的数据库设计 对于一个给定的应用环境，构造优化的数据库逻辑模式和物理结构，并据此建立数据库以及应用系统，使之能有效的存储和管理数据，满足各种用户的应用需求(DB+DBAS) 狭义的数据库设计 对一个给定的应用环境，构造优化的 数据库逻辑模式和物理结构 (DB) 模式设计阶段模式设计可以分为三个阶段，即 在逻辑设计阶段将E-R图转换为具体的数据库产品支持的数据模型(例如关系模型)，形成数据库 逻辑模式 根据用户处理的要求，安全性的考虑，在基本表的基础上建立必要的视图，形成数据的 外模式 在物理设计阶段根据DBMS特点和处理的需要，进行物理存储安排，设计索引，形成数据库 内模式 数据字典数据字典时进行详细设计的数据手机和数据分析所获得的主要成果。它是关于数据库中数据的描述，即元数据，而不是数据本身。 数据字典一般包含以下的内容 内容 含义 数据项 不可再分的数据单位 数据结构 反映数据之间的组合关系 数据流 数据结构在系统内传输的路径 数据存储 数据结构停留或保存的地方 处理过程 说明处理的功能和要求 E-R图E-R模型是用E-R图来描述现实世界的概念模型，主要包括实体、属性、实体之间的联系等。各元素的含义如下： 名称 图例 说明 实体 使用矩形表示 矩形框内写明实体名 属性 使用椭圆形表示 使用无向边连接对应的实体 联系 使用菱形表示 使用无向边连接相关的实体，联系本身也可以有属性 UML设计在数据库的概念模型中，可以使用UML图进行设计，关于此部分的内容，参考数据库设计与UML图 实施和维护 操作 含义 数据载入(Load) 数据库建立好以后，向输入库装载数据 功能测试 实际运行应用程序，执行对数据库的各种操作 性能测试 测量系统的性能指标，分析是否符合设计目标 转储和恢复(Backup/Recovery) 正式运行后的重要维护工作之一，从而保存数据库故障后能恢复到某种一致性的状态 重组织(Re-Organization) 在不改变物理模式的情况下，对数据进行重排，回收垃圾，减少指针链等操作 重构造(Re-Construction) 重新调整数据库的模式和内模式 第八章 数据库编程通用数据访问技术 名称 英文全称 产生原因 特点 ODBC Open Database Connectivity 使用统一的标准来访问不同的数据库 使用同一的API访问，数据库厂商提供驱动程序，可移植强 OLEDB Object Linking and Embedding Database 需要访问非关系型数据库 提供了对关系型数据库与非关系型数据库一致的访问 JDBC Java Database Connectivity Java平台使用的统一API 独立于数据库，统一的API，跨平台，可移植性好 ADO ActiveX Data Object 更简单的面向对象的编程接口 基于OLEDB，可以访问OLEDB和IDBC的接口 LINQ Language Integrated Query C#和VB的语言扩展 使用类似SQL的语法来查询任何形式的数据 NoSQL Not Only SQL 弥补传统数据库对超大规模数据的不足 高并发，低延迟的读和写，高伸缩性和高可用性 关于NoSQL的有关内容，可以参考大数据技术原理NoSQL的有关内容。 过程化SQLSQL的扩展，添加了过程化语句功能。常见的实例有Oracle的PL-SQL和SQL Server的Transaction-SQL 存储过程过程化的SQL有两种类型，即命名块和匿名块。直接编写的代码是匿名块，每次执行都需要重新编译。存储过程和函数是命名块，编译后存储在服务器端，可被多次调用。 第十章 数据库恢复技术数据库的恢复数据库的恢复(Recovery)是数据库管理系统把数据库从错误状态恢复到某一已知的正确状态，恢复技术是衡量系统优劣的重要指标。 故障种类 故障类型 解释 事务内部故障 通常指非预期的故障，例如运算溢出，死锁，强制中断等 系统故障 系统故障是造成系统停止的运作的任何事件，使得系统需要重新启动 介质故障 系统故障称为软故障(soft crash)，介质故障称为硬故障(hard crash) 计算机病毒 人为制造的恶意程序 事务出现故障后，通常需要进行事务撤销(UNDO)，使得事务好像根本没有启动。 如果故障无法被撤销，还可以利用存储在系统别处的冗余数据来重建数据库中被破坏的数据，即数据库的恢复。 恢复实现技术恢复的本质是冗余数据，因此建立冗余数据有两种常见的方法，即 恢复方法 解释 数据转储(Backup) 数据库管理员定期的将整个数据库复制到其他介质之中 登记日志文件(Logging) 记录数据库中所有的更新操作 对于转储，依据转储时是否可以更新数据库，分为静态转储和动态转储。对于存储的数据，可以分为海量转储和增量存储。 数据库镜像数据库镜像(Mirror)功能是指数据库管理系统自动把整个数据库或其中的关键数据复制到另外一个磁盘。由数据库管理系统保证镜像数据与主数据的一致性，从而一旦出现故障，可以直接使用镜像(热备份)进行恢复。","categories":[{"name":"计算机核心课程","slug":"计算机核心课程","permalink":"https://lizec.top/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%A0%B8%E5%BF%83%E8%AF%BE%E7%A8%8B/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://lizec.top/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"SQL","slug":"SQL","permalink":"https://lizec.top/tags/SQL/"}]},{"title":"汇编语言笔记","slug":"汇编语言笔记","date":"2017-12-05T14:31:19.000Z","updated":"2018-06-05T07:44:26.060Z","comments":true,"path":"2017/12/05/汇编语言笔记/","link":"","permalink":"https://lizec.top/2017/12/05/%E6%B1%87%E7%BC%96%E8%AF%AD%E8%A8%80%E7%AC%94%E8%AE%B0/","excerpt":"","text":"本文是对基于IBM-PC汇编语言程序设计的一些笔记。内容主要是汇编程序设计的基础知识和示例代码 目录 基本知识介绍 数据和内存 汇编程序结构 数据声明方式 数据寻址方式 循环程序设计 分支程序设计 子程序设计 标志位寄存器 中断程序设计 端口和外中断 标号与直接定址表 宏指令 显存操作 基本知识介绍 ----------------------- 首先介绍汇编语言的基本工具. 本文使用在dos环境下运行的MASM6.0. 为了需要运行dos环境, 首先需要下载dos的虚拟机. 这里推荐dosbox, 这是一个跨平台的dos虚拟机, 在其官网上可以下载到各个平台的程序. 首先介绍MASM6.0的程序结构, 下载了相应的程序后, 直接解压, 可以看到如下的几个程序, 程序名和作用如下表所示 程序结构 程序名 作用 MASM.exe 汇编主程序 Link.exe 链接器 ML.exe 汇编和链接 LIB.exe 相关库 DEBUG.exe 调试程序 其中, DEBUG.exe在前期使用较为频繁, 其相关指令较多, 因此下面给出DEBUG.exe的常见指令 基本操作 命令名 作用 示例 r(Register) 显示或修改寄存器数 r / r ax d(Dump) 显示指定位置的内存数据 d 1000:0004/d:1000:0004 38 e(Enter) 向指定位置写入数据 e 1000:0000 1 2 3 4 5 6 u(Unassmble) 显示指定位置对应的汇编代码 u 1000:0000 t(Trace) 执行一步 t a(Assemble) 向指定位置输入汇编代码 a q(quit) 退出程序 q 在DEBUG.exe输入r指令, 会显示所有寄存器的当前数值, 下面给出各个寄存器的含义 通用寄存器结构 名称 作用 名称 作用 AX 累加器 CS 代码段 BX 基址变址 DS 数据段 CX 计数 ES 附加段 DX 数据 SS 堆栈段 SP 堆栈指针 DI 目的变址 BP 基址指针 SI 源变址 IP 指令指针 段的几点说明 ax,bx,cx,dx除了作为16bit寄存器使用以外, 均可分为两个8bit的寄存器 由于偏移地址是一个16bit的寄存器, 所以一个段最多有64K的空间 一个段要求至少有16Byte的空间 段的起始位置和容量必须是16的整数倍 段实际地址 = 段地址x16+偏移地址 注意:不能使用立即数对段寄存器赋值 数据和内存 ----------- 数据在内存中的存放在内存中, 先存放低位数据, 再存放高位数据,例如数据0x1234 在内存中的实际存放顺序是34 12 内存寻址和ds寄存器在汇编代码中, 可以使用如下的格式引用内存中的数据 1mov ax [0] 上述代码实际是默认段寄存器为ds寄存器。汇编代码中访问内存时, 总是默认从ds指定的位置开始读取数据 注意: 不可以使用mov指令在两个内存单元中直接移动数据 内存中的栈在内存中, 有ss段寄存器和sp堆栈指针寄存器两者共同维护程序堆栈。由于堆栈从高位开始, 向低位扩展, 所以当选择一块区域作为栈时, ss指向这一区域的开始位置, 而sp指向这一区域的结束位置。在使用栈的过程中, sp始终指向当前的栈顶位置。执行Push操作时, sp先减2, 然后写入数据。执行Pop操作时, 先读取sp指向的位置的数据, 之后sp加2 注意事项 设置堆栈段寄存器和寄存器的时候, 两条指令必须连续执行 si和di只能作为16bit寄存器使用 不能直接在两个内存单元中传递数据 mov al [6]在asm文件中, 汇编器会将其汇编成mov al 6, 此时应该先将偏移地址放在某个寄存器中, 如bx, 使用mov al [bx]获得数据, 但是在DEBUG.exe程序中使用a指令逐行汇编时并没有这种问题 汇编程序结构 --------------------- 汇编语言程序组成 汇编指令 有对应的机器指令, 可以被编译成机器指令, 最终被CPU执行 伪操作(伪指令) 在源程序编译过程中由编译器处理的操作 汇编代码结构下面是一个完成的汇编程序的结构 12345678910111213141516171819assume cs:code,ds:data,ss:stack ;关联自定义段data segment ;定义数据段...data ends;------------------------stack segment ;定义栈段...stack ends;------------------------code segment ;定义代码段start: mov ax,data mov ds,ax ;初始段寄存器 ... mov ax, 4c00H ;这两句调用系统指令, 结束程序 int 21Hcode endsend start ;设置代码开始位置end 下面就上述代码中出现的语法元素进行简要介绍 定义段定义段的结构如下所示, 段名可以使任意合法的标识符 123段名 segment...段名 ends 注意:ends的含义是end segment 关联自定义段和程序段1ASSCUME CS: codeseg, DS:dataseg 上述指令将CS段与自定义的codeseg段关联, 将DS段与dataseg段关联 注意:语句结束后没有分号, 在汇编代码中, 分号表示注释 设置标号在汇编代码中, 可以在某一行的位置前设置一个标号, 类似于C语言中goto语句的标号, 此标号可在后续的其他语句中被引用, 表示程序的这个位置 设置程序起始位置默认情况下, 程序从CS段的起始位置开始执行, 使用end start语句, 可以使汇编器在汇编的时候, 将程序的起始位置指定在start处于的位置 结束汇编文件汇编语言文件中, 使用一个单独的END表示程序结束 数据声明方式 ---------------- 基本声明123DATA_BYTE db 10,4,10HDATA_WORD dw 100,100H,-5DATA_DW dd 3*20,0FFFDH ;所有的数值都必须是0-9开头, 因此使用16进制时, 高位使用0补齐 第一项是标号(一般称为变量), 表示数据在内存中的位置信息 第二项相当于变量类型, 上述三个分别代表byte, word, double word 第三项是逗号分割开的若干数据, 这些数据都是同样的类型 字符串12message1 db &#x27;HELLO&#x27;message2 dw &#x27;AB&#x27;,? 可以定义字符串, 字符串在内存中使用ASCII码保存 对于给定的字符串, 如果可以存入指定的数据类型中, 则按照小端的顺序存放, 否则在内存中按照顺序存放 对于不同的数据类型, 使用?占位时, 占据的空间与数据类型声明相同 标号和地址123PAR dw 100,200ADDR_TABLE1 dw PARADDR_TABLE2 dd PAR 标号可以像数据一样存入, 此时存入内存的是这个标号对应的内存地址, 此时创建的标号, 相当于指针的指针 一个数据的标号包含一个16bit的偏移地址, 和一个16bit的段地址 如果被赋值的数据类型足够大, 则将一个地址赋给变量时, 偏移地址在数据低位, 段地址在数据高位 如果被赋值的数据类型不够大, 则变量中只有偏移地址 大量数据分配12array db 100 dup(10) db 2 dup(0,2 dup(1,2),3) 第一行表示填充100个数据, 每个数据是10 第二行是嵌套表示, 外部表示总体重复两次, 内部的表示将1,2重复2次 即最后的序列为 0 1 2 1 2 3 类型转换12345OPER1 db 1,2OPER2 dw 1234H,5678H... mov ax, word ptr oper1+1 mov al, byte ptr oper2 使用ptr关键字可以进行类型转化 具体格式为 type ptr variable, 其中type可以为byte, word, dword 先进行计算, 计算完成后, 将结果按照制定的格式进行转换 其中的变量+1操作等于对应的内存地址+1 多类型123456byte_array label byteword_array dw 50 dup(?)... mov word_array + 2, 0 mov byte_array + 2, 0 使用label关键字指定类型 具体格式为 name label type, 其中type可选项与上一节相同 相当于给一个内存指定了两个名字, 在代码中可以任意的使用 数据寻址方式 -------------- 数据表达方式汇编语言中数据有3中表达方式 立即数 数据由字面值给出, 数据实际编码在机器指令中, 执行时, 保存在译码电路中 寄存器 数据存放在寄存器中 段地址：偏移地址 数据在内存中 寄存器间接寻址使用形如[bx]的形式进行寄存器间接寻址, 表示将指定的寄存器的内容作为内存的地址, 取出相应地址上的数据 寄存器相对寻址使用形如[bx+idata]的形式进行寄存器相对寻址, 表示将计算结果作为内存的地址, 取出相应地址上的数据相对寻址的特点在于每次执行的时候idata是不变的立即数, 而每次改变寄存器的值, 从而对一组相对位置不变的数据操作 基址变址寻址使用形如[si+bx]的形式进行基址变址寻址 相对基址变址寻址使用形如[bx+si+idata]的形式进行相对基址变址寻址 一些限制 在8086CPU中, 只有bx, si, di, bp可以用于[…] 只能以bx+si,bx+di,bp+si,bp+di的形式出现, 其他组合都是非法的形式 如果在[…]中使用bp, 且没有指定段寄存器, 则默认段寄存器为ss, 即[bp+di+5] &lt;=&gt; (ss)x16+(bp)+(di)+5 循环程序设计 ------------------ #### LOOP指令 - 指令格式 `LOOP 标号` - 执行步骤 1. `（CX) = (CX) - 1` 2. 判断CX的值, 如果不为零, 则转至标号处执行, 否在继续向下执行 循环指令的例子12345678910assume cs:codesegcodeseg segment mov ax, 2 mov cx, 11 ; 初始化循环变量, 执行11次s: add ax, ax loop s mov ax 4c00H int 21Hcodeseg endsend 类似于高级语言中的循环结构, 汇编语言中的循环结构基本按照上述形式固定不变 可以使用si寄存器和di寄存器作为一定数据的辅助段寄存器 分支程序设计 ---------------- offset操作offset是一个伪操作, 属于数值回送操作符, 作用是获得标号的偏移地址, 以下面的代码为例 12345678assume sc:codecode segment start: mov ax, offset start ;相当于 mov ax, 0 s: mov ax, offset s ;相当于 mov ax, 3 mov ax, 4C00H int 21Hcode endsend 指令分类8086CPU的跳转指令可以分成如下的几类 指令 效果 loop 循环 jmp 无条件跳转 jcxz 有条件跳转 call/ret 子程序调用 int 中断 无条件转移接下来介绍几种常见的无条件转移指令 名称 指令格式 特点 段内短转移 jmp short 标号 指令中使用8bit保存IP的偏移量 段内近转移 jmp near ptr 标号 指令中使用16bit保存IP的偏移量 段间直接远转移 jmp far ptr 标号 使用标号所在的段和偏移地址修改CS和SP 段内间接近转移 jmp word ptr 内存单元 使用指定内存单元的字修改IP 段间间接远转移 jmp dword ptr 内存单元 使用指定内存的两个字, 低位字修改IP, 高位字修改CS 寄存器转移 jmp 寄存器 使用指定寄存器的值修改IP 几点补充 在执行跳转指令时, IP以及指向下一条指令, 因此所有的偏移都是相对于下一条指令的开始位置 因为段内短转移使用8bit保存偏移量, 所以只能向前跳转128字节或向后跳转127字节 因为段内近转移使用16bit保存偏移量, 所以只能向前跳转32768字节, 或者向后跳转32767字节 有条件转移有条件转移根据之前的cmp指令计算结果决定是否转移, 且所有的转移都是短转移, 即只能在当前位置, 相对的跳转大约128个字节 有条件指令结构有条件转移指令都是j开头, 根据转移条件不同跟上不同的后续符号, 后续符号可以分成如下几种情况 类型 无符号 有符号 相等 e(equal) e(equal) 大于 a(abve) l(less) 小于 b(below) g(greater) 否定 n(not) n(not) 例如, 无符号的大于指令是ja 有符号的大于指令是jg 有符号的小于等于指令是jle 或者jng jcxz指令从名字可以知道, 此指令是比较cx寄存器是否为0, 所以当cx为0跳转到标号, 否则指向下一条指令。此指令跳转条件与loop正好相反 子程序设计 ----------------- ret指令利用栈中的数据, 修改ip寄存器的内容, 从而实现近转移, 等价于如下的代码 12(ip) = ((ss)*16+sp)(sp) = (sp) + 2; retf指令使用栈中的两个数据修改IP寄存器和CS寄存器, 用于实现远转移, 等价于如下的代码 1234(ip) = ((ss)*16+(sp)(sp) = (sp) + 2; (cs) = ((ss)*16+(sp))(sp) = (sp) + 2; 注： 实际上所有的入栈操作时, 都是先压入段寄存器, 在压入偏移地址寄存器, 所以出栈操作正好相反 retf即return far call指令将当前的IP或CS和IP压入栈中, 并根据指令格式中的目的地址进行转移, 各指令格式与等价操作如下所示 入栈操作 call 标号 call far ptr 标号 call 寄存器 call dword ptr 内存单元 (SP) = (SP) - 2 (SP) = (SP) - 2 (SP) = (SP) - 2 (SP) = (SP) - 2 ((SS)*16+(SP)) = (IP) ((SS)*16+(SP)) = (CS) ((SS)*16+(SP)) = (IP) ((SS)*16+(SP)) = (CS) |(SP) = (SP) - 2 | |(SP) = (SP) - 2 |((SS)*16+(SP)) = (IP) | |((SS)*16+(SP)) = (IP) 跳转操作 call 标号 call far ptr 标号 call 寄存器 call dword ptr 内存单元 (IP) = (IP) + 16bit位移 (IP) = 目标标号所在段的偏移地址 (IP) = (16bit寄存器) (IP) = 内存单元地址 |(CS) = 目标标号所在段的段地址 | |(CS) = 内存单元地址+2 注： call 标号不能实现短转移, 因为是否为短转移是按照偏移量长度区分 call 标号与jmp指令相同, call指令的二进制代码中保存的是标号相对于当前IP的偏移量, 而不是绝对地址 call far ptr 标号类似于远转移指令, 但是在跳转前分别压入CS寄存器IP寄存器的值 所有CS和IP同时出现的地方(内存地址和栈),都是IP在低位,CS在高位 MUL指令指令格式为：mul 寄存器/mul 内存单元两个8bit数据或两个16bit数据相乘 8bit数据使用al的值和指定的值相乘, 存放在ax中 16bit数据使用ax的值和指定的值相乘, 高位存放在dx, 低位存放在ax 参数传递方式 利用寄存器传递少量参数 在子程序的调用过程中, 如果不对寄存器做任何处理, 则寄存器中的值可以之间传递到子程序中 但是寄存器数量有限, 不能大量传递数据 使用内存单元 可以批量存放数据 对于需要批量返回的结果, 也可以使用此方法 寄存器冲突在调用子程序的时候, 由于寄存器数量有限, 因此当前程序和子程序可能使用了相同的寄存器。可以在子程序中可以很使用如下的框架来解决寄存器冲突 123456子程序入口：子程序中用到的寄存器入栈 ... 子程序内容 ... 子程序中用到的寄存器出栈 子程序返回 标志位寄存器 ----------------- 标志位说明 标志名 解释 选项1 选项2 含义 针对数据类型 OF 溢出标志位 NV(未溢出) OV(溢出) 记录运算结果是否溢出 有符号数 DF 方向标志位 UP(递增) DN(递减) 控制串传送的增减方式 无关 IF 允许中断标志位 DI(禁止) EI(许可) …… …… SF 符号标志位 PL(正) NG(负) 运算结果的符号状态 有符号数 ZF 零标志位 NZ(不等于零) ZF(等于零) 运算结果是否为零 全部类型 AF 辅助进位标志位 NA(无进位) AC(进位) …… …… PF 奇偶标志位 PO(奇) PE(偶) 当前二进制数据1的个数 全部类型 CF 进位标志位 NC(无进位) CY(进位) 记录运算结果的最高有效位进位或借位 无符号数 注: 选项一对应为0,选项二对应为1 只有算数运算置标志位,数据移动运算不置标志位 CF与OF比较 CF是Carry Flag, 即进位标志位, 只针对无符号数 OF是Overflow Flag, 即溢出标志位, 只针对有符号数 由于表示范围不一致,因此可以出现溢出但不进位 例如对于有符号两个较大的数相加 但无符号比有符号大一倍,没有进位 由于对于正负的认识不同,因此也可能出现进位但不溢出 例如有符号是负数+整数 对于无符号就是两个正数相加 此时无符号进位,有符号没有溢出 DF标志位 DF指示在进行串传递的时候, 每次执行si或di的变化 置为递增 指令格式cld 将DF置为0 置为递减 指令格式std 将DF置为1 串传送指令字节传送 指令格式 movsb 以字节为单位传送指令, 将ds:si指向的内存单元的数据传输到es:di执行的内存单元 执行过程如下 ((es)*16+di) = ((ds)*16+si) 如果DF=0, (si) = (si) + 1, (di) = (di) + 1 如果DF=1, (si) = (si) - 1, (di) = (di) - 1 字传送 指令格式 movsw 以字为单位传送指令, 将ds:si指向的内存单元的数据传输到es:di执行的内存单元 执行过程如下 ((es)*16+di) = ((ds)*16+si) 如果DF=0, (si) = (si) + 2, (di) = (di) + 2 如果DF=1, (si) = (si) - 2, (di) = (di) - 2 串传送 指令格式 rep movsb 或 rep movsw rep指令与movsb/movsw指令结合使用可用于串传送 rep movsb指令等价于12s: movsb loop s 将这样两条指令配合使用, 通过cx即可实现一段数据的传输 标志寄存器与栈操作入栈操作 指令格式： pushf 将标志寄存器的值入栈 出栈操作 指令格式：popf 将标志寄存器的值出栈 中断程序设计 ----------------- 内中断与外中断 由外设控制器或协处理器引起的中断称为硬件中断或外中断 由程序安排的中断指令INT产生的中断称为软件中断或内中断 内中断的产生原因 CPU内部错误, 如除数为零等 为调试程序设置的中断 执行into指令 执行int指令 常见中断类型 中断号 名称 作用 0 除法错误中断 执行除法指令时, 如果除数为零或者商操作寄存器范围, 立即产生此中断 1 单步执行中断 调试程序时, 使用此中断, 使得程序每次一条指令后立即中断 3 断点中断 当程序需要加入断点时, 使用此中断, 产生一个断点 4 溢出中断 程序产生溢出时, 产生此中断 注： 使用断点中断实际上就是在需要断点的地方插入一条int 3指令 产生溢出后, 可以使用into指令, 转入溢出中断处理, 如果没有溢出, 则into指令没有任何效果 中断向量表 80x86系统可以处理256种中断类型 中断向量表存放在内存单元0000:0000-0000:03FF的1024个内存单元中 一个表项占两个字(4个字节), 其中低位存放偏移地址, 高位存放段地址 中断过程根据中断类型码, 在中断向量表中获得中断向量并设置CS与IP称为中断过程, 此过程有硬件自动完成, 不能通过程序修改, 执行过程如下 获得中断类型码N 标志位寄存器入栈 CS寄存器入栈 IP寄存器入栈 设置TF标志位和IF标志位为0 从中断向量表获得数据, 设置CS和IP寄存器 跳转至中断程序 中断程序设计由于中断随时都有可能发生, 因此中断处理程序必须存放内存中的特定位置。中断程序步骤与子程序类似, 有如下几步 保存用到的寄存器 处理中断 恢复用到的寄存器 用iret返回 iret指令在调用中断程序之前, 标志位寄存器, CS寄存器, IP寄存器依次入栈, 因此iret执行相反的出栈操作即可恢复到中断以前的状态, 即iret等价于以下代码 123pop ippop cspopf DIV指令为 指令格式： div 寄存器/DIV 内存单元 指令含义 8bit除法, 被除数16bit存放在ax中, 计算后al保存商, ah保存余数 16bit除法, 被除数为32bit, 高位存放在dx, 低位存放在ax, 计算后ax保存商, dx保存余数 如果商大于al或ax的保存范围则产生除法溢出 安装程序结构编写一个安装程序可以分成如下的几个步骤 编写要被安装的程序, 并将代码置于安装程序中 设置ds:si指向被安装程序在安装程序中的位置, 将es:di执行被安装程序需要存在的位置 使用传输指令, 复制被安装程序 设置中断向量表以下是一个安装程序的示例12345678910111213141516171819202122232425262728293031323334353637assume cs:codesegcodeseg segmentstart: mov ax, cs mov ds, ax mov si, offset dd0 mov ax, 0 mov es, ax mov di, 200h mov cx, offset dd0end - offset dd0 cld rep movsb mov ax, 0 mov es, ax mov word ptr es:[0*4],200h mov word ptr es:[0*4+2],0 mov ax, 4C00H int 21Hdd0: jmp short dd0start db &quot;overflow!&quot;dd0start: mov ax, cs mov ds, ax mov si, 202h mov ax, 0b800h mov es, ax mov di, 12*160+36*2 mov cx, 9s: mov al, [si] mov es:[di], al inc si add di, 2 loop s mov ax, 4c00h int 21hdd0end: nopcodeseg endsend start 说明： 上述代码中, 从start标号开始, 到dd0标号之前, 是安装程序, 可以看到此部分程序严格按照上述顺序完成了安装操作 从dd0标号到dd0end标号之间的代码是被安装程序 上述示例中, 将程序安装到了200H的位置, 此处通常为空, 但是正式程序中不建议这么使用 mov cx, offset dd0end - offset dd0指令中, 使用两个标号的运算实现了被安装程序长度的可扩展性, 后续修改被安装程序的时候, 不需要修改安装程序 在dd0end标号对应的地方, 使用了一条nop指令占位, 从而可以添加一个标号, 之后用于计算程序长度 端口和外中断 ------------- IO设备的数据传输方式 程序控制方式(查询方式) 在PC系统中, 除存储器外, 和CPU通过总线连接的各种输入输出设备 每种IO设备都要通过一个硬件接口或控制器芯片和CPU相连 这些接口或控制器芯片都能支持输入输出指令与外部设备交换信息 中断方式 DMA方式 端口 在各种硬件接口或控制器芯片中, 有一组可由CPU读写的寄存器 CPU将这些寄存器作为端口, 对它们统一进行编制 CPU对它们进行读写控制都是通过控制总线向芯片发出端口的读写指令 端口地址空间 80x86系统允许设置64K个8bit端口或32K个16bit端口 对端口的读写需要使用IN和OUT指令进行信息传输 端口指令 格式 in al 60h CPU通过地址总线将地址信息60H发出 CUP通过控制总线发出端口读指令 端口所在芯片将60h端口中的数据通过数据总线送入CPU 端口指令的一些限制 对于端口号在0-255之间的端口, 可以直接访问 对于端口号在236-65535之间的端口, 端口地址需要放在dx寄存器中 访问8bit端口时, 数据只能存入al, 访问16bit端口时, 只能使用ax 通过端口访问CMOS RAM 芯片由电池供电 包含128个存储单元的RAM存储器 内部实时时钟占用0-d单元保存系统时间 内部有两个端口70H和71H, 通过这两个端口进行读写 70H端口为地址端口 71H端口为数据端口, 可以使用此端口读取或者写入数据1234567891011; 读取CMOS RAM 2号单元assume cs:codecode segmentstart: mov al, 2 out 70h, al in al,71h mov ax,4C00h int 21hcode endsend start 移位操作 SHL指令 shl 寄存器,n / shl 内存单元,n 逻辑左移 最后移出的位置CF标志位 如果移动次数大于1,移动次数存在cl中 SHR指令 shr 寄存器,n / shr 内存单元,n 逻辑右移 最后移出的位置CF标志位 如果移动次数大于1,移动次数存在cl中 SAL指令 sal 寄存器,n / sal 内存单元,n 算数左移 最后移出的位置CF标志位 如果移动次数大于1,移动次数存在cl中 SAR指令 sar 寄存器,n / sar 内存单元,n 算数右移 使用符号位补全高位 最后移出的位置CF标志位 如果移动次数大于1,移动次数存在cl中 可屏蔽中断 如果IF等于0,则不响应可屏蔽中断 在中断处理过程中,将IF置为0,即可屏蔽其他可屏蔽中断 几乎所有的外设引起的外中断都是可屏蔽中断 不可屏蔽中断 是CPU必须响应的外中断 中断码固定为2, 中断过程不需要取中断类型码 是系统有必须处理的紧急情况发生时,用于通知CPU的中断信息 标号与直接定址表 ------------------ 地址标号 地址标号代表一个内存单元地址 地址标号后跟上一个冒号 只能在代码段使用地址标号 数据标号 数据标号直接跟上数据,不加冒号 此标号除了代表内存地址以外,还隐含了此处数据的类型 在使用此标号代表内存单元时,会进行检查数据类型是否匹配 计算偏移的时候,类型信息没有影响 1234567891011121314151617assume cs:codesg, ds:datasg // 此信息仅用于编译,对程序不可见datasg segment a db 1,2,3,4 b dw 0datasg segmentcodesg segmentstart: mov ax,datasg // 声明了数据段关联,但还是需要手动为ds赋值 mov ds, ax mov si,0 mov cx,4s: mov ax, a[si] mov ah, 0 add b, ax inc si loop s 数据标号可以作为数据被定义,标号表示此标号所表示的地址 12345datasg segment datasg segment a db 1,2,3,4 a db 1,2,3,4 b dw 0 &lt;==&gt; b dw 0 c dw a, b c dw offset a, offset bdatasg segment datasg segment 12345datasg segment datasg segment a db 1,2,3,4 a db 1,2,3,4 b dw 0 &lt;==&gt; b dw 0 c dw a, b c dw offset a,seg, offset b,segdatasg segment datasg segment 使用dw时,只保存标号的偏移地址,使用dd时,保存偏移地址和标号所在段的段地址 直接定址表 用查表的方法的编程技巧 数值映射0-9 数值+30h10-15 数值+37h 使用直接定址表实现映射 其实就是类似数组的操作 可以提高算法的简洁性 由于可以查表,从而提升了运算速度 例子: 通过查表计算sin(x) 12345table db ag0 ag30 ag60 ag90ag0 db &#x27;0&#x27;,0ag30 db &#x27;0.5&#x27;, 0ag60 db &#x27;0.866&#x27;, 0ag90 db &#x27;1&#x27;,0 使用两步查询获得数据123mov bx, 2mov bx, table[bx] ; 先取出偏移地址mov ah, cs:[bx] ; 再从偏移地址取出实际内容 例子:清屏程序 清屏 设置前景色 设置背景色 向上滚动一行 先编写四个子函数,通过直接定址的方法,通过给定一个序号来指定调用的功能 清屏:将显存中当前屏幕字符设置为空格 设置前景色:设置属性字节(奇数字节)的0,1,2位 设置背景色:设置属性字节(奇数字节)的4,5,6位 向上滚动一行:依次将n+1行的内容复制到第n行,最后一行置为空 宏指令宏定义123456macro_name macro [dummy parameter list][local label1, label2 ...]endm dummy parameter list 相当于是高级语言中的形式参数列表 由local引导的是本地标签,在不同的地方调用时,本地标号会被展开成不同的唯一标号 标号必须是macro定义体的第一行,严格来说,之间包括注释也不能插入 宏调用1macro_name [actual parameter list] 宏展开 宏定义必须出现在调用之前 汇编过程中,将宏展开编程实际的代码 宏汇编操作符 &amp; 拼接指令,与C语言宏的##类似 ;; 在宏中使用的注释 % 计算表达式 在汇编过程中,计算%后的表达式,并将计算结果加入后续运算 12345678910strg macro string db &#x27;&amp;string&amp;&#x27;endm strg 25-1==&gt; db &#x27;25-1&#x27; strg % 25-1==&gt; db &#x27;24&#x27; 宏库的建立和调用 宏库macro.mac 调用include macro.mac 引入macro,mac文件中全部的宏 排除purge macroA … 制定宏名,剔除不需要的宏 rept expression… ;重复块endm 根据表达式的计算结果,重复制定次数 irp x, &lt;1,2,3,4,5,6,7,8,9,10&gt;db xendm x会依次带入后面的值 可以是数字或者寄存器,字符串等 显存操作显存结构 显存分为8页,每页4KB 显示器规格是每屏25行,每行80个字符 每个字符占2B,低位是对应ASCII码,高位是显示属性 每屏实际占用4000B,剩余96字节无效果 显存地址空间为B8000H-BFFFFH 字符属性 位数 含义 含义 7 BL 闪烁 6 R 背景色 5 G 背景色 4 B 背景色 3 I 高亮 2 R 前景色 1 G 前景色 0 B 前景色","categories":[{"name":"计算机核心课程","slug":"计算机核心课程","permalink":"https://lizec.top/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%A0%B8%E5%BF%83%E8%AF%BE%E7%A8%8B/"}],"tags":[{"name":"汇编语言","slug":"汇编语言","permalink":"https://lizec.top/tags/%E6%B1%87%E7%BC%96%E8%AF%AD%E8%A8%80/"}]},{"title":"设计模式","slug":"设计模式","date":"2017-11-05T13:58:52.000Z","updated":"2019-07-24T01:00:19.775Z","comments":true,"path":"2017/11/05/设计模式/","link":"","permalink":"https://lizec.top/2017/11/05/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/","excerpt":"","text":"自己也写了很多代码了, 最近在对一个以前写的Android项目进行重构, 在重构的过程中发现, 无论怎样调整各种类之间的关系, 在某些方面有所改进的同时, 在另外一些方面产生了严重的问题, 总是不能取得一个合适的平衡点. 而且有一些方案起初感觉良好, 可随着代码的重构, 才发现这些方案存在严重缺陷, 完全不可行. 在这样的重构过程中, 我花费了很多时间, 但没有取得什么良好的效果, 甚至还凭空增加了代码的复杂度. 实际上, 这些问题的本质都是设计模式的问题, 通过学习设计模式, 我们可以学习到程序设计的一些客观规律, 从而使程序更易于维护和修改. 本文将记录设计模式的有关知识. 依据设计模式来进行设计和开发, 能够使程序更加灵活, 更好的适应客户复杂而多变的需求. 目录 设计模式的基本原则 单例模式 设计模式的基本原则面向对象设计原则以下的一些原则是在面向对象设计的过程中, 应该遵守的基本原则虽然这些规则都不是强制的要求, 但是遵守这些规律可以减少我们对项目维护的难度. 设计模式的种类非常多, 所以我们更多的应该思考各种模式的本质, 从而做的自发的使用需要的模式. 原则 含义 单一职责 系统中的每一个类都应该只做一件事情 开闭原则 一个对象对扩展开放, 对修改关闭(通过增加代码完成新功能) 依赖倒转 抽象不应该依赖于细节，细节应该依赖于抽象 里氏替换 任何出现抽象类的地方都可以使用它的子类替代 合成复用 优先使用组合而不是继承 迪米特原则 一个对象对另外一个对象的了解要尽可能少 单一原则使得一个类只有一个改变原因, 从而不会扩大修改对系统的影响. 单例模式使用场景如果某个类只需要一个全局的唯一实例，则使用单例模式. 典型的场景是数据库的连接，日志的输出文件，这些类在整个程序中，都只需要唯一的实例. 实现代码12345678910111213141516public class Singleton&#123; private static Singleton instance = null; private Singleton() &#123; &#125; public static Singleton getInstance()&#123; if(instance == null)&#123; synchronized(Singleton.class)&#123; if(instance == null)&#123; instance = new Singleton(); &#125; &#125; &#125; return instance; &#125;&#125; 要点分析 通过是否为空判断，使得第一次调用此函数的时候，需要花费时间初始化，其他时候调用都直接返回实例 保证了始终使用同一个实例，从而一定程度保证了数据的一致性 保证了全局只有一个实例，一定程度的节省了系统开销","categories":[],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://lizec.top/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"Android使用SQLite","slug":"Android使用SQLite","date":"2017-10-19T09:33:26.000Z","updated":"2018-12-30T08:56:12.939Z","comments":true,"path":"2017/10/19/Android使用SQLite/","link":"","permalink":"https://lizec.top/2017/10/19/Android%E4%BD%BF%E7%94%A8SQLite/","excerpt":"","text":"操作步骤首先，从整体上概括一下Android使用数据库的操作方法，具体来说，可以分为以下的四步 继承SQLiteOpenHelper 实现其中的onCreate和onUpgrade方法 使用getWritableDatabase()和getReadableDatabase()获得一个数据库的类 在数据库的类上使用insert,update,delete,query等函数进行数据库操作 接来下对其中的一些细节进行说明 1. OnCreate方法OnCreate函数的注释如下： 12345678/** * Called when the database is created for the first time. This is where the * creation of tables and the initial population of the tables should happen. * * @param db The database. */@Overridepublic void onCreate(SQLiteDatabase db) &#123;...&#125; 这段注释说明，在数据库被创建的时候，才会调用此函数，所以此函数主要用来做一些初始化的工作，例如创建数据库的表。此函数传递了一个SQLiteDatabase对象，可以使用此对象进行数据库操作 2. OnUpgrade方法截取一段OnUpgrade方法的注释如下： 1234567891011/** * Called when the database needs to be upgraded. The implementation * should use this method to drop tables, add tables, or do anything else it * needs to upgrade to the new schema version. * * @param db The database. * @param oldVersion The old database version. * @param newVersion The new database version. */@Overridepublic void onUpgrade(SQLiteDatabase db, int oldVersion, int newVersion) &#123; ... &#125; 从说明可以知道，这个函数是用来升级数据库的，包括卸载表，添加表，或者其他改变数据库模式的事情。 3. 两种获得数据库的方法SQLite提供了两种获得数据库的方法，即 getWritableDatabased方法 和 getReadableDatabase方法。 还是一样，首先阅读这两个函数的函数注释 123456789101112131415161718192021222324/** * Create and/or open a database that will be used for reading and writing. * The first time this is called, the database will be opened and * &#123;@link #onCreate&#125;, &#123;@link #onUpgrade&#125; and/or &#123;@link #onOpen&#125; will be * called. * * &lt;p&gt;Once opened successfully, the database is cached, so you can * call this method every time you need to write to the database. * (Make sure to call &#123;@link #close&#125; when you no longer need the database.) * Errors such as bad permissions or a full disk may cause this method * to fail, but future attempts may succeed if the problem is fixed.&lt;/p&gt; * * &lt;p class=&quot;caution&quot;&gt;Database upgrade may take a long time, you * should not call this method from the application main thread, including * from &#123;@link android.content.ContentProvider#onCreate ContentProvider.onCreate()&#125;. * * @throws SQLiteException if the database cannot be opened for writing * @return a read/write database object valid until &#123;@link #close&#125; is called */public SQLiteDatabase getWritableDatabase() &#123; synchronized (this) &#123; return getDatabaseLocked(true); &#125;&#125; 这段注释有如下几个要点 这个函数第一次被调用的时候，会调用onCreate，onUpgrade和onOpen，由此也进一步说明了onCreate，onUpgrade的调用时机 一旦数据库被成功打开，那么就会被缓冲，因此可以每次在需要的时候调用此方法 如果确定不再使用数据库，则调用close()方法关闭数据库 如果存在权限或者磁盘满的问题，此次调用会失败，但是之后的尝试可能成功 数据库更新可能花费很多时间，因此不应该在主线程上调用此方法 123456789101112131415161718192021222324/** * Create and/or open a database. This will be the same object returned by * &#123;@link #getWritableDatabase&#125; unless some problem, such as a full disk, * requires the database to be opened read-only. In that case, a read-only * database object will be returned. If the problem is fixed, a future call * to &#123;@link #getWritableDatabase&#125; may succeed, in which case the read-only * database object will be closed and the read/write object will be returned * in the future. * * &lt;p class=&quot;caution&quot;&gt;Like &#123;@link #getWritableDatabase&#125;, this method may * take a long time to return, so you should not call it from the * application main thread, including from * &#123;@link android.content.ContentProvider#onCreate ContentProvider.onCreate()&#125;. * * @throws SQLiteException if the database cannot be opened * @return a database object valid until &#123;@link #getWritableDatabase&#125; * or &#123;@link #close&#125; is called. */public SQLiteDatabase getReadableDatabase() &#123; synchronized (this) &#123; return getDatabaseLocked(false); &#125;&#125; 这段注释有如下几个要点 其实getWritableDatabase() 和 getReadableDatabase()返回的对象完全相同 如果磁盘满，则返回一个只读的对象。如果后续磁盘问题解决了，那么之后调用此函数会返回一个可读可写的对象 4. ContentValues类在很多函数中，都需要使用这个类作为参数。实际上这是一个类似哈希表的数据结构，将列名和实际需要插入的值配对。 5. 使用？在很多函数中，都涉及了?的使用，但是应该注意以下几点 注意使用范围，?与占位符不同，并不能在任意位置取代任意词，具体使用需要看各个函数的说明 ?可以对用户输入的值进行转义，从而减少自己编写的程序的处理过程 拼接SQL语句时，固定的值使用String.format函数，包含用户输入的部分再使用? 在某些函数中，使用?替代的部分会视为字符串，具体使用需要看各个函数说明 6. 调试主要的函数都是通过返回值来决定是否执行成功。同时SQLiteDatabase也提供了一组抛出异常的类似函数，使用这些函数可以帮助定位数据库错误的原因。例如insertOrThrow函数是insert对应的抛出异常的版本。如果查看两者的源代码 12345678910111213public long insert(String table, String nullColumnHack, ContentValues values) &#123; try &#123; return insertWithOnConflict(table, nullColumnHack, values, CONFLICT_NONE); &#125; catch (SQLException e) &#123; Log.e(TAG, &quot;Error inserting &quot; + values, e); return -1; &#125;&#125;public long insertOrThrow(String table, String nullColumnHack, ContentValues values) throws SQLException &#123; return insertWithOnConflict(table, nullColumnHack, values, CONFLICT_NONE);&#125; 可以注意到，不抛出异常的版本只是简单的捕捉异常并在日志中输出，所以仅仅使用不抛出异常的版本，也能查看到错误信息，但如果需要程序出现异常时直接终止，那么抛出异常的函数则使用更加方便。 7. 其他 比较字符串作为条件时，字符串需要使用单引号括起来 总结本次学习SQLite的使用，踩了很多坑，尤其是在?的使用方面，遇到了很多问题，花了很多时间去调试。其间我也在网上查阅了很多资料，但是基本没有提及?使用的。实际上，后来仔细阅读了有关函数的注释，就发现每个函数的注释中都已经明确的指明了各个函数中如何使用?，所以网上也没有很多提及的文章。所以下次百度之前，还不如先多仔细看看提供的函数注释。","categories":[{"name":"Android","slug":"Android","permalink":"https://lizec.top/categories/Android/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://lizec.top/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"Android","slug":"Android","permalink":"https://lizec.top/tags/Android/"}]},{"title":"Android文件读写方法","slug":"Android文件读写方法","date":"2017-10-18T02:44:15.000Z","updated":"2018-03-31T02:12:21.262Z","comments":true,"path":"2017/10/18/Android文件读写方法/","link":"","permalink":"https://lizec.top/2017/10/18/Android%E6%96%87%E4%BB%B6%E8%AF%BB%E5%86%99%E6%96%B9%E6%B3%95/","excerpt":"","text":"由于中文翻译和表达的关系，Android中关于文件存储位置的有关词汇存在一些歧义，同时也存在一些在PC上并不存在的概念。为了便于查找，下面先给出其中的各种位置的路径获取方法和一些对比。之后对其中的一些概念和细节进行进一步的解释 各种存储位置的对比 名称 位置 获得方法 内部存储 /data/data/包名/files getFilesDir() 外部存储的公共空间 /storage/sdcard0 Environment.getExternalStorageDirectory() 系统的外部公共空间 /storage/sdcard0/类型名 Environment.getExternalStoragePublicDirectory(TYPE) 外部存储的私有空间 /storage/sdcard0/Android/data/包名/ getExternalFilesDir(TYPE) 名称 卸载后是否清除 用户是否可见 其他程序是否可见 主要用途 内部存储 是 否 否 APP私有文件存放的位置 外部存储的公共空间 否 是 是 希望与用户和其他程序共享的位置 系统的外部公共空间 否 是 是 希望与用户和其他程序共享的位置 外部存储的私有空间 是 是 否 对其他程序没有作用的其他次要文件 注意 TYPE指Environment中定义的常量，例如Environment.DIRECTORY_DOCUMENTS 如果TYPE置为null，则返回相应的根目录 几种方式的简要说明内部存储 内部存储类似系统空间，该位置对于非root用户不可见，在此处创建的文件，只有该APP可以进行读写 当APP被卸载的时，此空间内的所有文件都会被删除 APP有关的不需要共享的文件都可以存放在此文件夹中 外部存储的公共空间 外部存储的公共空间通常对应于手机存储，此处可以存放任意文件，用户和任何程序都可以对其中的文件进行读写 通常需要程序先创建一个文件夹，之后在此文件夹中操作 当APP被卸载时，此区域的文件不会被删除 APP需要共享的文件存放在此处 系统的外部公共空间 系统的外部公共空间是指系统预先定义的一系列文件夹，例如Document，Music等。 与外部存储的公共空间相比，由于系统预先定义，因此使用更加方便 APP需要共享的文件存放在此处 外部存储的私有空间 外部存储的私有空间存在于外部存储，但其又具有私有空间的性质，限制了其他APP访问此区域的文件 APP需要的大体积文件或其他次要文件存放在此处 外部存储与外置SD卡对于系统而言，只有内部存储和外部存储，即无论内置SD卡还是外置SD卡，都被视为外部存储，但是由于使用外置SD卡的设备越来越少，因此本文中不再讨论如何读写外置SD卡。 测试函数以下提供一个函数，用于测试有关存储空间的位置 12345678910111213141516171819202122void test()&#123; //内部存储位置 String L1 = getFilesDir().getAbsolutePath(); Log.i(&quot;内部存储&quot;,L1); // 外部存储的公共空间 String L2 = Environment.getExternalStorageDirectory().getAbsolutePath(); Log.i(&quot;外部存储的公共空间&quot;,L2); // 输出外部存储的公共空间下，所有的文件和文件夹 for(String file:Environment.getExternalStorageDirectory().list())&#123; Log.i(&quot;文件-&gt;&quot;,file); &#125; // 系统的外部公共空间，使用Environment指定类型 String L3 = Environment.getExternalStoragePublicDirectory(Environment.DIRECTORY_DOCUMENTS).toString(); Log.i(&quot;系统公共区域&quot;,L3); // 外部存储的私有空间 String L4 = getExternalFilesDir(Environment.DIRECTORY_DOCUMENTS).getAbsolutePath(); Log.i(&quot;外部私有区域&quot;,L4);&#125; 参考文献和扩展阅读彻底理解android中的内部存储与外部存储Android中的内部存储与外部存储android中的文件操作详解以及内部存储和外部存储Android 漫游之路——将文件保存到内存、SD以及获取手机内部存储与外部存储空间的大小","categories":[{"name":"Android","slug":"Android","permalink":"https://lizec.top/categories/Android/"}],"tags":[{"name":"Android","slug":"Android","permalink":"https://lizec.top/tags/Android/"}]},{"title":"Android开发记录","slug":"Android开发记录","date":"2017-10-12T07:38:17.000Z","updated":"2018-03-31T02:12:17.330Z","comments":true,"path":"2017/10/12/Android开发记录/","link":"","permalink":"https://lizec.top/2017/10/12/Android%E5%BC%80%E5%8F%91%E8%AE%B0%E5%BD%95/","excerpt":"","text":"内容概述这里记录了我在开发Android程序的过程中遇到的一些问题和解决方案，在帮助自己复习有关细节的时候，希望也能给其他人提供一些帮助 使用网络在Android程序中，如果想要正确的使用网络功能，需要满足以下条件 在AndroidManifest.xml 添加如下语句申请网络使用权限123456&lt;manifest ... &gt; ... &lt;uses-permission android:name=&quot;android.permission.INTERNET&quot; /&gt; ...&lt;/manifest&gt; 在单独的线程中编写网络相关代码 在主线程上使用start()方法启动线程 说明：在Android系统中，规定不允许在主线程执行网络操作，因此所有的网络相关操作都需要在单独的线程上进行 读写文件 在AndroidManifest.xml 中添加如下语句申请外部读写权限 1234567&lt;manifest ... &gt; ... &lt;uses-permission android:name=&quot;android.permission.WRITE_EXTERNAL_STORAGE&quot;/&gt; &lt;uses-permission android:name=&quot;android.permission.READ_EXTERNAL_STORAGE&quot;/&gt; ...&lt;/manifest&gt; 调用getExternalFilesDir函数获得外部存储上的私有空间 使用Environment上的常量指定具体的文件夹类型，一个例子如下 12// 获得外部储存上的私有空间下的download目录对应的位置File path = getExternalFilesDir(Environment.DIRECTORY_DOWNLOADS); 注意：给定的路径不一定存在，使用前需要判断是否存在该目录 更新UI 只有主线程可以更新UI 只有主线程可以弹出对话框 如下代码展示使用Handler类与Message类结合进行消息传递 12345678910111213141516171819202122232425262728// 位于主线程的handler接受信息，更新UIprivate Handler handler = new Handler()&#123; @Override public void handleMessage(Message msg) &#123; ProgressBar prbBook = (ProgressBar)findViewById(R.id.prbBook); if(msg.what == FINISH_LOAD_BOOK_FROM_NET)&#123; prbBook.setProgress(100); initInfo(); initCatalog(); &#125; else if(msg.what == UPDATE)&#123; prbBook.incrementProgressBy(msg.arg1); &#125; &#125;&#125;;//某个线程执行完毕使用Message类发送消息，通知handlerprivate class LoadBookThread implements Runnable&#123; @Override public void run() &#123; thisBook = new Book(bookURL); finishLoading = true; Message message = new Message(); message.what = FINISH_LOAD_BOOK_FROM_NET; handler.sendMessage(message); &#125;&#125; 注意：根据Android Studio的提示，直接使用handler类可能导致资源泄露,提示内容如下 123456789This Handler class should be static or leaks might occur (anonymous android.os.Handler) less... (Ctrl+F1) Since this Handler is declared as an inner class, it may prevent the outer class from being garbage collected.If the Handler is using a Looper or MessageQueue for a thread other than the main thread, then there is no issue. If the Handler is using the Looper or MessageQueue of the main thread, you need to fix your Handler declaration, as follows: Declare the Handler as a static class; In the outer class, instantiate a WeakReference to the outer class and pass this object to your Handler when you instantiate the Handler; Make all references to members of the outer class using the WeakReference object. 根据提示的内容，这样设置handler，可能会导致外部类的某些资源不能被释放，所以应该建立一些弱引用。有关于Java的弱引用，可以参看这篇文章处于这种情况，除了可以按照上述的提示，建立相关的弱引用以外，还可以使用AsyncTask类，具体使用方法，后续再补充 CharSequence接口TextView类的getText()方法返回的是CharSequence, 查阅API文档可知,CharSequence是一个接口, 已知实现这个接口的类有CharBuffer, Segment, String, StringBuffer, StringBuilder.所以如果直接使用getText()获得对象后，使用equals与字符串比较可能并不会获得期望的结果,所以正确的做法应该是先调用toString()获得一个String对象，然后再进行比较,示例代码如下 12TextView txtURL = (TextView)findViewById(R.id.txtURL);txtURL.getText().toString().equals(&quot;LiZeC&quot;); 在代码中获得xml资源1234java代码获取一个字符数组：String[] names = getResources().getStringArray(R.array.string_array_name);java代码获取一个整型数组：int[] names = getResources().getIntArray(R.array.integer_array_name); 扩展阅读 使用lambda表达式在Android Studio中直接使用lambda表达式，有可能会报错,内容为Error:Jack is required to support java 8 language features. Either enable Jack or remove sourceCompatibility JavaVersion.VERSION_1_8. 此时可以在app模块的build.gradle的android下添加两项，位置如下所示 123456789101112131415161718192021apply plugin: &#x27;com.android.application&#x27;android &#123; ...... defaultConfig &#123; jackOptions &#123; enabled true &#125; &#125; compileOptions &#123; sourceCompatibility JavaVersion.VERSION_1_8 targetCompatibility JavaVersion.VERSION_1_8 &#125; ......&#125; 使用Android Studio运行纯Java代码 创建一个Module,类型为Java Lib 在类中正确的输入main方法签名以后,左侧行号边会出现运行的符号,点击即可运行程序 如果使用中文,可能出现乱码,在lib的build.gradle中添加以下内容123tasks.withType(JavaCompile) &#123; options.encoding = &quot;UTF-8&quot;&#125; 个人推测把源代码文本变成GBK编码也能解决乱码问题 其他待补充内容 handler其他细节 使用菜单 使用配置文件有关类 Splash界面设计 隐藏ActionBar","categories":[{"name":"Android","slug":"Android","permalink":"https://lizec.top/categories/Android/"}],"tags":[{"name":"Android","slug":"Android","permalink":"https://lizec.top/tags/Android/"}]},{"title":"操作系统笔记","slug":"操作系统笔记","date":"2017-09-23T12:42:19.000Z","updated":"2018-06-05T07:44:06.242Z","comments":true,"path":"2017/09/23/操作系统笔记/","link":"","permalink":"https://lizec.top/2017/09/23/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0/","excerpt":"","text":"目录 第一章 绪论 第二章 用户界面 第三章 进程管理 第四章 处理机调度 第五章 存储管理 第六章 文件管理 第七章 设备管理 第一章 绪论==================== 计算机系统 硬件 中央处理器（运算器和控制器） 存储器 输入设备 输出设备 软件 系统软件 应用软件 计算机系统的几个阶段 手工操作阶段 由一道程序独占机器 需要人工操作 早期批处理 联机批处理 慢速的输入输出设备和主机直接相连 解决了作业自动转接的问题 设备输入时CPU有大量的空闲等待时间 脱机批处理 使用不和主机直接相连的专用输入输出设备(卫星机) 卫星机将数据转入速度较快的磁带机中，主机与磁带机交换数据 输入和计算可以并行，提高了CPU的利用率 多道程序系统 计算机的内存中可以同时存在多道程序 宏观上这些程序并行 微观上这些程序交替执行 由各个程序自行决定是否放弃CPU，从而让其他程序执行 分时操作系统 处理机的时间分成时间片 按照时间片轮流将处理机分配给各个作业 作业在一个时间片内无法完成任务，则该任务中断，将处理机让给下一个任务 由于时间片很短，因此每个用户都感觉自己独占计算机 实时操作系统 要求计算机对于外来信息在运行的时间内做出快速响应 通用操作系统 兼有多道批处理，分时，实时处理的功能的操作系统 操作系统的基本类型 批处理操作系统 用户脱机使用计算机 成批处理 多道程序运行 分时系统 交互性， 用户可以在执行过程中进行控制 多用户同时性， 多个用户可以在一台计算机上共享CPU和其他资源 独立性，每个用户都感觉自己独占计算机 操作系统的功能 处理机管理 存储管理 设备管理 文件系统管理 用户接口 第二章 用户界面=============== 作业 在一次应用业务的处理过程中，从输入开始到输出结束，用户要求计算机所做的有关该次业务处理的全部工作称为一次作业 作业的概念一般用于早期批处理系统和现在的大型机，巨型机 作业说明书作业说明书一般包括以下内容 作业的基本描述，通常包括用户名，作业名，使用的编程语言，最大处理时间等 作业的控制描述，包括控制的描述，例如是联机还是脱机 资源的要求描述，包括要求的内存大小，外设种类或实用程序等 一般用户的输入输出方式 联机输入输出方式，外围设备直接和主机相联 脱机输入输出方式，使用单独的输入输出设备，通过缓冲设备与主机交换数据 直接耦合方式，把主机和外围机通过一个共用大容量设备直接连接 spooling系统，多台外围设备通过通道或者DMA方式与主机的外出连接 网络联机方式 操作系统提供的两个接口 为用户提供的各种命令接口 为编程人员提供的系统调用 系统调用 设备管理，用于请求和释放相关的设备，以及启动设备操作等 文件管理，包括对文件的读，写，创建和删除等 进程管理，包括进程的创建，执行，撤销，等待，执行优先级控制等 进程通信，用于在进程之间传递消息或信号 存储管理，包括检查作业占据的内存大小，获得作业内存地址等 线程管理，包括线程的创建，调度，执行和撤销等 陷阱机构与陷阱指令 在系统中为控制系统调用服务的处理机构称为陷阱处理机构 由于系统调用因此处理机中断的指令称为陷阱指令(或访管指令) 陷阱指令传递参数有三种方法 陷阱指令自带的参数 专用的寄存器 内存中专门开辟的堆栈区 第三章 进程管理 =================== 程序顺序执行的特点 顺序性 封闭性，程序执行的结果由给定的初始结果充分决定，不受外界因素决定 可再现性，执行结果与运行速度无关，重复执行结果相同 多道程序执行特点 独立性，每道程序都是逻辑上独立的 随机性，各个程序的执行顺序是随机的 资源共享性，各个程序之间的硬件，软件资源是共享的 程序的并发执行一组在逻辑上互相独立的程序或程序段在执行过程中，其执行时间在客观上相互重叠的执行方式 进程进程是并发执行的程序在执行过程中分配和管理资源的基本单位，具有以下特点 进程是一个动态概念，而程序是一个静态概念 进程具有并发特性，而程序没有 进程是竞争计算机系统资源的基本单位，其并发现受到系统约束 不同的进程可以包含同一程序，只要该程序对应的数据集不同 进程控制块进程的静态描述由三部分组成，进程控制块(PCB)，有关程序段，该程序段操作的数据集，进程控制块具有如下结构 描述信息 包括进程名，用户名和进程家族关系等 控制信息 包括进程的当前状态，进程优先级，程序开始地址，各种计数信息，通讯信息 资源管理信息 占用内存大小以及管理数据的指针 对换或覆盖的有关信息 共享程序段大小以及起始位置 输入输出设备的设备号 指向文件系统的指针以及有关标识 CPU现场保护结构 一个专门的用于保存CPU数据的结构，可以用于进程中断后的恢复 总之，PCB是系统感知进程的唯一实体，通过对PCB的操作，系统为有关进程分配资源从而使的有关进程得以被调度和执行，执行结束后，也通过释放PCB来释放进程所占有的各种资源。 进程上下文 进程上下文是进程执行过程中顺序关联的静态描述 已执行过的进程指令和数据在相关寄存器中的内容称为上文 正在执行的指令和数据在寄存器中的内容称为正文 待执行的指令和数据在寄存器中的内容称为下文 进程上下文切换进程上下文的切换一般分为三个部分 保护被切换进程的正文部分至有关存储区 操作系统进程中，有关调度和资源分配的程序执行，并选择新的进程 将被选中的进程的正文部分从有关存储区恢复到有关寄存器和堆栈，激活被选中进程执行 进程状态和转换 进程至少可以分成五个状态： 初始状态，执行状态，等待状态，就绪状态，终止状态 一个进程被创建后，处于初始状态 处于就绪状态的进程得到了除CPU以外的所有资源，只要被调度就可以立即执行，进入执行状态 处于执行状态的进程有三种转移状态 时间片到达，回到就绪状态 由于某些事件，进入等待状态 完成程序，进入终止状态 处于等待状态的程序在某些事件的唤醒下，进入就绪状态 原语 在系统态下执行的完成系统特定功能的程序段 是一个不解分割的操作,不允许被中断,不能并发执行 进程控制1. 进程创建 查询PCB总链,是否有同名进程 如果有,则报错,否则向PCB资源池申请一个空PCB结构 如果不能获得申请,报错,否则填写PCB有关内容 将PCB放入就绪队列和PCB总链 2. 进程撤销 查询进程链表或进程家族 如果没有查到此进程,报错,否则查询该进程是否有子进程 如果有,递归的撤销子进程 释放该进程占用的资源 释放PCB结构本身 3. 进程阻塞 保存当前进程的CPU现场 设置该进程状态 该进程进入等待队列 转进程调度 4. 进程唤醒 从等待队列取出进程 将此进程置为就绪态 将进程送入就绪队列 转进程调度或返回 进程互斥 不允许多个并发程序交叉执行的一段程序称为临界区 由共享公共资源而造成的对并发进程执行速度的间接制约，简称间接制约 一组并发进程中的一个或多个程序段，因共享某一共有资源而导致它们必须以一个不允许交叉执行的顺序执行，称为互斥 信号量和PV原语 信号量sem是一个整数，当sem大于零时，表示并发进程可以使用的实体数量，当sem小于零时，表示正在等待使用临界资源的进程数 P原语操作主要动作如下 --sem 若sem仍大于等于零，则P原语返回，该进程继续执行 若sem小于零，则该进程被阻塞后，进入该信号量的等待队列，然后转进程调度 V原语操作的主要动作如下 ++sem 若sem仍大于零，则V原语返回，该进程继续执行 多sem小于等于零，则从该信号的等待队列中唤醒一个进程，然后返回原进程执行或转入进程调度 遇到临界区的时候，在临界区的两端分别加上P原语和V原语即可完成互斥操作 进程同步建立两个互补的私有信号量，通过交叉判断进行同步操作 1234567891011121314151617S1()&#123; ... P(empty) 写入数据 V(full) ...&#125;S2()&#123; ... P(full) 取出数据 V(empty) ...&#125; 其中Sa和Sb一个置为0,一个置为1 S1进程执行之前，会先判断缓冲区是否为空，确定为空后写入数据，最后使用V原语唤醒可能等待的S2进程 S2进程执行之前，会先判断缓冲区是否已满，确定已满后取出数据，最后使用V原语唤醒可能等待的S1进程 进程的一般模型1.生产者-消费者模型进程之间的资源申请和释放问题可以看作一个生产者-消费者问题，使用资源的进程可以看为消费者，而释放资源的进程可以看为生产者，一般而言这些进程的代码具有如下的结构 1234567891011121314151617deposit(data)&#123; P(avail) P(mutex) 写入数据 V(full) V(mutex)&#125;remove(data)&#123; P(full) P(mutex) 取出数据 V(avail) V(mutex)&#125; 其中avail和full信号量是私有信号量，用于两个不同进程的同步 mutex信号量是共有信号量，用于各个进程之间的互斥 V原语因为是释放操作，因此通常没有顺序要求 注意:要先执行同步P操作，再进程互斥P操作，从而确保互斥锁定之前，获得执行机会的进程一定可以执行完毕，避免进程死锁 2.读者-写者模型有两组并发的进程：读者和写者，其中要求任何时刻，写者之间互斥，读者与写者互斥，读者之间可以同时读取 1234567891011121314151617181920212223242526writer(data)&#123; P(w); 写入数据 V(w);&#125;reader(data)&#123; P(R); ++Rcount; if (Rcount == 1)&#123; P(w); &#125; V(R); ... 读取数据 ... P(R); --Rcount; if(Rcount == 0)&#123; V(w); &#125; V(R);&#125; 对于写者，只要开始访问数据，就可以直接锁定 对于读者，只有第一个需要互斥写者，只有最后一个需要释放锁定，因此需要使用一个计数器 因为多个进程访问计数器，因此计数器的读写需要锁定 3.哲学家吃饭模型 一共有5个哲学家，每个哲学家之间有一个筷子 哲学家拿到两个筷子时才能开始进餐 当一个哲学家拿到一个筷子以后，除非拿到另外一个筷子并完成进餐，否在绝对不会放下手中的筷子 实际上，进一步分析可知，如果限制最大吃饭人数，即限制最多4人同时吃饭，则可以保证4人中，至少有一人可以获得两个筷子，从而完成吃饭 12345678910111213141516171819202122232425main()&#123; int chopstick[5] = &#123;1&#125;; int count = 4; cobegin eat[0](); eat[1](); ... eat[4](); coend&#125;eat[i]()&#123; think; P(count); P(chopstick[i]); P(chopstick[(i+1) mod 5]); eat; V(chopstick[i]); V(chopstick[(i+1) mod 5]); V(count); think;&#125; 4.理发问题 有一个理发师，一把理发椅和n把供等待客户坐的椅子 如果没有顾客，理发师在理发椅上休息 当有一个顾客到来时，唤醒理发师进行理发 当理发师在理发的时候，如果有新顾客到来，则判断等待区是否有空闲，如果有则等待，否在离开 12345678910111213141516171819202122232425262728293031323334353637main()&#123; int customers = 0; int barbers = 1; int wait = 0; cobegin Barber(); Customer(); coend&#125;Barber()&#123; while() &#123; P(customers); wait = wait - 1; 理发; V(barbers); &#125;&#125;Customer()&#123; if(wait&lt;n) &#123; wait = wait + 1; V(customers); P(barbers); 理发; &#125; else &#123; 离开理发店; &#125;&#125; 进程通信 直接通信 在发送和接受时，都需要制定双方的标识 间接通信 借助共享的数据结构进行通信 进程间的通信方式 主从式 主进程可以自由的使用从进程的资源或数据 从进程的受到主进程的控制 实际上是一种控制关系 会话式 使用进程在使用服务进程提供的服务以前，必须获得服务进程的同意 服务进程根据使用进程的要求提供服务，但所提供的服务的控制由服务进程完成 实际上是一种调用关系 消息或邮箱机制 只要存在空缓冲区或邮箱，发送进程就可以发送消息 发送进程和接受进程之间没有直接的联系 实际上是一种平等的关系 共享存储区方式 共享存储区不需要移动数据 两个进程通过对同一共享存储区进行操作实现互相通信 这个共享区是每个互相通信的进程的一个组成部分 文件共享方式 借助文件系统原有机制进行通信 消息的结构 发送进程名 接受进程名 数据 数据的相关操作 消息缓冲机制 在发送进程把消息写入缓冲区和把换从区挂入消息队列时，应禁止其他进程对该缓冲区消息队列的访问 缓冲区中无消息存在时，接受进程不能收到任何消息 12345678910111213141516171819Send(B,m)&#123; 向系统申请一个缓冲区; P(mutex); 将发送区消息m送入新申请的消息缓冲区; 把消息缓冲区挂入接收进程的消息队列; V(mutex); V(SM);&#125;Receive(A,n)&#123; P(SM); P(mutex); 摘下消息队列中的消息n; 将消息n冲缓冲区复制到接收区; 释放缓冲区; V(mutex);&#125; 邮箱通信 邮箱由邮箱头和邮箱体组成，邮箱头总包含相关的身份信息，邮箱体中是需要传输的数据 两个进程之间是简单的同步问题，按照同步问题加锁即可 线程进程是资源的拥有者，也是调度单位，但是线程不拥有资源，只是一个调度单位，从而能更加方便的进行调度 死锁的必要条件 互斥条件：进程要求对所分配的资源进行排他性控制，即在一段时间之内某资源仅为一一个进程占有 部分分配，进程每次申请它所需要的一部分资源，在等待新资源的时候，不释放已经占有的资源 不剥夺条件：进程已经获得的资源，在没有使用完毕之前，不能被剥夺 环路条件，存在进程链循环，循环中每个进程已经获得的资源被下一个进程请求 死锁的排除方法 预防死锁：采取某种措施，限制并发进程对资源的请求，从而破坏产生死锁的必要条件中的一个或几个来防止死锁 互斥条件是设备的固有特性，不仅不能改变，而且还应该加以保护 摒弃”请求和保持”条件：资源预分配策略：运行前一次性分配给进程所有需要的资源 优点：简单易行且安全 缺点：资源浪费，进程延时运行 摒弃”不可剥夺”条件 缺点：实现复杂，系统代价很高 摒弃”环路等待”条件：把系统资源按照类型排序，进程要按照资源的序号递增的次序提出资源申请 优点：比上述两种方法的综合性能要好 缺点：限制了进程对资源的请求，同时给系统中所有资源编号增加来系统开销 避免死锁：系统在分配资源时，根据资源的使用情况预测是否会产生死锁 银行家算法 判断分配条件，并尝试分配 分配后进行安全性检测，如果安全则接受分配，否则撤销分配 安全性检测即在当前分配完成后,是否存在方案可以使后续进程都能分配需要的资源并完成 银行家算法数据结构 Available m元素的数组,表示资源可用总数 Max[i,j] 进程i对资源j的最大使用量 Allocation[i,j] 进程i当前已经获得的资源j的数量 Need[i,j] 进程i还需要的资源j的数量 Request 当前请求分配的资源数组 安全性检测数据结构 Work m元素向量,表示当前可以分配的资源,初始值Word = Available Finish n元素向量,表示任务是否可完成 死锁的检测和恢复 通过死锁检测算法检测系统中是否有死锁 通过中止进程，强制剥夺资源等方法解除死锁 第四章 处理机调度 ==================== 调度层次 作业调度：宏观调度，高级调度 按一定原则选择外存后备队列中的作业，为其分配内存等资源，并建立进程 在作业执行完毕后，回收系统资源 交换调度：内外存交换，中级调度 按给定的策略，将外存中处于就绪状态或等待状态的进程调入内存，或将内存中暂时不使用的进程调至外存 提高内存利用率和系统吞吐量 进程调度：微观调度，低级调度 决定就绪队列中那个进程获得处理机 线程调度 可有OS内核完成，也可由用户程序进行 作业的状态 提交状态 一个作业处于从输入设备进入外存的过程时处于的状态 后备状态 作业的全部内容都通过输入设备输入到外存输入井中，等待进入内存 执行状态 作业一旦被作业调度程序选中，则为其分配所需的资源，并创建进程，送入内存中投入运行 完成状态 作业运行完毕，准备退出系统时的状态（所占用的资源尚未全部被系统回收） 面向用户的性能指标 周转时期 作业从提交到完成所用的时间 包括平均周转时间和平均带权周转时间 平均带权周转时间的权值为 1/运行时间 响应时间 用户发出命令(例如键盘按键)到系统给出响应的时间(例如屏幕输出字符) 面向系统的性能指标 吞吐量 设备利用率 设备均衡利用 公平性 优先级 调度算法的衡量 易于实现 运行开销小 进程调度功能 记录所有进程的执行情况（静态和动态） 按一定策略，选择一个就绪进程 完成进程上下文切换 进程上下文切换步骤 检查是否可以进行进程切换 保存被切换进程现场 选择一个新进程 恢复被选中进程现场 引起进程调度的原因 正在执行的进程执行完毕，或由于某种错误而中止 执行中的进程自己调用阻塞原语，将自己阻塞进入等待 执行P原语 执行V原语，激活 提出I/O请求后被阻塞 执行完系统调用后 分时系统中时间片到 一个高优先级的进程就绪（可抢占式系统） 进程调度方式 非抢占式 某一进程被调度后，将一直执行到完成或者被阻塞 即是由于自身的原因而让出CPU 抢占式 由于优先权，短作业优先或时间片到等原因，系统强制剥夺正在执行的进程的CPU 进程调度性能衡量 定性衡量 公平性 可靠性 简洁性 定量评价 CPU利用率 响应时间 吞吐量 调度算法 先来先服务 短作业优先 每次一个任务执行完毕后,从当前等待的队列中选择耗时最短的作业 最高响应比法 响应比 = 响应时间 / 运行时间 响应时间 = 作业等待时间+预计执行时间 响应比 = 1 + 作业等待时间 / 运行时间 每次一个任务执行完毕后,从当前等待队列中选择响应比最高的作业 时间片轮转法 所有作业排成一个FIFO队列 依次选择队首进程执行一个时间片,时间片到后回到队尾 在执行过程中,如果任务结束,可以提前结束时间片,开始下一个作业的调度 多级队列法 可以设置多个队列,每个队列可采取不同的调度算法 优先级算法 静态优先级 所有进程根据各种因素确定一个优先级,在执行过程中始终不变 动态优先级 在执行过程中动态改变优先级,从而获得更好的调度效果 例如,等待时间越长,优先级越高 例如,每执行一个时间片,降低一个优先级 多级反馈轮转法 设置多个队列,赋予不同优先级 优先级越低,时间片越长 新进入的进程首先进入优先级最高的等待队列 如果一个时间片内进程未能执行完毕,则降级到下一个优先级队列(直到最低一级) 高优先级队列为空是,才调度低优先级的进程 第五章 存储管理 ==================== 程序逻辑结构 程序地址:用户编程时使用的地址 程序地址空间:用户的程序地址集合,总是从0开始编制,但既可以是一维空间也可以是多维空间 逻辑地址,物理地址与地址映射 逻辑地址(相对地址,虚地址): 用户的程序编译后使用的地址,通常是相对地址,且假设首地址是0,并且相对此地址进行编址 物理地址(绝对地址,实地址): 内存中存储单元的地址 地址映射:将逻辑地址转化为物理地址 存储管理功能 存储分配与回收 地址变换 程序加载时的重定位技术 程序运行时的地址变换机构和技术 存储共享与保护 代码和数据的共享,提高内存利用率 限制在各自的内存区域内操作,互不干扰 存储器扩充方式 覆盖 交换 请求调入 / 预调入 重定位在可执行文件装入时需要解决可执行文件中地址(包含指令和数据的地址)和内存地址的对应. 有三种重定位方式 绝对装入:编程或编译时确定绝对地址 静态地址重定位: 程序执行前,由装入程序完成地址映射,程序执行过程中,映射关系始终不变 动态地址重定位: 处理机执行程序时,由地址映射机构动态的完成地址映射 存储保护方法 界限保护(上界/下界寄存器 或 基址/限长寄存器) 所有访问都限定在指定的范围中,否在产生越界错误 由硬件判断是否允许访问,如果不允许则产生越界中断,有操作系统进行处理 访问方式保护(保护键) 对于允许多个进程共享的存储区域,每个进程都有自己的访问权限 如果一个进程对共享区域的访问违反了权限规定,则发生操作越权 (即读写保护) 为每一个被保护内存区域指定保护键和若干禁止的访问方式,同时进程指定保护键开关 如果访问时键值不匹配而且是被禁止的访问方式,则产生访问出错中断 虚拟存储器 为用户提供一种不受物理存储器结构和容量的限制的存储技术 使得用户编程时不需要考虑物理存储器的结构和容量 每个进程都有自己的虚存,且虚存大小不受物理存储器容量的限制 虚拟存储器物质基础 两级存储结构: 内存与外存储器 地址变化机构: 实现逻辑地址与物理地址的转化 虚拟存储器原理 程序运行时,不将全部的数据调入内存,只调入当前需要的部分 在程序执行过程中,如果需要访问的部分不再内存中,处理器通知操作系统将相应的程序或数据调入内存,然后继续执行 将内存中暂时不使用的数据移出内存,保存到外层,从而腾出内存空间 内外存数据传输控制 由应用程序控制 覆盖 由OS控制 交换(整个进程空间) 虚拟存储(部分进程空间) 请求调入 预调入 覆盖 一个程序的几个代码段或数据段按照时间先后占用公共的内存空间 用户负担大 程序段最大长度仍然受内存容量限制 不能实现虚拟存储器 交换 将暂时不能执行的程序送到外存,从而获得空闲内存空间装入新程序 虚拟存储 请求调入: 程序需要访问时,系统自动的从外存调入相关的内存段 预调入: 系统预测后续可能被访问的内存段,并提前调入 分区存储管理 把内存分为一些大小相等或不等的分区, 除了操作系统占用一个分区以外, 其余分区用来存放进程和程序和数据 适用于多道程序和简单的分时程序 难以进行内存分区共享 存在碎片 内碎片: 占用分区内难以利用的部分 外碎片: 占用分区之间难以利用的部分 分区分类 固定分区法: 系统初始化时固定的分区 分区大小不等 分区个数,大小不变 每个分区有一对界地址寄存器 采用静态重定位方式载入 实现简单,要求的硬件支持少,但内存利用率低 动态分区法: 在作业的处理过程中,按照需要分割 从可用表 /自由链中找到一个足够容纳该作业的可用空白块 如果空白块比需要的大,则将空白块一分为二,一部分是分配区,另一部分还是空白 空闲分区查找算法 最先适应法:按照内存地址由低向高依次查找 最佳适应法:从空白区间最小的开始查找 最坏适应法:从空白区间最大的开始查找 紧缩技术 将内存中占用的分区向一段移动,从而使空间分区聚集在另外一段 在分区释放或内存分配失败时执行此操作 页式存储管理 目标是解决分区管理内存利用率不高的问题 将逻辑空间分页和内存空间分块,页和块大小相等 当用户程序装入内存时,以页为单位装入 逻辑上连续的页可以装入物理上不连续的块中 地址映射方式 以2进制来看,低位部分是页类位移,高位即为页号 联想存储器 在页式存储技术中,每次都需要访问内存两次,严重影响系统效率(一次访问页表,一次访问内存) 因此使用联想存储器来加速查询速度 类似与Cache,但联想存储器和页表是并行查询 请求页式存储管理 纯页式管理提高了内存利用率,但还是不能为用户提供虚存 当用户程序页面数大于当前空闲内存块数时,系统还是不能装入此程序 用户程序依然受到物理内存大小限制 请求时页式存储管理技术的目标即解决上述问题 请求页式管理的区别 当用户程序要调入内存时,不是全部装入,而是只装入部分页 在程序运行过程中,如果发现需要访问的数据不在内存,则向系统发出缺页中断 系统将相应的页调入内存,程序继续运行 请求页式管理的数据结构变化 从调入角度,需要添加标志位,用于判断是否已经调入 从调出角度,需要添加标志位,用于判断最近是否访问,是否修改等 此外还需要记录有关数据在外存中的地址,以便以后续的调入 调度策略 预调入 请求调入 淘汰(置换)算法 随机淘汰法 随机选择一个页换出 轮转法和先进先出法 轮转法循环的换出内存中的某些块,这些块可能已经驻留很长时间,也可能刚刚调入 先进先出法每次淘汰内存中驻留时间最长的页 最近最久未使用算法 当淘汰一个页时,选择里当前时间最近的一段时间内,最长时间没有被使用的页 在表格中,向左寻找当前的项中最近一次出现的距离,选择距离最远的项淘汰 有两个近似算法 最不经常使用页面淘汰算法 淘汰到淘汰时间为止,访问次数最少的那一页 淘汰后,所有计数器清零,开始下一轮统计 最近没有使用页面淘汰算法 淘汰当淘汰时间为止,没有被访问的也 只用设置标志位,不用设置计数器 理想淘汰算法 淘汰以后不再使用或最长时间不再使用的页 在表格中,向右寻找当前项中最近一次出现的距离,选择距离最远的项淘汰注意: 第一次调入时也是缺页 Belady现象 使用FIFO算法时,在给进程分配内存块时,有时会出现分配的块越多,缺页次数反而增加的现象 页式管理优缺点 有效的解决了碎片问题 支持虚存 但是需要响应的硬件支持 增加了系统开销 如果调入算法不当,可能产生抖动 内碎片问题无法解决 不利于程序和数据共享 段式管理 一个程序按照其逻辑,分成若干段 每一段都从0开始编址 段长不固定,可根据需要动态增长 各段之间不需要连续 分页与分段的异同点 在内存中都不是整体连续,都使用地址映射机构进行转换 页时信息的物理单位,用户不需要处理. 段是信息的逻辑单位,分段可以更好的满足用户需求 页的大小是固定的,段的大小是可以变化的 分页的作业地址空间是一维的,分段的作业地址空间是二维的 段页式存储管理 结合分段的逻辑优势和分页的空间管理优势 将程序在逻辑上分段,在每段上分页 每段的页都从0开始依次变址 由此分段大小不再受内存可用区域的限制 第六章 文件管理 ====================== 文件 一段程序或数据的集合 一组赋名的相关联字符流的集合或相关联记录的集合 文件系统 负责为用户建立,撤销,读写,修改和复制文件 完成对文件的按名存取和存取控制 文件类型 按性质和用途分类 系统文件(可执行) 用户文件(可读可写可执行) 库文件(可读可执行) 按文件保护方式 只读文件 读写文件 可执行文件 不保护文件 按文件注释和处理方式 普通文件:一般的文本文件和二进制文件 目录文件:包含文件目录信息的文件,用于检索普通文件 特殊文件:输入输出设备可以看做特殊文件 按信息流 输入文件: 如读卡机或键盘,只能读入 输出文件: 如打印机,只能写出 输入/输出文件:如磁盘,既可读又可写 按文件的数据形式 源文件 目标文件 可执行文件 文件的组织结构 逻辑结构 字符流式无结构文件 记录式有结构文件 记录式结构文件种类 连续结构:把记录按照先后顺序排列 适用性强 排列顺序与内容无关(便于记录的追加) 搜索性能较差 多重结构:一个包含n个记录吗,m个键的文件构成一个mn的矩阵 如果矩阵i行j列值为1,则说明记录键k[i]在记录R[j]中 同一键可以同时属于不同的记录 以键k[i]为队首,以包含k[i]的记录为队列元素构成队列 此结构搜索效率高于连续结构,但必须先找到对应的键,并在其队列中顺序查找 转置结构:把含有相同键的记录指针全部指向该键 -把所有与同一键对应的记录的指针连续地置于目录中该键的位置下 顺序结构:把文件的键按照规定的顺序,如字母顺序排列 适合与按某种顺序来搜索,追加,删除记录 文件物理结构 顺序结构 把逻辑上连续的文件依次存放在连续的物理块上 结构简单,存取速度快 不能动态增长, 部分删除会有零头 链接结构 类似链表结构,每个块的末尾有指向下一块的指针 文件可以动态增长 不适合随机访问,一般只用于逻辑上连续且顺序访问的情景 索引结构 为每个文件建立一个索引表,从表中可以直接查询到指定块的物理块号(类似页表) 即可满足动态增长又可实现随机存取 使用索引表增加了存储空间开销,且需要至少访问两次存储器 索引表组织 连接模式:索引表占满一块就用指针链接下一块 多级索引:存放的不是索引,而是存索引块的地址 综合模式:索引表的头几项设置为直接寻址,后的设置为多重索引 磁盘调度算法 先到先服务 简单公平 效率不高,可能导致磁头反复移动 最短寻道时间优先 优先选择距离当前磁头最近的访问请求进行服务 改善了磁盘的平均服务时间 可能造成某些访问长时间得不到服务 扫描算法(电梯算法) 无访问时,磁头位置不动 有访问时,磁头按一个方向移动,依次处理经过的请求 如果到达边缘就转换方向 文件存储空间管理 空闲文件目录法: 所有空闲块记录在一个表中 适合仅有少量空白区域的情况 适合连续文件 空闲块链法: 所有块链接成一个链表 只需要一个头结点保存空闲区信息 效率低 成组链接法: 把文件存储设备的所有空闲块按组保存 例如见空闲块每50块分成一组 每组第一块存放前一组的总块数和各块块号,后面的块为空,作为空闲块等待分配 第一组只有49块,最后一组可能不足50块 将最后一组调入内存,并维持成栈结构 分配空间时,进行出栈操作,如果只剩下一块,就从此块中取出前一组地址,载入新的组,并将此块分配给请求进程 释放空间时,进行入栈操作,如果到达50块,就将所有块号存入,并清空栈,将栈的第一块链接到此组 位示图法: 使用一串二进制位反应空间分配情况 文件目录管理 文件组成 文件体: 文件本身的信息 文件说明(文件控制块FCB) 存放为了管理文件所需要的信息 包括文件名,起始物理位置,存取控制信息等 文件目录 单级目录 系统为所有存入系统的文件建立一张表 每个文件有一个表目 各个文件处于平等地位 简单且能够按名存取 不允许重名,且文件多时,查找速度慢 二级目录 主目录文件(MFD Main File Directory) 存放不同组名的有关存取控制信息 包括用户名,用户子目录所在文件物理地址等 用户文件目录(UFD User File Directory) 存放用户文件的文件说明 即该用户的FCB 文件名 &lt;==&gt; 用户名/文件名 解决了文件重名和文件共享的问题 由于有用户名,所以可以同名 由于UFD可以指定地址,所以可以在物理层面是上共享文件 不适合大量用户和大量文件的系统 多级目录结构 产生于Unix系统,已被现代操作系统广泛采用 多级目录中,处理最低一级的物理块总有文件信息,其他没记目录中都是存放下一级目录或文件说明信息 通过路径名解决了重名问题 查找速度快 文件共享 绕道法 要求用户处于当前目录下工作 所有的文件访问都是相对当前目录进行 当前目录一般存放在内存中 依次向上回溯到需要访问的节点与当前目录的公共节点,再从公共节点依次向下找到目标节点 效率低 链接法 将一个链接指针直接指向共享文件所在的目录 基本文件目录表 基本文件目录BFD(Basic File Directory) 包括文件的结构信息,物理块号,存取控制等信息 有系统赋予唯一的内部标识符来标识 此目录以连续文件的形式存于卷头部,此长度决定了卷内最大文件数 符号文件目录SFD(Symbol File Directory) 有用户给出文件名和文件内部标识符组成 用于建立文件名和文件内部标识符对应关系 第七章 设备管理 ====================== 设备管理的任务 选择和分配IO设备以进行数据传输操作 控制IO设备和内存数据之间交换数据 为用户提供友好的透明接口 提高并行操作度 设备管理的功能 提供和进程管理系统的接口 进行设备分配 实现设备和设备,设备和CPU之间的并行操作 进行缓冲区的分配,释放以及相关的管理 数据传送控制方式 程序直接控制 由用户进程直接控制 控制简单,不需要硬件支持 CPU和外围设备只能串行工作 无法发现和处理由于硬件产生的错误 中断方式 CPU利用率大大提高 支持多道程序与设备并行操作 一次数据传输可能需要多次中断,会消耗大量CPU时间 可能造成CPU无法响应中断和出现数据丢失的问题 DMA方式 在外围设备和内存之间开辟直接的数据交换通路 DMA通过挪用CPU的一个工作周期把数据送入内存 除了数据开始传送时需要CPU的启动指令,以及传送结束后CPU进行中断处理以外,不再需要CPU频繁干预 CPU中断处理次数大大减少 排除了数据丢失的问题 由于MDA方式对外围设备的某些操作还是需要CPU控制,且配备多个DMA是不经济的,因此DMA方式也存在一定的局限性 通道方式 一个独立于CPU的专门负责I/O控制的处理机 有自己的指令系统,通道指令受CPU启动,并在操作结束后向CPU发出中断信号 与DMA方式的区别 DMA方式中,数据的传输有CPU控制,通道中有专门的硬件控制 DMA方式中,每台设备至少一个DMA控制器,通道中一个通道可以控制多态设备与内存进行数据交换 缓冲技术 引入缓冲的目的 缓和CPU和I/O设备间速度不匹配的矛盾 减少CPU中断次数 解决DMA或或通道方式时的瓶颈问题 缓冲区种类 按照缓冲器个数 单缓冲 CPU与外设之间只设立一个缓冲区 共用资源需要互斥使用 双缓冲 设置两个缓冲区 实际很少使用此方案 多缓冲/缓冲池 把主存的多个缓冲区分为两个部分 输入缓冲区和输出缓冲区 每个缓冲区依然是临界资源,必须互斥使用 按照I/O控制 专用硬件 软件缓冲 缓冲区管理 用于收容输入数据的工作缓冲区(hin): 输入设备-&gt; 缓冲区 用于提取输入数据的工作缓冲区(sin): 缓冲区-&gt;CPU 用于收容输出数据的工作缓冲区(hout): CPU-&gt;缓冲区 用于提取输出数据的工作缓冲区(sout): 缓冲区-&gt;输出设备 设备分配技术 数据结构 系统设备表SDT(System Device Table) 记录所有I/O设备信息 包括设备类型,设备标识符,进程标识符,DCT指针等 设备控制表DCT(Device Control Table) 系统中的每台设备都有一张设备控制表 记录设备各方面特征,以及与设备相联的设备控制器入口位置 设备控制器表COCT(COntroller Control Table) 每个控制器有一张控制器控制表 包含控制器号,控制器状态,通道指针等 通道控制表CHCT(CHannel Control Table) 每个通道都有一张通道控制表 包括通道号,通道状态,等待队列指针等 设备分配方式 静态分配 在作业执行前,由系统一次性分配给该作业所需的全部设备,控制器和通道 在作业进行过程中,不再改变 不会死锁 设备利用率低 适用于独占型的设备 动态分配 在进行需要设备时,通过系统调用项系统提出请求,一旦使用个完毕,立即释放 提高了设备利用率 分配不当会引起死锁 适用于共享型的设备 设备独立性 指应用程序独立于具体使用的物理设备 用户编制程序使用的设备与实际使用的设备无关 设备分配策略 先请求先分配 优先级高者先分配 设备分配顺序 分配设备 分配控制器 分配通道 虚拟设备和假脱机技术 虚拟设备 虚拟设备是指代替独享设备的那部分存储空间以及有关的控制结构 SPOOLING系统(Simultaneous PeripheralOperation On Line) 同时联机的外围操作或假脱机操作 利用一台高速共享设备,将一台独享设备模拟成多台可并行操作的虚拟设备 提高了I/O速度 设备并没有分配给任何进程 实现了虚拟设备功能 I/O进程控制 从用户进程的I/O请求开始,给用户进程分配设备,启动有关设备进行I/O操作,以及在I/O在I/O操作之后响应中断,进行善后处理为止的整个系统控制过程 模块功能说明 I/O请求处理模块 将用户进程的I/O请求变换为设备管理程序所能接受的信息,并将I/O请求命令插入指向的相应DCT的I/O请求队列 设备分配程序 为I/O请求分配相应的设备,控制器和通道 缓冲区管理模块 为I/O传送申请必要的缓冲区,以及保证I/O传送的顺利完成 中断处理 数据传输结束后,外设发出中断请求,I/O控制过程根据中断原因调用中断处理程序,并作出中断响应 I/O控制的实现方式 作为请求I/O操作的进程的一部分实现 作为当前进程的一部分实现 当前进程处理中断 剩余部分有I/O进程控制 作为专门的系统进程 由系统进行I/O调度 I/O进程的实现方式 每个设备设置一个专门的I/O进程 该进程只能在系统态下执行 整个系统设置一个I/O进程 每类设备设置一个I/O进程 该进程既可在系统态也可在用户态执行 设备驱动程序 是驱动物理设备和DMA控制器或I/O控制器等直接进行I/O操作的子程序的集合 设备驱动程序负责设置相应设备有关寄存器的值,启动设备进行I/O操作,指定操作的类型和数据流向等 设备开关表(Device Switch Table, DST)对驱动程序进行管理 给出相应设备的各种操作子程序的入口地址 一般是二维的,行和列分别是设备类型和驱动程序类型 设备开关表也是I/O进程的一个数据结构","categories":[{"name":"计算机核心课程","slug":"计算机核心课程","permalink":"https://lizec.top/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%A0%B8%E5%BF%83%E8%AF%BE%E7%A8%8B/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"https://lizec.top/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}]},{"title":"Java编程中的BUG记录","slug":"Java编程中的BUG记录","date":"2017-09-01T11:57:09.000Z","updated":"2020-06-26T14:41:06.603Z","comments":true,"path":"2017/09/01/Java编程中的BUG记录/","link":"","permalink":"https://lizec.top/2017/09/01/Java%E7%BC%96%E7%A8%8B%E4%B8%AD%E7%9A%84BUG%E8%AE%B0%E5%BD%95/","excerpt":"","text":"Java删除文件 曾经有过使用Java删除文件的经历，但是偶尔会遇到删除失败。即使用file.delete()函数时，返回false。因为这个函数并不抛异常，所以并不清楚是什么原因导致了这一问题。如果查看file.delete()的源代码，可以发现这个函数的注释上写了如下的语句: 1234567/** * &lt;p&gt; Note that the &#123;@link java.nio.file.Files&#125; class defines the &#123;@link * java.nio.file.Files#delete(Path) delete&#125; method to throw an &#123;@link IOException&#125; * when a file cannot be deleted. This is useful for error reporting and to * diagnose why a file cannot be deleted. */ 上面这段注释指明，可以使用java.nio.file.Files类的静态方法delete(Path)来删除文件，这个函数会抛出异常来指明为什么删除失败。注意到delete(Path)方法需要传入一个Path类作为参数，而File类正好有一个toPath()方法可以将一个File类转化为Path类。 因此在明白了这些函数以后，可以将原来的代码中的相关删除操作换成这个会抛异常的方法，然后根据异常信息来确定具体的异常原因。替换后，抛出异常指出我想要删除的文件被正在被另外一个程序使用，进程无法访问。检查了一下代码的其他部分，很快就发现了之前读取这个文件的文件流没有关闭。因此在原来的代码中加入了关闭流的操作后，就可以顺利的将文件删除了。 值得一提的是，同样的代码，在Linux平台上，似乎并不会因为文件流没有关闭就导致文件无法被删除。但是因为Linux平台上使用的编译器和JVM与Windows平台不同，因此也不能确定这一差异是编译器导致的还是JVM或者操作系统导致的。如果下次有机会，可能会进一步探索一下其中的差异。 Apache fileupload 无法提取参数之前使用了Apache的fildupload实现了文件上传功能, 后来发现通过表单传递的参数无法通过request.getParameter()获得. 通过查阅Apache CommonIO文档可知, 使用以下方法获得参数 123456// Process a regular form fieldif (item.isFormField()) &#123; String name = item.getFieldName(); String value = item.getString(); ...&#125; 其中item通过以下方法获得 12345678910 Map&lt;String, List&lt;FileItem&gt;&gt; formItemMaps =upload.parseParameterMap(request); if (formItemMaps != null &amp;&amp; formItemMaps.size() &gt; 0) &#123; for (String name : formItemMaps.keySet()) &#123; List&lt;FileItem&gt; itemList = formItemMaps.get(name); for(FileItem item:itemList) &#123; // 在这里处理item &#125; &#125;&#125; 注意: 现在如果仅仅是文件上传, 其实并不需要使用CommonIO, Tomcat本身也支持有关功能.","categories":[{"name":"Java特性","slug":"Java特性","permalink":"https://lizec.top/categories/Java%E7%89%B9%E6%80%A7/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://lizec.top/tags/Java/"}]},{"title":"《SICP》读书笔记","slug":"《SICP》读书笔记","date":"2017-09-01T03:24:10.000Z","updated":"2020-06-26T14:43:13.410Z","comments":true,"path":"2017/09/01/《SICP》读书笔记/","link":"","permalink":"https://lizec.top/2017/09/01/%E3%80%8ASICP%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/","excerpt":"","text":"About This BookStructure and Interpretation of Computer Programs(also named as SICP) is a textbook about the principles of computer programming,such as abstraction in programming, metalinguistic abstracion, recursion, interpreters, and modular programming. It is widely considered a classic text in computer science. SCIP focuses on finding general patterns from specific problem and building software tools that embody each pattern. How to Start Learning This Book Get this book. Get Scheme dialect of Lisp. Get all code of this book. You can get all of those above from https://mitpress.mit.edu/sicp/ How to Use EdwinWhen I first tried to learn Sheme, I had a lot of problem about how to use the interpreter. One of the main reason is that Edwin is an Emacs-like editor, which is not easy for beginner to use. Therefore, I want to give an outline of Edwin. Edwin is an Emace-like editor, that is, all the usages of Edwin are almost same as Emacs. Emacs is a famous editor in Linux platforms, and almost all the commands used by Emacs are begin with Ctrl key or Alt key.Now I give some the most used commands to help beginner to use Edwin. In the following, the prefix C- refers to the Ctrl key. For example, C-x means to simultaneously press the Ctrl key and the x key. command means C-x c close Edwin and back to interpreter M-z evalute the expression C-i auto indent M-/ auto complete C-x C-s save this file C-x C-f open a new file C-x o switching windows C-x 0 close this windows For more commands, You can read the article written by me &lt;&lt;Edwin笔记&gt;&gt; Building Abstractions with ProceduresThe Elements of ProgrammingEvery powerful language has three mechanisms for accomplishing this: primitive expressions, which represent the simplest entities the language is concerned with. means of combinatoin, by which compound elements are built form simpler ones. means of abstraction, by which compound elements can be named and manipulated as units. In programming, we deal with two kinds of elements: procedures and data. Thus any powerful programming language should be able to describle primitive data and primitive procedures and should have methonds for combining and abstracting procedures and data. For example, in Java language, basic statements and basic number are primitive procedures and primitive data, and functions and classes are methonds for combining and abstracting procedures and data. When we defined a class in Java, we can manipulate it as an unit. Expressions There are some examples about based expressions in Scheme. 12345486(+ 137 248)(* 2.7 12) Expressions such as these,formed by delimiting a list of expresions within parentheses in order to denote procedure applicartion, are called combinations. The leftmost element in the list is called the operator,and the other elements are called operands. The value of a combination is obtained by applying the procedure specified by the operator to the arguments that are the values of the operands. The convention of placing the operator to the left of the operands is konwn as prefix notation. Prefix notation has several advantages it can accommodate procedures that may take an arbitray number of arguments. it extends in a straightforward way to allow combinations to be nested,that is, to have combinatons whose elements are themselver combinations 123(+ 137 248 342 23)(* (+ 4 3) (- 10 3)) There is no limit to the depth of such nesting and to the overall complexity of the expressions that the Lisp interpreter can evaluate. We can use a formatting convention known as pretty-printing, in which each long combination is written so that the operands are aligned vertically. 1234567(+ (* 3 (+ (* 2 4) (+ 3 5))) (+ (- 10 7) 6))(+ (* 3 (+ (* 2 4) (+ 3 5))) (+ (- 10 7) 6)) Read-Eval-Print Loop The interpreter always operates in the same basic cycle read an expression from the terminal evaluate the expression print the result This mode of operation is often expressed by saying that the interpreter runs in a read-eval-print loop(REPL). Naming A critical aspect of a programming language is the means it provides for using names to refer to computational objects. In the Scheme dialect of Lisp, we name things with define. 1234567(define size 2)(* size 5)(define PI 3.1415)(* 2 PI size) Evaluating Combinations To evaluate a combination, do the following: Evaluate the subexpressions of the combination Apply the procedure that is the value of the leftmost subexpression(the operator) to the arguments that are the value of the other subexpressions(the operands). Evaluating CombinationsApplicative order To evaluate a combination, do the following: Evaluate the subexpressions of the combination. Apply the proceduce that is the value of the leftmost subexpression (the operator) to the arguments that are the values of the other subexpressions. Normal order To evaluate a combination, do the following: Not evaluate a combination until its value was needed. substitute operand expressions for parameters until it obtained an expression involving only primitive operators,and would then preform the evaluation. Which is used in Scheme? Lisp uses applicative-order evaluation,partly because of the additional efficiency obtained from avoiding multiple evaluation of ecpressions. normal-order evaluation becomes much more complicated to deal with when we leave the realm of procedures that can be modeled by substitution. On the other hand, normal-order evaluation can be an extremely valuable tool. Compound ProceduresWe can use a much more powerful abstraction technique by which a compound operation can be given a name and then referred to as a unit. 123456789101112; General Form(define (&lt;name&gt; &lt;formal parameters&gt;) &lt;body&gt;); Examples(define (square x) (* x x))(define (return42 x) 42 )(define (sum-of-square x y) (+ (square x) (square y)))(define (f a) (sum-of-square (+ a 1) (* a 2)))(square 5)(square (+ 3 1)) The Substitution Model for Procedure ApplicationThe iterpreter follows much the samme process as for combinations whose operator name primitive procedures. To apply a compound procedure to arguments, evaluate the body of the procedure with each formal parameter replaced by the corresponding argument. 12345678; we can try to evaluate the combination(f 5)=&gt; (sum-of-square (+ 5 1) (* 5 2))=&gt; (sum-of-square 6 10)=&gt; (+ (square 6) (square 10))=&gt; (+ 36 100)=&gt; 136 The purpose of the substitution is to help us think about procedure application, not to provide a description of how the interpreter really works. But it is still an important model whicn can explain many question. Condtional Expressions and Predicates123456789101112131415161718192021222324252627;General Form(cond (&lt;p1&gt; &lt;e1&gt;) (&lt;p2&gt; &lt;e2&gt;) ... (&lt;pn&gt; &lt;en&gt;))(cond (&lt;p1&gt; &lt;e1&gt;) (&lt;p2&gt; &lt;e2&gt;) ... (else &lt;e&gt;))(if &lt;predicate&gt; &lt;consequent&gt; &lt;alternative&gt;); Example(define (abs x) (cond ((&gt; x 0) x) ((= x 0) 0) ((&lt; x 0) (- x))))(define (abs x) (cond ((&gt; x 0) x) (else (- x))))(define (abs x) (if (&lt; x 0) (- x) x)) Conditional expressions are evaluated as follows. The predicate &lt;p1&gt; is evaluated first. If its value is false, then &lt;p2&gt; is evaluated. If &lt;p2&gt;‘s value is also false, then &lt;p3&gt; is evaluated. This process continues until a predicate is found whose value is true, in which case the interpreter returns the value of the corresponding consequent expression. If none of the &lt;p&gt;‘s value is true, the value of the cond is undefined. If expressions are evaluated as follows. The interpreter starts by evaluating the &lt;predicate&gt; part of expression. If the &lt;predicate&gt; evaluates to a true value,the interpreter then evaluates the &lt;consequent&gt; and return its values Otherwise it evaluates the &lt;alternative&gt; and return its values. Attention: Conditional expression and If expression are special form, that is, this expression can’t be replaced by an ordinary procedure. Why If Expression Must Be a Special FormWe can just try to define a funtion to replace if expression, for example 123(define (new-if predicate then-clause else-clause) (cond (predicate then-clause) (else else-clause))) If we use this new-if like this: 1234(new-if (= 2 3) 0 5) ;value 5(new-if (= 1 2) 0 5);value 0 It is seems that new-if can work euqally. But if we use new-if in a more complicated procedure, we will find a tiny difference of if expression and new-if. The difference is also the reason why if expression must be a special form. 1234567(define (iter guess x) (new-if (= guess x) guess (iter (- guess 1) x)))(iter 10 3);Aborting!: maximum recursion depth exceeded If we use if expression, interpreter print the value 3 as we expected. But if we use new-if,interpreter tell us maximum recursion depth exceeded. In fact, we can use the Substitution Model to analyze this question 12345(iter 10 3)=&gt; (new-if (= 10 3) 3 (iter (- 10 1) x))=&gt; (new-if #f 3 (new-if (= 9 3) 3 (iter (- 9 1) x)))=&gt; (new-if #f 3 (new-if #f 3 (new-if (= 8 3) 3 (iter (- 8 1) x))))... In order to evaluate the value of new-if, we must first evaluate the value of (= 10 3) and (iter (- 10 1) x) . In order to evaluate the value of (iter (- 10 1) x) , we must fisrt evaluate the value of the new-if. This leads to an infinite recursion.However, if expression is different from new-if, if expression only evaluate a subexpression when predicate is decided. Therefore if we overwrite the iter by if expression and use the Substitution Model again, we can get the value we want finally. 12345678(iter 10 3)=&gt; (if (= 10 3) 3 (iter (- 10 1) x))=&gt; (iter 9 3)=&gt; (if (= 9 3) 3 (iter (- 9 1) x))...=&gt; (iter 3 3)=&gt; (if (= 3 3) 3 (iter (- 3 1) x))=&gt; 3 Logic12345;General Form(and &lt;e1&gt; ... &lt;en&gt;)(or &lt;e1&gt; ... &lt;en&gt;)(not &lt;e&gt;) An Example of Block Structure1234567891011121314(define (sqrt x) (define (square x) (* x x) ) (define (average x y) (/ (+ x y) 2)) (define (good-enough? guess) (&lt; (abs (- (square guess) x)) 0.001)) (define (improve guess) (average guess (/ x guess))) (define (sqrt-iter guess) (if (good-enough? guess) guess (sqrt-iter (improve guess)))) (sqrt-iter 1.0))(sqrt 2) We hava already learned the basic usages of those function. And there are two new usages Internal definitions and block structure. It allows a procedure to have internal definitions that are local to that procedure. lexical scoping. It allows x to be a free variable in the internal definitions. Thus, it is not necessary to pass x explicitly to each of these procedures.The idea of block structure originated with the programming language Algol 60. It appears in most advanced programming languages and is an important tool for helping to organize the construction of large programs. An Example of Exponentiation1234567(define (fast-expt b n) (cond ((= n 0) 1) ((even? n) (square (fast-expt b (/ n 2)))) (else (* b (fast-expt b (- n 1))))))(define (even? n) (= (remainder n 2) 0)) Higher-Order ProceduresProcedures that manipulate procedures are called higher-order proceduces. It can accept procedures as arguments or return proceduces as value.For example, we can define a procedure which computer the sum of the f(i) from i=a tp i=b. 123456(define (sum f a next b) (if (&gt; a b) 0 (+ (f a) (sum f (next a) next b))))(sum (lambda (x) x) 1 (lambda (x) (+ x 1)) 100) Constructing Procedures Using LambdaIn general, lambda is uesd to create procedures in the same way as define, except that no name is specified for the procedure 1234567;General Form(lambda (&lt;formal-parameters&gt;) &lt;body&gt;);An Example(define (plus4 x) (+ x 4)); is equivalent to(define plus4 (lambda (x) (+ x 4))) Like any expression that has a procedure as its value, a lambda expression can be used as the operator in a combination such as 12((lambda (x y z) (+ x (- y z))) 1 3 2);Value 2 Use let to create local variables12345678910111213141516;General Form(let ((&lt;var1&gt; &lt;exp1&gt;) (&lt;var2&gt; &lt;exp2&gt;) ... (&lt;varn&gt; &lt;expn&gt;)) &lt;body&gt;); An Example(define (f x y) (let ((a (+ 1 (* x y))) (b (- 1 y))) (+ (* x (* a a)) (* y b) (* a b))))(f 1 2);Value 4 The fisrt part of the let expression is a list of name-expression pairs. When the let is evaluated, each name is associated with the value of the corresponding expression. The body of the let is evaluated with these names bound as local variables. The way this happens is that the let expression is interpreted as an alternate synatax for 12345((lambda (&lt;var1&gt; ... &lt;varn&gt;) &lt;body&gt;)&lt;exp1&gt;...&lt;expn&gt;) No new mechanism is required in the interpreter in order to provide local variables. A let expression is simply syntactic sugar for the underlying lambda application. We can see from this equivalence that the scope of a variable specified by a let expression is the body of the let Procedures as Returned Values12345678910111213141516171819(define tolerance 0.00001)(define (fixed-point f first-guess) (define (close-enough? v1 v2) (&lt; (abs (- v1 v2)) tolerance)) (define (try guess) (let ((next (f guess))) (if (close-enough? guess next) next (try next)))) (try first-guess))(define (average-damp f) (lambda (x) (average x (f x))))(define (sqrt x) (fixed-point (average-damp (lambda (y) (/ x y))) 1.0)) Notice how this formulation makes explicit the three idesa in the method: fixed-point search, average damping, and the fuction y -&gt; x/y. It is instructive to compare this formulation of the suqare-root method with the original version. Bear in mind that these procedures express the same process, and notice how much clearer the idea becomes when we express the process in terms of these abstractions. PairScheme provides a compoind structure called a pair, which can be constructed with the primitive procedure cons. This procedure take two arguments and returns a compound data object that contains the two arguments as pairs. Given a pair, we can extract the parts using the primitive procedures car and cdr. Thus, we can use cons,car, and cdr as follows: 1234567(define x (cons 1 2))(car x);Value: 1(cdr x);Value: 2 Pair is an abstract conception. Therefor the implemention of pair is not importan. For example we can give a solution like this 12345678(define (cons x y) (lambda (m) (m x y)))(define (car z) (z (lambda (p q) p)))(define (cdr z) (z (lambda (p q) q))) we can verify this implemention by Substitution Model Abstraction BarriersIn gerneral, the underlying idea of data abstracion is to identify for each type of data object a basic set of operations in terms of which all manipulations of data objects of that type will be expressed, and then to use only those operations in manipulating the data. We can also find this idea in the other programming paradigms,such as OOP. This idea can reduce the complexity of programming. We know that the complexity is the major obstacle to build large program. Therefore this idea is widely use in programming paradigms.","categories":[],"tags":[{"name":"函数式编程","slug":"函数式编程","permalink":"https://lizec.top/tags/%E5%87%BD%E6%95%B0%E5%BC%8F%E7%BC%96%E7%A8%8B/"}]},{"title":"《程序设计实践》阅读笔记","slug":"《程序设计实践》阅读笔记","date":"2017-08-31T13:07:22.000Z","updated":"2017-10-17T11:09:52.861Z","comments":true,"path":"2017/08/31/《程序设计实践》阅读笔记/","link":"","permalink":"https://lizec.top/2017/08/31/%E3%80%8A%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1%E5%AE%9E%E8%B7%B5%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/","excerpt":"","text":"变量命名 一个名字应该是非形式的、简练的、容易记忆的。一个变量的作用域越大，它的名字所携带的信息就应该越多。 全局变量使用具有说明性的名字，局部变量用短名字。 给每个全局变量声明附一个简短注释也非常有帮助。 按常规方式使用的局部变量可以采用极短的名字。例如用 i、j作为循环变量，p、q作为指针，s、t表示字符串等。 人们常常鼓励程序员始终使用长的变量名。这种认识完全是错误的，清晰性经常是随着简洁而来的。 表达式和语句 应该以尽可能一目了然的形式写好表达式和语句。例如，通过给运算符两边加空格的方式说明分组。 用加括号的方式排除二义性。。括号表示分组，即使有时并不必要，加了括号也可能把意图表示得更清楚。 在混合使用互相无关的运算符时，多写几个括号是个好主意。 C语言以及与之相关的语言存在很险恶的优先级问题，在这里很容易犯错误。 我们的目标应该是写出最清晰的代码，而不是最巧妙的代码。 一致性与习惯用法 一致性带来的将是更好的程序。如果相同计算的每次出现总是采用同样方式，任何变化就预示着是经过了深思熟虑，要求读程序的人注意。 如果你工作在一个不是自己写的程序上，请注意保留程序原有的风格。当你需要做修改时，不要使用你自己的风格，即使你特别喜欢它。 程序的一致性比你本人的习惯更重要，因为这将使随你之后的其他人生活得更容易些。 一个判断应该尽可能接近它所对应的动作。也就是说，一旦做过了一个测试，马上就应该去做某些事情。（而不是先去嵌套其他语句） 注释 最好的注释是简洁地点明程序的突出特征，或是提供一种概观，帮助别人理解程序。","categories":[],"tags":[{"name":"C","slug":"C","permalink":"https://lizec.top/tags/C/"},{"name":"程序设计","slug":"程序设计","permalink":"https://lizec.top/tags/%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1/"}]},{"title":"Makefile使用笔记","slug":"Makefile使用笔记","date":"2017-08-31T12:14:56.000Z","updated":"2018-04-17T02:15:32.657Z","comments":true,"path":"2017/08/31/Makefile使用笔记/","link":"","permalink":"https://lizec.top/2017/08/31/Makefile%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/","excerpt":"","text":"基本规则基本规则1234target ... : prerequisites ... command ... ... target可以是一个目标文件，例如需要生成的可执行文件或中间文件 target也可以是一个标签 prerequisites是需要生成的文件依赖的文件 command是任意的shell指令 Makefile举例12345678all: gcc f.o codeTest.o -o codeTest.exef.o: f.c gcc -c f.ccodeTest.o: codeTest.c gcc -c codeTest.cclear: rm *.o 隐含规则和默认宏隐含规则makefile定义了一系列的隐含规则,这些规则可以帮助我们简化makefile的书写, 常见的隐含规则如下 .o文件指定依赖以后,默认执行$(CC) –c $(CFLAGS) [.c]类生成对应的.o文件 如果完全不提及.o文件依赖和生成规则, 则自动使用相应的.c文件编译 宏makefile使用了一些默认的宏,这些宏可能会用与隐含规则,常见的宏如下 CC 编译器类型 CFLAGS 编译参数 变量替换在C语言中往往.o文件和.c文件仅后缀不同,重复书写两次较为繁琐, 可以使用变量替换, 替换规则如下所示 123SRCS = fun1.c fun2.c main.c# 使用变量替换OBJS=$(SRCS: .c=.o) OBJS将SRC中所有的.c替换为.o, 文件名部分不变 Makefile举例使用自动推导演示1234567891011121314151617181920CC=clangEXEC=printAdd.exe# 替换规则,foo = $(var:a=b)，将var变量中的a替换成b，并返回给fooSRCS = fun1.c fun2.c main.c# 使用变量替换OBJS=$(SRCS: .c=.o)CFLAGS = -Wall -O2 CFLAGS += -I./ -L./LFLAGS = -lpthread -lm all: fun1.o fun2.o main.o $(CC) $(OBJS) -o $(EXEC)# .o文件自动推导,仅仅指定依赖# 其他文件完全不出现则自动依赖.c文件fun2.o: fun2.c fun2.hclean: rm -rf *.o rm -rf $(EXEC) 使用宏演示123456789101112131415161718CC=gccCFLAGS = -Wall -O2 CFLAGS += -I./ -L./LFLAGS = -lpthread -lm SRCS = fun1.c \\ fun2.c \\ main.cOBJS=$(SRCS:.c=.o)EXEC=testall:$(OBJS) $(CC) $(CFLAGS) $(OBJS) -o $(EXEC) $(LFLAGS)clean: rm -rf $(EXEC) $(OBJS) 多目录下makefile构成方法多目录项目一般结构假设在工作目录下有4个文件夹 分别是 sources（源文件） obj （中间文件） headers（头文件） bin（目标文件） 对于gcc的编译过程而言, 主要是需要在输入文件和输出文件是指出具体的路径,并且使用-I指定头文件位置 自动变量makefile提供了几个自动变量用于简化命令的书写, 这些变量是 $@ 表示要生成的目标 $^ 表示全部的依赖文件 $&lt; 表示第一个依赖文件 例如某makefile中有如下的一段 12obj/cn_work.o : sources/cn_work.c gcc -I headers -c $&lt; -o $@ 则在此时$@等价于obj/cn_work.o而$&lt;等价于sources/cn_work.c Makefile举例123456789101112131415CC=gccHD=-I headersSC=-c $&lt;OBJ=-o $@bin/cn_work : obj/main.o obj/cn_work.o obj/fun.o gcc $^ -o $@ obj/cn_work.o : sources/cn_work.c $(CC) $(HD) $(SC) $(OBJ)obj/main.o : sources/main.c $(CC) $(HD) $(SC) $(OBJ)obj/fun.o : sources/fun.c $(CC) $(HD) $(SC) $(OBJ)clean： rm -f bin/cn_work obj/*.o 参考文献和扩展阅读跟我一起写Makefile","categories":[],"tags":[{"name":"Makefile","slug":"Makefile","permalink":"https://lizec.top/tags/Makefile/"}]},{"title":"Linux下的C语言开发环境介绍","slug":"Linux下的C语言开发环境介绍","date":"2017-08-31T12:14:34.000Z","updated":"2020-06-26T14:51:25.868Z","comments":true,"path":"2017/08/31/Linux下的C语言开发环境介绍/","link":"","permalink":"https://lizec.top/2017/08/31/Linux%E4%B8%8B%E7%9A%84C%E8%AF%AD%E8%A8%80%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E4%BB%8B%E7%BB%8D/","excerpt":"","text":"在Linux下, 主要的C语言开发工具是GCC和GDB, 其中 GCC 是 GNU Compiler Collection, 是C语言的编译器, GDB是GNU Project Debugger, 是一个基于命令行的调试器. 此外, 与GCC相对应的还有一个G++, 是对应于C++的编译器. 通常情况下, Linux上的C语言开发都采用VIM作为集成开发环境, 但是VIM配置比较繁琐, 而最近出现的Visual Studio Code, 具有开箱即用的特点, 因此本文最后介绍如何将VSC配置为一个C/C++的集成开发环境. GCC介绍GCC编译过程gcc的编译过程可以分成四步, 即 预处理, 编译, 汇编, 链接, 各个部分的处理器和文件类型关系如下所示 步骤名称 生成文件类型 处理器名称 预处理 .i文件 预处理器 cpp 编译 .s文件 编译器 egcs 汇编 .o文件 汇编器 as 链接 可执行文件 链接器 ld GCC最基本的用法为直接在gcc后加上需要编译的 .c 文件, 例如 1gcc file1.c file2.c 此时默认生成名为a.out的可执行文件 GCC编译参数基本流程控制 参数名 效果 -c 只进行预处理, 编译和汇编, 生成.o文件 -S 只进行预处理和编译, 生成.s文件 -masm=intel 以Intel格式输出汇编代码 -E 只进行预处理, 将结果输出到终端 -save-temps 保留编译中间过程生成的.i和.o文件, 供用户查询和调试 -o 指定输出的文件的文件名 注意, 通常预处理后文件很长, 所以建议重定向到文件, 然后再查看文件, 否则可能因为缓冲区大小导致显示不完全 调试与优化 参数名 效果 -Wall 使gcc产生尽可能多的警告信息 -Wextra 输出额外的警告信息(即不包含在-Wall参数中的警告) -m32 强制生成32位版本的程序 -g 在编译过程中加入调试信息 -O 指定程序优化等级 -p 将编译时产生的Profiling信息加入最后的二进制代码中 -g参数一共有三个等级, 即-g1, -g2, -g3. -g1只包含基本的信息, -g2包含符号表, 行号等信息, -g3包含-g2的全部信息以外, 还包含源代码中定义的宏. 因为加入的调试信息, 对文件体积上和运行速度都会有一些影响. -O参数一共有三个等级, 即-O1, -O2, -O3. 数字越大, 优化等级越高, 较高的优化等级可能改变代码原有的行为, 导致调试时产生难以理解的问题, 因此通常仅仅在程序发布的时候才高等级优化 编译时产生的Profiling信息可帮助分析程序的性能瓶颈, 如果需要对程序性能进行分析, 可以使用此参数. 链接库 参数名 效果 -I 指定头文件搜索目录 -L 指定库文件搜索目录 -l&lt;name&gt; 指定链接库的名称 当导入的头文件既不处于标准目录(例如/usr/include)也不处于当前目录, 则可以使用-I指令来指定一个目录, 将其加入头文件的搜索路径之中. 当需要连接的库文件(例如.a文件或.so文件)不处于标准目录(例如/usr/lib)之中, 则可以使用-L指令来指定一个目录, 将其加入库文件的搜索路径之中. 使用-l&lt;name&gt;使编译器链接名为lib&lt;name&gt;的库, 例如使用-lm可以使编译器链接libm.a这个数学库. GDB介绍GDB是GNU Project debugger, 是Linux上一个非常常见的调试器. GDB的所有操作都是基于命令行的, 因此通常情况下并不直接使用GDB, 很多IDE(例如vscode)都可以将GDB的指令映射为可视化界面的按钮, 从而通过点击完成调试. 但是如果遇到没有源代码的情况, 或者进行汇编级别的程序开发, 则只能使用基于命令行的GDB进行调试. 因此有必要简单的了解GDB的有关语法, 大致的掌握GDB的使用. GDB基本指令 命令 解释 示例 file &lt;文件名&gt; 使GDB加载指定的文件 (gdb) file a.out r Run,运行程序 (gdb) r c Continue,继续运行程序 (gdb) c b Break,添加断点 (gdb) b mian d 指定一个数字,则删除指定断点,否则删除所有断点 (gdb) d 1 s,n Step,Next,以c语句为单位 (gdb) s si,ni 同上,但以汇编指令为单位 (gdb) si p Print 显示指定的变量的值 (gdb) p $eax dispaly 在每次中断后显示指定变量的值 (gdb) display $eax i 显示有关的信息 (gdb) i r q 退出 (gdb) q 详细说明添加断点实际上,添加断点有四种格式 b &lt;行号&gt; b &lt;函数名&gt; b *&lt;函数名&gt; b *&lt;代码地址&gt; 其中行号指的是C语言源代码的行号, 由于可执行程序中没有源代码的信息, 则只能使用函数名或者代码地址. 逐语句与逐过程 s表示Step,执行一个C语句,如果是函数,则会进入函数 n表示Next,执行一个C语句,如果是函数,则执行完函数 si表示逐语句的执行一条汇编指令 ni表示逐过程的执行一条汇编指令 显示变量值p指令可以显示一个C语言中定义的全局或局部变量的值 display指令 使用display指令,相当于添加了一个监视变量每次遇到断点或者使用了s或n以后,会打印指定的变量的值 使用display /i $pc可以打印下一条汇编指令 使用undisplay &lt;编号&gt; 可以取消指定序号的打印操作 显示所有寄存器的值 使用i r指令 GDB初始化脚本如果一个程序存在某些问题需要反复的调试, 则有些初始化的命令可能需要反复的被执行, 此时可以使用gdb脚本来减少工作量. 编写脚本gdb启动时会尝试加载当前目录下的.gdbinit文件, 如果存在此文件, 则将其中的内容作为GDB指令直接执行, 因此脚本中可以编写任意的GDB指令, 以下是一个示例 1234567set disassembly-flavor intelfile a.outdisplay /x $eaxdisplay /x $ebxdisplay /x $ecxdisplay /x $edxdisplay /i $pc 上述脚本启动了当前目录下的a.out文件, 将反汇编格式设为intel格式, 要求每次断点时显示eax, ebx, ecx, edx的值以及下一条指令的值. 脚本安全问题由于安全原因, gdb默认不加载.gdbinit文件, 如果直接启动gdb会给出相关的警告, 同时提示可以设置允许启动的路径. 因此按照要求,可以执行以下步骤来启用脚本 在用户文件夹下创建.gdbinit文件 在其中加入set auto-load safe-path / 如果担心安全问题, 也可以把上述指令中的/ 换成具体的目录名, 从而获得更细致的权限控制. Vscode配置和VIM一样, 在C/C++语言上, vscode实际上只是一个文本编辑器, 仅仅提供了基本的语法高亮和代码补全功能, 所以如果需要实现一个IDE的功能, 还需要配置编译器和调试器, 也就是上文介绍的GCC和GDB了. 创建项目文件夹如果需要使用vscode编译和调试项目, 需要使用vscode打开一个文件夹, 否则vscode不会创建相关的配置信息. 点击调试, 在调试界面中, 选择开始调试 此时vscode会提示选择环境,在linux平台上可以选择C++(GDB/LLDB),即使用GDB作为调试器 vscode会创建一个名为launch.json的文件, 此文件即为调试的配置文件 使用如下的配置替换原有配置 12345678910111213141516171819202122232425&#123; &quot;version&quot;: &quot;0.2.0&quot;, &quot;configurations&quot;: [ &#123; &quot;name&quot;: &quot;(gdb) Launch&quot;, &quot;type&quot;: &quot;cppdbg&quot;, &quot;request&quot;: &quot;launch&quot;, &quot;preLaunchTask&quot;: &quot;make&quot;, &quot;program&quot;: &quot;$&#123;workspaceRoot&#125;/compile/lscc&quot;, &quot;args&quot;: [], &quot;stopAtEntry&quot;: false, &quot;cwd&quot;: &quot;$&#123;workspaceRoot&#125;/compile/&quot;, &quot;environment&quot;: [], &quot;externalConsole&quot;: true, &quot;MIMode&quot;: &quot;gdb&quot;, &quot;setupCommands&quot;: [ &#123; &quot;description&quot;: &quot;Enable pretty-printing for gdb&quot;, &quot;text&quot;: &quot;-enable-pretty-printing&quot;, &quot;ignoreFailures&quot;: true &#125; ] &#125; ]&#125; 和默认的文件相比, 主要有如下的几项修改 program属性修改为要调试的程序的程序名, 例如$&#123;workspaceRoot&#125;/a.out表示要调试的程序是当前项目的目录下的a.out程序 添加一个preLaunchTask属性, 使得再执行调试操作前先执行指定的Task(通常是编译任务), 其中preLaunchTask的值需要与后面介绍的Task.json中的Task的label属性名一致 编辑tasks.json 完成launch.json后, 再次点击开始调试, vscode会提示 未配置任何任务运行程序 , 此时选择 配置任务允许程序 , 之后选择Others, vscode即可自动生成一个tasks.json 以下是两个可用的tasks.json, 第一个是简单文件的配置,第二个是较为复杂的文件配置1234567891011121314151617&#123; &quot;version&quot;: &quot;0.1.0&quot;, &quot;command&quot;: &quot;g++&quot;, &quot;args&quot;: [&quot;-g&quot;,&quot;scan.c&quot;,&quot;-o&quot;,&quot;a.out&quot;], &quot;problemMatcher&quot;: &#123; &quot;owner&quot;: &quot;cpp&quot;, &quot;fileLocation&quot;: [&quot;relative&quot;, &quot;$&#123;workspaceRoot&#125;&quot;], &quot;pattern&quot;: &#123; &quot;regexp&quot;: &quot;^(.*):(\\\\d+):(\\\\d+):\\\\s+(warning|error):\\\\s+(.*)$&quot;, &quot;file&quot;: 1, &quot;line&quot;: 2, &quot;column&quot;: 3, &quot;severity&quot;: 4, &quot;message&quot;: 5 &#125; &#125;&#125; 12345678910111213141516171819202122&#123; &quot;version&quot;: &quot;2.0.0&quot;, &quot;tasks&quot;: [ &#123; &quot;label&quot;: &quot;make&quot;, &quot;type&quot;: &quot;shell&quot;, &quot;command&quot;: &quot;./makeProject&quot;, &quot;problemMatcher&quot;: &#123; &quot;owner&quot;: &quot;cpp&quot;, &quot;fileLocation&quot;: [&quot;relative&quot;, &quot;$&#123;workspaceRoot&#125;/compile&quot;], &quot;pattern&quot;: &#123; &quot;regexp&quot;: &quot;^(.*):(\\\\d+):(\\\\d+):\\\\s+(warning|error):\\\\s+(.*)$&quot;, &quot;file&quot;: 1, &quot;line&quot;: 2, &quot;column&quot;: 3, &quot;severity&quot;: 4, &quot;message&quot;: 5 &#125; &#125; &#125; ]&#125; 说明: 上述配置文件正确执行以后 ,在编译的过程中,编译器报告的错误会被提取并在vscode的问题页面中显示 其中fileLocation表示编译器报告的文件名的位置关系, 上述示例中,使用的是相对关系,并且认为是直接相对于当前目录. 如果需要编译的文件在工作目录的子文件夹下,需要配置该属性为具体的子文件夹 注意事项 如果需要使用断点功能, 则被调试的程序中一定需要包含相关信息,即编译的时候, 需要-g参数 vscode默认的调试快捷键是F5, 对于笔记本而言, 那些F键实在是难以精确定位, 所以可以读默认快捷键进行修改. 依次选择文件-&gt;首选项-&gt;键盘快捷方式, 然后在界面上修改为其他方案即可(例如Ctrl+B) 参考文献和扩增阅读 关于C++的说明(英文版) 关于C++插件的说明(中文版) 关于配置信息的说明 关于task的官方说明(英文版) 一般配置参考","categories":[],"tags":[{"name":"C","slug":"C","permalink":"https://lizec.top/tags/C/"}]},{"title":"JavaGUI笔记","slug":"JavaGUI笔记","date":"2017-08-10T14:39:43.000Z","updated":"2020-06-26T14:41:20.283Z","comments":true,"path":"2017/08/10/JavaGUI笔记/","link":"","permalink":"https://lizec.top/2017/08/10/JavaGUI%E7%AC%94%E8%AE%B0/","excerpt":"","text":"Label类 基本的设置参考代码补全即可 Button类 构造函数可以直接设置上面的标签内容，也可以使用函数 TextField类 单行输入框，构造函数可以设置宽度或者初始文本，或者同时 设置宽度是指这个控件在界面上的长度大小 getEchoChar函数设置回显字符样式 setEditable函数设置是否可以编辑,此外估计setEnable功能类似 TextArea类 多行输入框，构造函数可以设置行和列数，初始文本，或者一起设置，或者增加是否需要滑动条 包含一些和上面类似的函数，可以使用append函数最后追加文本 Choice类 单选下拉框， 使用add添加可选字符串 可以使用索引获得某一指定字符串 使用getSelectedItem函数获得当前选中的字符串 使用select函数是控件显示为指定的字符串,如果不存在，实际上是不会执行这一操作 List类 可多选下拉框，构造函数可以设置有多少行可见选项被显示 或者加上一个额外的布尔值，表示能否多选,默认不能多选，实际上这个空间至少在Windows平台上看起来像一个列表而不是一个下拉框 设置和获得函数基本相同，但是因为可以多选，因此返回值是字符串的数组 Checkbox类 一个Checkbox是一个单独的选择，可以把一组Checkbox放入CheckboxGroup中，从而实现单选功能 构造函数可以为空，设置字符串，默认是否被选中，或者两张一起，此外还有一个三参数的构造函数，第三个参数指定一个CheckboxGroup，将若干个Checkbox放入该CheckboxGroup中 可以使用getState函数获得是否被选中 CheckboxGroup可以使用getSelectedCheckbox获得被选中的Checkbox 事件处理 如果一个类想要对发生的时间进行处理，需要实现指定的接口，如ActionEvent，ItemEvent，KeyEvent。不同的控件可以触发不同的事件，通常的做法是在一个类的内部创建一个内部类来专门处理这些事件，需要的时候，就new一个新的类去处理。这样可以实现分组（因为内部类也可以访问这个类的私有变量，从而不受访问权限的影响） 布局管理 Java大致分为三层容器 顶层：Applet，Frame，Dialog 中间：Panel，ScrollPane 基本：之前的如Button等元素 每个容器对象，都有他相应的布局管理器，使用setLayout（）设置。如果没有使用，默认的是顺序布局 Java应用程序Frame 表示一个窗口，在这个窗口上面可以和小应用程序一样的添加各种控件，设置窗口布局等 setBounds设置窗口的位置以及大小 WindowsEvent接口中定义了窗口中对应的事件除了创建一个frame对象以外，还可以选择将自己的类继承Frame类，然后设置各种方法和对象 关于事件处理 实际上实现的接口也不过就是一个函数，所以可以直接调用这些方法，使用适当的内部类可以对这些方法进行分类 JScrollPane 实际上，不应该把这个认为是一个附加的属性，而是把它认为是一个容器，所以也需要为这个容器制定布局以后，才能看到这个容器。 尤其主要要设置中央文件，才能看到包含在其中的内容 Java提示框 在Java中也有，利用JOptionPane类中的各个static方法来生成各种标准的对话框，实现显示出信息、提出问题、警告、用户输入参数等功能。这些对话框都是模式对话框。 ConfirmDialog — 确认对话框，提出问题，然后由用户自己来确认（按”Yes”或”No”按钮） InputDialog — 提示输入文本 MessageDialog — 显示信息 OptionDialog -－ 组合其它三个对话框类型。 这四个对话框可以采用showXXXDialog()来显示，如showConfirmDialog()显示确认对话框、showInputDialog()显示输入文本对话框、showMessageDialog()显示信息对话框、showOptionDialog() 选择性的对话框 ParentComponent：指示对话框的父窗口对象，一般为当前窗口。也可以为null即采用缺省的Frame作为父窗口，此时对话框将设置在屏幕的正中。 message：指示要在对话框内显示的描述性的文字 String title：标题条文字串。 Component：在对话框内要显示的组件（如按钮） Icon：在对话框内要显示的图标 messageType：一般可以为如下的值ERROR_MESSAGE、INFORMATION_MESSAGE、WARNING_MESSAGE、QUESTION_MESSAGE、PLAIN_MESSAGE、 optionType：它决定在对话框的底部所要显示的按钮选项。一般可以为DEFAULT_OPTION、YES_NO_OPTION、YES_NO_CANCEL_OPTION、OK_CANCEL_OPTION。 Java选择文件提示框 使用JFileChooser类，使用setFileSelectionMode函数设置提示框模式，使用showOpenDialog显示提示框，使用getSelectFile获得选中的文件 设置文本框居中 setLocationRelativeTo(null)，设置此窗口与其他窗口的相对位置，为null表示在屏幕上居中 菜单 一个界面可以有一个菜单栏(MenuBar) 每个菜单栏可以包含多个菜单(Menu) 每个菜单可以包含多个菜单选项(MenuItem) 每个菜单选择通过addActionListener函数实现事件响应","categories":[{"name":"Java特性","slug":"Java特性","permalink":"https://lizec.top/categories/Java%E7%89%B9%E6%80%A7/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://lizec.top/tags/Java/"}]},{"title":"配置LAMP笔记","slug":"配置LAMP笔记","date":"2017-08-10T14:15:57.000Z","updated":"2018-11-21T12:51:13.145Z","comments":true,"path":"2017/08/10/配置LAMP笔记/","link":"","permalink":"https://lizec.top/2017/08/10/%E9%85%8D%E7%BD%AELAMP%E7%AC%94%E8%AE%B0/","excerpt":"","text":"LAMP环境LAMP环境指Linux，Apache，MySQL，PHP 基本环境配置 执行以下两条命令中的任意一条即可完成基本安装12sudo apt-get install apache2 php5 mysql-server php-mysqlsudo tasksel install lamp-server 模块选择 注意：测试发现以下模块需要分开安装1sudo apt-get install php5-gd cur1 libcurl3 libcurl3-dev php5-curl openssh设置远程root登录 修改root密码1sudo passwd root 设置ssh配置文件 执行以下命令，找到PermitRootLogin 一行，设置为yes1sudo vi /etc/ssh/sshd_config 模块基本信息 名称 配置文件位置 配置文件名 Apache /etc/apache2 MySQL /etc/mysql my.cnf PHP /etc/php5 php.ini Apache简单介绍 Apache会首先加载apache.conf，因此这个文件是配置文件的入口 其下有若干子目录，含义如下 mods-* Apache模块 sites-* 虚拟主机 *-available 表示可用的配置 *-enable 表示已经启用的配置 使用ln命令创建软连接，将available中的文件链接到enable中 Windows10下hosts文件位置C:\\Windows\\System32\\drivers\\etc 虚拟主机配置 首先进入虚拟主机的可用配置目录1cd /etc/apache2/sites-available/ 对于每一个需要的域名，都需要创建一个配置文件。否则将转向默认的配置文件 在文件中，通过ServerName来指定该配置文件所对应的域名 在Directory标签下设置访问权限12345678&lt;Directory /wwwroot/vedio&gt; Options FollowSymLinks AllowOverride None Require all granted&lt;/Directory&gt; 创建软链接1sudo ln -s ../sites-available/video.conf video.conf 重启apache MySQL数据迁移 停止MySQL服务 在挂在的硬盘上，创建需要的目录 设置该目录所有者权限1sudo chown -vR mysql:mysql 创建的目录 设置该目录权限1sudo chown -vR 700 创建的目录 复制（首先切换到root）1cp -av 原来的目录/* 新目录（参数） 设置my.cnf 修改datadir的值（建议直接注释原来的哪一行，便于发生意外后恢复） 修改apparmor配置文件 找到 /var/lib/mysql 的两行，注释掉，然后在新的行中设置新的目录为原来的值 重启apparmor 启动mysql Apache 访问配置 访问权限 每一个不同的文件夹，都可以使用Directory标签设置权限，具体的权限设置方法可以参考网上的资料 访问其他路径 如果网站需要访问文件夹中的内容，需要设置虚拟路径，使用Alias设置路径的别名，格式为1Alisa 新的名称 原来的名称 注意：原来的名称需要在在双引号之中，例如1Alias /media/u_lizec/Data &quot;/media/u_lizec/Data&quot; 设置文件夹后，需要重新设置访问权限","categories":[],"tags":[{"name":"环境配置","slug":"环境配置","permalink":"https://lizec.top/tags/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"}]},{"title":"Ubuntu使用记录","slug":"Ubuntu使用记录","date":"2017-08-10T13:36:11.000Z","updated":"2020-11-04T14:53:10.000Z","comments":true,"path":"2017/08/10/Ubuntu使用记录/","link":"","permalink":"https://lizec.top/2017/08/10/Ubuntu%E4%BD%BF%E7%94%A8%E8%AE%B0%E5%BD%95/","excerpt":"","text":"内容概述本文包含我在日常使用Ubuntu系统中遇到的一些问题的记录，没有什么特定的顺序和联系，不定期更新 Ubuntu下如何挂载U盘 使用 sudo fdisk -l 命令查看U盘的位置12345678910111213# 结果可能包含如下字段$ sudo fdisk -lDisk /dev/sda: 16.1 GB, 16106127360 bytes2 heads, 63 sectors/track, 249660 cylinders, total 31457280 sectorsUnits = sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x003996fb Device Boot Start End Blocks Id System/dev/sda1 * 64 31457279 15728608 c W95 FAT32 (LBA)# 看到U盘的位置是/dev/sda1是一个FAT32格式 挂载U盘到指定节点 12345# 挂载FAT32格式的U盘$ sudo mount -t vfat /dev/sda1 /media/u # 挂载NTFS格式的U盘 $ sudo mount -t ntfs-3g /dev/sda1 /media/u # 其中/media/u 为你要挂载到的节点，这个可以随便指定，但是这个目录一定要存在 卸载u盘 12# 卸载之前挂载的U盘$ sudo umount /media/u ubuntu开机自动挂载新硬盘操作需要Root权限 查看分区的UUID 1sudo blkid 配置开机加载 打开/etc/fstab, 按照如下格式写入配置 1234UUID=66E85884E8585501 /home/deepin/WinHome/C ntfs defaults 0 1UUID=58682F90682F6BC6 /home/deepin/WinHome/D ntfs defaults 0 1UUID=FA1CAC411CABF733 /home/deepin/WinHome/E ntfs defaults 0 1UUID=0472ECE072ECD806 /home/deepin/WinHome/F ntfs defaults 0 1 以上配置前三项分别是分区ID, 挂载点, 分区格式. 其余的配置可以使用默认值. 验证配置 执行以下指令检查配置是否正确, 不正确的配置可能导致无法正常启动 1sudo mount -a 确认无误后重启系统即可使配置生效 ubuntu开机自动挂载新硬盘 清理软件安装缓存使用apt安装软件后, 相应的安装包会缓存在/var/cache/apt/archives/, 可以使用以下的指令查看这部分缓存占用的空间. 1sudo du -sh /var/cache/apt/archives/ 如果已经占用较大的空间, 可以使用以下指令自动清理缓存: 1sudo apt clean 扩展可用空间12$ sudo fs_resizeWARNING: Do you want to resize &quot;/dev/mmcblk0p2&quot; (y/N)? y 查看文件夹空间占用情况直接使用以下指令查看文件夹内空间占用情况的概述 1du -ah --max-depth=1 查看当前目录总共占的容量, 而不单独列出各子项占用的容量 1du -sh 查看当前目录下一级子文件和子目录占用的磁盘容量 1du -lh --max-depth=1 开机执行程序 找到 /etc/re.local 在此文件中写入需要的命令 注意: 在18.04中,可以在Tweak中直接设置开启启动程序 双系统设置默认启动项 打开相关的配置文件 1$ sudo gedit /etc/default/grub 修改相关选项 12345678# 节选其中的一段内容如下所示GRUB_DEFAULT=0 # 此项表示默认选择项位置，从0开始计数#GRUB_HIDDEN_TIMEOUT=0GRUB_HIDDEN_TIMEOUT_QUIET=trueGRUB_TIMEOUT=2 # 此项表示默认选择时间，单位为秒GRUB_DISTRIBUTOR=`lsb_release -i -s 2&gt; /dev/null || echo Debian`GRUB_CMDLINE_LINUX_DEFAULT=&quot;quiet splash&quot;GRUB_CMDLINE_LINUX=&quot;&quot; 更新只有更新上述设置以后，相关的修改才会生效 1$ sudo update-grub 添加搜索路径通常系统会在用户的home目录下添加一个搜索路径，以便于用户可以调用自己编写的程序，如果没有，可以按照如下方式添加 修改.bashrc 此文件位于用户的home目录下，可以使用顺手的编辑器打开 添加指令 例如将home目录下的bin目录添加到搜索路径中，则添加如下语句1export PATH=~/bin:&quot;$PATH&quot; 重启终端使配置生效 编译线程有关程序如果用到来pthread.h中的函数,在使用gcc编译的时候,需要加上-pthread MySQL中文乱码注意到在Ubuntu上的MySQL并非默认使用UTF8编码，因此需要手动将默认编码修改为UTF8，过程如下 修改/etc/mysql/my.cnf，添加如下的内容： 1234[client]default-character-set=utf8[mysqld]character-set-server=utf8 然后重启数据库。 注意： 以前添加的表还是会乱码，因此需要重新创建有关的表 查看已安装软件位置1dpkg -L &lt;软件名&gt; 创建桌面快捷方式使用文件编辑器在桌面创建一个以.desktop结尾的文件. 然后依据需要设置一下的内容 1234567891011[Desktop Entry]Encoding=UTF-8Version=1.0 #version of an app.Name[en_US]=yEd #name of an app.GenericName=GUI Port Scanner #longer name of an app.Exec=java -jar /opt/yed-3.11.1/yed.jar #command used to launch an app.Terminal=false #whether an app requires to be run in a terminalIcon[en_US]=/opt/yed-3.11.1/icons/yicon32.png #location of icon file.Type=Application #typeCategories=Application;Network;Security; #categories in which this app should be listed.Comment[en_US]=yEd Graph Editor #comment which appears as a tooltip. 如何在Linux的桌面上创建快捷方式或启动器 Linux系统目录结构 Linux各目录及每个目录的详细介绍 Linux 系统的/usr目录 Ubuntu管理多版本JavaUbuntu可以直接使用apt安装多个版本的Java, 多个版本的Java并不会直接产生冲突. 使用如下的指令, 可以切换java指令的版本 1sudo update-alternatives --config java 输入上述指令后, 会显示类似如下的内容 12345678There are 3 choices for the alternative java (providing /usr/bin/java). Selection Path Priority Status------------------------------------------------------------* 0 /usr/lib/jvm/java-11-openjdk-amd64/bin/java 1101 auto mode 1 /usr/lib/jvm/java-11-openjdk-amd64/bin/java 1101 manual mode 2 /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java 1081 manual mode 3 /usr/lib/jvm/java-8-oracle/jre/bin/java 1081 manual mode 输入相应的编号就可以切换java的默认版本. 同理还可以切换javac, javadoc等命令的版本. Zsh与oh-my-zsh Ubuntu 16.04下安装zsh和oh-my-zsh","categories":[],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://lizec.top/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://lizec.top/tags/Ubuntu/"}]},{"title":"正则表达式笔记","slug":"正则表达式笔记","date":"2017-08-08T08:23:36.000Z","updated":"2019-06-11T11:51:54.721Z","comments":true,"path":"2017/08/08/正则表达式笔记/","link":"","permalink":"https://lizec.top/2017/08/08/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E7%AC%94%E8%AE%B0/","excerpt":"","text":"正则表达式也叫做REs，regex，或者regex patterns. 通常正则表达式中出现的任意一个字符代表匹配和他们一样的字符, 但正则表达式也提供了额外的符号来表达更加复杂的含义. 基本符号以下符号相当于各种编程语言的关键字，它们并不匹配他们本身 1. ^ $ * + ? &#123; &#125; [ ] \\ | ( ) 上述转义字符前加上\\可以去除之后的一个字符的转义，例如 \\] 匹配字符 ] 字符类 在 “[“ 和 “]” 中的若干字符构成一个字符类(character class) 一个字符类表示，此位置可以匹配这个类中的任意一个字符 可以使用-来表示一个范围，例如[a-c]表示[abc] 在字符类中的特殊符号不被转义 反向匹配 在字符类中，如果以^开头，则表示匹配除此字符类中提及的任何其他字符 例如[^5]匹配任何不是5的字符 转义字符 字符 解释 等价正则表达式 \\d 匹配任意数字 [0-9] \\D 匹配任意的非数字 [^0-9] \\s 匹配任意空白字符 [ \\t\\n\\r\\f\\v](第一个是空格) \\S 匹配任意非空白字符 [^ \\t\\n\\r\\f\\v] \\w 匹配任意字符数字(alphanumeric) [a-zA-Z0-9_](最后一个是下划线) \\W 匹配任意非字符数字 [^a-zA-Z0-9_] 说明:这些字符可以和其他字符一样出现在任何合法的地方 高级的转义字符 符号 效果 &#124; 相当于或，A&#124;B表示此处可以匹配A或者B ^ 匹配字符串开头 $ 匹配字符串结尾 \\A 强制匹配字符串开头，无视MULTILINE标记 \\Z 强制匹配字符串结尾，无视MULTILINE标记 \\b 匹配单词边界，即非字母数字的任意其他字符 \\B 匹配非单词边界字符，\\b的反义 使用重复功能 符号 效果 |使此符号之前的字符重复0到多次 |使此符号之前的字符重复1到多次 ? |使此符号之前的字符重复0到1次{m,n} |使此符号之前的字符重复至少m次，至多n次（含n） 说明:这些字符都是采用贪婪匹配，即尽可能多的重复，从而匹配到最长的符合要求的字符串,如果想要最短匹配们可以在相应的符号后加上一个?,例如*?,+?等 Python和正则表达式12import rep = re.compile(&quot;ab+&quot;) 在Python中使用正则表达式需要两步, 即 导入re库 编译正则表达式 使用原生字符串在正则表达式中，使用\\表示转义，而在Python中碰巧也使用同样的符号表示转义,因此在正则表达式中，如果需要使用\\，在Python的字符串中，就要输入两个\\，即\\\\ 为了避免输入太多\\导致正则表达式难以理解，可以使用Python的原生字符串，即在字符串开头加上r,例如r&quot;\\sda&quot;,在这个字符串中，所有字符都是原来的字符，Python不进行任何转义 Re库主要函数功能 函数 说明 re.compile() 将一个字符串编译成正则表达式 re.search() 在一个字符串中搜索匹配的正则表达式的第一个位置，返回match对象 re.match() 在一个字符串中强制从开始位置起匹配正则表达式，返回match对象 re.findall() 搜索字符串，以列表类型返回全部能匹配的子串 re.split() 将一个字符串按照正则表达式匹配结果进行分割，返回列表类型 re.finditer() 搜索字符串，返回一个匹配结果的迭代类型，每个迭代元素是match对象 re.sub() 在一个字符串中替换所有匹配正则表达式的子串，返回替换后的字符串 regex = re.compile(pattern,flags=0) pattern:正则表达式的字符串或者原生字符串 flags:正则表达式的控制标记 re.search(pattern,string,flags=0) string:待匹配字符串 flags:控制标记 re.match(pattern,string,flags=0) 参数定义相同 re.spilt(pattern,string,maxsplit=0,flags=0) 增加一个新的参数，表示最大分割数，其余部分作为最后一个元素输出 re.finditer(pattern,string,flags=0) 参数定义相同，返回迭代结果，从而可以用 for in的形式遍历 re.sub(pattern,repl,string,conut=0,flag=0) repl:需要匹配替换的字符串 count:替换的最大次数 上述返回Match对象的函数如果没有匹配，则返回None，从而可以直接使用if语句进行判断是否匹配。上述标记，如果在编译字符串的时候就指定，则函数调用的时候，就无需再次指定 Match类简介 方法/属性 目的 group() 返回被正则表达式匹配到的字符串 start() 返回匹配的子字符串在字符串中的开始位置 end() 返回匹配的子字符串在字符串中的结束位置 span() 等价于(start(),end()) .string 待匹配字符串 .re 匹配时使用的正则表达式 .pos 正则表达式搜索文本的开始位置 .endpos 正则表达式搜索文本的结束位置 flags常用标记 常用标记(简写/全称) 说明 re.ASCII/re.A 使\\w,\\b,\\s和\\d只匹配ASCII字符 re.I/re.IGNORECASE 忽略正则表达式大小写 re.M/re.MULTILINE 使得正则表达式中的^从给定字符串的每一行开始匹配 re.S/re.DOTALL 使得.也可以匹配\\n字符 re.VERBOSE/re.X 使正则表达式可以附加解释信息 正则表达式的两种调用方法 函数式用法 re.search(...) 面向对象用法 编译后进行多次操作12pat = re.compile(表达式)rst = pat.search(...) 因为已经编译了，所以各个函数，相比于原来的函数，就需要去掉表示正则表达式的参数 说明:得益于解释器缓存，同一个正则表达式，使用函数式调用时，不会被多次编译，因此两种方式的消耗基本相同 VERBOSE模式实例123456789charref = re.compile(r&#x27;&#x27;&#x27;&amp;[#] # start of a numeric entity reference( 0[0-7]+ #Octal form | [0-9]+ #Decimal form | x[0-9a-fA-F]+ #Hexadecimal form); #Trailing semicolon&#x27;&#x27;&#x27;,re.VERBOSE) 分组 使用 “(“ 和 “)”可以对一个正则表达式分组，从而提取出正则表达式匹配的字符串中的部分内容1234567891011&gt;&gt;&gt; m = re.match(&quot;(a(b)c)d&quot;,&quot;abcd&quot;)&gt;&gt;&gt; m.group(0)&#x27;abcd&#x27;&gt;&gt;&gt; m.group(1)&#x27;abc&#x27;&gt;&gt;&gt; m.group(2)&#x27;b&#x27;&gt;&gt;&gt; m.group(2,0,2)(&#x27;b&#x27;, &#x27;abcd&#x27;, &#x27;b&#x27;)&gt;&gt;&gt; m.groups()(&#x27;abc&#x27;, &#x27;b&#x27;) 在字符串中，从左向右每遇到一个括号，序号+1。使用gruop(i)表示提取第i个括号中匹配的内容 0表示匹配字符串本身，所以无论正则表达式中是否含有分组，gruop(0)都是存在的 接受多个参数时，返回多个参数对于的内容的元组 使用groups()返回所有分组匹配的字符串组成的元组（因此不包含直接匹配的正则表达式) 逆向引用(Backreferences) 在一个正则表达式中，可以使用\\1,\\2等由\\加上一个数字来引用前面出现的分组,表示此处需要匹配前面分组匹配的字符串123&gt;&gt;&gt; p = re.compile(r&quot;(\\b\\w+)\\s+\\1&quot;)&gt;&gt;&gt; p.search(&quot;Paris in the the spring&quot;).group()&#x27;the the&#x27; 括号中需要匹配一个单词，此后\\1表示此处匹配一个和括号相同的单词 Python的扩展正则表达式注意:本节内容是正则表达式的扩展用法，并非标准正则表达式语法 扩展正则表达式符号 符号 作用 (?...) 匹配…中的字符串，但是不再捕捉其中的内容(语义标记) (?P&lt;name&gt;...) 匹配…中的字符串，同时此分组被命名为name 先行断言先行断言(Lookahead Assertion)是一种特殊的判断方法, 有正向和负向两种方式, 具体如下表 断言表示 类型 含义 (?=…) 正向 匹配…中的正则表达式，但是不消耗实际字符串的位置，为真时，才继续匹配 (?!…) 负向 匹配…中的正则表达式，当与实际的字符串不匹配时为真，否则整个正则表达式直接不匹配 扩展阅读 正则表达式扩展阅读 正则表达式扩展阅读 修改字符串Python字符串相关函数 方法 目的 spilt() 分割字符串，在匹配正则表达式的字符串处进行分割 sub() 查找匹配正则表达式的子字符串，并替换为指定的字符串 subn() 和sub()函数效果相同，增加额外的返回数据参数显示最大匹配次数 spilt(string[,maxsplit=0]) string:待匹配字符串 maxspilt:最大分割数 如果正则表达式中含有捕捉分组，则每次捕捉的结果会一同返回，并且正好在两个分割字符串的结果之间 sub(replacement,string[,count=0]) replacement:替换成的字符串 string:待替换字符串 count:最大替换次数 返回替换后的字符串，如果没有匹配，返回原来的字符串 subn() 参数和sub()相同 返回一个有两个元素的元组，第一个元素是替换后的字符串，第二个元素是替换次数 其他说明 sub函数高级用法 在sub函数的relpacement中，也可以使用\\1,\\2等引用正则表达式中的捕捉 如果使用了命名分组，也可以使用\\g&lt;name&gt;来应用，注意&lt;&gt;是必须的 使用\\g&lt;2&gt;与\\2相同，但可以减少歧义 relpacement也可以是一个接受match对象的函数，从而实现更加复杂的功能 高级用法实例代码1234567def hexrepl(match): &#x27;&#x27;&#x27;Return the hex string for a decimal number&#x27;&#x27;&#x27; value = int(match.group()) return hex(value) p = re.compile(r&#x27;\\d+&#x27;)p.sub(hexrepl,&#x27;Call 65490 for printing, 49152 for user code.&#x27;) 正则表达式最佳实践 使用正则表达式还是字符串方法 如果是无差别的文本替换，应该使用字符串的replace()方法 如果是无差别的单一字符替换，应该使用字符串的translate()方法 只有当替换操作是特异性的时候，才应该考虑代价更高的正则表达式方法 match()还是search() match()只从开始匹配，search()匹配任意位置 只有在确实需要从开头开始匹配，才应该使用match()，不要执着于非要只使用match() 正则表达式引擎会使用正则表达式的第一个确定字符进行匹配优化 贪婪匹配还是最小匹配 通常的重复匹配字符串都是贪婪匹配的，即匹配尽可能长的字符串 在各种重复匹配符后加上一个?表示最小匹配，例如+?,*?,??或者{m,n}? 最小匹配匹配尽可能短的字符串 使用re.VERBOSE 复杂的正则表达式的可读性较低，使用测此标记可以增加表达式的可读性 处理字符类中的空白字符，正则表达式中的所有空白都会被忽略 使用#添加注释 经典正则表达式实例 正则表达式 解释 ^[A-Za-z]+$ 由26个字母组成的字符串 ^[A-Za-z0-9]+$ 由26个字母和数字组成的字符串 ^-?\\d+$ 整数形式的字符串 ^[0-9]*[1-9][0-9]*$ 正整数形式的字符串 [\\u4e00-\\u9fa5] 判断是不是中文字符 高级正则表达式实例123456\\s* #Skip leading whitespace(?P&lt;header&gt;[^:]+) #Header name\\s* : #Whitespace, and a colon(?P&lt;value&gt;.*) #The header&#x27;s value -- *? used to #lost the following trailing whitespace\\s*$ #Trailing whitespace to end-of-line","categories":[],"tags":[{"name":"Python","slug":"Python","permalink":"https://lizec.top/tags/Python/"},{"name":"正则表达式","slug":"正则表达式","permalink":"https://lizec.top/tags/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/"}]},{"title":"Git笔记之基础操作","slug":"Git笔记之基础操作","date":"2017-08-07T11:10:36.000Z","updated":"2021-01-28T10:05:40.452Z","comments":true,"path":"2017/08/07/Git笔记之基础操作/","link":"","permalink":"https://lizec.top/2017/08/07/Git%E7%AC%94%E8%AE%B0%E4%B9%8B%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/","excerpt":"","text":"本文介绍GIT的基础知识, 包括GIT的初始化, 基本的指令, 基本原理, 以及GIT标签和GIT别名. 本文从GIT的原理出发, 重点分析了各种情况下的代码撤回操作. Git的基本使用用户初始化12$ git config --global user.name &quot;Your Name&quot;$ git config --global user.email &quot;email@example.com&quot; 上述两条指令用于指定用户名和邮箱, 这些信息会显示在之后的提交信息之中, –global表明上述配置为全局有效. 完成上述配置以后才能使用Git 基础指令 指令 作用 git init 将当前文件夹初始化为一个git库 git add . 将当前目录和子目录下的所有改变提交 git add –all 将所有改变放入暂存区(包括父目录中的更改) git add filename 将指定的文件提交 git commit -m “XXX” 使用-m参数指定本次提交的信息, 该信息保留在提交日志中, 从而用于识别提交的内容 git status 查看当前的状态, Git同时给出下一步可以执行的操作 Git的基本概念Git的几个区域Git中存在三个区域, 每个区域的名称和作用如下 名称 解释 工作区 与当前文件系统同步变化的区域工作区 暂存区 执行add之后后的文件存在的区域 版本库 执行commit操作以后的文件进入版本库 其中暂存区(staging area)也被称为缓冲区(buffer)或者索引(index). Git基本原理Git的三个区域都直接保存文件的快照, 而不是文件的修改. Git通过对比两个快照之间的差异来识别做出了什么更改. 当暂存区和工作区存在差异时提示有文件被修改(或者有新创建的文件), 当版本库和暂存区存在差异时提示有Changes to be committed 工作区的快照始终和当前的文件系统保持同步. 执行add操作后, 相应的文件就会同步到暂存区, 使得工作区和暂存区保持一致. 执行commit操作时, 暂存区的快照同步到版本库之中, 使得版本库和暂存区保持一致. Git存储原理每次执行commit操作后, 版本库都会有一个新的快照, Git会对此快照计算哈希值, 并且使用一个节点表示, 各次提交产生的节点通过链表的形式连接(类似比特币), 从而形成提交历史. 同时Git中还存在一个HEAD指针, 此指针指向当前版本库的状态, 通过修改此指针的指向就可以将版本库恢复到某个历史状态, 例如某个版本库中可能有如下的状态： 1234* f6264d3 &lt;- master &lt;- HEAD* fae731a * 104e8db * 61cfc62 Git的撤销操作所有版本控制系统的本质都是创建一些安全的文件快照, 从而保证你的代码不会受到不可挽回的修改破坏. 因此Git中所有的撤销操作本质上都是基于对三个工作区的修改, 明确这一点有助于对Git撤销的原理的理解. 基本操作 操作类型 操作指令 含义 版本库 git reset --soft &lt;loc&gt; 版本库快照回退到指定的版本, 其他区域快照不变 版本库-&gt;暂存区 git reset --mixed &lt;loc&gt; 版本库和暂存区都回到指定版本, 其他区域不变 版本库-&gt;暂存区-&gt;工作区 git reset --hard &lt;loc&gt; 版本库, 暂存区, 工作区都回到版本 版本库-&gt;工作区 git checkout &lt;loc&gt; &lt;file&gt; 将指定文件的指定版本回退到工作区 其中&lt;loc&gt;表示某一个提交版本, 既可以使用HEAD表达, 也可以使用哈希值表达. &lt;file&gt;表示一个文件的文件名 原理分析假设当前有如下的一组提交历史 1D-C-B-A 即按照时间顺序依次提交了D,C,B,A四个版本, 当前处于A状态. 注意, 这意味着版本库, 暂存区以及工作区都处于A状态. 如果此时使用 1git reset --mixed HEAD~ 则版本库和暂存区回退到B状态, 但是工作区还维持A状态. 此时Git对比暂存区和工作区的区别, 就会将B到A之间的差异视为Changes not staged for commit, 这就如同将之前的提交撤回到了工作区, 从而可以重新组织需要提交的内容. 一些常见的撤回操作对应的指令如下所示: 撤销类型 指令 说明 撤回提交 git reset HEAD~ commit的内容撤回到工作区 撤回暂存 git reset HEAD 暂存区更改丢失,工作区代码不变 清除未跟踪文件 git clean -df 删除新创建的文件和文件夹 撤销工作区更改 git checkout -- filename 工作区更改完全丢失 HEAD是头指针,表示当前版本. HEAD表示上一个版本, 如果是之前的第100个版本, 则可写为HEAD100. 使用git status显示当前状态时, Git会提示上面的大部分指令, 因此这些指令并不需要记忆, 了解实现原理即可. 清理工作区工作区与其他区域相比有一些不同, 在工作区存在新建文件和修改文件的区别. 虽然两种都会使工作区与暂存区产生差异, 但是新建的文件默认都是不跟踪的, 如果不执行add操作, 则Git默认不管理这些文件. 因此撤销工作区的更改, 有两个指令, 分别用于清除新添加的文件和恢复文件的修改. 对于git clean指令, 具有如下的参数 参数 含义 -d 清理文件夹 -f 强制清理, 通常情况下不指定此参数会拒绝执行 -n 模拟执行一次, 显示会删除的文件 -x 删除被.gitignore忽略的文件 对于git checkout, 既可以使用 git checkout -- filename也可以使用git checkout &lt;loc&gt; &lt;file&gt;, 两种格式是等价的. 远程撤销更改1$ git revert HEAD 使用后分支并不会被回退, 而是创建了一个新的提交, 该提交通过反向修改恢复了代码. 由于这本身也是一个提交操作, 因此即使以及有其他人在此分支上切出, 只要没有同时修改回退的内容, 就不会产生任何的影响. reset适用于私有分支,而revert可以适用于公共分支. 分支文件替换git checkout指令可以将一个文件切换到指定的版本, 因此可以通过此指令将一个文件用另外一个分支的文件替换, 例如 1$ git checkout test -- pom.xml 可以将当前分支的pom.xml文件替换为test分支上的相应文件. 参考资料 Git reset checkout commit 命令详解 Git的监视指令查看记录123$ git log$ git log --pretty=oneline$ git reflog 直接使用log指令会展示详细的提交记录, 如果使用online参数, 则只显示提交ID和提交信息. reflog相对于对git所有的操作进行了版本控制, 其中展示了所有git指令的哈希值, 从而可以方便的回滚git操作 查看更新123$ git diff$ git diff filename$ git diff --staged 使用前两种指令将显示工作区中的内容和暂存区中内容的区别(尚未add的版本和最近一次add或commit的版本的区别) 使用第三中指令将显示暂存区中内容和版本库中内容的区别 标签管理添加标签1234$ git tag //显示所有标签$ git tag tagName //给最近一次提交添加标签$ git tag tagName digs //给指定ID的提交添加标签$ git tag -a tagName -m tagMessage digs //给指定ID的提交添加标签和详细信息 操作标签123$ git tag -d tagName //删除指定的标签$ git push origin tagName //推送指定的标签$ git push origin --tags //推送所有的标签 设置别名如果经常使用命令行进行Git操作, 那么执行如下的指令来设置一些简称可能有助于提高指令的输入速度 12345git config --global alias.st statusgit config --global alias.co checkoutgit config --global alias.ci commitgit config --global alias.br branchgit config --global alias.lg &quot;log --color --graph --pretty=format:&#x27;%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)&lt;%an&gt;%Creset&#x27; --abbrev-commit&quot; Win10创建可执行文件使用如下的指令, 将foo.sh添加可执行权限. 1git update-index --chmod=+x foo.sh 如何在Windows上的Git中创建文件执行模式的权限？ 参考资料和扩展阅读 Git教程 GitHub基本使用 Git撤销 git reset soft,hard,mixed之区别深解 有关 Git 中 commit 的原理 理解 及 reset、checkout 命令详解 Learn Git with Bitbucket Cloud Git的原理简介和常用命令 Git工作流","categories":[{"name":"Git笔记","slug":"Git笔记","permalink":"https://lizec.top/categories/Git%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Git","slug":"Git","permalink":"https://lizec.top/tags/Git/"}]},{"title":"统计回归与计量经济学笔记","slug":"统计回归与计量经济学笔记","date":"2017-08-05T03:17:09.000Z","updated":"2020-06-26T14:49:53.657Z","comments":true,"path":"2017/08/05/统计回归与计量经济学笔记/","link":"","permalink":"https://lizec.top/2017/08/05/%E7%BB%9F%E8%AE%A1%E5%9B%9E%E5%BD%92%E4%B8%8E%E8%AE%A1%E9%87%8F%E7%BB%8F%E6%B5%8E%E5%AD%A6%E7%AC%94%E8%AE%B0/","excerpt":"","text":"多元回归参数的含义 表示在其他参数都不变的情况下，这一参数改变一个单位对解释变量的影响 普通最小二乘法 利用一组数据求出回归参数的估计值的最常用方法 普通最小二乘法使得一个特定样本的残差平方和最小 调整的判定系数，可以一定程度抵消一部分因为自由度降低导致R方变大的问题 不应该将此系数最大作为优化目标 是否添加一个变量，应该有理论和逻辑支持，而不是根据调整的判定系数确定 回归分析的一般步骤 查阅文献，建立理论模型 查阅文献是必备的步骤 应该从前人的基础上开始 确定模型，选择解释变量和函数形式 确定解释变量，以及如何测量解释变量 确定函数形式 确定随机误差项的性质 对参数符号做出假定 通过参数符合，可以在后续过程中对模型进行简单的检验 提前决定符号也有助于后续的假设性检验 效果不确定的参数符号可以先不确定，待后续进行进一步的解释 搜集、检查和整理数据 首先需要选择尽可能多的样本数据，从而能尽可能抵消随机误差 对数据要进行一定的检查，如数据是否在合理的范围内， 估计和评价方程 通过软件计算得到方程的参数 通过相关的假设检验方法对参数合理性进行评价 结果报告 虚拟变量 对于某种只能取特定离散值的变量，例如性别，季节等可以采用虚拟变量 以性别为例，可以令X=0表示男，X=1表示女 通常两个对立事件使用一个虚拟变量，从而避免完全多重共线性 古典假设 回归模型是线性的，模型设定无误且含有误差项 误差项均值为0 所有解释变量与误差项都不相关 误差项观测值互不相关 误差项具有同方差（不存在异方差性） 任何一个解释变量都不是其他解释变量的完全线性函数（不存在完全多重共线性） 误差项服从正态分布满足1-5的假设的误差项称为古典误差项，如果还满足7，则称为古典正态误差项 古典假设的常用符号图片，待补充 古典原假设和备择假设 原假设是研究者不希望出现的情况 备选假设是研究者希望出现的情况 对于不同的检验方法，有单侧检验和双侧检验 通过是否拒绝原假设来进行检验 两类错误 第一类错误：拒接了正确的原假设 第二类错误：接受的错误的原假设 判定规则 比较样本统计量与预先设置的临界值 可以通过比较产生两类错误的损失来设置临界值 t检验 通过比较产生两类错误的损失来设置临界值 如果不能确定损失，不妨取5%的显著水平 t值越大，显著性越强 p值 在原假设为真的情况下，t统计值的临界值大于等于样本数据t值的概率 p值是一个概率值，范围在0到1之间 p值越小，越有理由拒绝原假设 t检验的步骤 建立原假设和备选假设 选择一个显著水平，确定临界值 对方程进行回归，得到t估计值 对t估计值和临界值进行比较 确定t估计值的绝对值是否大于临界值 确定t估计值的符号与预先的假设是否一致 t检验的局限性 t检验不能检验理论有效性 一个变量显著不能说明模型一定有效，还是需要理论和逻辑支持 一个变量不显著可以考虑是否不需要添加这个变量 t检验不能检验重要性 t检验不是针对总体的检验 数据量越大，t值越趋向于无穷，进而失去意义 置信区间 通过t检验可以计算一个参数在一定置信水平下的区间范围 可以作为t检验的补充分析 F检验 F检验是对多个参数共同显著性的检验 F检验将原假设的条件带入方程中，比较两个方程的差异程度，从而说明这些参数的效果 对于通常的方程的F检验，就相当于比较回归方程和样本均值函数的差异程度 如果存在相互关联的虚拟变量（如季节），则应该将这些变量视为整体，进行F检验 解释变量的选择 尽量少的选择解释变量 选择变量尽量从理论上获得支持，而不是从统计显著性上获得支持 不应该根据变量的效果设置方程，应该根据理论设置方程，否则容易导致方程只能在当前样本上具有良好效果可以通过考察残差大致的了解遗漏变量可能的形态 不相干变量的判断和控制四个重要原则 理论：变量的含义是否模糊不清，从理论上是否合理 t检验：变量的被估参数在预期下是否显著 调整的判定系数R方：变量加入以后，方程的整体拟合优度是否得到改善 偏误：变量加入方程以后，其他变量的参数是否发生显著改变 对上述原则的分析 如果加入的参数不能满足上述条件，则基本可以断定这个变量是一个无关变量 反之，如果不能同时满足上述条件，那么就应该谨慎的考虑是否添加这个变量 但无论如何，从理论上判断是最有力的，任何统计方式都不能否认理论上证明存在关系的变量 注意： 如果在理论上可以确定一个变量确实应该作为解释变量，即使它不满足上述四个原则，也应该试图解释为什么这个变量不显著，而不是简单删除 设定搜索搜索原则 在选择变量，方程形式或其他类似问题时，尽可能多的依据理论，而不是统计结果 最小化待估方程的数量 在注释或附录中，展示所有待估的备选模型 变量选择的一个原则 应该选择哪些变量应该放入方程 不能因为一个变量没有拒绝的理由，就将其放入方程，所有放入的变量本身应该由充分的理由 如果长时间对数据进行严刑拷打，数据也会屈打成招 数据挖掘 通过组合不同的参数来寻找最优的方程，然后装作从未进行过测试，几乎可以肯定是最差的方案 可以适当的组合参数，但是一定要使用另外的数据集进行测试 敏感性分析 通过将多个可能的回归方程进行分析，从而推论不同的形式不显著影响结果的分析 其他高级检验方法 拉姆齐回归设定偏误检验（Ramsey RESET test） 可用于帮助研究者对是否存在设定偏误进行判断 Akaike信息准则 Bayesian信息准则 多重线性和时间序列的相关问题","categories":[{"name":"经济学","slug":"经济学","permalink":"https://lizec.top/categories/%E7%BB%8F%E6%B5%8E%E5%AD%A6/"}],"tags":[]},{"title":"Edwin笔记","slug":"Edwin笔记","date":"2017-08-04T08:10:25.000Z","updated":"2020-06-26T14:50:56.869Z","comments":true,"path":"2017/08/04/Edwin笔记/","link":"","permalink":"https://lizec.top/2017/08/04/Edwin%E7%AC%94%E8%AE%B0/","excerpt":"","text":"重设堆栈大小程序启动后可能存在堆栈空间分配失败的问题，此时可在快捷方式后–heap参数，即 1--heap 512 基本操作启动和关闭123C-x c 关闭Edwin并回到交互命令行C-x z 挂起Edwin，此时Edwin不再响应输入，命令行变为可输入C-x C-c 退出所有界面 表达式求值12C-x C-e 求光标左侧表达式的值M-z 求光标所在处的全部表达式的值 基本操作12345C-i 自动缩进光标M-/ 自动补全M-u 光标选定的词变大写M-; 光标所在行末尾添加注释 C-o 光标处插入回车 文本编辑1234C-@ 开始记录C-w 剪切M-w 复制C-y 粘贴 文件操作12345678C-x C-s 保存 C-x C-w 另存为 C-x C-f 打开文件 C-x C-r 只读方式打开 C-x C-v 读入另外一个文件代替当前buffer的文件 C-x s 保存所有 C-x i 将文件的内容插入 M-x revert-buffer 恢复到原始状态 窗口123456C-x 0 关掉当前窗口 C-x 1 关掉其他窗口 C-x o 切换窗口 C-x 2 水平两分窗口 C-x 3 垂直两分窗口 C-x 5 2 新frame 一种友好的使用方式 创建一个新的窗口 在新窗口中打开其他需要阅读的文件 在新窗口中执行其中的相关函数，返回值会在原窗口中显示 删除1234567M-d 后一词 C-d 后一字 M-del 前一词 M-k 到句尾 M-&quot; 前面的所有空白 M-z 删到指定字母处 C-k 删除到行尾 交互环境操作交互环境 即命令行下，读取循环(REPL)过程中的操作 基本操作1234C-u 退出当前REPLC-g 回到第一层REPLC-x 杀死正在运行的求值过程，并回到当前REPLC-b 暂停当前求值过程，并进入断点REPL 启动或恢复Edwin执行以下两条命令中的任意一条即可启动或者恢复Edwin 12(edit)(edwin) 文件操作1234(load &quot;e:\\\\c.scm&quot;) 载入文件(cd &quot;e:\\\\temp&quot;) 切换工作目录(disk-save &quot;image&quot;) 保存当前执行环境(disk-restore &quot;image&quot;) 恢复执行环境 Emacs其他高级操作跳转123456789前/后 单位 C-f/b 字 M-f/b 词 C-a/e 行内(移动到开头或结尾)M-a/e 句(一个表达式) M-&lt;/&gt; 文档 C-p/n 行间 M-&#123;/&#125; 段落 C-x ]/[ 页 编辑12345678910M-u 后面单词变为大写 M-l 后面单词变为小写 M-c 后面单词的首字母变大写 M-/ 补全 C-j 从当前位置分成两行,相当于RET + tab M-( 插入() C-q tab 插入tab C-q C-m 插入^M M-; 插入注释 C-o 回车 撤销1234C-/ C-x u C-_ C-z 重做1234C-g M-x undo C-g C-/ C-g C-z C-g C-_ 其他注意事项 Lisp不区分大小写，但是操作系统区分大小写，因此对于外部的路径，文件名等，都应该使用小写，以免解释器无法正确识别路径","categories":[],"tags":[]},{"title":"批处理使用笔记","slug":"批处理使用笔记","date":"2017-08-04T07:56:20.000Z","updated":"2017-10-17T11:11:01.203Z","comments":true,"path":"2017/08/04/批处理使用笔记/","link":"","permalink":"https://lizec.top/2017/08/04/%E6%89%B9%E5%A4%84%E7%90%86%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/","excerpt":"","text":"Echo的换行与空行 使用 echo. 来输出一行空白行 使用 echo|set /p = message 来不换行的输出message","categories":[],"tags":[{"name":"批处理","slug":"批处理","permalink":"https://lizec.top/tags/%E6%89%B9%E5%A4%84%E7%90%86/"}]}],"categories":[{"name":"Go语言笔记","slug":"Go语言笔记","permalink":"https://lizec.top/categories/Go%E8%AF%AD%E8%A8%80%E7%AC%94%E8%AE%B0/"},{"name":"Python笔记","slug":"Python笔记","permalink":"https://lizec.top/categories/Python%E7%AC%94%E8%AE%B0/"},{"name":"MySQL笔记","slug":"MySQL笔记","permalink":"https://lizec.top/categories/MySQL%E7%AC%94%E8%AE%B0/"},{"name":"深入理解JVM","slug":"深入理解JVM","permalink":"https://lizec.top/categories/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JVM/"},{"name":"CSAPP笔记","slug":"CSAPP笔记","permalink":"https://lizec.top/categories/CSAPP%E7%AC%94%E8%AE%B0/"},{"name":"机器学习","slug":"机器学习","permalink":"https://lizec.top/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"PyTorch笔记","slug":"PyTorch笔记","permalink":"https://lizec.top/categories/PyTorch%E7%AC%94%E8%AE%B0/"},{"name":"Scala笔记","slug":"Scala笔记","permalink":"https://lizec.top/categories/Scala%E7%AC%94%E8%AE%B0/"},{"name":"数学","slug":"数学","permalink":"https://lizec.top/categories/%E6%95%B0%E5%AD%A6/"},{"name":"经济学","slug":"经济学","permalink":"https://lizec.top/categories/%E7%BB%8F%E6%B5%8E%E5%AD%A6/"},{"name":"Spring","slug":"Spring","permalink":"https://lizec.top/categories/Spring/"},{"name":"公告","slug":"公告","permalink":"https://lizec.top/categories/%E5%85%AC%E5%91%8A/"},{"name":"Java特性","slug":"Java特性","permalink":"https://lizec.top/categories/Java%E7%89%B9%E6%80%A7/"},{"name":"学术写作","slug":"学术写作","permalink":"https://lizec.top/categories/%E5%AD%A6%E6%9C%AF%E5%86%99%E4%BD%9C/"},{"name":"JDK笔记","slug":"JDK笔记","permalink":"https://lizec.top/categories/JDK%E7%AC%94%E8%AE%B0/"},{"name":"Maven笔记","slug":"Maven笔记","permalink":"https://lizec.top/categories/Maven%E7%AC%94%E8%AE%B0/"},{"name":"Spring笔记","slug":"Spring笔记","permalink":"https://lizec.top/categories/Spring%E7%AC%94%E8%AE%B0/"},{"name":"JavaWeb","slug":"JavaWeb","permalink":"https://lizec.top/categories/JavaWeb/"},{"name":"Git笔记","slug":"Git笔记","permalink":"https://lizec.top/categories/Git%E7%AC%94%E8%AE%B0/"},{"name":"Java单元测试","slug":"Java单元测试","permalink":"https://lizec.top/categories/Java%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95/"},{"name":"Java多线程","slug":"Java多线程","permalink":"https://lizec.top/categories/Java%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"大数据分析案例","slug":"大数据分析案例","permalink":"https://lizec.top/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%A1%88%E4%BE%8B/"},{"name":"论文阅读","slug":"论文阅读","permalink":"https://lizec.top/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"},{"name":"大数据","slug":"大数据","permalink":"https://lizec.top/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"LaTeX","slug":"LaTeX","permalink":"https://lizec.top/categories/LaTeX/"},{"name":"计算机核心课程","slug":"计算机核心课程","permalink":"https://lizec.top/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%A0%B8%E5%BF%83%E8%AF%BE%E7%A8%8B/"},{"name":"Android","slug":"Android","permalink":"https://lizec.top/categories/Android/"}],"tags":[{"name":"Go","slug":"Go","permalink":"https://lizec.top/tags/Go/"},{"name":"Python","slug":"Python","permalink":"https://lizec.top/tags/Python/"},{"name":"数据库","slug":"数据库","permalink":"https://lizec.top/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"MySQL","slug":"MySQL","permalink":"https://lizec.top/tags/MySQL/"},{"name":"Java","slug":"Java","permalink":"https://lizec.top/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"https://lizec.top/tags/JVM/"},{"name":"数据结构","slug":"数据结构","permalink":"https://lizec.top/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"多线程","slug":"多线程","permalink":"https://lizec.top/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"机器学习","slug":"机器学习","permalink":"https://lizec.top/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"docker","slug":"docker","permalink":"https://lizec.top/tags/docker/"},{"name":"PyTorch","slug":"PyTorch","permalink":"https://lizec.top/tags/PyTorch/"},{"name":"Excel","slug":"Excel","permalink":"https://lizec.top/tags/Excel/"},{"name":"自然语言处理","slug":"自然语言处理","permalink":"https://lizec.top/tags/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/"},{"name":"环境配置","slug":"环境配置","permalink":"https://lizec.top/tags/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"},{"name":"Scala","slug":"Scala","permalink":"https://lizec.top/tags/Scala/"},{"name":"线性代数","slug":"线性代数","permalink":"https://lizec.top/tags/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/"},{"name":"概率论","slug":"概率论","permalink":"https://lizec.top/tags/%E6%A6%82%E7%8E%87%E8%AE%BA/"},{"name":"经济学","slug":"经济学","permalink":"https://lizec.top/tags/%E7%BB%8F%E6%B5%8E%E5%AD%A6/"},{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"https://lizec.top/tags/RabbitMQ/"},{"name":"Spring","slug":"Spring","permalink":"https://lizec.top/tags/Spring/"},{"name":"HTTP","slug":"HTTP","permalink":"https://lizec.top/tags/HTTP/"},{"name":"公告","slug":"公告","permalink":"https://lizec.top/tags/%E5%85%AC%E5%91%8A/"},{"name":"LaTeX","slug":"LaTeX","permalink":"https://lizec.top/tags/LaTeX/"},{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://lizec.top/tags/SpringCloud/"},{"name":"Maven","slug":"Maven","permalink":"https://lizec.top/tags/Maven/"},{"name":"Shell","slug":"Shell","permalink":"https://lizec.top/tags/Shell/"},{"name":"论文阅读","slug":"论文阅读","permalink":"https://lizec.top/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"},{"name":"CMake","slug":"CMake","permalink":"https://lizec.top/tags/CMake/"},{"name":"动态链接","slug":"动态链接","permalink":"https://lizec.top/tags/%E5%8A%A8%E6%80%81%E9%93%BE%E6%8E%A5/"},{"name":"Git","slug":"Git","permalink":"https://lizec.top/tags/Git/"},{"name":"单元测试","slug":"单元测试","permalink":"https://lizec.top/tags/%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95/"},{"name":"StreamAPI","slug":"StreamAPI","permalink":"https://lizec.top/tags/StreamAPI/"},{"name":"函数式编程","slug":"函数式编程","permalink":"https://lizec.top/tags/%E5%87%BD%E6%95%B0%E5%BC%8F%E7%BC%96%E7%A8%8B/"},{"name":"大数据","slug":"大数据","permalink":"https://lizec.top/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"SQL","slug":"SQL","permalink":"https://lizec.top/tags/SQL/"},{"name":"Javascript","slug":"Javascript","permalink":"https://lizec.top/tags/Javascript/"},{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://lizec.top/tags/Ubuntu/"},{"name":"Matlab","slug":"Matlab","permalink":"https://lizec.top/tags/Matlab/"},{"name":"计算机网络","slug":"计算机网络","permalink":"https://lizec.top/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"name":"编译原理","slug":"编译原理","permalink":"https://lizec.top/tags/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/"},{"name":"人工智能","slug":"人工智能","permalink":"https://lizec.top/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"},{"name":"CSharp","slug":"CSharp","permalink":"https://lizec.top/tags/CSharp/"},{"name":"汇编语言","slug":"汇编语言","permalink":"https://lizec.top/tags/%E6%B1%87%E7%BC%96%E8%AF%AD%E8%A8%80/"},{"name":"设计模式","slug":"设计模式","permalink":"https://lizec.top/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"Android","slug":"Android","permalink":"https://lizec.top/tags/Android/"},{"name":"操作系统","slug":"操作系统","permalink":"https://lizec.top/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"C","slug":"C","permalink":"https://lizec.top/tags/C/"},{"name":"程序设计","slug":"程序设计","permalink":"https://lizec.top/tags/%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1/"},{"name":"Makefile","slug":"Makefile","permalink":"https://lizec.top/tags/Makefile/"},{"name":"正则表达式","slug":"正则表达式","permalink":"https://lizec.top/tags/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/"},{"name":"批处理","slug":"批处理","permalink":"https://lizec.top/tags/%E6%89%B9%E5%A4%84%E7%90%86/"}]}